#!/usr/bin/env python3
"""
μ²΄ν¬ν¬μΈνΈ νμΌ κµ¬μ΅° λ¶„μ„ μ¤ν¬λ¦½νΈ
μ‹¤μ  Mobile VLA λ¨λΈμ κµ¬μ΅°λ¥Ό νμ•…ν•κ³  κ°„λ‹¨ν• μ¶”λ΅  ν…μ¤νΈ
"""

import torch
import torch.nn as nn
import numpy as np
import time
import os
import sys
from typing import Dict, Any, Optional, List

def analyze_checkpoint(checkpoint_path: str):
    """μ²΄ν¬ν¬μΈνΈ νμΌ κµ¬μ΅° λ¶„μ„"""
    print("=" * 60)
    print("π” μ²΄ν¬ν¬μΈνΈ νμΌ κµ¬μ΅° λ¶„μ„")
    print("=" * 60)
    
    if not os.path.exists(checkpoint_path):
        print(f"β μ²΄ν¬ν¬μΈνΈ νμΌμ„ μ°Ύμ„ μ μ—†μµλ‹λ‹¤: {checkpoint_path}")
        return None
    
    print(f"π“¦ μ²΄ν¬ν¬μΈνΈ κ²½λ΅: {checkpoint_path}")
    
    try:
        # μ²΄ν¬ν¬μΈνΈ λ΅λ“
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        
        print(f"π“ μ²΄ν¬ν¬μΈνΈ ν‚¤: {list(checkpoint.keys())}")
        
        if 'model_state_dict' in checkpoint:
            state_dict = checkpoint['model_state_dict']
            print(f"π“‹ λ¨λΈ μƒνƒ λ”•μ…”λ„λ¦¬ ν‚¤ μ: {len(state_dict)}")
            
            # μ£Όμ” ν‚¤λ“¤ λ¶„μ„
            print("\nπ”‘ μ£Όμ” λ¨λΈ κµ¬μ„± μ”μ†:")
            key_groups = {}
            for key in state_dict.keys():
                prefix = key.split('.')[0]
                if prefix not in key_groups:
                    key_groups[prefix] = []
                key_groups[prefix].append(key)
            
            for prefix, keys in key_groups.items():
                print(f"   {prefix}: {len(keys)}κ° νλΌλ―Έν„°")
                if len(keys) <= 5:  # 5κ° μ΄ν•λ©΄ λ¨λ‘ μ¶λ ¥
                    for key in keys:
                        shape = state_dict[key].shape if hasattr(state_dict[key], 'shape') else 'N/A'
                        print(f"     - {key}: {shape}")
                else:  # 5κ° μ΄κ³Όλ©΄ μ²μ 3κ°λ§ μ¶λ ¥
                    for key in keys[:3]:
                        shape = state_dict[key].shape if hasattr(state_dict[key], 'shape') else 'N/A'
                        print(f"     - {key}: {shape}")
                    print(f"     ... λ° {len(keys)-3}κ° λ”")
            
            # λ¨λΈ μ •λ³΄
            if 'epoch' in checkpoint:
                print(f"\nπ“ ν›λ ¨ μ—ν¬ν¬: {checkpoint['epoch']}")
            if 'loss' in checkpoint:
                print(f"π“‰ μ†μ‹¤κ°’: {checkpoint['loss']:.4f}")
            if 'val_mae' in checkpoint:
                print(f"π“ κ²€μ¦ MAE: {checkpoint['val_mae']:.4f}")
            
            return state_dict, checkpoint
        else:
            print("β μ²΄ν¬ν¬μΈνΈμ— model_state_dictκ°€ μ—†μµλ‹λ‹¤.")
            return None, checkpoint
            
    except Exception as e:
        print(f"β μ²΄ν¬ν¬μΈνΈ λ¶„μ„ μ‹¤ν¨: {e}")
        import traceback
        traceback.print_exc()
        return None, None

def create_simple_inference_model(state_dict: Dict[str, torch.Tensor]):
    """μ²΄ν¬ν¬μΈνΈ λ¶„μ„μ„ λ°”νƒ•μΌλ΅ κ°„λ‹¨ν• μ¶”λ΅  λ¨λΈ μƒμ„±"""
    print("\n" + "=" * 40)
    print("π§  κ°„λ‹¨ν• μ¶”λ΅  λ¨λΈ μƒμ„±")
    print("=" * 40)
    
    # μ•΅μ… μμΈ΅ λ¶€λ¶„λ§ μ¶”μ¶
    action_keys = [k for k in state_dict.keys() if 'actions' in k]
    
    if not action_keys:
        print("β μ•΅μ… μμΈ΅ κ΄€λ ¨ νλΌλ―Έν„°λ¥Ό μ°Ύμ„ μ μ—†μµλ‹λ‹¤.")
        return None
    
    print(f"π― μ•΅μ… μμΈ΅ νλΌλ―Έν„°: {len(action_keys)}κ°")
    for key in action_keys:
        shape = state_dict[key].shape
        print(f"   - {key}: {shape}")
    
    # κ°„λ‹¨ν• μ•΅μ… μμΈ΅ λ¨λΈ μƒμ„±
    class SimpleActionModel(nn.Module):
        def __init__(self, input_dim: int = 2048, hidden_dim: int = 1024, output_dim: int = 2):
            super().__init__()
            self.mlp = nn.Sequential(
                nn.Linear(input_dim, hidden_dim),
                nn.ReLU(),
                nn.Dropout(0.1),
                nn.Linear(hidden_dim, hidden_dim // 2),
                nn.ReLU(),
                nn.Dropout(0.1),
                nn.Linear(hidden_dim // 2, output_dim)
            )
        
        def forward(self, x):
            return self.mlp(x)
    
    # λ¨λΈ μƒμ„±
    model = SimpleActionModel()
    
    print(f"π“ μƒμ„±λ λ¨λΈ νλΌλ―Έν„° μ: {sum(p.numel() for p in model.parameters()):,}")
    
    return model

def test_simple_inference(model: nn.Module, device: torch.device):
    """κ°„λ‹¨ν• μ¶”λ΅  ν…μ¤νΈ"""
    print("\n" + "=" * 40)
    print("π”¬ κ°„λ‹¨ν• μ¶”λ΅  μ„±λ¥ ν…μ¤νΈ")
    print("=" * 40)
    
    model = model.to(device)
    model.eval()
    
    # ν…μ¤νΈ λ°μ΄ν„° μƒμ„±
    batch_size = 1
    input_dim = 2048
    test_input = torch.randn(batch_size, input_dim).to(device)
    
    print(f"π“¥ μ…λ ¥ ν¬κΈ°: {test_input.shape}")
    
    # μ›λ°μ—…
    print("π”¥ μ›λ°μ—… μ¤‘...")
    with torch.no_grad():
        for _ in range(10):
            _ = model(test_input)
    
    # μ¶”λ΅  μ‹κ°„ μΈ΅μ •
    num_runs = 100
    times = []
    
    print(f"β±οΈ {num_runs}ν μ¶”λ΅  μ‹κ°„ μΈ΅μ • μ¤‘...")
    with torch.no_grad():
        for i in range(num_runs):
            start_time = time.time()
            output = model(test_input)
            end_time = time.time()
            times.append(end_time - start_time)
    
    # κ²°κ³Ό λ¶„μ„
    avg_time = np.mean(times)
    min_time = np.min(times)
    max_time = np.max(times)
    fps = 1.0 / avg_time
    
    print(f"π“¤ μ¶λ ¥ ν¬κΈ°: {output.shape}")
    print(f"β±οΈ ν‰κ·  μ¶”λ΅  μ‹κ°„: {avg_time*1000:.2f} ms")
    print(f"β΅ μµμ† μ¶”λ΅  μ‹κ°„: {min_time*1000:.2f} ms")
    print(f"π μµλ€ μ¶”λ΅  μ‹κ°„: {max_time*1000:.2f} ms")
    print(f"π€ μ¶”λ΅  FPS: {fps:.1f}")
    
    # μ•΅μ… κ°’ μ¶λ ¥
    print(f"π― μμΈ΅ μ•΅μ…: {output.cpu().numpy()}")
    
    return True

def main():
    """λ©”μΈ ν•¨μ"""
    print("π€ Mobile VLA μ²΄ν¬ν¬μΈνΈ λ¶„μ„ λ° κ°„λ‹¨ν• μ¶”λ΅  ν…μ¤νΈ")
    print("=" * 60)
    
    # μ²΄ν¬ν¬μΈνΈ κ²½λ΅ μ„¤μ •
    checkpoint_paths = [
        "./Robo+/Mobile_VLA/simple_clip_lstm_model/best_simple_clip_lstm_model.pth",
        "./mobile-vla-omniwheel/best_simple_lstm_model.pth"
    ]
    
    checkpoint_path = None
    for path in checkpoint_paths:
        if os.path.exists(path):
            checkpoint_path = path
            break
    
    if checkpoint_path is None:
        print("β μ‚¬μ© κ°€λ¥ν• μ²΄ν¬ν¬μΈνΈ νμΌμ„ μ°Ύμ„ μ μ—†μµλ‹λ‹¤.")
        return False
    
    # μ²΄ν¬ν¬μΈνΈ λ¶„μ„
    state_dict, checkpoint = analyze_checkpoint(checkpoint_path)
    
    if state_dict is None:
        print("β μ²΄ν¬ν¬μΈνΈ λ¶„μ„ μ‹¤ν¨")
        return False
    
    # κ°„λ‹¨ν• μ¶”λ΅  λ¨λΈ μƒμ„±
    model = create_simple_inference_model(state_dict)
    
    if model is None:
        print("β μ¶”λ΅  λ¨λΈ μƒμ„± μ‹¤ν¨")
        return False
    
    # μ¶”λ΅  ν…μ¤νΈ
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    inference_ok = test_simple_inference(model, device)
    
    # κ²°κ³Ό μ”μ•½
    print("\n" + "=" * 60)
    print("π“ ν…μ¤νΈ κ²°κ³Ό μ”μ•½")
    print("=" * 60)
    
    results = {
        "μ²΄ν¬ν¬μΈνΈ λ¶„μ„": "β…" if state_dict is not None else "β",
        "λ¨λΈ μƒμ„±": "β…" if model is not None else "β",
        "μ¶”λ΅  ν…μ¤νΈ": "β…" if inference_ok else "β"
    }
    
    for test_name, result in results.items():
        print(f"{test_name}: {result}")
    
    all_passed = all([state_dict is not None, model is not None, inference_ok])
    
    if all_passed:
        print("\nπ‰ μ²΄ν¬ν¬μΈνΈ λ¶„μ„ λ° μ¶”λ΅  ν…μ¤νΈ μ„±κ³µ!")
        print("\nπ“‹ λ‹¤μ λ‹¨κ³„:")
        print("   1. μ‹¤μ  λ¨λΈ κµ¬μ΅° μ¬κµ¬μ„±")
        print("   2. μ΄λ―Έμ§€ μ „μ²λ¦¬ νμ΄ν”„λΌμΈ κµ¬μ„±")
        print("   3. μ‹¤μ‹κ°„ μ¶”λ΅  μ‹μ¤ν… μ™„μ„±")
    else:
        print("\nβ οΈ μΌλ¶€ ν…μ¤νΈ μ‹¤ν¨. μ²΄ν¬ν¬μΈνΈ νμΌμ„ ν™•μΈν•΄μ£Όμ„Έμ”.")
    
    return all_passed

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
