#!/usr/bin/env python3
"""
ë¡œì»¬ Mobile VLA ì¶”ë¡  í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
Jetson í™˜ê²½ì—ì„œ CUDA ì§€ì› PyTorchë¥¼ ì‚¬ìš©í•œ ì¶”ë¡  í…ŒìŠ¤íŠ¸
"""

import torch
import torch.nn as nn
import numpy as np
import cv2
from PIL import Image
import time
import os
import sys
from typing import Optional, Tuple

# CUDA í…ŒìŠ¤íŠ¸
def test_cuda():
    """CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í…ŒìŠ¤íŠ¸"""
    print("=" * 60)
    print("ğŸš€ CUDA í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    print(f"ğŸ“¦ PyTorch ë²„ì „: {torch.__version__}")
    print(f"ğŸ”§ CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"ğŸ“± CUDA ë””ë°”ì´ìŠ¤ ìˆ˜: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            device_name = torch.cuda.get_device_name(i)
            device_capability = torch.cuda.get_device_capability(i)
            print(f"   ë””ë°”ì´ìŠ¤ {i}: {device_name} (Compute Capability: {device_capability})")
        
        # ë©”ëª¨ë¦¬ ì •ë³´
        memory_total = torch.cuda.get_device_properties(0).total_memory
        print(f"ğŸ’¾ ì´ ë©”ëª¨ë¦¬: {memory_total / 1024**2:.1f} MB")
        
        # ê°„ë‹¨í•œ CUDA ì—°ì‚° í…ŒìŠ¤íŠ¸
        try:
            print("\nğŸ§ª CUDA ì—°ì‚° í…ŒìŠ¤íŠ¸...")
            x = torch.randn(1000, 1000).cuda()
            y = torch.randn(1000, 1000).cuda()
            z = torch.mm(x, y)
            print("âœ… CUDA ì—°ì‚° ì„±ê³µ!")
            print(f"   ê²°ê³¼ í…ì„œ í¬ê¸°: {z.shape}")
            print(f"   ê²°ê³¼ í…ì„œ ë””ë°”ì´ìŠ¤: {z.device}")
            return True
        except Exception as e:
            print(f"âŒ CUDA ì—°ì‚° ì‹¤íŒ¨: {e}")
            return False
    else:
        print("âŒ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False

class SimpleMobileVLAModel(nn.Module):
    """ê°„ë‹¨í•œ Mobile VLA ëª¨ë¸ (í…ŒìŠ¤íŠ¸ìš©)"""
    
    def __init__(self, input_dim: int = 2048, hidden_dim: int = 1024, action_dim: int = 2):
        super().__init__()
        
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.action_dim = action_dim
        
        # ê°„ë‹¨í•œ MLP êµ¬ì¡°
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, action_dim)
        )
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """ìˆœì „íŒŒ"""
        return self.encoder(x)

def test_model_inference():
    """ëª¨ë¸ ì¶”ë¡  í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 60)
    print("ğŸ§  ëª¨ë¸ ì¶”ë¡  í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ”§ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
    
    # ëª¨ë¸ ìƒì„±
    model = SimpleMobileVLAModel().to(device)
    model.eval()
    
    print(f"ğŸ“Š ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in model.parameters()):,}")
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    batch_size = 1
    input_dim = 2048
    test_input = torch.randn(batch_size, input_dim).to(device)
    
    print(f"ğŸ“¥ ì…ë ¥ í¬ê¸°: {test_input.shape}")
    
    # ì¶”ë¡  ì‹œê°„ ì¸¡ì •
    num_runs = 100
    times = []
    
    # ì›Œë°ì—…
    with torch.no_grad():
        for _ in range(10):
            _ = model(test_input)
    
    # ì‹¤ì œ ì¸¡ì •
    with torch.no_grad():
        for i in range(num_runs):
            start_time = time.time()
            output = model(test_input)
            end_time = time.time()
            times.append(end_time - start_time)
    
    avg_time = np.mean(times)
    fps = 1.0 / avg_time
    
    print(f"ğŸ“¤ ì¶œë ¥ í¬ê¸°: {output.shape}")
    print(f"â±ï¸ í‰ê·  ì¶”ë¡  ì‹œê°„: {avg_time*1000:.2f} ms")
    print(f"ğŸš€ ì¶”ë¡  FPS: {fps:.1f}")
    
    return True

def test_image_processing():
    """ì´ë¯¸ì§€ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 60)
    print("ğŸ“· ì´ë¯¸ì§€ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
    test_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
    
    print(f"ğŸ“ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°: {test_image.shape}")
    
    # OpenCV ì²˜ë¦¬
    start_time = time.time()
    resized = cv2.resize(test_image, (224, 224))
    normalized = resized.astype(np.float32) / 255.0
    cv_time = time.time() - start_time
    
    print(f"ğŸ”§ OpenCV ì²˜ë¦¬ ì‹œê°„: {cv_time*1000:.2f} ms")
    print(f"ğŸ“ ë¦¬ì‚¬ì´ì¦ˆëœ ì´ë¯¸ì§€ í¬ê¸°: {resized.shape}")
    
    # PIL ì²˜ë¦¬
    pil_image = Image.fromarray(test_image)
    start_time = time.time()
    pil_resized = pil_image.resize((224, 224))
    pil_time = time.time() - start_time
    
    print(f"ğŸ–¼ï¸ PIL ì²˜ë¦¬ ì‹œê°„: {pil_time*1000:.2f} ms")
    
    return True

def test_transformers():
    """Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 60)
    print("ğŸ¤— Transformers í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    try:
        from transformers import AutoProcessor, AutoModel
        print("âœ… Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ê°€ëŠ¥")
        
        # ê°„ë‹¨í•œ ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸ (ì‹¤ì œ ë‹¤ìš´ë¡œë“œëŠ” í•˜ì§€ ì•ŠìŒ)
        print("ğŸ”„ ëª¨ë¸ ì •ë³´ í™•ì¸ ì¤‘...")
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡
        available_models = [
            "microsoft/kosmos-2-patch14-224",
            "openai/clip-vit-base-patch32",
            "minium/mobile-vla"
        ]
        
        print("ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸:")
        for model_name in available_models:
            print(f"   - {model_name}")
        
        return True
        
    except ImportError as e:
        print(f"âŒ Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ: {e}")
        return False
    except Exception as e:
        print(f"âŒ Transformers í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ Mobile VLA ë¡œì»¬ ì¶”ë¡  í™˜ê²½ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # 1. CUDA í…ŒìŠ¤íŠ¸
    cuda_ok = test_cuda()
    
    # 2. ëª¨ë¸ ì¶”ë¡  í…ŒìŠ¤íŠ¸
    model_ok = test_model_inference()
    
    # 3. ì´ë¯¸ì§€ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
    image_ok = test_image_processing()
    
    # 4. Transformers í…ŒìŠ¤íŠ¸
    transformers_ok = test_transformers()
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 60)
    
    results = {
        "CUDA ì§€ì›": "âœ…" if cuda_ok else "âŒ",
        "ëª¨ë¸ ì¶”ë¡ ": "âœ…" if model_ok else "âŒ",
        "ì´ë¯¸ì§€ ì²˜ë¦¬": "âœ…" if image_ok else "âŒ",
        "Transformers": "âœ…" if transformers_ok else "âŒ"
    }
    
    for test_name, result in results.items():
        print(f"{test_name}: {result}")
    
    all_passed = all([cuda_ok, model_ok, image_ok, transformers_ok])
    
    if all_passed:
        print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! ë¡œì»¬ ì¶”ë¡  í™˜ê²½ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("\nğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:")
        print("   1. ì‹¤ì œ Mobile VLA ëª¨ë¸ ë¡œë“œ")
        print("   2. ì¹´ë©”ë¼ ì…ë ¥ ì²˜ë¦¬")
        print("   3. ì‹¤ì‹œê°„ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ êµ¬ì„±")
    else:
        print("\nâš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. í™˜ê²½ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    
    return all_passed

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
