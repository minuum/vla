#!/usr/bin/env python3
"""
κ°„λ‹¨ν• ν†µν•© λ¨λΈ λ΅λ” ν…μ¤νΈ
"""

import torch
import os
import sys

def test_cuda():
    """CUDA ν…μ¤νΈ"""
    print("π”§ CUDA ν™κ²½ ν…μ¤νΈ")
    print(f"   - PyTorch: {torch.__version__}")
    print(f"   - CUDA Available: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"   - CUDA Device: {torch.cuda.get_device_name(0)}")
        print(f"   - CUDA Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    print()

def test_checkpoint():
    """μ²΄ν¬ν¬μΈνΈ νμΌ ν…μ¤νΈ"""
    print("π“¦ μ²΄ν¬ν¬μΈνΈ νμΌ ν…μ¤νΈ")
    
    checkpoint_paths = [
        "./mobile-vla-omniwheel/best_simple_lstm_model.pth",
        "./vla/mobile-vla-omniwheel/best_simple_lstm_model.pth",
        "/workspace/vla/mobile-vla-omniwheel/best_simple_lstm_model.pth"
    ]
    
    for path in checkpoint_paths:
        if os.path.exists(path):
            size_mb = os.path.getsize(path) / (1024 * 1024)
            print(f"β… μ²΄ν¬ν¬μΈνΈ λ°κ²¬: {path} ({size_mb:.1f} MB)")
            
            try:
                # μ²΄ν¬ν¬μΈνΈ λ΅λ“ ν…μ¤νΈ
                checkpoint = torch.load(path, map_location='cpu')
                print(f"   - λ΅λ“ μ„±κ³µ: {type(checkpoint)}")
                
                if isinstance(checkpoint, dict):
                    print(f"   - ν‚¤: {list(checkpoint.keys())}")
                    if 'model_state_dict' in checkpoint:
                        print(f"   - λ¨λΈ μƒνƒ λ”•μ…”λ„λ¦¬ ν¬ν•¨")
                    if 'epoch' in checkpoint:
                        print(f"   - μ—ν¬ν¬: {checkpoint['epoch']}")
                    if 'val_mae' in checkpoint:
                        print(f"   - κ²€μ¦ MAE: {checkpoint['val_mae']}")
                else:
                    print(f"   - μ§μ ‘ λ¨λΈ μƒνƒ λ”•μ…”λ„λ¦¬")
                
                return path
            except Exception as e:
                print(f"   - λ΅λ“ μ‹¤ν¨: {e}")
        else:
            print(f"β μ²΄ν¬ν¬μΈνΈ μ—†μ: {path}")
    
    print("β μ‚¬μ© κ°€λ¥ν• μ²΄ν¬ν¬μΈνΈκ°€ μ—†μµλ‹λ‹¤.")
    return None

def test_model_creation():
    """λ¨λΈ μƒμ„± ν…μ¤νΈ"""
    print("π—οΈ λ¨λΈ μƒμ„± ν…μ¤νΈ")
    
    try:
        # κ°„λ‹¨ν• λ¨λΈ κµ¬μ΅° μ •μ
        class SimpleTestModel(torch.nn.Module):
            def __init__(self):
                super().__init__()
                self.linear = torch.nn.Linear(2048, 2)
            
            def forward(self, x):
                return self.linear(x)
        
        model = SimpleTestModel()
        print(f"β… λ¨λΈ μƒμ„± μ„±κ³µ: {type(model)}")
        print(f"   - νλΌλ―Έν„° μ: {sum(p.numel() for p in model.parameters()):,}")
        
        # ν…μ¤νΈ μ¶”λ΅ 
        x = torch.randn(1, 2048)
        with torch.no_grad():
            output = model(x)
        print(f"   - μ¶”λ΅  μ„±κ³µ: {output.shape}")
        
        return True
    except Exception as e:
        print(f"β λ¨λΈ μƒμ„± μ‹¤ν¨: {e}")
        return False

def main():
    """λ©”μΈ ν•¨μ"""
    print("π§ κ°„λ‹¨ν• ν†µν•© λ¨λΈ λ΅λ” ν…μ¤νΈ")
    print("=" * 50)
    
    test_cuda()
    checkpoint_path = test_checkpoint()
    model_success = test_model_creation()
    
    print("\nπ“ ν…μ¤νΈ κ²°κ³Ό μ”μ•½:")
    print(f"   - CUDA μ‚¬μ© κ°€λ¥: {torch.cuda.is_available()}")
    print(f"   - μ²΄ν¬ν¬μΈνΈ λ°κ²¬: {checkpoint_path is not None}")
    print(f"   - λ¨λΈ μƒμ„± μ„±κ³µ: {model_success}")
    
    if checkpoint_path and model_success:
        print("\nβ… λ¨λ“  ν…μ¤νΈ ν†µκ³Ό! ν†µν•© λ¨λΈ λ΅λ” μ‚¬μ© κ°€λ¥")
    else:
        print("\nβ μΌλ¶€ ν…μ¤νΈ μ‹¤ν¨. λ¬Έμ  ν•΄κ²° ν•„μ”")

if __name__ == "__main__":
    main()
