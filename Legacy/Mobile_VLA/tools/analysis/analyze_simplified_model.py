#!/usr/bin/env python3
"""
Simplified RoboVLMs ëª¨ë¸ êµ¬ì¡° ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
"""

import torch
import torch.nn as nn
from transformers import AutoProcessor, CLIPVisionModel, CLIPTextModel
import json

def analyze_simplified_model():
    """Simplified RoboVLMs ëª¨ë¸ êµ¬ì¡° ë¶„ì„"""
    
    checkpoint_path = "models/experimental/simplified_robovlms_best.pth"
    
    print("ğŸ” Simplified RoboVLMs ëª¨ë¸ êµ¬ì¡° ë¶„ì„")
    print("="*60)
    
    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    checkpoint = torch.load(checkpoint_path, map_location='cpu')
    state_dict = checkpoint.get('model_state_dict', {})
    
    print(f"âœ… ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì™„ë£Œ")
    print(f"   MAE: {checkpoint.get('val_mae', 'N/A')}")
    print(f"   ì—í¬í¬: {checkpoint.get('epoch', 'N/A')}")
    print(f"   ëª¨ë¸ í‚¤ ìˆ˜: {len(state_dict)}")
    print()
    
    # ëª¨ë¸ êµ¬ì¡° ë¶„ì„
    print("ğŸ“Š ëª¨ë¸ êµ¬ì¡° ë¶„ì„")
    print("-"*40)
    
    # CLIP ê´€ë ¨ í‚¤ë“¤
    clip_vision_keys = [key for key in state_dict.keys() if 'clip_vision' in key.lower()]
    clip_text_keys = [key for key in state_dict.keys() if 'clip_text' in key.lower()]
    
    # ê¸°íƒ€ ì»´í¬ë„ŒíŠ¸ë“¤
    fusion_keys = [key for key in state_dict.keys() if 'fusion' in key.lower()]
    action_keys = [key for key in state_dict.keys() if 'action' in key.lower()]
    lstm_keys = [key for key in state_dict.keys() if 'lstm' in key.lower()]
    rnn_keys = [key for key in state_dict.keys() if 'rnn' in key.lower()]
    
    print(f"CLIP Vision í‚¤: {len(clip_vision_keys)}ê°œ")
    print(f"CLIP Text í‚¤: {len(clip_text_keys)}ê°œ")
    print(f"Fusion í‚¤: {len(fusion_keys)}ê°œ")
    print(f"Action í‚¤: {len(action_keys)}ê°œ")
    print(f"LSTM í‚¤: {len(lstm_keys)}ê°œ")
    print(f"RNN í‚¤: {len(rnn_keys)}ê°œ")
    print()
    
    # ì£¼ìš” ì»´í¬ë„ŒíŠ¸ ìƒì„¸ ë¶„ì„
    print("ğŸ”§ ì£¼ìš” ì»´í¬ë„ŒíŠ¸ ìƒì„¸ ë¶„ì„")
    print("-"*40)
    
    # CLIP Vision ë¶„ì„
    if clip_vision_keys:
        print("ğŸ‘ï¸ CLIP Vision ëª¨ë¸:")
        for key in clip_vision_keys[:5]:  # ì²˜ìŒ 5ê°œë§Œ
            shape = state_dict[key].shape
            print(f"   {key}: {shape}")
        if len(clip_vision_keys) > 5:
            print(f"   ... (ì´ {len(clip_vision_keys)}ê°œ)")
        print()
    
    # CLIP Text ë¶„ì„
    if clip_text_keys:
        print("ğŸ’¬ CLIP Text ëª¨ë¸:")
        for key in clip_text_keys[:5]:  # ì²˜ìŒ 5ê°œë§Œ
            shape = state_dict[key].shape
            print(f"   {key}: {shape}")
        if len(clip_text_keys) > 5:
            print(f"   ... (ì´ {len(clip_text_keys)}ê°œ)")
        print()
    
    # Action Head ë¶„ì„
    if action_keys:
        print("ğŸ¯ Action Head:")
        for key in action_keys:
            shape = state_dict[key].shape
            print(f"   {key}: {shape}")
        print()
    
    # RNN/LSTM ë¶„ì„
    if rnn_keys or lstm_keys:
        print("ğŸ”„ RNN/LSTM:")
        for key in rnn_keys + lstm_keys:
            shape = state_dict[key].shape
            print(f"   {key}: {shape}")
        print()
    
    # ëª¨ë¸ êµ¬ì¡° ì¶”ì •
    print("ğŸ—ï¸ ì¶”ì •ëœ ëª¨ë¸ êµ¬ì¡°")
    print("-"*40)
    
    # CLIP Vision ì°¨ì› ì¶”ì •
    if clip_vision_keys:
        for key in clip_vision_keys:
            if 'embeddings' in key and 'patch_embedding' in key:
                vision_dim = state_dict[key].shape[-1]
                print(f"CLIP Vision ì°¨ì›: {vision_dim}")
                break
    
    # CLIP Text ì°¨ì› ì¶”ì •
    if clip_text_keys:
        for key in clip_text_keys:
            if 'embeddings' in key and 'token_embedding' in key:
                text_dim = state_dict[key].shape[-1]
                print(f"CLIP Text ì°¨ì›: {text_dim}")
                break
    
    # Action ì°¨ì› ì¶”ì •
    if action_keys:
        for key in action_keys:
            if 'weight' in key and 'action' in key:
                if len(state_dict[key].shape) == 2:
                    action_dim = state_dict[key].shape[0]
                    print(f"Action ì°¨ì›: {action_dim}")
                    break
    
    # RNN/LSTM ì°¨ì› ì¶”ì •
    if rnn_keys or lstm_keys:
        for key in rnn_keys + lstm_keys:
            if 'weight_ih_l0' in key:
                hidden_dim = state_dict[key].shape[0] // 4  # LSTMì˜ ê²½ìš° 4ê°œ ê²Œì´íŠ¸
                print(f"RNN/LSTM Hidden ì°¨ì›: {hidden_dim}")
                break
    
    print()
    
    # ëª¨ë¸ êµ¬ì¡° ì¬êµ¬ì„±
    print("ğŸ”„ Simplified ëª¨ë¸ êµ¬ì¡° ì¬êµ¬ì„±")
    print("-"*40)
    
    class SimplifiedRoboVLMsModel(nn.Module):
        def __init__(self, processor):
            super().__init__()
            self.processor = processor
            
            # CLIP ëª¨ë¸ë“¤
            self.clip_vision = CLIPVisionModel.from_pretrained("openai/clip-vit-base-patch32")
            self.clip_text = CLIPTextModel.from_pretrained("openai/clip-vit-base-patch32")
            
            # Fusion ë ˆì´ì–´
            self.fusion = nn.Sequential(
                nn.Linear(768 + 512, 512),  # CLIP Vision + Text
                nn.ReLU(),
                nn.Dropout(0.2)
            )
            
            # Action Head
            self.action_head = nn.Sequential(
                nn.Linear(512, 256),
                nn.ReLU(),
                nn.Dropout(0.2),
                nn.Linear(256, 2)  # 2D action
            )
        
        def forward(self, images, text):
            # CLIP Vision
            vision_outputs = self.clip_vision(images)
            vision_features = vision_outputs.pooler_output  # [batch, 768]
            
            # CLIP Text
            text_outputs = self.clip_text(text)
            text_features = text_outputs.pooler_output  # [batch, 512]
            
            # Feature Fusion
            combined = torch.cat([vision_features, text_features], dim=1)
            fused = self.fusion(combined)
            
            # Action Prediction
            actions = self.action_head(fused)
            
            return actions
    
    print("âœ… Simplified ëª¨ë¸ êµ¬ì¡° ì¬êµ¬ì„± ì™„ë£Œ")
    print("   - CLIP Vision + Text ê¸°ë°˜")
    print("   - Feature Fusion")
    print("   - Simple Action Head")
    print("   - 2D Action ì¶œë ¥")
    
    return checkpoint

if __name__ == "__main__":
    analyze_simplified_model()
