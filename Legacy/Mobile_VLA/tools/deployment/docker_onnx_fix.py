#!/usr/bin/env python3
"""
Docker ì»¨í…Œì´ë„ˆ ONNX Runtime ì„¤ì¹˜ ë¬¸ì œ í•´ê²°
"""

import subprocess
import sys
import os

def run_docker_command(command: str) -> bool:
    """Docker ëª…ë ¹ì–´ ì‹¤í–‰"""
    try:
        print(f"ğŸ”§ Running: {command}")
        result = subprocess.run(command, shell=True, capture_output=True, text=True)
        
        if result.returncode == 0:
            print(f"âœ… Success: {result.stdout}")
            return True
        else:
            print(f"âŒ Error: {result.stderr}")
            return False
            
    except Exception as e:
        print(f"âŒ Exception: {e}")
        return False

def install_onnx_runtime():
    """ONNX Runtime ì„¤ì¹˜ ì‹œë„"""
    print("ğŸš€ Installing ONNX Runtime in Docker container")
    print("=" * 60)
    
    # ë°©ë²• 1: CPU ë²„ì „ ì„¤ì¹˜
    print("\n1ï¸âƒ£ Trying ONNX Runtime CPU version...")
    success1 = run_docker_command(
        'docker exec -it mobile_vla_robovlms_final bash -c "pip install onnxruntime"'
    )
    
    if not success1:
        # ë°©ë²• 2: GPU ë²„ì „ ì„¤ì¹˜
        print("\n2ï¸âƒ£ Trying ONNX Runtime GPU version...")
        success2 = run_docker_command(
            'docker exec -it mobile_vla_robovlms_final bash -c "pip install onnxruntime-gpu"'
        )
        
        if not success2:
            # ë°©ë²• 3: íŠ¹ì • ë²„ì „ ì„¤ì¹˜
            print("\n3ï¸âƒ£ Trying specific ONNX Runtime version...")
            success3 = run_docker_command(
                'docker exec -it mobile_vla_robovlms_final bash -c "pip install onnxruntime==1.17.0"'
            )
            
            if not success3:
                # ë°©ë²• 4: conda ì‚¬ìš©
                print("\n4ï¸âƒ£ Trying conda installation...")
                success4 = run_docker_command(
                    'docker exec -it mobile_vla_robovlms_final bash -c "conda install -c conda-forge onnxruntime"'
                )
                
                if not success4:
                    print("\nâŒ All installation methods failed!")
                    return False
    
    print("\nâœ… ONNX Runtime installation completed!")
    return True

def test_onnx_runtime():
    """ONNX Runtime í…ŒìŠ¤íŠ¸"""
    print("\nğŸ§ª Testing ONNX Runtime...")
    print("=" * 60)
    
    test_script = '''
import onnxruntime as ort
print("âœ… ONNX Runtime imported successfully!")
print(f"Version: {ort.__version__}")
print(f"Available providers: {ort.get_available_providers()}")
'''
    
    success = run_docker_command(
        f'docker exec -it mobile_vla_robovlms_final bash -c "python3 -c \'{test_script}\'"'
    )
    
    return success

def check_docker_status():
    """Docker ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸"""
    print("ğŸ” Checking Docker container status...")
    print("=" * 60)
    
    # ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸
    run_docker_command("docker ps | grep mobile_vla_robovlms_final")
    
    # ì»¨í…Œì´ë„ˆ ë‚´ë¶€ í™•ì¸
    run_docker_command(
        'docker exec -it mobile_vla_robovlms_final bash -c "ls -la /workspace/vla/"'
    )

def create_alternative_solution():
    """ëŒ€ì•ˆ í•´ê²°ì±… ìƒì„±"""
    print("\nğŸ’¡ Creating alternative solution...")
    print("=" * 60)
    
    # PyTorchë§Œ ì‚¬ìš©í•˜ëŠ” ë²„ì „ ìƒì„±
    alternative_code = '''
# ONNX Runtime ì—†ì´ PyTorchë§Œ ì‚¬ìš©í•˜ëŠ” ë²„ì „
import torch
import torch.nn as nn

class SimplePyTorchModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.feature_extractor = nn.Sequential(
            nn.Linear(3*224*224, 512),
            nn.ReLU(),
            nn.Linear(512, 256),
            nn.ReLU()
        )
        self.action_predictor = nn.Linear(256, 3)
    
    def forward(self, x):
        x = x.view(x.size(0), -1)
        features = self.feature_extractor(x)
        actions = self.action_predictor(features)
        return actions

# ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
model = SimplePyTorchModel()
print("âœ… Simple PyTorch model created successfully!")
'''
    
    # íŒŒì¼ë¡œ ì €ì¥
    with open("Robo+/Mobile_VLA/simple_pytorch_model.py", "w") as f:
        f.write(alternative_code)
    
    print("âœ… Alternative PyTorch-only solution created!")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ Docker ONNX Runtime Fix Script")
    print("ğŸ¯ Solving ONNX Runtime installation issues")
    
    # 1. Docker ìƒíƒœ í™•ì¸
    check_docker_status()
    
    # 2. ONNX Runtime ì„¤ì¹˜ ì‹œë„
    if install_onnx_runtime():
        # 3. ì„¤ì¹˜ í…ŒìŠ¤íŠ¸
        if test_onnx_runtime():
            print("\nğŸ‰ ONNX Runtime installation and test successful!")
        else:
            print("\nâš ï¸ Installation succeeded but test failed!")
            create_alternative_solution()
    else:
        print("\nâŒ ONNX Runtime installation failed!")
        create_alternative_solution()
    
    print("\nğŸ“‹ Summary:")
    print("- Docker container: mobile_vla_robovlms_final")
    print("- Issue: ONNX Runtime not installed")
    print("- Solution: Multiple installation methods attempted")
    print("- Alternative: PyTorch-only model created")

if __name__ == "__main__":
    main()
