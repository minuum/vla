# π“ RoboVLMs λ…Όλ¬Έ Appendix C: IMPLEMENTATION DETAILS μ„Ήμ… λ¶„μ„

> **μΈμ©**: λ…Όλ¬Έ "APPENDIX C: IMPLEMENTATION DETAILS" μ„Ήμ…

## π― **1. κµ¬ν„ μ„Έλ¶€μ‚¬ν•­ κ°μ”**

### **κµ¬ν„ μ„Έλ¶€μ‚¬ν•­μ μ¤‘μ”μ„±**
> **μΈμ©**: "With different formulations, the best setting of hyperparameters like batch size, weight decay, and learning rate could be varied." (λ…Όλ¬Έ Appendix C μ„Ήμ…)

#### **ν•μ΄νΌνλΌλ―Έν„°μ μ¤‘μ”μ„±**
- **λ‹¤μ–‘μ„±**: λ‹¤μ–‘ν• κ³µμ‹ν™”μ— λ”°λ¥Έ μµμ  ν•μ΄νΌνλΌλ―Έν„° μ„¤μ •μ μ°¨μ΄
- **μ„±λ¥ μν–¥**: λ°°μΉ ν¬κΈ°, κ°€μ¤‘μΉ κ°μ‡ , ν•™μµλ¥  λ“±μ μ„±λ¥μ— λ―ΈμΉλ” μν–¥
- **μµμ ν™”**: κ° μ‹¤ν—μ— μµμ ν™”λ ν•μ΄νΌνλΌλ―Έν„° μ„¤μ •μ ν•„μ”μ„±

## β™οΈ **2. ν•μ΄νΌνλΌλ―Έν„° λ° ν›λ ¨ μ„Έλ¶€μ‚¬ν•­**

### **ν•μ΄νΌνλΌλ―Έν„° μ„¤μ • μ „λµ**
> **μΈμ©**: "Although OpenVLA suggests utilizing the same hyper-param as in the VLM pretrain phase, we find that a varied setting of the hyper-param could improve the performance." (λ…Όλ¬Έ Appendix C μ„Ήμ…)

#### **OpenVLAμ™€μ μ°¨μ΄μ **
- **OpenVLA μ μ•**: VLM μ‚¬μ „ ν›λ ¨ λ‹¨κ³„μ™€ λ™μΌν• ν•μ΄νΌνλΌλ―Έν„° μ‚¬μ©
- **RoboVLMs λ°κ²¬**: λ‹¤μ–‘ν• ν•μ΄νΌνλΌλ―Έν„° μ„¤μ •μ΄ μ„±λ¥ ν–¥μƒμ— λ„μ›€
- **μµμ ν™”**: κ° μ‹¤ν—μ— λ§λ” μµμ ν™”λ ν•μ΄νΌνλΌλ―Έν„° μ„¤μ •

### **ν•μ΄νΌνλΌλ―Έν„° μ„ νƒ λ°©λ²•**
> **μΈμ©**: "The hyperparameters for fine-tuning VLAs are mainly derived from the VLMs training setups, for example, we select the weight decay from [0, 1e β’ 1], and the learning rate as one of [1e β’ 4, 2e β’ 5, 1e β’ 5]. We conduct a grid search over and select the one with the best performance." (λ…Όλ¬Έ Appendix C μ„Ήμ…)

#### **κ°€μ¤‘μΉ κ°μ‡  (Weight Decay)**
- **λ²”μ„**: [0, 1e-1]
- **μ„ νƒ**: κ·Έλ¦¬λ“ μ„μΉλ¥Ό ν†µν• μµμ κ°’ μ„ νƒ
- **λ©μ **: κ³Όμ ν•© λ°©μ§€ λ° μΌλ°ν™” μ„±λ¥ ν–¥μƒ

#### **ν•™μµλ¥  (Learning Rate)**
- **ν›„λ³΄κ°’**: [1e-4, 2e-5, 1e-5]
- **μ„ νƒ λ°©λ²•**: κ·Έλ¦¬λ“ μ„μΉλ¥Ό ν†µν• μµμ κ°’ μ„ νƒ
- **μμ**: λ¨λΈ μλ ΄ μ†λ„ λ° μµμΆ… μ„±λ¥μ— μν–¥

#### **κ·Έλ¦¬λ“ μ„μΉ (Grid Search)**
- **λ°©λ²•**: λ¨λ“  μ΅°ν•©μ— λ€ν• μ²΄κ³„μ  νƒμƒ‰
- **λ©μ **: μµμ  μ„±λ¥μ„ λ‹¬μ„±ν•λ” ν•μ΄νΌνλΌλ―Έν„° μ΅°ν•© λ°κ²¬
- **ν¨μ¨μ„±**: μ²΄κ³„μ  νƒμƒ‰μ„ ν†µν• ν¨μ¨μ  μµμ ν™”

### **κΈ°λ³Έ μ„¤μ •**
> **μΈμ©**: "We set the global batch size as 128 and the warmup ratio is 0.25 epoch (5K steps for OpenX Embodiment pre-train)." (λ…Όλ¬Έ Appendix C μ„Ήμ…)

#### **λ°°μΉ ν¬κΈ° (Batch Size)**
- **μ„¤μ •κ°’**: 128
- **μμ**: λ©”λ¨λ¦¬ ν¨μ¨μ„±κ³Ό ν›λ ¨ μ•μ •μ„±μ κ· ν•
- **μΌκ΄€μ„±**: λ¨λ“  μ‹¤ν—μ—μ„ λ™μΌν• λ°°μΉ ν¬κΈ° μ‚¬μ©

#### **μ›λ°μ—… (Warmup)**
- **μΌλ° μ„¤μ •**: 0.25 epoch
- **OpenX Embodiment**: 5K steps
- **λ©μ **: ν›λ ¨ μ΄κΈ° μ•μ •μ„± ν™•λ³΄

### **ν•λ“μ›¨μ–΄ μ„¤μ •**
> **μΈμ©**: "All models included in this paper are trained on a cluster of 4 x 8 A100 GPUs." (λ…Όλ¬Έ Appendix C μ„Ήμ…)

#### **GPU ν΄λ¬μ¤ν„°**
- **κµ¬μ„±**: 4 x 8 A100 GPUs
- **μ΄ GPU μ**: 32κ° A100 GPU
- **μμ**: λ€κ·λ¨ λ¨λΈ ν›λ ¨μ„ μ„ν• μ¶©λ¶„ν• μ»΄ν“¨ν… μμ›

## π“ **3. Table VI: ν•μ΄νΌνλΌλ―Έν„° μ„¤μ •**

### **μ‹¤ν—λ³„ ν•μ΄νΌνλΌλ―Έν„° μ„¤μ •**

#### **CALVIN Perform (Tab. II)**
- **Backbone**: All
- **Window Size**: 16
- **Chunk Size**: 10
- **Input View**: Side+Wrist
- **Batch Size**: 128
- **Warmup**: 0.25 Ep
- **Scheduler**: Constant
- **Optimizer**: AdamW
- **Learning Rate**: 1e-4
- **Total Epochs/Iters**: 5 Ep

#### **SimplerEnv Perform (Fig. 14)**
- **Backbone**: All
- **Window Size**: 16
- **Chunk Size**: 10
- **Input View**: Side
- **Batch Size**: 128
- **Warmup**: 5K Iters
- **Scheduler**: Constant
- **Optimizer**: AdamW
- **Learning Rate**: 1e-4
- **Total Epochs/Iters**: 50K Iters

#### **CALVIN VL Pre-train (Fig. 6)**
- **Backbone**: All
- **Window Size**: 16
- **Chunk Size**: 10
- **Input View**: Side+Wrist
- **Batch Size**: 128
- **Warmup**: 0.25 Ep
- **Scheduler**: Constant
- **Optimizer**: AdamW
- **Learning Rate**: 1e-4
- **Total Epochs/Iters**: 5 Ep

#### **Real Perform (Fig. 7)**
- **Backbone**: All
- **Window Size**: 8
- **Chunk Size**: 10
- **Input View**: Side+Wrist
- **Batch Size**: 128
- **Warmup**: 0.25 Ep
- **Scheduler**: Constant
- **Optimizer**: AdamW
- **Learning Rate**: 1e-4
- **Total Epochs/Iters**: 5 Ep

#### **VLA Structure (Tab.III)**
**LLaVA λ°±λ³Έ:**
- **Backbone**: LLaVA
- **Window Size**: 8
- **Chunk Size**: 10
- **Input View**: Side+Wrist
- **Batch Size**: 128
- **Warmup**: 0.25 Ep
- **Scheduler**: Constant
- **Optimizer**: AdamW
- **Learning Rate**: 2e-5
- **Total Epochs/Iters**: 5 Ep

**κΈ°νƒ€ λ°±λ³Έ:**
- **Backbone**: Else
- **Window Size**: 16
- **Chunk Size**: 10
- **Input View**: Side+Wrist
- **Batch Size**: 128
- **Warmup**: 0.25 Ep
- **Scheduler**: Constant
- **Optimizer**: AdamW
- **Learning Rate**: 1e-4
- **Total Epochs/Iters**: 5 Ep

#### **CALVIN Generalization (Fig. 9)**
- **Backbone**: All
- **Window Size**: 16
- **Chunk Size**: 10
- **Input View**: Side+Wrist
- **Batch Size**: 128
- **Warmup**: 0.25 Ep
- **Scheduler**: Constant
- **Optimizer**: AdamW
- **Learning Rate**: 1e-4
- **Total Epochs/Iters**: 5 Ep

#### **CALVIN Data Efficiency (Tab. IV)**
- **Backbone**: All
- **Window Size**: 16
- **Chunk Size**: 10
- **Input View**: Side+Wrist
- **Batch Size**: 128
- **Warmup**: 0.25 Ep
- **Scheduler**: Constant
- **Optimizer**: AdamW
- **Learning Rate**: 1e-4
- **Total Epochs/Iters**: 5 Ep

#### **CALVIN Backbone (Tab V)**
- **Backbone**: All
- **Window Size**: 8
- **Chunk Size**: 10
- **Input View**: Side
- **Batch Size**: 128
- **Warmup**: 0.25 Ep
- **Scheduler**: Constant
- **Optimizer**: AdamW
- **Learning Rate**: 2e-5
- **Total Epochs/Iters**: 5 Ep

#### **Simpler Training Recipe (Fig 10)**
- **Backbone**: All
- **Window Size**: 16
- **Chunk Size**: 10
- **Input View**: Side
- **Batch Size**: 128
- **Warmup**: 5K Iters
- **Scheduler**: Constant
- **Optimizer**: AdamW
- **Learning Rate**: 2e-5
- **Total Epochs/Iters**: 50K Iters

#### **CALVIN few-shot (Fig. 11)**
- **Backbone**: All
- **Window Size**: 16
- **Chunk Size**: 10
- **Input View**: Side
- **Batch Size**: 128
- **Warmup**: 0 Iter
- **Scheduler**: Constant
- **Optimizer**: AdamW
- **Learning Rate**: 2e-5
- **Total Epochs/Iters**: 5K Iters

## π” **4. μ²΄ν¬ν¬μΈνΈ μ„ νƒ**

### **μ²΄ν¬ν¬μΈνΈ μ„ νƒμ μ–΄λ ¤μ›€**
> **μΈμ©**: "We find out that, normally, the performance of robot policies does not fully depend on offline evaluation metrics [16], such as the validation loss, due to the compounding error in long-horizon rollouts." (λ…Όλ¬Έ Appendix C μ„Ήμ…)

#### **μ¤ν”„λΌμΈ ν‰κ°€ μ§€ν‘μ ν•κ³„**
- **κ²€μ¦ μ†μ‹¤**: Validation lossμ ν•κ³„
- **λ³µν•© μ¤μ°¨**: Long-horizon rolloutsμ—μ„μ λ³µν•© μ¤μ°¨
- **μ„±λ¥ λ¶μΌμΉ**: μ¤ν”„λΌμΈ μ§€ν‘μ™€ μ‹¤μ  μ„±λ¥μ λ¶μΌμΉ

#### **μ²΄ν¬ν¬μΈνΈ μ„ νƒμ λ„μ „κ³Όμ **
- **λ³µμ΅μ„±**: λ΅λ΄‡ μ •μ±…μ λ³µμ΅ν• μ„±λ¥ νΉμ„±
- **μ¥κΈ° κ¶¤μ **: Long-horizon rolloutsμ λ³µν•© μ¤μ°¨
- **ν‰κ°€ μ–΄λ ¤μ›€**: μµμ  μ²΄ν¬ν¬μΈνΈ μ„ νƒμ μ–΄λ ¤μ›€

### **κ³µμ •ν• λΉ„κµλ¥Ό μ„ν• μ„¤μ •**
> **μΈμ©**: "Therefore, it is challenging to select the best checkpoint during training. For fair comparisons, we train all VLAs for a fixed number of epochs or timesteps." (λ…Όλ¬Έ Appendix C μ„Ήμ…)

#### **κ³ μ • ν›λ ¨ μ„¤μ •**
- **λ©μ **: κ³µμ •ν• λΉ„κµλ¥Ό μ„ν• μΌκ΄€λ μ„¤μ •
- **λ°©λ²•**: κ³ μ •λ μ—ν¬ν¬ μ λλ” νƒ€μ„μ¤ν… μ
- **μμ**: μ‹¤ν— κ°„ κ³µμ •ν• λΉ„κµ κ°€λ¥

### **μ‹¤ν—λ³„ ν›λ ¨ μ„¤μ •**

#### **CALVIN μ‹¤ν—**
> **μΈμ©**: "Concretely, on CALVIN, we train each model for 5 epochs with a batch size of 128 truncated trajectories and report the performance of the final model." (λ…Όλ¬Έ Appendix C μ„Ήμ…)

- **ν›λ ¨ μ—ν¬ν¬**: 5 epochs
- **λ°°μΉ ν¬κΈ°**: 128 truncated trajectories
- **μ„±λ¥ λ³΄κ³ **: μµμΆ… λ¨λΈμ μ„±λ¥
- **μΌκ΄€μ„±**: λ¨λ“  λ¨λΈμ— λ™μΌν• μ„¤μ • μ μ©

#### **SimplerEnv μ‹¤ν—**
> **μΈμ©**: "For SimplerEnv, we train the model for 100K iterations with a batch size of 512 truncated trajectories and report the best-performing model with a 10K-iteration training interval." (λ…Όλ¬Έ Appendix C μ„Ήμ…)

- **ν›λ ¨ λ°λ³µ**: 100K iterations
- **λ°°μΉ ν¬κΈ°**: 512 truncated trajectories
- **μ„±λ¥ λ³΄κ³ **: 10K-iteration κ°„κ²©μΌλ΅ μµκ³  μ„±λ¥ λ¨λΈ
- **μµμ ν™”**: μµμ  μ„±λ¥ λ¨λΈ μ„ νƒ

#### **μ‹¤μ  ν™κ²½ μ‹¤ν—**
> **μΈμ©**: "In real-world experiments, we train the model for 5 epochs with a batch size of 512 truncated trajectories, and we only report the performance of the last model." (λ…Όλ¬Έ Appendix C μ„Ήμ…)

- **ν›λ ¨ μ—ν¬ν¬**: 5 epochs
- **λ°°μΉ ν¬κΈ°**: 512 truncated trajectories
- **μ„±λ¥ λ³΄κ³ **: λ§μ§€λ§‰ λ¨λΈμ μ„±λ¥λ§ λ³΄κ³ 
- **μ‹¤μ©μ„±**: μ‹¤μ  ν™κ²½μ—μ„μ μ‹¤μ©μ  μ ‘κ·Ό

## π“ **5. ν•μ΄νΌνλΌλ―Έν„° λ¶„μ„**

### **κ³µν†µ μ„¤μ •**
- **Optimizer**: AdamW (λ¨λ“  μ‹¤ν—)
- **Scheduler**: Constant (λ¨λ“  μ‹¤ν—)
- **Batch Size**: 128 (λ€λ¶€λ¶„ μ‹¤ν—)

### **μ‹¤ν—λ³„ μ°¨μ΄μ **

#### **Window Size**
- **CALVIN**: 16 (λ€λ¶€λ¶„), 8 (μΌλ¶€)
- **SimplerEnv**: 16
- **Real**: 8
- **μμ**: μ‹¤ν— λ©μ μ— λ”°λ¥Έ μµμ  μλ„μ° ν¬κΈ°

#### **Input View**
- **Side+Wrist**: CALVIN, Real μ‹¤ν—
- **Side**: SimplerEnv, Backbone μ‹¤ν—
- **μμ**: μ‹¤ν— ν™κ²½μ— λ”°λ¥Έ μµμ  μ…λ ¥ λ·°

#### **Learning Rate**
- **1e-4**: CALVIN, SimplerEnv μ‹¤ν—
- **2e-5**: LLaVA, Backbone, Training Recipe, Few-shot μ‹¤ν—
- **μμ**: λ¨λΈ νΉμ„±μ— λ”°λ¥Έ μµμ  ν•™μµλ¥ 

#### **Warmup**
- **0.25 Ep**: λ€λ¶€λ¶„ μ‹¤ν—
- **5K Iters**: SimplerEnv, Training Recipe
- **0 Iter**: Few-shot μ‹¤ν—
- **μμ**: μ‹¤ν— νΉμ„±μ— λ”°λ¥Έ μµμ  μ›λ°μ—…

## π― **6. κµ¬ν„ μ„Έλ¶€μ‚¬ν•­μ μμ**

### **μ¬ν„μ„± (Reproducibility)**
- **μƒμ„Έ μ„¤μ •**: λ¨λ“  ν•μ΄νΌνλΌλ―Έν„°μ λ…ν™•ν• μ μ‹
- **μΌκ΄€μ„±**: μ‹¤ν— κ°„ μΌκ΄€λ μ„¤μ •
- **κ²€μ¦ κ°€λ¥**: λ‹¤λ¥Έ μ—°κµ¬μλ“¤μ μ¬ν„ κ°€λ¥

### **μµμ ν™” (Optimization)**
- **κ·Έλ¦¬λ“ μ„μΉ**: μ²΄κ³„μ μΈ ν•μ΄νΌνλΌλ―Έν„° μµμ ν™”
- **μ‹¤ν—λ³„ μµμ ν™”**: κ° μ‹¤ν—μ— μµμ ν™”λ μ„¤μ •
- **μ„±λ¥ ν–¥μƒ**: μµμ ν™”λ¥Ό ν†µν• μ„±λ¥ ν–¥μƒ

### **κ³µμ •μ„± (Fairness)**
- **μΌκ΄€λ μ„¤μ •**: κ³µμ •ν• λΉ„κµλ¥Ό μ„ν• μΌκ΄€λ μ„¤μ •
- **κ³ μ • ν›λ ¨**: κ³ μ •λ ν›λ ¨ μ„¤μ •
- **κ°κ΄€μ  ν‰κ°€**: κ°κ΄€μ μΈ μ„±λ¥ ν‰κ°€

## π€ **7. κ²°λ΅ **

### **κµ¬ν„ μ„Έλ¶€μ‚¬ν•­μ ν•µμ‹¬**
1. **μµμ ν™”**: κ° μ‹¤ν—μ— μµμ ν™”λ ν•μ΄νΌνλΌλ―Έν„° μ„¤μ •
2. **μΌκ΄€μ„±**: μ‹¤ν— κ°„ μΌκ΄€λ μ„¤μ •μΌλ΅ κ³µμ •ν• λΉ„κµ
3. **μ¬ν„μ„±**: μƒμ„Έν• μ„¤μ • μ μ‹λ΅ μ¬ν„ κ°€λ¥ν• μ‹¤ν—

### **μ—°κµ¬μ μμ**
1. **μ²΄κ³„μ  μ ‘κ·Ό**: μ²΄κ³„μ μΈ ν•μ΄νΌνλΌλ―Έν„° μµμ ν™”
2. **κ³µμ •ν• λΉ„κµ**: μΌκ΄€λ μ„¤μ •μ„ ν†µν• κ³µμ •ν• λΉ„κµ
3. **μ¬ν„ κ°€λ¥μ„±**: μƒμ„Έν• κµ¬ν„ μ„Έλ¶€μ‚¬ν•­ μ μ‹

### **λ―Έλ μ—°κµ¬ λ°©ν–¥**
1. **μλ™ν™”**: μλ™ν™”λ ν•μ΄νΌνλΌλ―Έν„° μµμ ν™”
2. **ν¨μ¨μ„±**: λ” ν¨μ¨μ μΈ ν›λ ¨ λ°©λ²•λ΅ 
3. **μΌλ°ν™”**: λ‹¤μ–‘ν• λ„λ©”μΈμ— μ μ© κ°€λ¥ν• μ„¤μ •

---

*λ¶„μ„ μ‘μ„±μΌ: 2024λ…„ 12μ›”*  
*μ›λ³Έ λ…Όλ¬Έ: "Towards Generalist Robot Policies: What Matters in Building Vision-Language-Action Models"*
