# 📊 ABCD 분할 (ABCD Split) 분석

> **인용**: 논문 Table II의 ABCD 분할 훈련 결과

## 🎯 **ABCD 분할 개요**

### **ABCD 분할의 정의**
ABCD 분할은 CALVIN 벤치마크에서 로봇 VLA 모델의 일반화 능력을 평가하기 위해 설계된 데이터셋 구성 방식입니다.

### **분할 구성**
- **A**: 훈련 데이터에 포함된 작업과 동일한 작업을 포함하되, 새로운 환경이나 조건에서 수행되는 테스트 데이터
- **B**: 훈련 데이터에 포함되지 않은 새로운 작업을 포함하는 테스트 데이터
- **C**: 훈련 데이터에 포함된 작업과 동일한 작업이지만, 새로운 도구나 객체를 사용하는 테스트 데이터
- **D**: 훈련 데이터에 포함되지 않은 새로운 작업과 새로운 도구나 객체를 사용하는 테스트 데이터

## 📈 **ABCD 분할에서의 성능 결과**

### **Table II: ABCD 분할 훈련 결과**

| Method | VLA? | Train | 1 | 2 | 3 | 4 | 5 | Avg. Len. |
|--------|------|-------|---|---|---|---|---|-----------|
| MCIL | ✗ | ABCD | 0.373 | 0.027 | 0.002 | 0.000 | 0.000 | 0.40 |
| R3M (Frozen) | ✗ | ABCD | 0.085 | 0.005 | 0.001 | 0.000 | 0.000 | 0.10 |
| Voltron (Frozen) | ✗ | ABCD | 0.101 | 0.003 | 0.001 | 0.000 | 0.000 | 0.11 |
| Voltron (Fine-tuned) | ✗ | ABCD | 0.837 | 0.566 | 0.352 | 0.208 | 0.115 | 2.08 |
| RT-1 | ✗ | ABCD | 0.844 | 0.617 | 0.438 | 0.323 | 0.227 | 2.45 |
| HULC | ✗ | ABCD | 0.889 | 0.733 | 0.587 | 0.475 | 0.383 | 3.06 |
| **GR-1** | ✓ | ABCD | **0.949** | **0.896** | **0.844** | **0.789** | **0.731** | **4.21** |
| **KosMos P.H. (RoboVLMs)** | ✓ | ABCD | **0.967** | **0.930** | **0.899** | **0.865** | **0.826** | **4.49** |

## 🏆 **KosMos P.H. (RoboVLMs) 성능 분석**

### **연속 작업 성공률**
- **1개 작업**: 96.7% (GR-1 94.9% 대비 +1.8%p)
- **2개 작업**: 93.0% (GR-1 89.6% 대비 +3.4%p)
- **3개 작업**: 89.9% (GR-1 84.4% 대비 +5.5%p)
- **4개 작업**: 86.5% (GR-1 78.9% 대비 +7.6%p)
- **5개 작업**: 82.6% (GR-1 73.1% 대비 +9.5%p)

### **평균 달성 작업 수 (Avg. Len.)**
- **KosMos P.H. (RoboVLMs)**: 4.49
- **GR-1**: 4.21
- **성능 향상**: +0.28 (6.7% 향상)

## 🔍 **ABCD 분할의 의미**

### **일반화 능력 평가**
ABCD 분할은 모델이 학습한 작업과 환경을 넘어 새로운 상황에서도 얼마나 잘 일반화할 수 있는지를 평가합니다.

### **VLA vs Non-VLA 성능 비교**
- **VLA 모델들** (GR-1, KosMos P.H.): 높은 성능 달성
- **Non-VLA 모델들** (MCIL, R3M, Voltron, RT-1, HULC): 상대적으로 낮은 성능

### **RoboVLMs의 우수성**
- **모든 연속 작업에서 최고 성능**: 1개~5개 연속 작업 모두에서 최고 성공률
- **일관된 성능 향상**: 작업 수가 증가할수록 더 큰 성능 차이
- **강건한 일반화**: 다양한 새로운 상황에서 안정적 성능

## 📊 **성능 트렌드 분석**

### **연속 작업 수에 따른 성능 변화**
1. **1개 작업**: 모든 모델이 상대적으로 높은 성능
2. **2-3개 작업**: VLA 모델들의 우위가 명확해짐
3. **4-5개 작업**: KosMos P.H.의 압도적 우위

### **VLA 아키텍처의 효과**
- **Policy Head + Continuous Action**: 최적의 조합
- **KosMos 백본**: 우수한 일반화 능력
- **RoboVLMs 프레임워크**: 체계적 설계의 효과

---

*분석 작성일: 2024년 12월*  
*원본 논문: "Towards Generalist Robot Policies: What Matters in Building Vision-Language-Action Models"*
