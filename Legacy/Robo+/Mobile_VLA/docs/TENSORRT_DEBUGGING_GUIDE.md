# ğŸ”§ TensorRT ë””ë²„ê¹… ê°€ì´ë“œ

## ğŸš¨ í˜„ì¬ ë°œìƒí•œ ì˜¤ë¥˜ ë¶„ì„

### âŒ **CUDA ì´ˆê¸°í™” ì˜¤ë¥˜**
```
[TRT] [E] createInferRuntime: Error Code 6: API Usage Error 
(CUDA initialization failure with error: 35)
```

### ğŸ” **ì˜¤ë¥˜ ì›ì¸ ë¶„ì„**
1. **CUDA ë“œë¼ì´ë²„ ë²„ì „ ë¶ˆì¼ì¹˜**
2. **TensorRTì™€ CUDA ë²„ì „ í˜¸í™˜ì„± ë¬¸ì œ**
3. **GPU ë©”ëª¨ë¦¬ í• ë‹¹ ì‹¤íŒ¨**
4. **í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ë¬¸ì œ**

## ğŸ› ï¸ TensorRT ë””ë²„ê¹… í•´ê²° ë°©ë²•

### 1. **ì‹œìŠ¤í…œ í™˜ê²½ í™•ì¸**

#### âœ… **í˜„ì¬ í™˜ê²½ ìƒíƒœ**
- **GPU**: NVIDIA RTX A5000
- **CUDA Driver**: 560.35.05
- **CUDA Runtime**: 12.6
- **CUDA Compiler**: 12.1.105
- **TensorRT**: 10.13.2.6

#### âš ï¸ **ë²„ì „ í˜¸í™˜ì„± ë¬¸ì œ**
- **TensorRT 10.13.2.6**ëŠ” **CUDA 12.1**ê³¼ í˜¸í™˜
- **ì‹œìŠ¤í…œ CUDA**: 12.6 (ë¶ˆì¼ì¹˜)

### 2. **í•´ê²° ë°©ë²•**

#### ğŸ”§ **ë°©ë²• 1: CUDA 12.1 ì„¤ì¹˜**
```bash
# CUDA 12.1 ì„¤ì¹˜
wget https://developer.download.nvidia.com/compute/cuda/12.1.0/local_installers/cuda_12.1.0_530.30.02_linux.run
sudo sh cuda_12.1.0_530.30.02_linux.run
```

#### ğŸ”§ **ë°©ë²• 2: TensorRT ë²„ì „ ë‹¤ìš´ê·¸ë ˆì´ë“œ**
```bash
# TensorRT 8.6.1 ì„¤ì¹˜ (CUDA 12.6 í˜¸í™˜)
pip uninstall tensorrt
pip install tensorrt==8.6.1
```

#### ğŸ”§ **ë°©ë²• 3: í™˜ê²½ ë³€ìˆ˜ ì„¤ì •**
```bash
# CUDA ê²½ë¡œ ì„¤ì •
export CUDA_HOME=/usr/local/cuda-12.1
export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH
export PATH=$CUDA_HOME/bin:$PATH
```

### 3. **TensorRT ìµœì í™” ê¸°ë²•**

#### ğŸš€ **ì£¼ìš” ìµœì í™” ê¸°ë²•**
1. **ê·¸ë˜í”„ ìµœì í™”**: ë¶ˆí•„ìš”í•œ ë ˆì´ì–´ ì œê±° ë° ìœµí•©
2. **ì •ë°€ë„ ë³´ì •**: FP16/INT8 ì–‘ìí™”
3. **ì»¤ë„ ìë™ íŠœë‹**: GPU ìµœì í™”
4. **í…ì„œ ë©”ëª¨ë¦¬ ìµœì í™”**: ë©”ëª¨ë¦¬ ì¬ì‚¬ìš©

#### ğŸ“Š **ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ**
- **FP16 ì–‘ìí™”**: 2-3ë°° ì„±ëŠ¥ í–¥ìƒ
- **INT8 ì–‘ìí™”**: 3-5ë°° ì„±ëŠ¥ í–¥ìƒ
- **ê·¸ë˜í”„ ìµœì í™”**: 10-30% ì„±ëŠ¥ í–¥ìƒ

### 4. **ëŒ€ì•ˆ í•´ê²°ì±…**

#### ğŸ”„ **ONNX Runtime ìµœì í™”**
```python
# ONNX Runtime ìµœì í™” ì„¤ì •
providers = [
    ('CUDAExecutionProvider', {
        'device_id': 0,
        'arena_extend_strategy': 'kNextPowerOfTwo',
        'gpu_mem_limit': 2 * 1024 * 1024 * 1024,  # 2GB
        'cudnn_conv_use_max_workspace': '1',
        'do_copy_in_default_stream': '1',
    }),
    'CPUExecutionProvider'
]
```

#### ğŸ”„ **PyTorch ìµœì í™”**
```python
# PyTorch ìµœì í™”
torch.backends.cudnn.benchmark = True
torch.backends.cudnn.deterministic = False
model = torch.jit.script(model)  # TorchScript ìµœì í™”
```

### 5. **ë””ë²„ê¹… ìŠ¤í¬ë¦½íŠ¸**

#### ğŸ” **TensorRT ìƒíƒœ í™•ì¸**
```python
import tensorrt as trt
import pycuda.driver as cuda
import pycuda.autoinit

def check_tensorrt_status():
    """TensorRT ìƒíƒœ í™•ì¸"""
    try:
        # TensorRT ë²„ì „ í™•ì¸
        print(f"TensorRT Version: {trt.__version__}")
        
        # CUDA ì»¨í…ìŠ¤íŠ¸ í™•ì¸
        cuda.init()
        device = cuda.Device(0)
        print(f"GPU: {device.name()}")
        print(f"Compute Capability: {device.compute_capability()}")
        
        # ë©”ëª¨ë¦¬ í™•ì¸
        free, total = cuda.mem_get_info()
        print(f"GPU Memory: {free/1024**3:.1f}GB free / {total/1024**3:.1f}GB total")
        
        return True
    except Exception as e:
        print(f"TensorRT check failed: {e}")
        return False
```

#### ğŸ” **ê°„ë‹¨í•œ TensorRT í…ŒìŠ¤íŠ¸**
```python
def simple_tensorrt_test():
    """ê°„ë‹¨í•œ TensorRT í…ŒìŠ¤íŠ¸"""
    try:
        logger = trt.Logger(trt.Logger.WARNING)
        builder = trt.Builder(logger)
        
        if builder.platform_has_fast_fp16:
            print("âœ… FP16 ì§€ì›ë¨")
        else:
            print("âŒ FP16 ì§€ì› ì•ˆë¨")
            
        if builder.platform_has_fast_int8:
            print("âœ… INT8 ì§€ì›ë¨")
        else:
            print("âŒ INT8 ì§€ì› ì•ˆë¨")
            
        return True
    except Exception as e:
        print(f"TensorRT test failed: {e}")
        return False
```

### 6. **ê¶Œì¥ í•´ê²° ìˆœì„œ**

#### ğŸ¯ **1ë‹¨ê³„: í™˜ê²½ í™•ì¸**
```bash
# 1. CUDA í™˜ê²½ í™•ì¸
nvidia-smi
nvcc --version

# 2. TensorRT ì„¤ì¹˜ í™•ì¸
python -c "import tensorrt as trt; print(trt.__version__)"
```

#### ğŸ¯ **2ë‹¨ê³„: ë²„ì „ í˜¸í™˜ì„± í•´ê²°**
```bash
# TensorRT 8.6.1 ì„¤ì¹˜ (CUDA 12.6 í˜¸í™˜)
pip uninstall tensorrt
pip install tensorrt==8.6.1
```

#### ğŸ¯ **3ë‹¨ê³„: í…ŒìŠ¤íŠ¸ ì‹¤í–‰**
```bash
# ê°„ë‹¨í•œ TensorRT í…ŒìŠ¤íŠ¸
python -c "
import tensorrt as trt
logger = trt.Logger(trt.Logger.WARNING)
builder = trt.Builder(logger)
print('TensorRT ì´ˆê¸°í™” ì„±ê³µ!')
"
```

### 7. **ì„±ëŠ¥ ë¹„êµ ì˜ˆìƒ**

#### ğŸ“Š **TensorRT ì ìš© ì‹œ ì˜ˆìƒ ì„±ëŠ¥**
| í”„ë ˆì„ì›Œí¬ | í˜„ì¬ ì„±ëŠ¥ | TensorRT ì ìš© í›„ | í–¥ìƒë¥  |
|------------|-----------|------------------|--------|
| **PyTorch** | 0.377ms | 0.1-0.2ms | **2-4ë°°** |
| **ONNX Runtime** | 4.852ms | 1-2ms | **3-5ë°°** |

#### ğŸ¤– **ë¡œë´‡ ì œì–´ì—ì„œì˜ ì˜ë¯¸**
- **0.1ms ì¶”ë¡ **: ê±°ì˜ ì¦‰ì‹œ ë°˜ì‘
- **20ms ì œì–´ ì£¼ê¸°**: 0.5% ì‚¬ìš© (ë§¤ìš° ì—¬ìœ )
- **10ms ì œì–´ ì£¼ê¸°**: 1% ì‚¬ìš© (ì™„ë²½í•œ ì‹¤ì‹œê°„)

### 8. **ì°¸ê³  ìë£Œ**

#### ğŸ“š **ê³µì‹ ë¬¸ì„œ**
- [NVIDIA TensorRT Documentation](https://docs.nvidia.com/tensorrt/)
- [TensorRT Installation Guide](https://docs.nvidia.com/deeplearning/tensorrt/install-guide/)
- [CUDA Installation Guide](https://docs.nvidia.com/cuda/cuda-installation-guide-linux/)

#### ğŸ”§ **ë””ë²„ê¹… ë„êµ¬**
- **NVIDIA Nsight Systems**: ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§
- **TensorRT Inspector**: ëª¨ë¸ ë¶„ì„
- **CUDA-GDB**: GPU ë””ë²„ê¹…

---

**í˜„ì¬ ìƒíƒœ**: TensorRT ì„¤ì¹˜ ì™„ë£Œ, CUDA ë²„ì „ í˜¸í™˜ì„± ë¬¸ì œ  
**ë‹¤ìŒ ë‹¨ê³„**: TensorRT 8.6.1 ë‹¤ìš´ê·¸ë ˆì´ë“œë¡œ í•´ê²° ì‹œë„  
**ì˜ˆìƒ ê²°ê³¼**: 2-4ë°° ì„±ëŠ¥ í–¥ìƒìœ¼ë¡œ 0.1ms ì¶”ë¡  ê°€ëŠ¥
