"""
ì•¡ì…˜ ë°ì´í„° ë¶„ì„ ë° MAE ì„±ëŠ¥ í•´ì„
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import json
import sys
import os

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from data.mobile_dataset import MobileVLADataset

def analyze_action_distribution():
    """ì•¡ì…˜ ë°ì´í„°ì˜ ë¶„í¬ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
    
    # ë°ì´í„°ì…‹ ë¡œë“œ
    dataset = MobileVLADataset(
        data_dir="/home/billy/25-1kp/vla/ROS_action/mobile_vla_dataset/",
        sequence_length=18,
        image_size=(224, 224),
        normalize_actions=True
    )
    
    # ëª¨ë“  ì•¡ì…˜ ë°ì´í„° ìˆ˜ì§‘
    all_actions = []
    
    print("ğŸ“Š ì•¡ì…˜ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
    for i in range(len(dataset)):
        sample = dataset[i]
        actions = sample['actions']  # [seq_len, action_dim]
        # 2D ì•¡ì…˜ë§Œ ì‚¬ìš© (linear_x, linear_y)
        actions_2d = actions[:, :2]  # [seq_len, 2]
        all_actions.append(actions_2d)
        
        if (i + 1) % 10 == 0:
            print(f"   - {i + 1}/{len(dataset)} ìƒ˜í”Œ ì²˜ë¦¬ ì™„ë£Œ")
    
    # ëª¨ë“  ì•¡ì…˜ì„ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
    all_actions = np.concatenate(all_actions, axis=0)  # [total_frames, 2]
    
    print(f"\nğŸ“Š ì•¡ì…˜ ë°ì´í„° ë¶„ì„:")
    print(f"   - ì´ í”„ë ˆì„ ìˆ˜: {len(all_actions):,}")
    print(f"   - ì•¡ì…˜ ì°¨ì›: {all_actions.shape[1]} (linear_x, linear_y)")
    
    # ê¸°ë³¸ í†µê³„
    print(f"\nğŸ“ˆ ê¸°ë³¸ í†µê³„:")
    print(f"   - linear_x ë²”ìœ„: [{all_actions[:, 0].min():.4f}, {all_actions[:, 0].max():.4f}]")
    print(f"   - linear_y ë²”ìœ„: [{all_actions[:, 1].min():.4f}, {all_actions[:, 1].max():.4f}]")
    print(f"   - linear_x í‰ê· : {all_actions[:, 0].mean():.4f}")
    print(f"   - linear_y í‰ê· : {all_actions[:, 1].mean():.4f}")
    print(f"   - linear_x í‘œì¤€í¸ì°¨: {all_actions[:, 0].std():.4f}")
    print(f"   - linear_y í‘œì¤€í¸ì°¨: {all_actions[:, 1].std():.4f}")
    
    # ì•¡ì…˜ í¬ê¸° ë¶„ì„
    action_magnitudes = np.sqrt(all_actions[:, 0]**2 + all_actions[:, 1]**2)
    print(f"\nğŸ¯ ì•¡ì…˜ í¬ê¸° ë¶„ì„:")
    print(f"   - í‰ê·  ì•¡ì…˜ í¬ê¸°: {action_magnitudes.mean():.4f}")
    print(f"   - ìµœëŒ€ ì•¡ì…˜ í¬ê¸°: {action_magnitudes.max():.4f}")
    print(f"   - ì•¡ì…˜ í¬ê¸° í‘œì¤€í¸ì°¨: {action_magnitudes.std():.4f}")
    
    # MAE ì„±ëŠ¥ í•´ì„
    mae_values = [0.212, 0.222]
    
    print(f"\nğŸ¯ MAE ì„±ëŠ¥ í•´ì„:")
    for mae in mae_values:
        print(f"\n   MAE {mae}:")
        
        # ì•¡ì…˜ í¬ê¸° ëŒ€ë¹„ ì˜¤ì°¨ ë¹„ìœ¨
        avg_magnitude = action_magnitudes.mean()
        error_ratio = mae / avg_magnitude * 100
        print(f"     - í‰ê·  ì•¡ì…˜ í¬ê¸° ëŒ€ë¹„ ì˜¤ì°¨: {error_ratio:.1f}%")
        
        # í‘œì¤€í¸ì°¨ ëŒ€ë¹„ ì˜¤ì°¨ ë¹„ìœ¨
        std_magnitude = action_magnitudes.std()
        error_ratio_std = mae / std_magnitude * 100
        print(f"     - ì•¡ì…˜ í¬ê¸° í‘œì¤€í¸ì°¨ ëŒ€ë¹„ ì˜¤ì°¨: {error_ratio_std:.1f}%")
        
        # ì •í™•ë„ ì¶”ì • (ì„ê³„ê°’ ê¸°ë°˜)
        thresholds = [0.1, 0.2, 0.3, 0.5]
        for threshold in thresholds:
            accurate_predictions = np.sum(action_magnitudes <= threshold + mae)
            accuracy = accurate_predictions / len(action_magnitudes) * 100
            print(f"     - {threshold:.1f} ì´ë‚´ ì •í™•ë„: {accuracy:.1f}%")
    
    # ì‹œê°í™”
    plt.figure(figsize=(15, 10))
    
    # 1. ì•¡ì…˜ ë¶„í¬
    plt.subplot(2, 3, 1)
    plt.scatter(all_actions[:, 0], all_actions[:, 1], alpha=0.5, s=1)
    plt.xlabel('linear_x')
    plt.ylabel('linear_y')
    plt.title('ì•¡ì…˜ ë¶„í¬ (linear_x vs linear_y)')
    plt.grid(True)
    
    # 2. linear_x íˆìŠ¤í† ê·¸ë¨
    plt.subplot(2, 3, 2)
    plt.hist(all_actions[:, 0], bins=50, alpha=0.7, color='blue')
    plt.xlabel('linear_x')
    plt.ylabel('ë¹ˆë„')
    plt.title('linear_x ë¶„í¬')
    plt.grid(True)
    
    # 3. linear_y íˆìŠ¤í† ê·¸ë¨
    plt.subplot(2, 3, 3)
    plt.hist(all_actions[:, 1], bins=50, alpha=0.7, color='red')
    plt.xlabel('linear_y')
    plt.ylabel('ë¹ˆë„')
    plt.title('linear_y ë¶„í¬')
    plt.grid(True)
    
    # 4. ì•¡ì…˜ í¬ê¸° ë¶„í¬
    plt.subplot(2, 3, 4)
    plt.hist(action_magnitudes, bins=50, alpha=0.7, color='green')
    plt.xlabel('ì•¡ì…˜ í¬ê¸°')
    plt.ylabel('ë¹ˆë„')
    plt.title('ì•¡ì…˜ í¬ê¸° ë¶„í¬')
    plt.grid(True)
    
    # 5. MAE ì„±ëŠ¥ ë¹„êµ
    plt.subplot(2, 3, 5)
    models = ['Simple CLIP LSTM', 'Simple LSTM']
    colors = ['red', 'blue']
    bars = plt.bar(models, mae_values, color=colors, alpha=0.7)
    plt.ylabel('MAE')
    plt.title('ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ')
    plt.ylim(0, 0.3)
    
    # ê°’ í‘œì‹œ
    for bar, mae in zip(bars, mae_values):
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height + 0.005,
                f'{mae:.3f}', ha='center', va='bottom')
    
    # 6. ì •í™•ë„ ë¹„êµ
    plt.subplot(2, 3, 6)
    thresholds = [0.1, 0.2, 0.3, 0.5]
    clip_accuracies = []
    lstm_accuracies = []
    
    for threshold in thresholds:
        # Simple CLIP LSTM (MAE 0.212)
        accurate_clip = np.sum(action_magnitudes <= threshold + 0.212)
        accuracy_clip = accurate_clip / len(action_magnitudes) * 100
        clip_accuracies.append(accuracy_clip)
        
        # Simple LSTM (MAE 0.222)
        accurate_lstm = np.sum(action_magnitudes <= threshold + 0.222)
        accuracy_lstm = accurate_lstm / len(action_magnitudes) * 100
        lstm_accuracies.append(accuracy_lstm)
    
    x = np.arange(len(thresholds))
    width = 0.35
    
    plt.bar(x - width/2, clip_accuracies, width, label='Simple CLIP LSTM', alpha=0.7)
    plt.bar(x + width/2, lstm_accuracies, width, label='Simple LSTM', alpha=0.7)
    
    plt.xlabel('ì„ê³„ê°’')
    plt.ylabel('ì •í™•ë„ (%)')
    plt.title('ì„ê³„ê°’ë³„ ì •í™•ë„ ë¹„êµ')
    plt.xticks(x, [f'{t:.1f}' for t in thresholds])
    plt.legend()
    plt.grid(True)
    
    plt.tight_layout()
    plt.savefig('action_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # ê²°ê³¼ ì €ì¥
    results = {
        'total_frames': len(all_actions),
        'action_dimensions': all_actions.shape[1],
        'linear_x_range': [float(all_actions[:, 0].min()), float(all_actions[:, 0].max())],
        'linear_y_range': [float(all_actions[:, 1].min()), float(all_actions[:, 1].max())],
        'linear_x_mean': float(all_actions[:, 0].mean()),
        'linear_y_mean': float(all_actions[:, 1].mean()),
        'linear_x_std': float(all_actions[:, 0].std()),
        'linear_y_std': float(all_actions[:, 1].std()),
        'action_magnitude_mean': float(action_magnitudes.mean()),
        'action_magnitude_max': float(action_magnitudes.max()),
        'action_magnitude_std': float(action_magnitudes.std()),
        'mae_analysis': {
            '0.212': {
                'error_ratio_mean': float(mae_values[0] / action_magnitudes.mean() * 100),
                'error_ratio_std': float(mae_values[0] / action_magnitudes.std() * 100),
                'accuracies': {f'threshold_{t}': float(np.sum(action_magnitudes <= t + mae_values[0]) / len(action_magnitudes) * 100) for t in thresholds}
            },
            '0.222': {
                'error_ratio_mean': float(mae_values[1] / action_magnitudes.mean() * 100),
                'error_ratio_std': float(mae_values[1] / action_magnitudes.std() * 100),
                'accuracies': {f'threshold_{t}': float(np.sum(action_magnitudes <= t + mae_values[1]) / len(action_magnitudes) * 100) for t in thresholds}
            }
        }
    }
    
    with open('action_analysis_results.json', 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\nğŸ’¾ ë¶„ì„ ê²°ê³¼ê°€ 'action_analysis_results.json'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"ğŸ“Š ì‹œê°í™”ê°€ 'action_analysis.png'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    analyze_action_distribution()
