---
license: apache-2.0
tags:
- vision-language-action
- mobile-robot
- kosmos-2b
- robotics
- obstacle-avoidance
datasets:
- mobile-vla-dataset
language:
- en
- ko
metrics:
- mae
- r2_score
library_name: transformers
pipeline_tag: robotics
---

# ğŸš€ Mobile VLA: Vision-Language-Action Model for Mobile Robots

## ğŸ“‹ Model Description

Mobile VLAëŠ” Kosmos-2Bë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ Mobile Robot ì „ìš© Vision-Language-Action ëª¨ë¸ì…ë‹ˆë‹¤. 
ì¥ì• ë¬¼ íšŒí”¼ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì—°ì†ì ì¸ 3D ì•¡ì…˜ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

### ğŸ¯ í•µì‹¬ ê¸°ëŠ¥

- **Vision-Language-Action**: ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ì§€ì‹œì‚¬í•­ì„ ë°›ì•„ ë¡œë´‡ ì•¡ì…˜ ì˜ˆì¸¡
- **3D ì—°ì† ì œì–´**: `[linear_x, linear_y, angular_z]` í˜•íƒœì˜ ì—°ì† ì•¡ì…˜ ê³µê°„
- **ì¥ì• ë¬¼ íšŒí”¼**: 1-box, 2-box ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì¢Œìš° íšŒí”¼ ì „ëµ í•™ìŠµ
- **ì‹¤ì‹œê°„ ì²˜ë¦¬**: íš¨ìœ¨ì ì¸ vision-only ì²˜ë¦¬ë¡œ ë¹ ë¥¸ ì¶”ë¡ 

### ğŸ”§ ê¸°ìˆ  ì‚¬ì–‘

- **ë°±ë³¸ ëª¨ë¸**: microsoft/kosmos-2-patch14-224
- **ì…ë ¥**: RGB ì´ë¯¸ì§€ (224x224) + í…ìŠ¤íŠ¸ ì§€ì‹œì‚¬í•­
- **ì¶œë ¥**: 3D ì—°ì† ì•¡ì…˜ ë²¡í„°
- **í•™ìŠµ ë°©ì‹**: Huber Loss ê¸°ë°˜ íšŒê·€
- **ë°ì´í„°**: 72ê°œ ì‹¤ì œ ë¡œë´‡ ì—í”¼ì†Œë“œ

## ğŸ“Š ì„±ëŠ¥ ì§€í‘œ

### ì „ì²´ ì„±ëŠ¥
- **ì „ì²´ MAE**: 0.285
- **ì„ê³„ê°’ ì •í™•ë„ (0.1)**: 37.5%

### ì•¡ì…˜ë³„ ì„±ëŠ¥
| ì•¡ì…˜ | MAE | RÂ² Score | ì„¤ëª… |
|------|-----|----------|------|
| linear_x | 0.243 | 0.354 | ì „ì§„/í›„ì§„ (ìš°ìˆ˜) |
| linear_y | 0.550 | 0.293 | ì¢Œìš° ì´ë™ (ë³´í†µ) |
| angular_z | 0.062 | 0.000 | íšŒì „ (ë‚®ìŒ) |

### ì‹œë‚˜ë¦¬ì˜¤ë³„ ì„±ëŠ¥
| ì‹œë‚˜ë¦¬ì˜¤ | MAE | ë“±ê¸‰ | ì„¤ëª… |
|----------|-----|------|------|
| 1box_right_vertical | 0.217 | B+ | ìš°ìˆ˜ |
| 1box_left_horizontal | 0.303 | B | ì–‘í˜¸ |
| 2box_left_vertical | 0.322 | B | ì–‘í˜¸ |
| 1box_left_vertical | 0.337 | B- | ë³´í†µ |

## ğŸš€ ì‚¬ìš© ë°©ë²•

### ì„¤ì¹˜
```bash
pip install transformers torch pillow numpy
```

### ê¸°ë³¸ ì‚¬ìš©ë²•
```python
from mobile_vla import MobileVLAModel, MobileVLATrainer
from PIL import Image
import torch

# ëª¨ë¸ ë¡œë“œ
model = MobileVLAModel.from_pretrained("minuum/mobile-vla")

# ì´ë¯¸ì§€ì™€ íƒœìŠ¤í¬ ì¤€ë¹„
image = Image.open("robot_camera.jpg")
task = "Navigate around obstacles to track the target cup"

# ì˜ˆì¸¡
with torch.no_grad():
    actions = model.predict(image, task)
    
print(f"Predicted actions: {actions}")
# ì¶œë ¥: [linear_x, linear_y, angular_z]
```

### ê³ ê¸‰ ì‚¬ìš©ë²•
```python
# ë°°ì¹˜ ì²˜ë¦¬
images = [Image.open(f"frame_{i}.jpg") for i in range(8)]
actions = model.predict_sequence(images, task)

# ì‹¤ì‹œê°„ ì œì–´
for frame in camera_stream:
    action = model.predict(frame, task)
    robot.execute(action)
```

## ğŸ—ï¸ ëª¨ë¸ ì•„í‚¤í…ì²˜

```
[RGB Images] â†’ [Kosmos-2B Vision] â†’ [Action Head] â†’ [3D Actions]
     â†“              â†“                    â†“             â†“
   224x224    Image Features         Regression    [x, y, Î¸]
```

### í•µì‹¬ ì»´í¬ë„ŒíŠ¸
1. **Kosmos-2B Vision Model**: ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ
2. **Action Head**: 3D íšŒê·€ í—¤ë“œ (512 â†’ 3*chunk_size)
3. **Window/Chunk**: 8í”„ë ˆì„ ê´€ì°° â†’ 2í”„ë ˆì„ ì˜ˆì¸¡

## ğŸ“ˆ RoboVLMsì™€ì˜ ë¹„êµ

| í•­ëª© | RoboVLMs | Mobile VLA |
|------|----------|------------|
| **ë°ì´í„° ìš”êµ¬ëŸ‰** | ìˆ˜ë°±ë§Œ ë°ëª¨ | 72 ì—í”¼ì†Œë“œ |
| **ì•¡ì…˜ ê³µê°„** | 7-DOF Discrete | 3D Continuous |
| **ì¶”ë¡  ì†ë„** | ë³µí•©ì  | ë¹ ë¦„ |
| **íŠ¹í™” ë¶„ì•¼** | ë²”ìš© Manipulation | Mobile Robot |
| **í‰ê°€ ë°©ì‹** | ì„±ê³µë¥  | ë‹¤ì°¨ì› íšŒê·€ ì§€í‘œ |

## ğŸ¯ ì£¼ìš” ê°œì„ ì‚¬í•­

- **ë°ì´í„° íš¨ìœ¨ì„±**: 1000ë°° ì ì€ ë°ì´í„°ë¡œ ì‹¤ìš©ì  ì„±ëŠ¥
- **ì‹¤ì‹œê°„ ì„±ëŠ¥**: Vision-only ì²˜ë¦¬ë¡œ ë¹ ë¥¸ ì¶”ë¡ 
- **ì—°ì† ì œì–´**: ì •ë°€í•œ 3D ì•¡ì…˜ ì˜ˆì¸¡
- **ì‹œë‚˜ë¦¬ì˜¤ íŠ¹í™”**: ì¥ì• ë¬¼ íšŒí”¼ ì „ìš© ìµœì í™”

## ğŸ“š í•™ìŠµ ë°ì´í„°

- **ì—í”¼ì†Œë“œ ìˆ˜**: 72ê°œ
- **ì‹œë‚˜ë¦¬ì˜¤**: 1box/2box Ã— left/right Ã— vertical/horizontal
- **ì•¡ì…˜**: [linear_x, linear_y, angular_z] ì—°ì† ê°’
- **ì´ë¯¸ì§€**: ì‹¤ì œ ë¡œë´‡ ì¹´ë©”ë¼ RGB (224x224)

## ğŸ”¬ ì—°êµ¬ ë°°ê²½

ì´ ëª¨ë¸ì€ RoboVLMsì˜ Window/Chunk ë©”ì»¤ë‹ˆì¦˜ì„ ìœ ì§€í•˜ë©´ì„œ Mobile Robotì— íŠ¹í™”ëœ ê¸°ëŠ¥ì„ ì¶”ê°€í•œ ì—°êµ¬ì…ë‹ˆë‹¤:

1. **Window/Chunk ìœ ì§€**: 8í”„ë ˆì„ ê´€ì°° â†’ 2í”„ë ˆì„ ì˜ˆì¸¡ êµ¬ì¡°
2. **Kosmos-2B í†µí•©**: Vision-Language ë°±ë³¸ í™œìš©
3. **ì—°ì† ì œì–´**: Discrete â†’ Continuous ì•¡ì…˜ ê³µê°„ ì „í™˜
4. **ì‹¤ì œ ë¡œë´‡ ë°ì´í„°**: HDF5 í˜•íƒœì˜ ì‹¤ì œ ìˆ˜ì§‘ ë°ì´í„°

## ğŸ“„ ì¸ìš©

```bibtex
@misc{mobile_vla_2024,
  title={Mobile VLA: Vision-Language-Action Model for Mobile Robot Navigation},
  author={Mobile VLA Team},
  year={2024},
  publisher={HuggingFace},
  url={https://huggingface.co/minuum/mobile-vla}
}
```

## ğŸ¤ ê¸°ì—¬

ì´ ëª¨ë¸ì€ RoboVLMs í”„ë ˆì„ì›Œí¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°œë°œë˜ì—ˆìœ¼ë©°, Mobile Robot ì»¤ë®¤ë‹ˆí‹°ì˜ ë°œì „ì„ ìœ„í•´ ê³µê°œë©ë‹ˆë‹¤.

## ğŸ“ ì—°ë½ì²˜

- **Issues**: [GitHub Issues](https://github.com/minuum/vla/issues)
- **Discussions**: [HuggingFace Discussions](https://huggingface.co/minuum/mobile-vla/discussions)

---
*Generated on 2025-08-21*
