# Mobile VLA LoRA Finetuning κ°€μ΄λ“ (2025-11-14)

## π“ μΌμ£ΌμΌκ°„ μ»¤λ°‹ λ¶„μ„ μ”μ•½

### μ£Όμ” λ³€κ²½μ‚¬ν•­ (μµκ·Ό 1μ£ΌμΌ, 16κ° μ»¤λ°‹)

1. **λ°μ΄ν„° μμ§‘ κ΄€λ ¨ (8κ° μ»¤λ°‹)**
   - 25κ° μ—ν”Όμ†λ“ μλ™ μμ§‘ μ™„λ£
   - μ—ν”Όμ†λ“ ν”„λ μ„ μ 18κ°λ΅ μμ • (μ΄κΈ° 1κ° + μ•΅μ… 17κ°)
   - μλ™ μΈ΅μ •/λ³µκ·€ λ©”μ»¤λ‹μ¦ κ°μ„ 

2. **μ„λΈλ¨λ“ μ—…λ°μ΄νΈ (2κ° μ»¤λ°‹)**
   - `RoboVLMs_upstream`μ— `MobileVLAH5Dataset` μ¶”κ°€
   - `lora_utils.py` μ¶”κ°€ (LoRA μ ν‹Έλ¦¬ν‹° ν•¨μ)
   - Import μ¤λ¥ μμ • (turtle.pd β†’ pandas.pd)
   - Gradient μ¤λ¥ μμ • (requires_grad=True)

3. **λ¬Έμ„ν™” (4κ° μ»¤λ°‹)**
   - ν•™μµ λ¶„μ„ λΈλ¦¬ν•‘ λ¬Έμ„
   - 20 epoch ν•™μµ κ²°κ³Ό λ¬Έμ„
   - λ―Έν…μ© μ§„ν–‰ λ³΄κ³ μ„

4. **κΈ°νƒ€ (2κ° μ»¤λ°‹)**
   - Git μƒνƒ μ •λ¦¬
   - λ§ν¬λ‹¤μ΄ νμΌ λ“¤μ—¬μ“°κΈ° λ³µκµ¬

### ν„μ¬ λ°μ΄ν„°μ…‹ μƒνƒ

- **μ΄ μ—ν”Όμ†λ“ νμΌ:** 136κ°
- **μµμ‹  λ°μ΄ν„°:** `episode_20251114_*.h5` (μµκ·Ό μμ§‘)
- **μ΄μ „ λ°μ΄ν„°:** `episode_20251106_*.h5` (μ΄μ „ ν•™μµμ— μ‚¬μ©)

---

## π― LoRA Finetuning κ³ λ ¤μ‚¬ν•­

### 1. **κΈ°μ΅΄ ν•™μµ κ²°κ³Ό λ¶„μ„ (20 Epochs)**

**μ„±κ³µμ μΈ ν•™μµ:**
- Train Loss: 0.126 β†’ 0.019 (84.9% κ°μ†)
- Val Loss: 0.122 β†’ 0.020 (83.8% κ°μ†)
- **κ³Όμ ν•© μ—†μ** (Train-Val Gap: 0.0004)

**λ¬Έμ μ :**
- λ°μ΄ν„° λ¶€μ΅± (13κ° μ—ν”Όμ†λ“, 218 ν”„λ μ„)
- μ•΅μ… λ‹¤μ–‘μ„± λ‚®μ (5κ°€μ§€ ν¨ν„΄λ§)
- μƒν”/νλΌλ―Έν„° λΉ„μ¨: 0.02 (λ§¤μ° λ‚®μ)

### 2. **ν„μ¬ μƒν™© κ°μ„ **

**λ°μ΄ν„° μ¦κ°€:**
- μ΄μ „: 13κ° μ—ν”Όμ†λ“ β†’ ν„μ¬: 136κ° μ—ν”Όμ†λ“ (10λ°° μ¦κ°€!)
- λ” λ§μ€ λ°μ΄ν„°λ΅ ν•™μµ κ°€λ¥

**μ„λΈλ¨λ“ ν†µν•©:**
- `MobileVLAH5Dataset`μ΄ `robovlms.data`μ— λ“±λ΅λ¨
- RoboVLMsμ ν‘μ¤€ ν•™μµ νμ΄ν”„λΌμΈ μ‚¬μ© κ°€λ¥

### 3. **κΈ°μ΅΄ μ½”λ“ κΈ°λ° μ‚¬μ©**

**μ‚¬μ©ν•  μ½”λ“:**
- `RoboVLMs_upstream/main.py` - λ©”μΈ ν•™μµ μ¤ν¬λ¦½νΈ
- `RoboVLMs_upstream/robovlms/data/mobile_vla_h5_dataset.py` - λ°μ΄ν„°μ…‹
- `Mobile_VLA/configs/mobile_vla_20251106_lora.json` - μ„¤μ • νμΌ (μ—…λ°μ΄νΈ ν•„μ”)

**μ‚¬μ©ν•μ§€ μ•μ„ μ½”λ“:**
- `Mobile_VLA/src/training/finetune_lora_20251106.py` - λ…λ¦½ κµ¬ν„ (μ‚¬μ© μ• ν•¨)

---

## π€ μ‹¤ν–‰ λ°©λ²•

### 1. μ„¤μ • νμΌ μ—…λ°μ΄νΈ

μµμ‹  λ°μ΄ν„°λ¥Ό μ‚¬μ©ν•λ„λ΅ μ„¤μ • νμΌμ„ μ—…λ°μ΄νΈ:

```json
{
  "train_dataset": {
    "type": "MobileVLAH5Dataset",
    "data_dir": "/home/billy/25-1kp/vla/ROS_action/mobile_vla_dataset",
    "episode_pattern": "episode_20251114_*.h5",  // μµμ‹  λ°μ΄ν„° μ‚¬μ©
    ...
  },
  "val_dataset": {
    "type": "MobileVLAH5Dataset",
    "data_dir": "/home/billy/25-1kp/vla/ROS_action/mobile_vla_dataset",
    "episode_pattern": "episode_20251114_*.h5",  // μµμ‹  λ°μ΄ν„° μ‚¬μ©
    ...
  }
}
```

### 2. μ‹¤ν–‰ μ¤ν¬λ¦½νΈ

```bash
cd /home/billy/25-1kp/vla/RoboVLMs_upstream
python3 main.py ../Mobile_VLA/configs/mobile_vla_20251106_lora.json
```

### 3. μ£Όμ” μ„¤μ • νλΌλ―Έν„°

**LoRA μ„¤μ •:**
- `lora_r`: 32
- `lora_alpha`: 16
- `lora_dropout`: 0.1
- `freeze_backbone`: true

**ν•™μµ μ„¤μ •:**
- `batch_size`: 1 (effective 8 with gradient accumulation)
- `accumulate_grad_batches`: 8
- `learning_rate`: 1e-4
- `max_epochs`: 20 (λλ” λ” λ§μ΄)
- `window_size`: 4
- `action_dim`: 7 (2D μ•΅μ…μ„ 7Dλ΅ ν¨λ”©)

**λ°μ΄ν„° μ„¤μ •:**
- `train_split`: 0.8
- `window_size`: 4
- `fwd_pred_next_n`: 10

---

## β οΈ μ£Όμμ‚¬ν•­

### 1. **λ°μ΄ν„° ν¨ν„΄ ν™•μΈ**
- μµμ‹  λ°μ΄ν„°μ μ—ν”Όμ†λ“ ν¨ν„΄ ν™•μΈ ν•„μ”
- `episode_20251114_*.h5` λλ” λ‹¤λ¥Έ λ‚ μ§ ν¨ν„΄ μ‚¬μ© κ°€λ¥

### 2. **λ©”λ¨λ¦¬ μ μ•½**
- Jetson ν™κ²½: 16GB λ©”λ¨λ¦¬
- `batch_size=1`, `accumulate_grad_batches=8` κ¶μ¥
- FP16 mixed precision μ‚¬μ©

### 3. **ν•™μµ μ‹κ°„**
- μ΄μ „ κ²½ν—: 20 epochs β‰ 20λ¶„
- λ” λ§μ€ λ°μ΄ν„°λ΅ μΈν•΄ μ‹κ°„ μ¦κ°€ κ°€λ¥

### 4. **μ²΄ν¬ν¬μΈνΈ κ΄€λ¦¬**
- Best model μλ™ μ €μ¥
- μ£ΌκΈ°μ  μ²΄ν¬ν¬μΈνΈ μ €μ¥ (10 epochsλ§λ‹¤)
- LoRA μ–΄λ‘ν„°λ§ μ €μ¥ (μ MB)

---

## π“ μμƒ κ²°κ³Ό

### λ°μ΄ν„° μ¦κ°€ ν¨κ³Ό

**μ΄μ „ (13 μ—ν”Όμ†λ“):**
- Train μƒν”: ~47κ°
- Val μƒν”: ~14κ°
- Loss: 0.122 β†’ 0.020

**ν„μ¬ (136 μ—ν”Όμ†λ“, μμƒ):**
- Train μƒν”: ~500-1000κ° (10-20λ°° μ¦κ°€)
- Val μƒν”: ~100-200κ°
- **λ” λ‚μ€ μΌλ°ν™” κΈ°λ€**

### κ¶μ¥ ν•™μµ μ „λµ

1. **μ΄κΈ° ν•™μµ (20 epochs)**
   - λΉ λ¥Έ μλ ΄ ν™•μΈ
   - Loss κ³΅μ„  λ¨λ‹ν„°λ§

2. **μ¶”κ°€ ν•™μµ (50-100 epochs)**
   - λ” λ§μ€ λ°μ΄ν„°λ΅ λ” λ‚μ€ μ„±λ¥ κΈ°λ€
   - κ³Όμ ν•© λ¨λ‹ν„°λ§

3. **κ²€μ¦**
   - λ‹¤μ–‘ν• ν™κ²½μ—μ„ ν…μ¤νΈ
   - Edge case μ„±λ¥ ν™•μΈ

---

## π”§ λ¬Έμ  ν•΄κ²°

### 1. λ°μ΄ν„°μ…‹ λ΅λ“ μ‹¤ν¨
```bash
# μ—ν”Όμ†λ“ νμΌ ν™•μΈ
find ROS_action/mobile_vla_dataset -name "episode_*.h5" | wc -l

# ν¨ν„΄ ν™•μΈ
ls ROS_action/mobile_vla_dataset/episode_20251114_*.h5 | head -5
```

### 2. λ©”λ¨λ¦¬ λ¶€μ΅±
- `batch_size` κ°μ†
- `num_workers` κ°μ†
- `gradient_checkpointing` ν™μ„±ν™”

### 3. ν•™μµ μ†λ„ λλ¦Ό
- `num_workers` μ¦κ°€ (λ©”λ¨λ¦¬ ν—μ© μ‹)
- `precision` ν™•μΈ (FP16 μ‚¬μ©)

---

## π“ μ²΄ν¬λ¦¬μ¤νΈ

- [ ] μµμ‹  λ°μ΄ν„° μ—ν”Όμ†λ“ ν¨ν„΄ ν™•μΈ
- [ ] μ„¤μ • νμΌ μ—…λ°μ΄νΈ (episode_pattern)
- [ ] CUDA ν™•μΈ (`torch.cuda.is_available()`)
- [ ] λ°μ΄ν„°μ…‹ λ΅λ“ ν…μ¤νΈ
- [ ] ν•™μµ μ‹μ‘
- [ ] Loss λ¨λ‹ν„°λ§
- [ ] μ²΄ν¬ν¬μΈνΈ μ €μ¥ ν™•μΈ

---

**μ‘μ„±μΌ:** 2025-11-14  
**κΈ°λ° μ½”λ“:** RoboVLMs_upstream/main.py  
**λ°μ΄ν„°μ…‹:** MobileVLAH5Dataset (μ„λΈλ¨λ“μ— λ“±λ΅λ¨)

