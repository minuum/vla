#!/bin/bash
# Mobile VLA LoRA Fine-tuning ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ (2025-11-14)
# ê¸°ì¡´ RoboVLMs ì½”ë“œ ê¸°ë°˜ìœ¼ë¡œ ì‹¤í–‰

set -e

echo "========================================="
echo "Mobile VLA LoRA Fine-tuning"
echo "Date: 2025-11-14"
echo "========================================="

# ì‘ì—… ë””ë ‰í† ë¦¬ í™•ì¸
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
cd "$SCRIPT_DIR"

# RoboVLMs ì„œë¸Œëª¨ë“ˆ ë””ë ‰í† ë¦¬ë¡œ ì´ë™
cd RoboVLMs_upstream

# CUDA ì„¤ì •
export CUDA_VISIBLE_DEVICES=0
export RANK=0
export WORLD_SIZE=1
export MASTER_ADDR=localhost
export MASTER_PORT=29500

# Config ê²½ë¡œ (ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©)
CONFIG="$SCRIPT_DIR/Mobile_VLA/configs/mobile_vla_20251114_lora.json"

echo ""
echo "ğŸ“„ Config: $CONFIG"
echo "ğŸ”§ Device: CUDA"
echo "ğŸ“¦ Model: Kosmos-2 with LoRA"
echo ""

# CUDA í™•ì¸ (Poetry í™˜ê²½ ì‚¬ìš©)
echo "ğŸ” CUDA í™•ì¸..."
cd "$SCRIPT_DIR"  # ë©”ì¸ ë””ë ‰í† ë¦¬ë¡œ ëŒì•„ê°€ì„œ Poetry í™˜ê²½ ì‚¬ìš©
poetry run python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}'); print(f'CUDA device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\"}')"
cd RoboVLMs_upstream  # ë‹¤ì‹œ RoboVLMs ë””ë ‰í† ë¦¬ë¡œ
echo ""

# ë°ì´í„°ì…‹ í™•ì¸
echo "ğŸ“Š ë°ì´í„°ì…‹ í™•ì¸..."
cd "$SCRIPT_DIR"  # ë©”ì¸ ë””ë ‰í† ë¦¬ë¡œ
EPISODE_COUNT=$(find ROS_action/mobile_vla_dataset -name "episode_2025111*.h5" | wc -l)
echo "  - Found $EPISODE_COUNT episodes matching pattern 'episode_2025111*.h5'"
if [ "$EPISODE_COUNT" -eq 0 ]; then
    echo "  âš ï¸  Warning: No episodes found! Check episode_pattern in config."
else
    echo "  âœ… Episodes found"
fi
echo ""

# ì„¤ì • íŒŒì¼ í™•ì¸
if [ ! -f "$CONFIG" ]; then
    echo "âŒ Error: Config file not found: $CONFIG"
    exit 1
fi

echo "ğŸš€ LoRA Fine-tuning ì‹œì‘..."
echo "   - Using RoboVLMs main.py"
echo "   - Dataset: MobileVLAH5Dataset"
echo "   - LoRA: r=32, alpha=16, dropout=0.1"
echo "   - Epochs: 20"
echo ""

# í•™ìŠµ ì‹œì‘ (Poetry í™˜ê²½ ì‚¬ìš©)
# ë©”ì¸ ë””ë ‰í† ë¦¬ì—ì„œ Poetry í™˜ê²½ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸° (RoboVLMs_upstreamì˜ í™˜ê²½ì´ ì•„ë‹Œ ë©”ì¸ í”„ë¡œì íŠ¸ í™˜ê²½)
cd "$SCRIPT_DIR"  # ë©”ì¸ ë””ë ‰í† ë¦¬ë¡œ ëŒì•„ê°€ì„œ Poetry í™˜ê²½ ì‚¬ìš©
PYTHON_BIN=$(poetry env info --path)/bin/python
cd RoboVLMs_upstream  # RoboVLMs ë””ë ‰í† ë¦¬ë¡œ ì´ë™
# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
export CUDA_VISIBLE_DEVICES=0
export RANK=0
export WORLD_SIZE=1
export MASTER_ADDR=localhost
export MASTER_PORT=29500
# ë©”ì¸ í”„ë¡œì íŠ¸ì˜ Poetry í™˜ê²½ Python ì‚¬ìš©
$PYTHON_BIN main.py "$CONFIG"

echo ""
echo "âœ… LoRA Fine-tuning ì™„ë£Œ!"
echo ""
echo "ğŸ“ ê²°ê³¼ í™•ì¸:"
echo "   - Checkpoints: runs/mobile_vla_lora_20251114/checkpoints/"
echo "   - Logs: runs/mobile_vla_lora_20251114/logs/"
echo ""

