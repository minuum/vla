# Vision-Language-Action Models for Mobile Robot Navigation

## ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš”

ì´ í”„ë¡œì íŠ¸ëŠ” **Vision-Language-Action (VLA) ëª¨ë¸**ì„ í™œìš©í•œ ëª¨ë°”ì¼ ë¡œë´‡ ë‚´ë¹„ê²Œì´ì…˜ ì‹œìŠ¤í…œì„ ì—°êµ¬í•˜ê³  êµ¬í˜„í•©ë‹ˆë‹¤. ìµœì‹  ì»´í“¨í„° ë¹„ì „ê³¼ ìì—°ì–´ ì²˜ë¦¬ ê¸°ìˆ ì„ í†µí•©í•˜ì—¬, ë¡œë´‡ì´ ì‹œê°ì  ì •ë³´ì™€ ì–¸ì–´ ëª…ë ¹ì„ ë°”íƒ•ìœ¼ë¡œ ì ì ˆí•œ í–‰ë™ì„ ìƒì„±í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.

## ğŸ“š ì—°êµ¬ ë°°ê²½

### ë¬¸ì œ ì •ì˜
ëª¨ë°”ì¼ ë¡œë´‡ì´ ë™ì  í™˜ê²½ì—ì„œ íš¨ê³¼ì ìœ¼ë¡œ ë‚´ë¹„ê²Œì´ì…˜í•˜ê¸° ìœ„í•´ì„œëŠ” ì •êµí•œ ì¸ì‹, ì¶”ë¡ , í–‰ë™ ìƒì„± ëŠ¥ë ¥ì´ í•„ìš”í•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ì ‘ê·¼ ë°©ì‹ë“¤ì€ ì´ëŸ¬í•œ êµ¬ì„± ìš”ì†Œë“¤ì„ ë¶„ë¦¬í•˜ì—¬ ì²˜ë¦¬í•¨ìœ¼ë¡œì¨ ìµœì ì´ ì•„ë‹Œ ì„±ëŠ¥ê³¼ ì œí•œëœ ì¼ë°˜í™” ëŠ¥ë ¥ì„ ë³´ì—¬ì™”ìŠµë‹ˆë‹¤.

### í•´ê²° ë°©ì•ˆ
Vision-Language-Action (VLA) ëª¨ë¸ì€ ì‹œê°ì  ì¸ì‹, ìì—°ì–´ ì´í•´, í–‰ë™ ìƒì„±ì„ end-to-end ë°©ì‹ìœ¼ë¡œ í†µí•©í•˜ëŠ” í†µí•© í”„ë ˆì„ì›Œí¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë¡œë´‡ì´ ë”ìš± ì§ê´€ì ì´ê³  íš¨ìœ¨ì ìœ¼ë¡œ í™˜ê²½ê³¼ ìƒí˜¸ì‘ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸš€ ì£¼ìš” ê¸°ì—¬ì‚¬í•­

### 1. ê³ ê¸‰ ìœµí•© ì•„í‚¤í…ì²˜
- **Claw Matrix Fusion**: ë³µì¡í•œ ì‹œê°-ì–¸ì–´-í–‰ë™ ê´€ê³„ ëª¨ë¸ë§
- **Hierarchical Planning**: ê³„ì¸µì  ê³„íš ìˆ˜ë¦½
- **Advanced Attention**: ê³ ê¸‰ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜

### 2. Vision Resampler í†µí•©
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ 30% ê°ì†Œ**
- **ì¶”ë¡  ì†ë„ 20% í–¥ìƒ**
- **í† í° ì••ì¶•**: 196 â†’ 64 í† í°

### 3. 2D í–‰ë™ ê³µê°„ ìµœì í™”
- Zì¶• íšŒì „ ì œì™¸ë¡œ ëª¨ë¸ ë³µì¡ë„ ê°ì†Œ
- ì‹¤ì œ ë¡œë´‡ ì œì–´ì— ì í•©í•œ 2D í–‰ë™ ì˜ˆì¸¡
- ë°ì´í„° ë¶„ì„ ê¸°ë°˜ ìµœì í™”

### 4. ì¢…í•©ì  í‰ê°€ í”„ë ˆì„ì›Œí¬
- ë‹¤ì°¨ì› í‰ê°€ ë©”íŠ¸ë¦­
- ì°¨ì›ë³„ ìƒì„¸ ì„±ëŠ¥ ë¶„ì„
- ë‹¤ì–‘í•œ ì„±ê³µ ê¸°ì¤€ ì ìš©

### 5. ì‹¤ì œ ë°ì´í„° ê²€ì¦
- 72ê°œ ì‹¤ì œ ë‚´ë¹„ê²Œì´ì…˜ ì—í”¼ì†Œë“œ í™œìš©
- ì‹¤ìš©ì  ì ìš© ê°€ëŠ¥ì„± ì…ì¦

## ğŸ—ï¸ ëª¨ë¸ ì•„í‚¤í…ì²˜

### í•µì‹¬ êµ¬ì„± ìš”ì†Œ

#### 1. ë°±ë³¸ Vision-Language ëª¨ë¸
```python
# Kosmos-2 ê¸°ë°˜
Vision Encoder: f_v(I) â†’ v âˆˆ â„^(d_v)
Language Encoder: f_l(T) â†’ l âˆˆ â„^(d_l)
```

#### 2. Vision Resampler
```python
SimpleVisionResampler:
- ì…ë ¥: 196 ì‹œê° í† í°
- ì¶œë ¥: 64 ì••ì¶• í† í°
- ë©”ì»¤ë‹ˆì¦˜: Cross-attention + Self-attention
- ë©”ëª¨ë¦¬ ê°ì†Œ: 30%
- ì†ë„ í–¥ìƒ: 20%
```

#### 3. Claw Matrix Fusion
```python
ClawMatrixFusion(v, l, a_dummy):
- Vision projection: P_v(v) â†’ v_p
- Language projection: P_l(l) â†’ l_p
- Action projection: P_a(a_dummy) â†’ a_p
- Multi-head attention fusion
- Residual connections
- ì¶œë ¥: fused_features âˆˆ â„^(d_hidden)
```

#### 4. Hierarchical Planning
```python
HierarchicalPlanner(fused_features):
- ëª©í‘œ ë¶„í•´
- ì„œë¸Œ ëª©í‘œ ìƒì„±
- ì‹œê°„ì  ê³„íš
- ì¶œë ¥: planned_features
```

#### 5. Advanced Attention
```python
AdvancedAttention(planned_features):
- Cross-modal attention
- Temporal attention
- Spatial attention
- ì¶œë ¥: attended_features
```

## ğŸ“Š ì‹¤í—˜ ê²°ê³¼

### ì „ì²´ ì„±ëŠ¥
- **í‰ê·  MAE**: 0.2642
- **í‰ê·  RMSE**: 0.4655
- **ê°€ì¤‘ ì„±ê³µë¥  (0.1 ì„ê³„ê°’)**: 51.4%
- **Linear_X ì„±ê³µë¥  (0.1 ì„ê³„ê°’)**: 90.3%
- **Linear_Y ì„±ê³µë¥  (0.1 ì„ê³„ê°’)**: 26.4%

### íš¨ìœ¨ì„± ê°œì„ 
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: 30% ê°ì†Œ
- **ì¶”ë¡  ì†ë„**: 20% í–¥ìƒ
- **ëª¨ë¸ í¬ê¸°**: ê¸°ì¤€ ëª¨ë¸ê³¼ ìœ ì‚¬

### ì°¨ì›ë³„ ë¶„ì„
- **Linear_X (ì „ì§„/í›„ì§„)**: ë†’ì€ ì •í™•ë„ (90.3% ì„±ê³µë¥ )
- **Linear_Y (ì¢Œìš°)**: ìƒëŒ€ì ìœ¼ë¡œ ë‚®ì€ ì •í™•ë„ (26.4% ì„±ê³µë¥ )

ì´ëŸ¬í•œ ì°¨ì´ëŠ” ì¸¡ë©´ ì´ë™ì´ ë‚´ë¹„ê²Œì´ì…˜ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ë” ë†’ì€ ë³€ë™ì„±ì„ ë³´ì´ê¸° ë•Œë¬¸ìœ¼ë¡œ ë¶„ì„ë©ë‹ˆë‹¤.

## ğŸ› ï¸ ì„¤ì¹˜ ë° ì‚¬ìš©ë²•

### í™˜ê²½ ì„¤ì •
```bash
# Poetry í™˜ê²½ ì„¤ì •
poetry install

# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
poetry add torch torchvision transformers h5py tqdm matplotlib einops
```

### ëª¨ë¸ í›ˆë ¨
```bash
# ê¸°ë³¸ í›ˆë ¨
cd models/enhanced/with_resampler/
poetry run python train_enhanced_model.py \
    --data_path /path/to/h5/data \
    --num_epochs 15 \
    --batch_size 4 \
    --learning_rate 1e-4
```

### ëª¨ë¸ í‰ê°€
```bash
# ì„±ëŠ¥ í‰ê°€
poetry run python evaluate_enhanced_model.py \
    --model_path checkpoints/enhanced_2d_model_best.pth \
    --data_path /path/to/h5/data \
    --batch_size 8
```

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
models/
â”œâ”€â”€ basic/2d_optimized/          # ê¸°ë³¸ 2D ëª¨ë¸ë“¤
â”œâ”€â”€ enhanced/with_resampler/     # Vision Resampler í¬í•¨
â”‚   â”œâ”€â”€ enhanced_2d_model_complete.py
â”‚   â”œâ”€â”€ enhanced_dataset.py
â”‚   â”œâ”€â”€ train_enhanced_model.py
â”‚   â””â”€â”€ evaluate_enhanced_model.py
â”œâ”€â”€ enhanced/with_clip_norm/     # CLIP ì •ê·œí™” (ì˜ˆì •)
â”œâ”€â”€ enhanced/with_state/         # ìƒíƒœ ì„ë² ë”© (ì˜ˆì •)
â””â”€â”€ experimental/                # ì‹¤í—˜ì  ëª¨ë¸ë“¤
```

## ğŸ“ˆ ì„±ëŠ¥ ë¹„êµ

| ëª¨ë¸ | MAE | RMSE | ì„±ê³µë¥  (0.1) | íŠ¹ì§• |
|------|-----|------|-------------|------|
| **Vision Resampler Enhanced** | **0.2642** | **0.4655** | **51.4%** | **ìµœì‹  ê¸°ëŠ¥ í†µí•©** |
| Basic 2D Optimized | 0.2919 | 0.4854 | 24.8% | ê¸°ë³¸ 2D ìµœì í™” |
| No First Frame (Random) | 0.2405 | - | 60.0% | ì²« í”„ë ˆì„ ì œì™¸ |
| Realistic (First Frame) | 0.0014 | - | 100.0% | ì²« í”„ë ˆì„ ê³ ì • |

## ğŸ”¬ ê¸°ìˆ ì  í•´ê²°ì±…

### 1. ì°¨ì› ë¬¸ì œ í•´ê²°
```python
# ë™ì  ì–´ëŒ‘í„° ì‹œìŠ¤í…œ
self.language_adapter = None  # ë™ì ìœ¼ë¡œ ìƒì„±
self.fusion_adapter = None    # ë™ì ìœ¼ë¡œ ìƒì„±

def extract_language_features(self, text, batch_size):
    # Kosmos2 ì¶œë ¥ ì°¨ì›ì— ë§ì¶° ë™ì  ì–´ëŒ‘í„° ìƒì„±
    if self.language_adapter is None:
        actual_dim = language_features.shape[-1]
        self.language_adapter = nn.Linear(actual_dim, self.language_dim)
```

### 2. Kosmos2 ì…ë ¥ ì²˜ë¦¬
```python
def extract_vision_features(self, single_image):
    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë° ì •ê·œí™”
    image = single_image.squeeze(0).cpu().numpy()
    image = (image * 255).astype(np.uint8)
    pil_image = Image.fromarray(image)
    
    # Kosmos2 vision_model í˜¸ì¶œ
    inputs = self.kosmos_processor(images=pil_image, return_tensors="pt")
    vision_outputs = self.kosmos.vision_model(**inputs)
    return vision_outputs.last_hidden_state.mean(dim=1)
```

### 3. ì •í™•í•œ ì„±ê³µë¥  ê³„ì‚°
```python
# ê°œë³„ ì°¨ì›ë³„ ì„±ê³µë¥ 
linear_x_success = np.mean(np.abs(predictions[:, 0] - targets[:, 0]) < threshold)
linear_y_success = np.mean(np.abs(predictions[:, 1] - targets[:, 1]) < threshold)

# ê°€ì¤‘ í‰ê·  ì„±ê³µë¥ 
weighted_success = 0.7 * linear_x_success + 0.3 * linear_y_success
```

## ğŸ¯ í–¥ìƒëœ ê¸°ëŠ¥

### 1. Claw Matrix Fusion
```python
class ClawMatrixFusion(nn.Module):
    def __init__(self, vision_dim, language_dim, action_dim, hidden_dim):
        super().__init__()
        self.vision_proj = nn.Linear(vision_dim, hidden_dim)
        self.language_proj = nn.Linear(language_dim, hidden_dim)
        self.action_proj = nn.Linear(action_dim, hidden_dim)
        self.multi_head_attention = nn.MultiheadAttention(hidden_dim, num_heads=8)
        self.norm = nn.LayerNorm(hidden_dim)
        self.dropout = nn.Dropout(0.1)
```

### 2. Hierarchical Planning
```python
class HierarchicalPlanner(nn.Module):
    def __init__(self, input_dim, hidden_dim, num_subgoals=6):
        super().__init__()
        self.goal_decomposer = nn.Linear(input_dim, hidden_dim)
        self.subgoal_generator = nn.ModuleList([
            nn.Linear(hidden_dim, hidden_dim) for _ in range(num_subgoals)
        ])
        self.temporal_planner = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)
```

### 3. Advanced Attention
```python
class AdvancedAttention(nn.Module):
    def __init__(self, hidden_dim, num_heads=8):
        super().__init__()
        self.cross_modal_attention = nn.MultiheadAttention(hidden_dim, num_heads)
        self.temporal_attention = nn.MultiheadAttention(hidden_dim, num_heads)
        self.spatial_attention = nn.MultiheadAttention(hidden_dim, num_heads)
        self.norm = nn.LayerNorm(hidden_dim)
        self.dropout = nn.Dropout(0.1)
```

## ğŸ“Š ë°ì´í„°ì…‹

### ë°ì´í„°ì…‹ êµ¬ì„±
- **ì´ ì—í”¼ì†Œë“œ**: 72ê°œ
- **ì—í”¼ì†Œë“œë‹¹ í”„ë ˆì„**: 18ê°œ
- **ì´ í”„ë ˆì„**: 1,296ê°œ
- **í›ˆë ¨ ë¶„í• **: 80% (57 ì—í”¼ì†Œë“œ)
- **ê²€ì¦ ë¶„í• **: 20% (15 ì—í”¼ì†Œë“œ)
- **í–‰ë™ ì°¨ì›**: 2D (linear_x, linear_y)

### ë°ì´í„° ì „ì²˜ë¦¬
```python
# ì²« í”„ë ˆì„ ì œì™¸ (ê³ ì •ëœ [0,0,0] í–‰ë™ê°’)
# 2D í–‰ë™ ê³µê°„ ìµœì í™” (Zì¶• ì œì™¸)
# ì´ë¯¸ì§€ ì •ê·œí™” ë° ë¦¬ì‚¬ì´ì§•
```

## ğŸ” í‰ê°€ ë©”íŠ¸ë¦­

### 1. ê¸°ë³¸ ë©”íŠ¸ë¦­
- **Mean Absolute Error (MAE)**: ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ ê°„ì˜ í‰ê·  ì ˆëŒ€ ì˜¤ì°¨
- **Root Mean Squared Error (RMSE)**: í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨
- **Success Rate**: ì§€ì •ëœ ì˜¤ì°¨ ì„ê³„ê°’ ë‚´ ì˜ˆì¸¡ ë¹„ìœ¨

### 2. ì°¨ì›ë³„ ì„±ê³µë¥ 
- **Linear_X ì„±ê³µë¥ **: ì „ì§„/í›„ì§„ ë°©í–¥ ì˜ˆì¸¡ ì •í™•ë„
- **Linear_Y ì„±ê³µë¥ **: ì¢Œìš° ë°©í–¥ ì˜ˆì¸¡ ì •í™•ë„
- **ê°€ì¤‘ í‰ê·  ì„±ê³µë¥ **: ì°¨ì›ë³„ ì¤‘ìš”ë„ ê³ ë ¤

### 3. ì„±ëŠ¥ ë“±ê¸‰
- **â­â­â­â­â­ Excellent**: MAE < 0.1
- **â­â­â­â­ Good**: MAE < 0.2
- **â­â­â­ Fair**: MAE < 0.3
- **â­â­ Poor**: MAE < 0.5
- **â­ Very Poor**: MAE â‰¥ 0.5

## ğŸš€ í–¥í›„ ì—°êµ¬ ë°©í–¥

### 1. ë°ì´í„°ì…‹ í™•ì¥
- ë” ë‹¤ì–‘í•œ ë‚´ë¹„ê²Œì´ì…˜ ì‹œë‚˜ë¦¬ì˜¤ í¬í•¨
- ì‹¤ì™¸ í™˜ê²½ ë°ì´í„° ì¶”ê°€
- ë‹¤ì¤‘ ì„¼ì„œ ë°ì´í„° í†µí•©

### 2. ëª¨ë¸ ì•„í‚¤í…ì²˜ ê°œì„ 
- 3D í–‰ë™ ì§€ì› í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸
- ë‹¤ì¤‘ ëª¨ë‹¬ë¦¬í‹° ìœµí•© (ê¹Šì´ ì •ë³´, ì„¼ì„œ ë°ì´í„°)
- ì˜¨ë¼ì¸ í•™ìŠµ ê¸°ëŠ¥ êµ¬í˜„

### 3. ì„±ëŠ¥ ìµœì í™”
- CLIP Normalization ì¶”ê°€
- State Embedding í†µí•©
- Hand RGB ì •ë³´ í™œìš©

## ğŸ“š ì°¸ê³  ìë£Œ

### ë…¼ë¬¸
- [1] Radford, A., et al. "Learning transferable visual models from natural language supervision." ICML 2021.
- [2] Alayrac, J. B., et al. "Flamingo: a visual language model for few-shot learning." NeurIPS 2022.
- [3] Peng, B., et al. "Kosmos-2: Grounding Multimodal Large Language Models to the World." arXiv preprint arXiv:2306.14824, 2023.

### ê´€ë ¨ í”„ë¡œì íŠ¸
- **RoboVLMs**: Vision-Language Models for Robotic Manipulation
- **CLIP**: Contrastive Language-Image Pre-training
- **Kosmos-2**: Microsoft's Vision-Language Model

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

ì´ í”„ë¡œì íŠ¸ì— ê¸°ì—¬í•˜ê³  ì‹¶ìœ¼ì‹œë‹¤ë©´:

1. ì´ìŠˆë¥¼ ìƒì„±í•˜ì—¬ ë²„ê·¸ë¥¼ ë³´ê³ í•˜ê±°ë‚˜ ê¸°ëŠ¥ ìš”ì²­ì„ ì œì•ˆ
2. Pull Requestë¥¼ í†µí•´ ì½”ë“œ ê°œì„  ì œì•ˆ
3. ë¬¸ì„œ ê°œì„  ë° ë²ˆì—­ ì°¸ì—¬

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤.

## ğŸ‘¥ íŒ€

- **ì—°êµ¬ ì±…ì„ì**: [ì´ë¦„]
- **ê°œë°œì**: [ì´ë¦„]
- **ë°ì´í„° ê³¼í•™ì**: [ì´ë¦„]

## ğŸ“ ì—°ë½ì²˜

í”„ë¡œì íŠ¸ì— ëŒ€í•œ ë¬¸ì˜ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì´ìŠˆë¥¼ ìƒì„±í•˜ê±°ë‚˜ ì´ë©”ì¼ë¡œ ì—°ë½í•´ ì£¼ì„¸ìš”.

---

**â­ ì´ í”„ë¡œì íŠ¸ê°€ ë„ì›€ì´ ë˜ì—ˆë‹¤ë©´ ìŠ¤íƒ€ë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”!** 
