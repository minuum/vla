#!/usr/bin/env python3
"""
Vision Resampler Enhanced 2D Action Model Evaluation Script
í‰ê°€ ë©”íŠ¸ë¦­: MAE, RMSE, ì„±ê³µë¥  (ê°œë³„ ì°¨ì›ë³„, ì „ì²´)
"""

import torch
import torch.nn as nn
import numpy as np
import json
import argparse
from pathlib import Path
from tqdm import tqdm
from transformers import AutoProcessor
from enhanced_2d_model_complete import Enhanced2DActionModel
from enhanced_dataset import create_enhanced_data_loaders

def evaluate_enhanced_model(model, test_loader, device, thresholds=[0.01, 0.05, 0.1, 0.2]):
    """
    í–¥ìƒëœ ëª¨ë¸ í‰ê°€
    """
    model.eval()
    all_predictions = []
    all_targets = []
    total_loss = 0
    criterion = nn.MSELoss()
    
    print("ğŸ” ëª¨ë¸ í‰ê°€ ì¤‘...")
    with torch.no_grad():
        for batch in tqdm(test_loader, desc="í‰ê°€ ì§„í–‰"):
            images = batch['image'].to(device)
            actions = batch['action'].to(device)
            texts = batch['text']
            
            predictions = model(images, texts)
            loss = criterion(predictions, actions)
            total_loss += loss.item()
            
            all_predictions.append(predictions.cpu().numpy())
            all_targets.append(actions.cpu().numpy())
    
    # ê²°ê³¼ í†µí•©
    all_predictions = np.concatenate(all_predictions, axis=0)
    all_targets = np.concatenate(all_targets, axis=0)
    
    # ê¸°ë³¸ ë©”íŠ¸ë¦­ ê³„ì‚°
    mae = np.mean(np.abs(all_predictions - all_targets))
    rmse = np.sqrt(np.mean((all_predictions - all_targets) ** 2))
    
    # ì°¨ì›ë³„ ì„±ê³µë¥  ê³„ì‚°
    success_rates = {}
    for threshold in thresholds:
        # ê°œë³„ ì°¨ì›ë³„ ì„±ê³µë¥ 
        linear_x_success = np.mean(np.abs(all_predictions[:, 0] - all_targets[:, 0]) < threshold)
        linear_y_success = np.mean(np.abs(all_predictions[:, 1] - all_targets[:, 1]) < threshold)
        
        # ëª¨ë“  ì°¨ì›ì´ ë™ì‹œì— ì„±ê³µí•˜ëŠ” ê²½ìš°
        all_dims_success = np.mean(np.all(np.abs(all_predictions - all_targets) < threshold, axis=1))
        
        # ê°€ì¤‘ í‰ê·  ì„±ê³µë¥  (linear_xì— ë” ë†’ì€ ê°€ì¤‘ì¹˜)
        weighted_success = 0.7 * linear_x_success + 0.3 * linear_y_success
        
        success_rates[f'threshold_{threshold}'] = {
            'linear_x_success_rate': float(linear_x_success),
            'linear_y_success_rate': float(linear_y_success),
            'all_dims_success_rate': float(all_dims_success),
            'weighted_success_rate': float(weighted_success)
        }
    
    # ì°¨ì›ë³„ ìƒì„¸ ë¶„ì„
    dimension_analysis = {
        'linear_x': {
            'mae': float(np.mean(np.abs(all_predictions[:, 0] - all_targets[:, 0]))),
            'rmse': float(np.sqrt(np.mean((all_predictions[:, 0] - all_targets[:, 0]) ** 2))),
            'std': float(np.std(all_predictions[:, 0] - all_targets[:, 0])),
            'min_error': float(np.min(np.abs(all_predictions[:, 0] - all_targets[:, 0]))),
            'max_error': float(np.max(np.abs(all_predictions[:, 0] - all_targets[:, 0])))
        },
        'linear_y': {
            'mae': float(np.mean(np.abs(all_predictions[:, 1] - all_targets[:, 1]))),
            'rmse': float(np.sqrt(np.mean((all_predictions[:, 1] - all_targets[:, 1]) ** 2))),
            'std': float(np.std(all_predictions[:, 1] - all_targets[:, 1])),
            'min_error': float(np.min(np.abs(all_predictions[:, 1] - all_targets[:, 1]))),
            'max_error': float(np.max(np.abs(all_predictions[:, 1] - all_targets[:, 1])))
        }
    }
    
    return {
        'overall_metrics': {
            'mae': float(mae),
            'rmse': float(rmse),
            'avg_loss': float(total_loss / len(test_loader))
        },
        'success_rates': success_rates,
        'dimension_analysis': dimension_analysis,
        'sample_count': len(all_predictions)
    }

def main():
    parser = argparse.ArgumentParser(description='Vision Resampler Enhanced Model Evaluation')
    parser.add_argument('--model_path', type=str, required=True, help='ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ')
    parser.add_argument('--data_path', type=str, required=True, help='ë°ì´í„°ì…‹ ê²½ë¡œ')
    parser.add_argument('--batch_size', type=int, default=8, help='ë°°ì¹˜ í¬ê¸°')
    parser.add_argument('--device', type=str, default='cuda', help='ë””ë°”ì´ìŠ¤ (cuda/cpu)')
    parser.add_argument('--output_file', type=str, default='enhanced_model_evaluation_results.json', help='ê²°ê³¼ ì €ì¥ íŒŒì¼')
    
    args = parser.parse_args()
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = args.device if torch.cuda.is_available() and args.device == 'cuda' else 'cpu'
    print(f"ğŸ–¥ï¸  ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
    
    # í”„ë¡œì„¸ì„œ ë¡œë“œ
    processor = AutoProcessor.from_pretrained("microsoft/kosmos-2-patch14-224")
    
    # ëª¨ë¸ ìƒì„± ë° ë¡œë“œ
    print("ğŸ“¦ ëª¨ë¸ ë¡œë”© ì¤‘...")
    model = Enhanced2DActionModel(
        processor=processor,
        vision_dim=1024, language_dim=1024, action_dim=2, hidden_dim=512, dropout=0.2,
        use_vision_resampler=True
    )
    
    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    checkpoint = torch.load(args.model_path, map_location=device)
    if 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
    else:
        model.load_state_dict(checkpoint)
    
    model.to(device)
    print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {args.model_path}")
    
    # ë°ì´í„° ë¡œë” ìƒì„±
    print("ğŸ“Š ë°ì´í„° ë¡œë” ìƒì„± ì¤‘...")
    _, test_loader = create_enhanced_data_loaders(
        data_path=args.data_path, processor=processor, batch_size=args.batch_size,
        train_split=0.8, frame_selection='random', use_vision_resampler=True
    )
    
    print(f"ğŸ“ˆ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜: {len(test_loader.dataset)}")
    
    # ëª¨ë¸ í‰ê°€
    results = evaluate_enhanced_model(model, test_loader, device)
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*60)
    print("ğŸ¯ Vision Resampler Enhanced Model í‰ê°€ ê²°ê³¼")
    print("="*60)
    
    print(f"\nğŸ“Š ì „ì²´ ì„±ëŠ¥:")
    print(f"   MAE: {results['overall_metrics']['mae']:.4f}")
    print(f"   RMSE: {results['overall_metrics']['rmse']:.4f}")
    print(f"   í‰ê·  ì†ì‹¤: {results['overall_metrics']['avg_loss']:.4f}")
    print(f"   í‰ê°€ ìƒ˜í”Œ ìˆ˜: {results['sample_count']}")
    
    print(f"\nğŸ¯ ì„±ê³µë¥  (ì„ê³„ê°’ë³„):")
    for threshold, rates in results['success_rates'].items():
        print(f"\n   ì„ê³„ê°’ {threshold.split('_')[1]}:")
        print(f"     Linear_X ì„±ê³µë¥ : {rates['linear_x_success_rate']:.1%}")
        print(f"     Linear_Y ì„±ê³µë¥ : {rates['linear_y_success_rate']:.1%}")
        print(f"     ì „ì²´ ì°¨ì› ì„±ê³µë¥ : {rates['all_dims_success_rate']:.1%}")
        print(f"     ê°€ì¤‘ í‰ê·  ì„±ê³µë¥ : {rates['weighted_success_rate']:.1%}")
    
    print(f"\nğŸ“ˆ ì°¨ì›ë³„ ìƒì„¸ ë¶„ì„:")
    for dim, metrics in results['dimension_analysis'].items():
        print(f"\n   {dim.upper()}:")
        print(f"     MAE: {metrics['mae']:.4f}")
        print(f"     RMSE: {metrics['rmse']:.4f}")
        print(f"     í‘œì¤€í¸ì°¨: {metrics['std']:.4f}")
        print(f"     ìµœì†Œ ì˜¤ì°¨: {metrics['min_error']:.4f}")
        print(f"     ìµœëŒ€ ì˜¤ì°¨: {metrics['max_error']:.4f}")
    
    # ê²°ê³¼ ì €ì¥
    with open(args.output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ ê²°ê³¼ê°€ {args.output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # ì„±ëŠ¥ ë“±ê¸‰ í‰ê°€
    mae = results['overall_metrics']['mae']
    if mae < 0.1:
        grade = "â­â­â­â­â­ Excellent"
    elif mae < 0.2:
        grade = "â­â­â­â­ Good"
    elif mae < 0.3:
        grade = "â­â­â­ Fair"
    elif mae < 0.5:
        grade = "â­â­ Poor"
    else:
        grade = "â­ Very Poor"
    
    print(f"\nğŸ† ì„±ëŠ¥ ë“±ê¸‰: {grade} (MAE: {mae:.4f})")

if __name__ == "__main__":
    main()
