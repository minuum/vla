import os
import sys
import argparse
import logging
import json
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, random_split
from torchvision import transforms
import h5py
from PIL import Image
import numpy as np
from transformers import AutoProcessor
from tqdm import tqdm
import matplotlib.pyplot as plt

# ìƒˆë¡œìš´ ëª¨ë¸ íŒŒì¼ì—ì„œ import
from advanced_multimodal_model_v2 import AdvancedMultimodalModelV2, AdvancedMultimodalTrainerV2, create_advanced_multimodal_model_v2

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(levelname)s:%(name)s:%(message)s')
logger = logging.getLogger(__name__)

class AdvancedDataset:
    """ê³ ê¸‰ ë°ì´í„°ì…‹ - ë‹¤ì–‘í•œ ì¦ê°• ê¸°ë²• ì ìš©"""
    
    def __init__(self, data_path, transform=None, use_augmentation=True):
        self.data_path = data_path
        self.transform = transform
        self.use_augmentation = use_augmentation
        self.episodes = []
        
        # ë°ì´í„° ë¡œë“œ
        self._load_episodes()
        
        # ì¦ê°• ê¸°ë²•ë“¤
        self.augmentations = [
            self._brightness_contrast_augmentation,
            self._gaussian_noise_augmentation,
            self._rotation_augmentation,
            self._crop_augmentation,
            self._blur_augmentation
        ]
        
    def _load_episodes(self):
        """ì—í”¼ì†Œë“œ ë°ì´í„° ë¡œë“œ"""
        if os.path.isfile(self.data_path):
            # ë‹¨ì¼ H5 íŒŒì¼
            try:
                with h5py.File(self.data_path, 'r') as f:
                    if 'images' in f and 'actions' in f:
                        self.episodes.append({
                            'file': self.data_path,
                            'num_frames': len(f['images'])
                        })
                        logger.info(f"âœ… {self.data_path} ë¡œë“œ ì™„ë£Œ - {len(f['images'])} í”„ë ˆì„")
            except Exception as e:
                logger.error(f"âŒ {self.data_path} ë¡œë“œ ì˜¤ë¥˜: {e}")
        else:
            # ë””ë ‰í† ë¦¬
            for root, dirs, files in os.walk(self.data_path):
                for file in files:
                    if file.endswith('.h5'):
                        file_path = os.path.join(root, file)
                        try:
                            with h5py.File(file_path, 'r') as f:
                                if 'images' in f and 'actions' in f:
                                    self.episodes.append({
                                        'file': file_path,
                                        'num_frames': len(f['images'])
                                    })
                                    logger.info(f"âœ… {file_path} ë¡œë“œ ì™„ë£Œ - {len(f['images'])} í”„ë ˆì„")
                        except Exception as e:
                            logger.error(f"âŒ {file_path} ë¡œë“œ ì˜¤ë¥˜: {e}")
        
        logger.info(f"ì´ {len(self.episodes)}ê°œ ì—í”¼ì†Œë“œ ë¡œë“œ ì™„ë£Œ")
    
    def _brightness_contrast_augmentation(self, image):
        """ë°ê¸°/ëŒ€ë¹„ ì¦ê°•"""
        import random
        brightness_factor = random.uniform(0.8, 1.2)
        contrast_factor = random.uniform(0.8, 1.2)
        
        from PIL import ImageEnhance
        enhancer = ImageEnhance.Brightness(image)
        image = enhancer.enhance(brightness_factor)
        enhancer = ImageEnhance.Contrast(image)
        image = enhancer.enhance(contrast_factor)
        
        return image
    
    def _gaussian_noise_augmentation(self, image):
        """ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ì¦ê°•"""
        import random
        import cv2
        
        # PILì„ numpyë¡œ ë³€í™˜
        img_array = np.array(image)
        
        # ë…¸ì´ì¦ˆ ì¶”ê°€
        noise = np.random.normal(0, random.uniform(5, 15), img_array.shape)
        noisy_img = img_array + noise
        noisy_img = np.clip(noisy_img, 0, 255).astype(np.uint8)
        
        # numpyë¥¼ PILë¡œ ë³€í™˜
        return Image.fromarray(noisy_img)
    
    def _rotation_augmentation(self, image):
        """íšŒì „ ì¦ê°•"""
        import random
        angle = random.uniform(-15, 15)
        return image.rotate(angle, fillcolor=(128, 128, 128))
    
    def _crop_augmentation(self, image):
        """í¬ë¡­ ì¦ê°•"""
        import random
        
        width, height = image.size
        crop_ratio = random.uniform(0.8, 0.95)
        
        new_width = int(width * crop_ratio)
        new_height = int(height * crop_ratio)
        
        left = random.randint(0, width - new_width)
        top = random.randint(0, height - new_height)
        right = left + new_width
        bottom = top + new_height
        
        cropped = image.crop((left, top, right, bottom))
        return cropped.resize((width, height))
    
    def _blur_augmentation(self, image):
        """ë¸”ëŸ¬ ì¦ê°•"""
        import random
        import cv2
        
        # PILì„ numpyë¡œ ë³€í™˜
        img_array = np.array(image)
        
        # ë¸”ëŸ¬ ì ìš©
        kernel_size = random.choice([3, 5])
        blurred = cv2.GaussianBlur(img_array, (kernel_size, kernel_size), 0)
        
        # numpyë¥¼ PILë¡œ ë³€í™˜
        return Image.fromarray(blurred)
    
    def __len__(self):
        total_frames = 0
        for episode in self.episodes:
            total_frames += episode['num_frames']
        return total_frames
    
    def __getitem__(self, idx):
        # ì—í”¼ì†Œë“œì™€ í”„ë ˆì„ ì¸ë±ìŠ¤ ì°¾ê¸°
        current_idx = 0
        for episode in self.episodes:
            if current_idx + episode['num_frames'] > idx:
                frame_idx = idx - current_idx
                break
            current_idx += episode['num_frames']
        else:
            # ë§ˆì§€ë§‰ ì—í”¼ì†Œë“œì˜ ë§ˆì§€ë§‰ í”„ë ˆì„
            episode = self.episodes[-1]
            frame_idx = episode['num_frames'] - 1
        
        # ë°ì´í„° ë¡œë“œ
        with h5py.File(episode['file'], 'r') as f:
            # ì´ë¯¸ì§€ ë¡œë“œ
            image_data = f['images'][frame_idx]
            if len(image_data.shape) == 3:
                image = Image.fromarray(image_data)
            else:
                image = Image.fromarray(image_data, mode='RGB')
            
            # ì•¡ì…˜ ë¡œë“œ (2Dë¡œ ë³€í™˜)
            action_data = f['actions'][frame_idx]
            if len(action_data) >= 3:
                action = torch.tensor([action_data[0], action_data[1]], dtype=torch.float32)  # linear_x, linear_yë§Œ
            else:
                action = torch.tensor([0.0, 0.0], dtype=torch.float32)
            
            # í…ìŠ¤íŠ¸ (ì—í”¼ì†Œë“œ íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œ)
            episode_name = os.path.basename(episode['file'])
            text = f"Episode: {episode_name}, Frame: {frame_idx}"
        
        # ì¦ê°• ì ìš©
        if self.use_augmentation and np.random.random() < 0.3:
            augmentation = np.random.choice(self.augmentations)
            image = augmentation(image)
        
        # ë³€í™˜ ì ìš©
        if self.transform:
            image = self.transform(image)
        
        return {
            'image': image,
            'action': action,
            'text': text,
            'episode_id': episode['file']
        }

def custom_collate_fn(batch):
    """PIL ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì»¤ìŠ¤í…€ collate í•¨ìˆ˜"""
    images = [item['image'] for item in batch]
    actions = torch.stack([item['action'] for item in batch])
    texts = [item['text'] for item in batch]
    episode_ids = [item['episode_id'] for item in batch]
    
    return {
        'image': images,  # PIL ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸
        'action': actions,
        'text': texts,
        'episode_id': episode_ids
    }

def create_advanced_data_loaders(data_path, batch_size=4, train_ratio=0.7, val_ratio=0.15):
    """ê³ ê¸‰ ë°ì´í„° ë¡œë” ìƒì„±"""
    # ë°ì´í„°ì…‹ ìƒì„±
    dataset = AdvancedDataset(data_path, use_augmentation=True)
    
    # ë°ì´í„° ë¶„í• 
    total_size = len(dataset)
    train_size = int(train_ratio * total_size)
    val_size = int(val_ratio * total_size)
    test_size = total_size - train_size - val_size
    
    train_dataset, val_dataset, test_dataset = random_split(
        dataset, [train_size, val_size, test_size]
    )
    
    # ë°ì´í„° ë¡œë” ìƒì„±
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=0,
        pin_memory=True,
        collate_fn=custom_collate_fn
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=0,
        pin_memory=True,
        collate_fn=custom_collate_fn
    )
    
    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=0,
        pin_memory=True,
        collate_fn=custom_collate_fn
    )
    
    return train_loader, val_loader, test_loader

def evaluate_final_performance(model, test_loader, device, output_path):
    """ìµœì¢… ì„±ëŠ¥ í‰ê°€"""
    model.eval()
    
    all_predictions = []
    all_targets = []
    all_losses = []
    
    with torch.no_grad():
        for batch in tqdm(test_loader, desc="í‰ê°€ ì¤‘"):
            images = batch['image']  # PIL ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸
            actions = batch['action'].to(device)
            texts = batch['text']
            
            # ì˜ˆì¸¡
            predicted_actions = model(images, texts)
            
            # ì†ì‹¤ ê³„ì‚°
            loss = nn.MSELoss()(predicted_actions, actions)
            all_losses.append(loss.item())
            
            # ì˜ˆì¸¡ê³¼ íƒ€ê²Ÿ ì €ì¥
            all_predictions.append(predicted_actions.cpu())
            all_targets.append(actions.cpu())
    
    # ê²°ê³¼ ê²°í•©
    all_predictions = torch.cat(all_predictions, dim=0)
    all_targets = torch.cat(all_targets, dim=0)
    
    # ë©”íŠ¸ë¦­ ê³„ì‚°
    mse = torch.mean((all_predictions - all_targets) ** 2).item()
    mae = torch.mean(torch.abs(all_predictions - all_targets)).item()
    rmse = torch.sqrt(torch.mean((all_predictions - all_targets) ** 2)).item()
    
    # RÂ² ìŠ¤ì½”ì–´
    ss_res = torch.sum((all_targets - all_predictions) ** 2)
    ss_tot = torch.sum((all_targets - torch.mean(all_targets)) ** 2)
    r2 = 1 - (ss_res / ss_tot).item()
    
    # ì •í™•ë„ ê³„ì‚° (ë‹¤ì–‘í•œ ì„ê³„ê°’)
    thresholds = [0.1, 0.2, 0.5, 1.0]
    accuracies = {}
    
    for threshold in thresholds:
        within_threshold = torch.all(torch.abs(all_predictions - all_targets) < threshold, dim=1)
        accuracy = torch.mean(within_threshold.float()).item() * 100
        accuracies[f'acc_{threshold}'] = accuracy
    
    # ê°œë³„ ì¶• ì •í™•ë„
    axis_accuracies = {}
    for i, axis_name in enumerate(['linear_x', 'linear_y']):
        for threshold in thresholds:
            within_threshold = torch.abs(all_predictions[:, i] - all_targets[:, i]) < threshold
            accuracy = torch.mean(within_threshold.float()).item() * 100
            axis_accuracies[f'{axis_name}_acc_{threshold}'] = accuracy
    
    # ê²°ê³¼ ì €ì¥
    results = {
        'mse': mse,
        'mae': mae,
        'rmse': rmse,
        'r2': r2,
        'accuracies': accuracies,
        'axis_accuracies': axis_accuracies,
        'num_samples': len(all_predictions)
    }
    
    with open(os.path.join(output_path, 'final_evaluation.json'), 'w') as f:
        json.dump(results, f, indent=2)
    
    # ê²°ê³¼ ì¶œë ¥
    logger.info("ğŸ“Š ìµœì¢… ì„±ëŠ¥ í‰ê°€ ê²°ê³¼:")
    logger.info(f"  - MSE: {mse:.6f}")
    logger.info(f"  - MAE: {mae:.6f}")
    logger.info(f"  - RMSE: {rmse:.6f}")
    logger.info(f"  - RÂ² Score: {r2:.4f}")
    
    for threshold, acc in accuracies.items():
        logger.info(f"  - ì •í™•ë„ ({threshold}): {acc:.2f}%")
    
    for axis, acc in axis_accuracies.items():
        logger.info(f"  - {axis}: {acc:.2f}%")
    
    return results

def main():
    parser = argparse.ArgumentParser(description='Case 3: ê³ ê¸‰ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ í›ˆë ¨')
    parser.add_argument('--data_path', type=str, required=True, help='ë°ì´í„° ê²½ë¡œ')
    parser.add_argument('--output_dir', type=str, default='case3_results', help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    parser.add_argument('--num_epochs', type=int, default=10, help='ì—í¬í¬ ìˆ˜')
    parser.add_argument('--batch_size', type=int, default=4, help='ë°°ì¹˜ í¬ê¸°')
    parser.add_argument('--learning_rate', type=float, default=1e-4, help='í•™ìŠµë¥ ')
    parser.add_argument('--patience', type=int, default=5, help='ì¡°ê¸° ì¢…ë£Œ ì¸ë‚´ì‹¬')
    
    args = parser.parse_args()
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    logger.info(f"ğŸš€ ë””ë°”ì´ìŠ¤: {device}")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(args.output_dir, exist_ok=True)
    
    # Kosmos2 í”„ë¡œì„¸ì„œ ë¡œë“œ
    processor = AutoProcessor.from_pretrained("microsoft/kosmos-2-patch14-224")
    logger.info("âœ… Kosmos2 í”„ë¡œì„¸ì„œ ë¡œë“œ ì™„ë£Œ")
    
    # ë°ì´í„° ë¡œë” ìƒì„±
    train_loader, val_loader, test_loader = create_advanced_data_loaders(
        args.data_path, args.batch_size
    )
    logger.info(f"âœ… ë°ì´í„° ë¡œë” ìƒì„± ì™„ë£Œ - í›ˆë ¨: {len(train_loader)}, ê²€ì¦: {len(val_loader)}, í…ŒìŠ¤íŠ¸: {len(test_loader)}")
    
    # ëª¨ë¸ ìƒì„±
    model, trainer = create_advanced_multimodal_model_v2(
        processor=processor,
        device=device,
        vision_dim=1024,
        language_dim=2048,  # Kosmos2 text ëª¨ë¸ ì¶œë ¥ ì°¨ì›
        action_dim=2,
        hidden_dim=512,
        dropout=0.3,
        use_hierarchical_planning=True
    )
    logger.info("âœ… ê³ ê¸‰ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ V2 ìƒì„± ì™„ë£Œ")
    
    # í›ˆë ¨ ë£¨í”„
    best_mae = float('inf')
    patience_counter = 0
    training_history = []
    
    logger.info("ğŸ¯ Case 3 í›ˆë ¨ ì‹œì‘!")
    
    for epoch in range(args.num_epochs):
        # í›ˆë ¨
        model.train()
        train_losses = []
        train_pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{args.num_epochs} [Train]")
        
        for batch in train_pbar:
            try:
                loss = trainer.train_step(batch)
                train_losses.append(loss)
                train_pbar.set_postfix({'loss': f'{loss:.4f}'})
            except Exception as e:
                logger.error(f"âŒ í›ˆë ¨ ë°°ì¹˜ ì˜¤ë¥˜: {e}")
                continue
        
        avg_train_loss = np.mean(train_losses)
        
        # ê²€ì¦
        model.eval()
        val_losses = []
        val_maes = []
        val_pbar = tqdm(val_loader, desc=f"Epoch {epoch+1}/{args.num_epochs} [Val]")
        
        for batch in val_pbar:
            try:
                loss, mae = trainer.validate_step(batch)
                val_losses.append(loss)
                val_maes.append(mae)
                val_pbar.set_postfix({'loss': f'{loss:.4f}', 'mae': f'{mae:.4f}'})
            except Exception as e:
                logger.error(f"âŒ ê²€ì¦ ë°°ì¹˜ ì˜¤ë¥˜: {e}")
                continue
        
        avg_val_loss = np.mean(val_losses)
        avg_val_mae = np.mean(val_maes)
        
        # íˆìŠ¤í† ë¦¬ ì €ì¥
        training_history.append({
            'epoch': epoch + 1,
            'train_loss': avg_train_loss,
            'val_loss': avg_val_loss,
            'val_mae': avg_val_mae
        })
        
        logger.info(f"ğŸ“Š Epoch {epoch+1}/{args.num_epochs} - "
                   f"Train Loss: {avg_train_loss:.4f}, "
                   f"Val Loss: {avg_val_loss:.4f}, "
                   f"Val MAE: {avg_val_mae:.4f}")
        
        # ëª¨ë¸ ì €ì¥
        if avg_val_mae < best_mae:
            best_mae = avg_val_mae
            patience_counter = 0
            
            # ëª¨ë¸ ì €ì¥
            torch.save({
                'epoch': epoch + 1,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': trainer.optimizer.state_dict(),
                'best_mae': best_mae,
                'training_history': training_history
            }, os.path.join(args.output_dir, 'best_model.pth'))
            
            logger.info(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ (MAE: {best_mae:.4f})")
        else:
            patience_counter += 1
        
        # ì¡°ê¸° ì¢…ë£Œ
        if patience_counter >= args.patience:
            logger.info(f"â¹ï¸ ì¡°ê¸° ì¢…ë£Œ (patience: {args.patience})")
            break
    
    # ìµœì¢… ì„±ëŠ¥ í‰ê°€
    logger.info("ğŸ” ìµœì¢… ì„±ëŠ¥ í‰ê°€ ì¤‘...")
    final_results = evaluate_final_performance(model, test_loader, device, args.output_dir)
    
    # í›ˆë ¨ íˆìŠ¤í† ë¦¬ ì €ì¥
    with open(os.path.join(args.output_dir, 'training_history.json'), 'w') as f:
        json.dump(training_history, f, indent=2)
    
    # ëª©í‘œ ë‹¬ì„± ì—¬ë¶€ í™•ì¸
    target_mae = 0.5
    achieved = best_mae < target_mae
    
    logger.info(f"âœ… Case 3 í›ˆë ¨ ì™„ë£Œ! - ìµœê³  MAE: {best_mae:.6f} - "
               f"ëª©í‘œ ë‹¬ì„±: {'âœ…' if achieved else 'âŒ'} (ëª©í‘œ: < {target_mae}) - "
               f"ìµœì¢… ì—í¬í¬: {epoch+1} - "
               f"ê²°ê³¼ ì €ì¥: {args.output_dir}")

if __name__ == '__main__':
    main()
