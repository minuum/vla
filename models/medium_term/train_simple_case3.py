#!/usr/bin/env python3
"""
Case 3 í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ - Case 1 ê¸°ë°˜
"""
import os
import sys
import argparse
import logging
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, random_split
from transformers import AutoProcessor
import numpy as np
from sklearn.metrics import r2_score
import json
from datetime import datetime

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from simple_case3_model import create_simple_case3_model
from simple_case3_dataset import SimpleCase3Dataset

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(levelname)s:%(name)s:%(message)s')
logger = logging.getLogger(__name__)

def create_simple_case3_data_loaders(data_path, processor, batch_size=2,
                                    train_split=0.7, val_split=0.15, test_split=0.15):
    """Case 3 ë°ì´í„° ë¡œë” ìƒì„±"""
    logger.info("ğŸ“Š ê°„ë‹¨í•œ ë°ì´í„° ë¡œë” ìƒì„± ì¤‘...")
    
    # ì „ì²´ ë°ì´í„°ì…‹ ìƒì„±
    full_dataset = SimpleCase3Dataset(
        data_path=data_path,
        processor=processor,
        frame_selection='random'  # ëœë¤ í”„ë ˆì„ ì‚¬ìš©
    )
    
    # ë°ì´í„°ì…‹ ë¶„í• 
    total_size = len(full_dataset)
    train_size = int(train_split * total_size)
    val_size = int(val_split * total_size)
    test_size = total_size - train_size - val_size
    
    train_dataset, val_dataset, test_dataset = random_split(
        full_dataset, [train_size, val_size, test_size]
    )
    
    # DataLoader ìƒì„±
    train_loader = DataLoader(
        train_dataset, 
        batch_size=batch_size, 
        shuffle=True,
        collate_fn=custom_collate_fn
    )
    
    val_loader = DataLoader(
        val_dataset, 
        batch_size=batch_size, 
        shuffle=False,
        collate_fn=custom_collate_fn
    )
    
    test_loader = DataLoader(
        test_dataset, 
        batch_size=batch_size, 
        shuffle=False,
        collate_fn=custom_collate_fn
    )
    
    logger.info("âœ… Simple Case 3 Data Loaders ìƒì„± ì™„ë£Œ")
    return train_loader, val_loader, test_loader

def custom_collate_fn(batch):
    """ì»¤ìŠ¤í…€ ë°°ì¹˜ í•¨ìˆ˜"""
    images = [item['image'] for item in batch]
    texts = [item['text'] for item in batch]
    actions = torch.stack([item['action'] for item in batch])
    
    return {
        'image': images,
        'text': texts,
        'action': actions
    }

def train_simple_case3_model(data_path, output_dir, num_epochs=5, batch_size=2, 
                            learning_rate=5e-5, weight_decay=1e-3, patience=5):
    """Case 3 ëª¨ë¸ í›ˆë ¨"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    logger.info(f"ğŸš€ Case 3 í›ˆë ¨ ì‹œì‘ - ë””ë°”ì´ìŠ¤: {device}")
    
    # Kosmos2 í”„ë¡œì„¸ì„œ ë¡œë“œ
    logger.info("ğŸ“¥ Kosmos2 í”„ë¡œì„¸ì„œ ë¡œë“œ ì¤‘...")
    processor = AutoProcessor.from_pretrained("microsoft/kosmos-2-patch14-224")
    
    # ë°ì´í„° ë¡œë” ìƒì„±
    train_loader, val_loader, test_loader = create_simple_case3_data_loaders(
        data_path, processor, batch_size
    )
    
    # ëª¨ë¸ ë° í›ˆë ¨ê¸° ìƒì„±
    logger.info("ğŸ¤– ê°„ë‹¨í•œ ëª¨ë¸ ë° í›ˆë ¨ê¸° ìƒì„± ì¤‘...")
    model, trainer = create_simple_case3_model(processor, device)
    
    # í›ˆë ¨ ì„¤ì •
    logger.info("ğŸ¯ í›ˆë ¨ ì„¤ì •:")
    logger.info(f"   - ì—í¬í¬: {num_epochs}")
    logger.info(f"   - ë°°ì¹˜ í¬ê¸°: {batch_size}")
    logger.info(f"   - í•™ìŠµë¥ : {learning_rate}")
    logger.info(f"   - Weight Decay: {weight_decay}")
    logger.info(f"   - ì¡°ê¸° ì¢…ë£Œ ì¸ë‚´ì‹¬: {patience}")
    
    # í›ˆë ¨ ë£¨í”„
    best_val_loss = float('inf')
    patience_counter = 0
    
    for epoch in range(num_epochs):
        logger.info(f"\nğŸ“ˆ Epoch {epoch+1}/{num_epochs}")
        
        # í›ˆë ¨
        model.train()
        train_losses = []
        
        for batch_idx, batch in enumerate(train_loader):
            try:
                loss = trainer.train_step(batch)
                if loss is not None:
                    train_losses.append(loss)
            except Exception as e:
                logger.error(f"âŒ í›ˆë ¨ ë°°ì¹˜ ì˜¤ë¥˜: {e}")
                continue
        
        # ê²€ì¦
        model.eval()
        val_losses = []
        val_maes = []
        
        with torch.no_grad():
            for batch_idx, batch in enumerate(val_loader):
                try:
                    loss, mae = trainer.validate_step(batch)
                    if loss is not None and mae is not None:
                        val_losses.append(loss)
                        val_maes.append(mae)
                except Exception as e:
                    logger.error(f"âŒ ê²€ì¦ ë°°ì¹˜ ì˜¤ë¥˜: {e}")
                    continue
        
        # í‰ê·  ê³„ì‚°
        avg_train_loss = np.mean(train_losses) if train_losses else float('inf')
        avg_val_loss = np.mean(val_losses) if val_losses else float('inf')
        avg_val_mae = np.mean(val_maes) if val_maes else float('inf')
        
        # ê²°ê³¼ ì¶œë ¥
        logger.info(f"ğŸ“Š Epoch {epoch+1} ê²°ê³¼:")
        logger.info(f"   - í›ˆë ¨ ì†ì‹¤: {avg_train_loss:.6f}")
        logger.info(f"   - ê²€ì¦ ì†ì‹¤: {avg_val_loss:.6f}")
        logger.info(f"   - ê²€ì¦ MAE: {avg_val_mae:.6f}")
        logger.info(f"   - í•™ìŠµë¥ : {trainer.optimizer.param_groups[0]['lr']:.2e}")
        
        # ì¡°ê¸° ì¢…ë£Œ ì²´í¬
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            patience_counter = 0
            
            # ìµœê³  ëª¨ë¸ ì €ì¥
            checkpoint_path = os.path.join(output_dir, f"best_case3_model.pth")
            trainer.save_checkpoint(checkpoint_path, epoch+1, avg_val_loss, avg_val_mae)
        else:
            patience_counter += 1
            logger.info(f"â³ ì¡°ê¸° ì¢…ë£Œ ì¹´ìš´í„°: {patience_counter}/{patience}")
        
        # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§
        trainer.scheduler.step()
        
        # ì¡°ê¸° ì¢…ë£Œ
        if patience_counter >= patience:
            logger.info("ğŸ›‘ ì¡°ê¸° ì¢…ë£Œ!")
            break
    
    # ìµœì¢… ì„±ëŠ¥ í‰ê°€
    logger.info("ğŸ“Š ìµœì¢… ì„±ëŠ¥ í‰ê°€ ì¤‘...")
    test_loss, test_mae, test_results = evaluate_final_performance(model, test_loader, device)
    
    # ê²°ê³¼ ì €ì¥
    results = {
        'case': 'Case 3',
        'model_type': 'Simple Case 3 Model',
        'training_config': {
            'num_epochs': num_epochs,
            'batch_size': batch_size,
            'learning_rate': learning_rate,
            'weight_decay': weight_decay,
            'patience': patience
        },
        'final_performance': {
            'test_loss': test_loss,
            'test_mae': test_mae,
            'target_achieved': test_mae < 0.3 if test_mae != float('inf') else False
        },
        'test_results': test_results,
        'timestamp': datetime.now().isoformat()
    }
    
    results_path = os.path.join(output_dir, 'case3_results.json')
    with open(results_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    logger.info(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {results_path}")
    logger.info("âœ… Case 3 í›ˆë ¨ ì™„ë£Œ!")
    
    return model, trainer

def evaluate_final_performance(model, test_loader, device):
    """ìµœì¢… ì„±ëŠ¥ í‰ê°€"""
    model.eval()
    all_predictions = []
    all_targets = []
    test_losses = []
    test_maes = []
    
    with torch.no_grad():
        for batch_idx, batch in enumerate(test_loader):
            try:
                images = batch['image']
                texts = batch['text']
                targets = batch['action'].to(device)
                
                predictions = model(images, texts)
                
                # ì†ì‹¤ ê³„ì‚°
                criterion = nn.HuberLoss(delta=0.1)
                loss = criterion(predictions, targets)
                mae = torch.mean(torch.abs(predictions - targets))
                
                test_losses.append(loss.item())
                test_maes.append(mae.item())
                
                all_predictions.append(predictions.cpu().numpy())
                all_targets.append(targets.cpu().numpy())
                
            except Exception as e:
                logger.error(f"âŒ í…ŒìŠ¤íŠ¸ ë°°ì¹˜ ì˜¤ë¥˜: {e}")
                continue
    
    if not test_losses:
        logger.error("âŒ ì„±ê³µì ì¸ í…ŒìŠ¤íŠ¸ ë°°ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤")
        return float('inf'), float('inf'), {}
    
    # í‰ê·  ê³„ì‚°
    avg_test_loss = np.mean(test_losses)
    avg_test_mae = np.mean(test_maes)
    
    # ì˜ˆì¸¡ ê²°ê³¼ ë¶„ì„
    all_predictions = np.concatenate(all_predictions, axis=0)
    all_targets = np.concatenate(all_targets, axis=0)
    
    # ì •í™•ë„ ê³„ì‚° (ì‹¤ì œ ë¡œë´‡ ì œì–´ ê´€ì )
    thresholds = [0.3, 0.2, 0.15]  # 0.3m/s, 0.2m/s, 0.15m/s
    accuracies = {}
    
    for threshold in thresholds:
        # ì „ì²´ ì •í™•ë„ (ëª¨ë“  ì¶•ì´ ì„ê³„ê°’ ë‚´)
        all_axes_success = np.all(np.abs(all_predictions - all_targets) < threshold, axis=1)
        accuracies[f'accuracy_{threshold}'] = np.mean(all_axes_success) * 100
        
        # ê°œë³„ ì¶• ì •í™•ë„
        for i, axis_name in enumerate(['linear_x', 'linear_y']):
            axis_success = np.abs(all_predictions[:, i] - all_targets[:, i]) < threshold
            accuracies[f'{axis_name}_{threshold}'] = np.mean(axis_success) * 100
    
    # ì‹¤ì œ ë¡œë´‡ ì œì–´ ì„±ëŠ¥ ì§€í‘œ ì¶”ê°€
    # 1. ì¶”ì  ì„±ëŠ¥ (ëª©í‘œ ì§€ì  ê·¼ì²˜ ë„ë‹¬ë¥ )
    tracking_threshold = 0.5  # 0.5m/s ì´ë‚´ë©´ ì„±ê³µ
    tracking_success = np.all(np.abs(all_predictions - all_targets) < tracking_threshold, axis=1)
    tracking_accuracy = np.mean(tracking_success) * 100
    
    # 2. ë°©í–¥ ì •í™•ë„ (ë¶€í˜¸ê°€ ë§ëŠ”ì§€)
    direction_correct_x = np.sign(all_predictions[:, 0]) == np.sign(all_targets[:, 0])
    direction_correct_y = np.sign(all_predictions[:, 1]) == np.sign(all_targets[:, 1])
    direction_accuracy_x = np.mean(direction_correct_x) * 100
    direction_accuracy_y = np.mean(direction_correct_y) * 100
    
    # 3. í¬ê¸° ìˆœì„œ ì •í™•ë„ (ìƒëŒ€ì  í¬ê¸°ê°€ ë§ëŠ”ì§€)
    magnitude_order_correct = (
        (all_predictions[:, 0] > all_predictions[:, 1]) == (all_targets[:, 0] > all_targets[:, 1])
    )
    magnitude_order_accuracy = np.mean(magnitude_order_correct) * 100
    
    # RÂ² ì ìˆ˜ ê³„ì‚° (ëª¨ë¸ì˜ ì˜ˆì¸¡ ëŠ¥ë ¥ ì¸¡ì •)
    r2_scores = {}
    for i, axis_name in enumerate(['linear_x', 'linear_y']):
        r2_scores[f'{axis_name}_r2'] = r2_score(all_targets[:, i], all_predictions[:, i])
    
    # ìƒê´€ê´€ê³„ ê³„ì‚°
    correlations = {}
    for i, axis_name in enumerate(['linear_x', 'linear_y']):
        correlations[f'{axis_name}_corr'] = np.corrcoef(all_targets[:, i], all_predictions[:, i])[0, 1]
    
    # ê²°ê³¼ ì¶œë ¥
    logger.info(f"ğŸ“Š Case 3 ìµœì¢… ì„±ëŠ¥ ê²°ê³¼:")
    logger.info(f"   - í…ŒìŠ¤íŠ¸ ì†ì‹¤: {avg_test_loss:.6f}")
    logger.info(f"   - í…ŒìŠ¤íŠ¸ MAE: {avg_test_mae:.6f}")
    logger.info(f"   - ëª©í‘œ ë‹¬ì„±: {'âœ…' if avg_test_mae < 0.3 else 'âŒ'} (ëª©í‘œ: < 0.3)")
    
    # ì‹¤ì œ ë¡œë´‡ ì œì–´ ì„±ëŠ¥
    logger.info(f"   - ì¶”ì  ì„±ëŠ¥ (0.5m/s): {tracking_accuracy:.2f}%")
    logger.info(f"   - ë°©í–¥ ì •í™•ë„:")
    logger.info(f"     - linear_x: {direction_accuracy_x:.2f}%")
    logger.info(f"     - linear_y: {direction_accuracy_y:.2f}%")
    logger.info(f"   - í¬ê¸° ìˆœì„œ ì •í™•ë„: {magnitude_order_accuracy:.2f}%")
    
    for threshold in thresholds:
        logger.info(f"   - ì •í™•ë„ ({threshold}): {accuracies[f'accuracy_{threshold}']:.2f}%")
    
    # RÂ² ì ìˆ˜ ì¶œë ¥
    logger.info(f"   - RÂ² ì ìˆ˜:")
    logger.info(f"     - linear_x: {r2_scores['linear_x_r2']:.4f}")
    logger.info(f"     - linear_y: {r2_scores['linear_y_r2']:.4f}")
    
    # ìƒê´€ê´€ê³„ ì¶œë ¥
    logger.info(f"   - ìƒê´€ê´€ê³„:")
    logger.info(f"     - linear_x: {correlations['linear_x_corr']:.4f}")
    logger.info(f"     - linear_y: {correlations['linear_y_corr']:.4f}")
    
    test_results = {
        'test_loss': avg_test_loss,
        'test_mae': avg_test_mae,
        'target_achieved': avg_test_mae < 0.3,
        'accuracies': accuracies,
        'tracking_accuracy': tracking_accuracy,
        'direction_accuracy': {
            'linear_x': direction_accuracy_x,
            'linear_y': direction_accuracy_y
        },
        'magnitude_order_accuracy': magnitude_order_accuracy,
        'r2_scores': r2_scores,
        'correlations': correlations,
        'predictions': all_predictions.tolist(),
        'targets': all_targets.tolist()
    }
    
    return avg_test_loss, avg_test_mae, test_results

def main():
    parser = argparse.ArgumentParser(description='Case 3 í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸')
    parser.add_argument('--data_path', type=str, required=True, help='ë°ì´í„° ê²½ë¡œ')
    parser.add_argument('--output_dir', type=str, required=True, help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    parser.add_argument('--num_epochs', type=int, default=5, help='ì—í¬í¬ ìˆ˜')
    parser.add_argument('--batch_size', type=int, default=2, help='ë°°ì¹˜ í¬ê¸°')
    parser.add_argument('--learning_rate', type=float, default=5e-5, help='í•™ìŠµë¥ ')
    parser.add_argument('--weight_decay', type=float, default=1e-3, help='Weight decay')
    parser.add_argument('--patience', type=int, default=5, help='ì¡°ê¸° ì¢…ë£Œ ì¸ë‚´ì‹¬')
    
    args = parser.parse_args()
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(args.output_dir, exist_ok=True)
    
    # í›ˆë ¨ ì‹¤í–‰
    model, trainer = train_simple_case3_model(
        data_path=args.data_path,
        output_dir=args.output_dir,
        num_epochs=args.num_epochs,
        batch_size=args.batch_size,
        learning_rate=args.learning_rate,
        weight_decay=args.weight_decay,
        patience=args.patience
    )

if __name__ == "__main__":
    main()
