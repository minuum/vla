=========================================
Mobile VLA LoRA Fine-tuning
Date: 2025-11-14
=========================================

üìÑ Config: /home/billy/25-1kp/vla/Mobile_VLA/configs/mobile_vla_20251114_lora.json
üîß Device: CUDA
üì¶ Model: Kosmos-2 with LoRA

üîç CUDA ÌôïÏù∏...
CUDA available: True
CUDA device: NVIDIA RTX A5000

üìä Îç∞Ïù¥ÌÑ∞ÏÖã ÌôïÏù∏...
  - Found 219 episodes matching pattern 'episode_2025111*.h5'
  ‚úÖ Episodes found

üöÄ LoRA Fine-tuning ÏãúÏûë...
   - Using RoboVLMs main.py
   - Dataset: MobileVLAH5Dataset
   - LoRA: r=32, alpha=16, dropout=0.1
   - Epochs: 20

[rank: 0] Seed set to 123
Using 16bit Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
/home/billy/.cache/pypoetry/virtualenvs/vla-tensorrt-sSUdR_m1-py3.10/lib/python3.10/site-packages/transformers/models/auto/modeling_auto.py:2199: FutureWarning: The class `AutoModelForVision2Seq` is deprecated and will be removed in v5.0. Please use `AutoModelForImageTextToText` instead.
  warnings.warn(
config not in config. The value is /home/billy/25-1kp/vla/Mobile_VLA/configs/mobile_vla_20251114_lora.json.
log_dir not in config. The value is None.
output_dir not in config. The value is None.
data_dir not in config. The value is None.
annotation_file not in config. The value is None.
data_subfolder not in config. The value is None.
task_num not in config. The value is None.
use_multi_modal_emb not in config. The value is False.
no_video_pretrained_model not in config. The value is False.
finetune not in config. The value is False.
llm not in config. The value is {'type': None, 'n_embd': None, 'n_layer': None, 'n_head': None}.
--------------- model configs ---------------
{'robovlm_name': 'RoboKosMos', 'exp_name': 'mobile_vla_lora_20251114', 'parent': None, 'task_name': 'mobile_vla_finetune', 'model': 'kosmos', 'model_url': 'https://huggingface.co/microsoft/kosmos-2-patch14-224', 'seq_len': 1, 'image_size': 224, 'image_mean': [0.48145466, 0.4578275, 0.40821073], 'image_std': [0.26862954, 0.26130258, 0.27577711], 'window_size': 8, 'fwd_pred_next_n': 10, 'arm_gripper_loss_ratio': 0.0, 'cap_loss_ratio': 0.0, 'fwd_loss_ratio': 0, 'seed': 123, 'batch_size': 1, 'num_workers': 2, 'data_scale': 1, 'optimizer': 'adamw', 'learning_rate': 0.0001, 'min_lr_scale': 0.001, 'weight_decay': 0.01, 'warmup_epochs': 0.1, 'warmup_steps': 0, 'warmup_ratio': None, 'use_hand_rgb': False, 'use_time_causal_attn': False, 'use_mim_obs_loss': False, 'use_pixel_loss': False, 'use_obs_queries': True, 'use_vision_resampler': False, 'vision_masked_ratio': 0.9, 'use_tube_mask': False, 'cache_root': 'runs/cache/kosmos', 'model_load_path': None, 'model_load_source': 'torch', 'resume': None, 'model_path': '.vlms/kosmos-2-patch14-224', 'model_config': '.vlms/kosmos-2-patch14-224/config.json', 'gpus': 1, 'num_nodes': 1, 'train_setup': {'precision': '16-mixed', 'predict_action': True, 'predict_forward': False, 'predict_forward_hand': False, 'predict_caption': False, 'train_vision': False, 'bits': -1, 'freeze_mm_mlp_adapter': False, 'freeze_backbone': True, 'freeze_resampler': False, 'tune_mm_mlp_adapter': False, 'mm_use_im_start_end': False, 'mm_use_im_patch_token': False, 'gradient_checkpointing': False, 'lora_enable': True, 'mm_projector_lr': 0.0001, 'lora_r': 32, 'lora_alpha': 16, 'lora_dropout': 0.1, 'lora_bias': 'none', 'train_text_embedding': False}, 'vision_resampler': {'vis_dim': 1024, 'depth': 8, 'dim_head': 64, 'heads': 8, 'num_latents': 64}, 'act_encoder': None, 'trainer_type': 'MobileVLATrainer', 'act_head': {'type': 'MobileVLALSTMDecoder', 'hidden_size': 512, 'action_dim': 2, 'down_sample': 'none', 'latent': 1, 'fwd_pred_next_n': 10, 'window_size': 8, 'action_space': 'continuous', 'with_history': True, 'history_type': 'post'}, 'fwd_head': None, 'tokenizer': {'type': 'AutoProcessor', 'pretrained_model_name_or_path': '.vlms/kosmos-2-patch14-224', 'tokenizer_type': 'kosmos', 'max_text_len': 256, 'additional_special_tokens': None}, 'vlm': {'type': 'AutoModelForVision2Seq', 'name': 'kosmos', 'pretrained_model_name_or_path': '.vlms/kosmos-2-patch14-224'}, 'trainer': {'accelerator': 'gpu', 'strategy': 'auto', 'precision': '16-mixed', 'logger': ['tensorboard', 'csv'], 'gradient_clip_val': 1.0, 'use_distributed_sampler': False, 'log_every_n_steps': 5, 'max_epochs': 20, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'max_steps': -1, 'accumulate_grad_batches': 8}, 'train_dataset': {'type': 'MobileVLAH5Dataset', 'data_dir': '/home/billy/25-1kp/vla/ROS_action/mobile_vla_dataset', 'episode_pattern': 'episode_2025111*.h5', 'shift_first': False, 'model_name': 'kosmos', 'rgb_pad': 10, 'train_split': 0.8}, 'val_dataset': {'type': 'MobileVLAH5Dataset', 'data_dir': '/home/billy/25-1kp/vla/ROS_action/mobile_vla_dataset', 'episode_pattern': 'episode_2025111*.h5', 'model_name': 'kosmos', 'train_split': 0.8, 'is_validation': True}, 'norm_action': True, 'norm_min': -1.0, 'norm_max': 1.0, 'raw_config_path': '/home/billy/25-1kp/vla/Mobile_VLA/configs/mobile_vla_20251114_lora.json', 'config': '/home/billy/25-1kp/vla/Mobile_VLA/configs/mobile_vla_20251114_lora.json', 'log_dir': 'runs/mobile_vla_lora_20251114/kosmos/mobile_vla_finetune/2025-11-19/mobile_vla_lora_20251114', 'output_dir': 'runs/mobile_vla_lora_20251114/kosmos/mobile_vla_finetune/2025-11-19/mobile_vla_lora_20251114', 'data_dir': None, 'annotation_file': None, 'data_subfolder': None, 'task_num': None, 'use_multi_modal_emb': False, 'no_video_pretrained_model': False, 'finetune': False, 'llm': {'type': None, 'n_embd': None, 'n_layer': None, 'n_head': None}}
fwd next n: 10
Traceback (most recent call last):
  File "/home/billy/.cache/pypoetry/virtualenvs/vla-tensorrt-sSUdR_m1-py3.10/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 737, in getattribute_from_module
    return getattribute_from_module(transformers_module, attr)
  File "/home/billy/.cache/pypoetry/virtualenvs/vla-tensorrt-sSUdR_m1-py3.10/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 741, in getattribute_from_module
    raise ValueError(f"Could not find {attr} in {transformers_module}!")
ValueError: Could not find Kosmos2ForConditionalGeneration in <module 'transformers' from '/home/billy/.cache/pypoetry/virtualenvs/vla-tensorrt-sSUdR_m1-py3.10/lib/python3.10/site-packages/transformers/__init__.py'>!

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/billy/25-1kp/vla/RoboVLMs_upstream/main.py", line 369, in <module>
    experiment(variant=configs)
  File "/home/billy/25-1kp/vla/RoboVLMs_upstream/main.py", line 168, in experiment
    model = TrainerClass.from_checkpoint(
  File "/home/billy/25-1kp/vla/RoboVLMs_upstream/robovlms/train/base_trainer.py", line 125, in from_checkpoint
    return cls(configs)
  File "/home/billy/25-1kp/vla/RoboVLMs_upstream/robovlms/train/base_trainer.py", line 26, in __init__
    self._initialize()
  File "/home/billy/25-1kp/vla/RoboVLMs_upstream/robovlms/train/base_trainer.py", line 85, in _initialize
    self.model = self._init_policy()
  File "/home/billy/25-1kp/vla/RoboVLMs_upstream/robovlms/train/base_trainer.py", line 41, in _init_policy
    model = self.model_fn(
  File "/home/billy/25-1kp/vla/RoboVLMs_upstream/robovlms/model/backbone/base_backbone.py", line 90, in __init__
    self.tokenizer, self.backbone = self._init_backbone()
  File "/home/billy/25-1kp/vla/RoboVLMs_upstream/robovlms/model/backbone/base_backbone.py", line 207, in _init_backbone
    tokenizer, model = build_vlm(self.configs["vlm"], self.configs["tokenizer"])
  File "/home/billy/25-1kp/vla/RoboVLMs_upstream/robovlms/model/vlm_builder.py", line 38, in build_vlm
    model = getattr(transformers, model_type).from_pretrained(
  File "/home/billy/.cache/pypoetry/virtualenvs/vla-tensorrt-sSUdR_m1-py3.10/lib/python3.10/site-packages/transformers/models/auto/modeling_auto.py", line 2204, in from_pretrained
    return super().from_pretrained(pretrained_model_name_or_path, *model_args, **kwargs)
  File "/home/billy/.cache/pypoetry/virtualenvs/vla-tensorrt-sSUdR_m1-py3.10/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 597, in from_pretrained
    model_class = _get_model_class(config, cls._model_mapping)
  File "/home/billy/.cache/pypoetry/virtualenvs/vla-tensorrt-sSUdR_m1-py3.10/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 394, in _get_model_class
    supported_models = model_mapping[type(config)]
  File "/home/billy/.cache/pypoetry/virtualenvs/vla-tensorrt-sSUdR_m1-py3.10/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 803, in __getitem__
    return self._load_attr_from_module(model_type, model_name)
  File "/home/billy/.cache/pypoetry/virtualenvs/vla-tensorrt-sSUdR_m1-py3.10/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 817, in _load_attr_from_module
    return getattribute_from_module(self._modules[module_name], attr)
  File "/home/billy/.cache/pypoetry/virtualenvs/vla-tensorrt-sSUdR_m1-py3.10/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 739, in getattribute_from_module
    raise ValueError(f"Could not find {attr} neither in {module} nor in {transformers_module}!")
ValueError: Could not find Kosmos2ForConditionalGeneration neither in <module 'transformers.models.kosmos2' from '/home/billy/.cache/pypoetry/virtualenvs/vla-tensorrt-sSUdR_m1-py3.10/lib/python3.10/site-packages/transformers/models/kosmos2/__init__.py'> nor in <module 'transformers' from '/home/billy/.cache/pypoetry/virtualenvs/vla-tensorrt-sSUdR_m1-py3.10/lib/python3.10/site-packages/transformers/__init__.py'>!
