# RoboVLMs Results Analysis

## 주요 성과 요약

### 1. CALVIN 벤치마크 결과

#### ABCD → D 분할 (일반화 평가)
- **KosMos P.H. (RoboVLMs)**: 96.7% 단일 작업 성공률
- **5개 연속 작업**: 82.6% 성공률
- **평균 달성 작업 수**: 4.49개
- **기존 SOTA 대비**: GR-1 대비 0.28개 작업 향상

#### ABC → D 분할 (강화된 일반화 평가)
- **KosMos P.H. (RoboVLMs)**: 98.0% 단일 작업 성공률
- **5개 연속 작업**: 70.4% 성공률
- **평균 달성 작업 수**: 4.25개
- **기존 SOTA 대비**: GR-1 대비 1.19개 작업 향상

### 2. SimplerEnv 벤치마크 결과

#### WidowX+Bridge 환경
- **Put Spoon on Towel**: 70.8% 성공률
- **Put Carrot on Plate**: 45.8% 성공률
- **Stack Green Block on Yellow Block**: 33.3% 성공률
- **Put Eggplant in Yellow Basket**: 20.8% 성공률

#### Google Robot 환경
- **Pick Coke Can**: 94.0% 성공률
- **Move Near**: 47.0% 성공률
- **Open/Close Drawer**: 91.0% 성공률
- **Open Drawer & Place Apple**: 77.3% 성공률

### 3. 실제 로봇 실험 결과

#### 전체 성능
- **Simple 설정**: 75% 성공률
- **Unseen Distractor**: 60% 성공률
- **Unseen Background**: 50% 성공률
- **Unseen Object**: 55% 성공률
- **Novel Skill Description**: 33% 성공률

#### 베이스라인 대비 성능
- **OpenVLA 대비**: 모든 설정에서 우수한 성능
- **Octo 대비**: 특히 Unseen 설정에서 뛰어난 일반화

## 핵심 발견사항

### 1. VLA의 우수성 입증
- **시뮬레이션**: CALVIN과 SimplerEnv에서 SOTA 달성
- **실제 로봇**: 다양한 설정에서 강력한 성능
- **일반화**: Unseen 설정에서도 안정적인 성능

### 2. Vision-Language 사전 훈련의 중요성
- **VL 사전 훈련 있음**: 4.49 Avg. Len. (ABCD)
- **VL 사전 훈련 없음**: 2.70 Avg. Len. (ABCD)
- **개선폭**: 1.79개 작업 향상

### 3. 최적 구조: Policy Head + Continuous Action
- **Policy Head**: 히스토리 융합에 효과적
- **Continuous Action**: 이산 액션 대비 우수한 성능
- **일반화**: 다양한 환경에서 안정적

### 4. Cross-embodiment 데이터의 효과
- **Few-shot 학습**: 17.2% 성능 향상
- **Post-training**: 전체 성능 향상
- **In-domain 데이터**: Cross-embodiment보다 효과적

## 데이터 효율성 분석

### 모델 크기별 성능
| 모델 크기 | Avg. Len. (ABCD) | Avg. Len. (ABC) |
|-----------|------------------|-----------------|
| 3B | 3.97 | 1.69 |
| 9B | 4.46 | 2.35 |

### 데이터 스케일별 성능
| 데이터 스케일 | Avg. Len. (ABCD) | Avg. Len. (ABC) |
|---------------|------------------|-----------------|
| 0.1x ABCD | 1.38 | - |
| ABCD | 4.49 | 2.51 |
| 5x ABCD | 4.51 | 2.32 |

## 자가 수정 능력

### 발견된 능력
- **자동 위치 조정**: 첫 시도 실패 시 자동 수정
- **훈련 데이터 없음**: 이 능력은 훈련 데이터에 포함되지 않음
- **베이스라인 대비**: 다른 모델에서는 관찰되지 않음

### 예시: Open The Oven 작업
1. 첫 번째 시도: 오븐 손잡이에 도달하지 못함
2. 자동 수정: 엔드 이펙터 위치 조정
3. 두 번째 시도: 성공적으로 작업 완료

## 성능 비교표

### CALVIN ABCD → D
| 방법 | VLA? | 1 | 2 | 3 | 4 | 5 | Avg. Len. |
|------|------|---|---|---|---|---|-----------|
| RT-1 | ✖ | 0.844 | 0.617 | 0.438 | 0.323 | 0.227 | 2.45 |
| HULC | ✖ | 0.889 | 0.733 | 0.587 | 0.475 | 0.383 | 3.06 |
| GR-1 | ✔ | 0.949 | 0.896 | 0.844 | 0.789 | 0.731 | 4.21 |
| **KosMos P.H.** | ✔ | **0.967** | **0.930** | **0.899** | **0.865** | **0.826** | **4.49** |

### CALVIN ABC → D
| 방법 | VLA? | 1 | 2 | 3 | 4 | 5 | Avg. Len. |
|------|------|---|---|---|---|---|-----------|
| RT-1 | ✖ | 0.533 | 0.222 | 0.094 | 0.038 | 0.013 | 0.90 |
| HULC | ✖ | 0.418 | 0.165 | 0.057 | 0.019 | 0.011 | 0.67 |
| GR-1 | ✔ | 0.854 | 0.712 | 0.596 | 0.497 | 0.401 | 3.06 |
| **KosMos P.H.** | ✔ | **0.980** | **0.936** | **0.854** | **0.778** | **0.704** | **4.25** |

## 실용적 의미

### 1. VLA 설계 가이드라인
- **백본 선택**: 충분한 VL 사전 훈련된 VLM
- **구조 선택**: Policy Head + Continuous Action
- **데이터 활용**: Post-training 전략

### 2. 성능 향상 요소
- **Vision-Language 사전 훈련**: 필수 요소
- **히스토리 정보 활용**: 일반화에 중요
- **Cross-embodiment 데이터**: Few-shot 학습에 도움

### 3. 실제 적용 가능성
- **실시간 제어**: 대형 모델의 도전과제
- **일반화 능력**: 다양한 환경에서 안정적
- **자가 수정**: 예상치 못한 능력 발견
