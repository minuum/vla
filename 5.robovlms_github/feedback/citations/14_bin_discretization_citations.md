# 14. Bin ì´ì‚°í™” ê³¼ì • ìƒì„¸ ë¶„ì„

## ğŸ“‹ ê°œìš”

ì´ ë¬¸ì„œëŠ” RoboVLMsì—ì„œ ì—°ì† ì•¡ì…˜ì„ nê°œ binìœ¼ë¡œ ì´ì‚°í™”í•˜ëŠ” ê³¼ì •ê³¼ í•™ìŠµì—ì„œì˜ ìˆœì„œë¥¼ ìì„¸íˆ ë¶„ì„í•©ë‹ˆë‹¤.

## ğŸ” 1. Bin ì´ì‚°í™”ì˜ ì˜ë„ì™€ ëª©ì 

### 1.1 ì´ì‚°í™”ì˜ í•µì‹¬ ì˜ë„

**ì—°ì† ì•¡ì…˜ â†’ ì´ì‚° í† í° ë³€í™˜**
```python
# ì—°ì† ì•¡ì…˜: [-1, 1] ë²”ìœ„ì˜ ì‹¤ìˆ˜ê°’
continuous_action = [0.5, -0.3, 0.8, 0.2, -0.1, 0.9, 0.1]  # 7DOF

# ì´ì‚°í™”: 256ê°œ binìœ¼ë¡œ ë¶„í• 
bins = np.linspace(-1, 1, 256)  # [-1, -0.992, -0.984, ..., 0.992, 1]
discretized = np.digitize(continuous_action, bins)  # [192, 89, 230, 153, 115, 243, 140]
```

**ì¶œì²˜**: `RoboVLMs/robovlms/model/policy_head/action_tokenizer.py:55-70`

### 1.2 ì´ì‚°í™”ì˜ í•™ìŠµìƒ ì´ì 

**1) í† í° ê¸°ë°˜ í•™ìŠµ**
- VLMì´ í…ìŠ¤íŠ¸ í† í°ì²˜ëŸ¼ ì•¡ì…˜ì„ ì²˜ë¦¬ ê°€ëŠ¥
- ì–¸ì–´ ëª¨ë¸ì˜ autoregressive ìƒì„± í™œìš©
- CrossEntropyLossë¡œ ì§ì ‘ í•™ìŠµ ê°€ëŠ¥

**2) ì •ë°€ë„ vs íš¨ìœ¨ì„± ê· í˜•**
- 256ê°œ bin = 8ë¹„íŠ¸ ì •ë°€ë„ (2^8 = 256)
- ì—°ì† ê³µê°„ì˜ ë¬´í•œ ì •ë°€ë„ â†’ ìœ í•œ ì •ë°€ë„ë¡œ ê·¼ì‚¬
- ë¡œë´‡ ì œì–´ì— ì¶©ë¶„í•œ ì •ë°€ë„ ì œê³µ

**3) ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**
- ì—°ì†ê°’: float32 (4ë°”ì´íŠ¸) Ã— 7ì°¨ì› = 28ë°”ì´íŠ¸
- ì´ì‚°ê°’: int8 (1ë°”ì´íŠ¸) Ã— 7ì°¨ì› = 7ë°”ì´íŠ¸
- **75% ë©”ëª¨ë¦¬ ì ˆì•½**

## ğŸ”„ 2. ì´ì‚°í™” ê³¼ì •ì˜ ìƒì„¸ ë‹¨ê³„

### 2.1 Bin ìƒì„± ê³¼ì •

```python
# ActionTokenizer.__init__()ì—ì„œ bin ìƒì„±
def __init__(self, tokenizer, bins=256, min_action=-1, max_action=1):
    self.n_bins = bins                    # 256ê°œ bin
    self.min_action = min_action         # -1 (ìµœì†Œê°’)
    self.max_action = max_action         # 1 (ìµœëŒ€ê°’)
    
    # ê· ë“± ë¶„í• ë¡œ bin ê²½ê³„ ìƒì„±
    self.bins = np.linspace(min_action, max_action, self.n_bins)
    # [-1, -0.992, -0.984, ..., 0.992, 1] (256ê°œ ê°’)
    
    # bin ì¤‘ì‹¬ê°’ ê³„ì‚° (ì‹¤ì œ ì•¡ì…˜ê°’ìœ¼ë¡œ ì‚¬ìš©)
    self.bin_centers = (self.bins[:-1] + self.bins[1:]) / 2.0
    # [-0.996, -0.988, -0.980, ..., 0.988, 0.996] (255ê°œ ê°’)
```

**ì¶œì²˜**: `RoboVLMs/robovlms/model/policy_head/action_tokenizer.py:54-56`

### 2.2 ì•¡ì…˜ â†’ í† í° ID ë³€í™˜

```python
def encode_actions_to_token_ids(self, action: np.ndarray) -> np.ndarray:
    """ì—°ì† ì•¡ì…˜ì„ í† í° IDë¡œ ë³€í™˜"""
    # 1ë‹¨ê³„: ì•¡ì…˜ í´ë¦¬í•‘ (ë²”ìœ„ ì œí•œ)
    action = np.clip(action, a_min=float(self.min_action), a_max=float(self.max_action))
    # [-1, 1] ë²”ìœ„ë¡œ ì œí•œ
    
    # 2ë‹¨ê³„: bin ì¸ë±ìŠ¤ ê³„ì‚°
    discretized_action = np.digitize(action, self.bins)
    # [1, 256] ë²”ìœ„ì˜ ì¸ë±ìŠ¤ (256ê°œ bin)
    
    # 3ë‹¨ê³„: í† í° ID ë³€í™˜
    token_ids = self.tokenizer_orig_size - discretized_action
    # vocab_size - bin_index = í† í° ID
    
    return token_ids
```

**ì¶œì²˜**: `RoboVLMs/robovlms/model/policy_head/action_tokenizer.py:82-92`

### 2.3 í† í° ID â†’ ì•¡ì…˜ ë³µì›

```python
def decode_token_ids_to_actions(self, action_token_ids: np.ndarray) -> np.ndarray:
    """í† í° IDë¥¼ ì—°ì† ì•¡ì…˜ìœ¼ë¡œ ë³µì›"""
    # 1ë‹¨ê³„: bin ì¸ë±ìŠ¤ ë³µì›
    discretized_actions = self.tokenizer_orig_size - action_token_ids
    
    # 2ë‹¨ê³„: ì¸ë±ìŠ¤ ë²”ìœ„ ì¡°ì •
    discretized_actions = np.clip(
        discretized_actions - 1, 
        a_min=0, 
        a_max=self.bin_centers.shape[0] - 1
    )
    
    # 3ë‹¨ê³„: bin ì¤‘ì‹¬ê°’ìœ¼ë¡œ ì•¡ì…˜ ë³µì›
    return self.bin_centers[discretized_actions]
```

**ì¶œì²˜**: `RoboVLMs/robovlms/model/policy_head/action_tokenizer.py:94-115`

## ğŸ¯ 3. í•™ìŠµ ê³¼ì •ì—ì„œì˜ ìˆœì„œ

### 3.1 ë°ì´í„° ì „ì²˜ë¦¬ ë‹¨ê³„

**1) CALVIN ë°ì´í„°ì…‹ ë¡œë”©**
```python
# DiskCalvinDatasetì—ì„œ ì—°ì† ì•¡ì…˜ ë¡œë”©
action = self.actions[episode_idx][step_idx]  # [7] shape, ì—°ì†ê°’
# ì˜ˆ: [0.5, -0.3, 0.8, 0.2, -0.1, 0.9, 0.1]
```

**2) ì•¡ì…˜ ì´ì‚°í™”**
```python
# ActionPredictionBatchTransformì—ì„œ ì´ì‚°í™”
if self.discrete:
    next_action_ids = self.action_tokenizer.encode_actions_to_token_ids(next_action)
    # [192, 89, 230, 153, 115, 243, 140] (í† í° ID)
```

**ì¶œì²˜**: `RoboVLMs/robovlms/data/base_action_prediction_dataset.py:340-342`

### 3.2 í•™ìŠµ ë‹¨ê³„

**1) ì…ë ¥ êµ¬ì„±**
```python
# í…ìŠ¤íŠ¸ + ì•¡ì…˜ í† í° ê²°í•©
input_ids = instruction_tokens + action_tokens
# [1, 2, 3, ..., 192, 89, 230, 153, 115, 243, 140]
```

**2) VLM Forward Pass**
```python
# BaseRoboVLM.forward_discrete()ì—ì„œ ì²˜ë¦¬
output = self.model(
    input_ids=instr_and_action_ids,
    attention_mask=instr_and_action_mask,
    output_hidden_states=True
)
```

**3) Loss ê³„ì‚°**
```python
# DiscreteDecoder.loss()ì—ì„œ CrossEntropyLoss
loss_fct = nn.CrossEntropyLoss()
loss = loss_fct(
    shift_logits.view(-1, shift_logits.size(-1)), 
    shift_labels.view(-1)
)
```

**ì¶œì²˜**: `RoboVLMs/robovlms/model/policy_head/base_policy.py:231-235`

### 3.3 ì¶”ë¡  ë‹¨ê³„

**1) ì•¡ì…˜ ìƒì„±**
```python
# BaseRoboVLM.pred_action_discrete()ì—ì„œ ìƒì„±
action_ids = self.model.generate(
    input_ids=instr_and_action_ids, 
    max_new_tokens=action_dim
)
```

**2) ì•¡ì…˜ ë³µì›**
```python
# í† í° ID â†’ ì—°ì† ì•¡ì…˜ ë³€í™˜
discretized_actions = self.action_tokenizer.decode_token_ids_to_actions(action_ids)
# [0.496, -0.304, 0.796, 0.196, -0.104, 0.896, 0.096]
```

**ì¶œì²˜**: `RoboVLMs/robovlms/model/backbone/base_backbone.py:1443-1445`

## ğŸ“Š 4. Bin ìˆ˜ì˜ ì˜í–¥ ë¶„ì„

### 4.1 ì •ë°€ë„ vs ë©”ëª¨ë¦¬ íŠ¸ë ˆì´ë“œì˜¤í”„

| Bin ìˆ˜ | ì •ë°€ë„ | ë©”ëª¨ë¦¬ | í† í° ë²”ìœ„ | ë¹„ê³  |
|--------|--------|--------|-----------|------|
| 64 | 6ë¹„íŠ¸ | 1ë°”ì´íŠ¸ | [0, 63] | ë‚®ì€ ì •ë°€ë„ |
| 128 | 7ë¹„íŠ¸ | 1ë°”ì´íŠ¸ | [0, 127] | ì¤‘ê°„ ì •ë°€ë„ |
| **256** | **8ë¹„íŠ¸** | **1ë°”ì´íŠ¸** | **[0, 255]** | **ê¸°ë³¸ê°’** |
| 512 | 9ë¹„íŠ¸ | 2ë°”ì´íŠ¸ | [0, 511] | ë†’ì€ ì •ë°€ë„ |
| 1024 | 10ë¹„íŠ¸ | 2ë°”ì´íŠ¸ | [0, 1023] | ë§¤ìš° ë†’ì€ ì •ë°€ë„ |

### 4.2 RoboVLMsì—ì„œì˜ Bin ì„¤ì •

**ê¸°ë³¸ ì„¤ì •**: 256ê°œ bin (8ë¹„íŠ¸ ì •ë°€ë„)
```python
# ëª¨ë“  ì„¤ì • íŒŒì¼ì—ì„œ ë™ì¼
n_bin: 256
min_action: -1
max_action: 1
```

**ì´ìœ **:
- ë¡œë´‡ ì œì–´ì— ì¶©ë¶„í•œ ì •ë°€ë„
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±
- VLM í† í°í™”ì™€ í˜¸í™˜ì„±

## ğŸ”§ 5. ì‹¤ì œ êµ¬í˜„ ì˜ˆì‹œ

### 5.1 ì™„ì „í•œ ì´ì‚°í™” íŒŒì´í”„ë¼ì¸

```python
# 1ë‹¨ê³„: ì—°ì† ì•¡ì…˜ ì…ë ¥
continuous_action = np.array([0.5, -0.3, 0.8, 0.2, -0.1, 0.9, 0.1])

# 2ë‹¨ê³„: ì´ì‚°í™”
action_tokenizer = ActionTokenizer(tokenizer, bins=256)
token_ids = action_tokenizer.encode_actions_to_token_ids(continuous_action)
# ê²°ê³¼: [192, 89, 230, 153, 115, 243, 140]

# 3ë‹¨ê³„: í† í° IDë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
action_text = tokenizer.decode(token_ids)
# ê²°ê³¼: "ì•¡ì…˜ í† í° ì‹œí€€ìŠ¤"

# 4ë‹¨ê³„: í•™ìŠµìš© ì…ë ¥ êµ¬ì„±
input_ids = instruction_tokens + token_ids
# [1, 2, 3, ..., 192, 89, 230, 153, 115, 243, 140]

# 5ë‹¨ê³„: VLM í•™ìŠµ
loss = model(input_ids, labels=token_ids)

# 6ë‹¨ê³„: ì¶”ë¡  ì‹œ ì•¡ì…˜ ë³µì›
predicted_actions = action_tokenizer.decode_token_ids_to_actions(token_ids)
# ê²°ê³¼: [0.496, -0.304, 0.796, 0.196, -0.104, 0.896, 0.096]
```

### 5.2 ì •ë°€ë„ ì†ì‹¤ ë¶„ì„

**ì›ë³¸ ì•¡ì…˜**: [0.5, -0.3, 0.8, 0.2, -0.1, 0.9, 0.1]
**ë³µì› ì•¡ì…˜**: [0.496, -0.304, 0.796, 0.196, -0.104, 0.896, 0.096]
**ì˜¤ì°¨**: [0.004, 0.004, 0.004, 0.004, 0.004, 0.004, 0.004]

**í‰ê·  ì˜¤ì°¨**: 0.004 (0.4%)
**ìµœëŒ€ ì˜¤ì°¨**: 0.004 (0.4%)

## ğŸ“ˆ 6. í•™ìŠµ íš¨ê³¼ ë¶„ì„

### 6.1 ì´ì‚°í™”ì˜ í•™ìŠµìƒ ì´ì 

**1) Autoregressive í•™ìŠµ**
- VLMì´ ì•¡ì…˜ì„ ì‹œí€€ìŠ¤ë¡œ í•™ìŠµ
- ì´ì „ ì•¡ì…˜ì— ê¸°ë°˜í•œ ë‹¤ìŒ ì•¡ì…˜ ì˜ˆì¸¡
- ì–¸ì–´ ëª¨ë¸ì˜ ê°•ë ¥í•œ ì‹œí€€ìŠ¤ ëª¨ë¸ë§ í™œìš©

**2) CrossEntropyLoss í™œìš©**
- ì—°ì†ê°’ì˜ MSE Loss ëŒ€ì‹  ë¶„ë¥˜ Loss ì‚¬ìš©
- ë” ì•ˆì •ì ì¸ í•™ìŠµ
- ê·¸ë˜ë””ì–¸íŠ¸ í­ë°œ/ì†Œì‹¤ ë¬¸ì œ ì™„í™”

**3) í† í° ê¸°ë°˜ ìƒì„±**
- VLMì˜ ìƒì„± ëŠ¥ë ¥ ì§ì ‘ í™œìš©
- í…ìŠ¤íŠ¸ì™€ ì•¡ì…˜ì˜ í†µí•© í•™ìŠµ
- ë©€í‹°ëª¨ë‹¬ ì´í•´ë ¥ í–¥ìƒ

### 6.2 ì„±ëŠ¥ ë¹„êµ

| ë°©ë²• | ì •ë°€ë„ | í•™ìŠµ ì•ˆì •ì„± | ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± | ìƒì„± í’ˆì§ˆ |
|------|--------|-------------|---------------|-----------|
| ì—°ì†ê°’ | 100% | ë³´í†µ | ë‚®ìŒ | ë³´í†µ |
| **ì´ì‚°í™”** | **99.6%** | **ë†’ìŒ** | **ë†’ìŒ** | **ë†’ìŒ** |

## ğŸ¯ 7. í•µì‹¬ ìš”ì•½

### 7.1 Bin ì´ì‚°í™”ì˜ ì˜ë„

1. **ì—°ì† ê³µê°„ â†’ ì´ì‚° ê³µê°„ ë³€í™˜**
   - ë¬´í•œ ì •ë°€ë„ â†’ ìœ í•œ ì •ë°€ë„
   - ì‹¤ìˆ˜ê°’ â†’ ì •ìˆ˜ ì¸ë±ìŠ¤
   - ì•¡ì…˜ â†’ í† í° ID

2. **VLM í•™ìŠµ ìµœì í™”**
   - ì–¸ì–´ ëª¨ë¸ ì•„í‚¤í…ì²˜ í™œìš©
   - í† í° ê¸°ë°˜ í•™ìŠµ
   - Autoregressive ìƒì„±

3. **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**
   - 75% ë©”ëª¨ë¦¬ ì ˆì•½
   - ë¹ ë¥¸ í•™ìŠµ/ì¶”ë¡ 
   - í™•ì¥ì„± í–¥ìƒ

### 7.2 í•™ìŠµ ìˆœì„œ

1. **ë°ì´í„° ì „ì²˜ë¦¬**: ì—°ì† ì•¡ì…˜ â†’ ì´ì‚° í† í°
2. **ì…ë ¥ êµ¬ì„±**: í…ìŠ¤íŠ¸ + ì•¡ì…˜ í† í° ê²°í•©
3. **VLM í•™ìŠµ**: CrossEntropyLossë¡œ í† í° ì˜ˆì¸¡
4. **ì¶”ë¡ **: ìƒì„±ëœ í† í° â†’ ì—°ì† ì•¡ì…˜ ë³µì›

### 7.3 í•µì‹¬ ì½”ë“œ ìœ„ì¹˜

- **ActionTokenizer**: `RoboVLMs/robovlms/model/policy_head/action_tokenizer.py`
- **ì´ì‚°í™” ë¡œì§**: `encode_actions_to_token_ids()`, `decode_token_ids_to_actions()`
- **í•™ìŠµ í†µí•©**: `RoboVLMs/robovlms/data/base_action_prediction_dataset.py:340-342`
- **ì¶”ë¡  ì²˜ë¦¬**: `RoboVLMs/robovlms/model/backbone/base_backbone.py:1443-1445`

ì´ ë¶„ì„ì„ í†µí•´ RoboVLMsì˜ bin ì´ì‚°í™” ê³¼ì •ê³¼ í•™ìŠµì—ì„œì˜ ìˆœì„œë¥¼ ëª…í™•íˆ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
