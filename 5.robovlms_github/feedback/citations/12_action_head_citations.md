# 12. Action Head Simultaneous Learning - Citation Evidence

## ğŸ” **GitHub Code Implementation (100% Confirmed)**

### **12.1 Action Head Forward Pass**
- **File**: `RoboVLMs/robovlms/model/backbone/base_backbone.py:542-561`
- **Implementation**: `_forward_action_head()` function
- **Code**:
```python
def _forward_action_head(
    self,
    action_tokens: torch.Tensor,                    # ì•¡ì…˜ í† í°
    action_labels: Tuple[torch.Tensor, torch.Tensor] = None,  # ì•¡ì…˜ ë ˆì´ë¸”
    action_mask: torch.Tensor = None,              # ì•¡ì…˜ ë§ˆìŠ¤í¬
    **kwargs,                                      # ì¶”ê°€ í‚¤ì›Œë“œ ì¸ìˆ˜ë“¤
):
    """ì•¡ì…˜ í—¤ë“œ ìˆœì „íŒŒ ë° ë™ì‹œ í•™ìŠµ"""
    # ì•¡ì…˜ ì˜ˆì¸¡ì„ ìœ„í•œ ì•¡ì…˜ í—¤ë“œ
    action = self.act_head(
        action_tokens, actions=action_labels, action_masks=action_mask, **kwargs
    )
    
    # ë™ì‹œ í•™ìŠµ ì†ì‹¤ ê³„ì‚°
    if action_labels is not None:
        # ì•¡ì…˜ í—¤ë“œì—ì„œ ë ˆì´ë¸” ì²˜ë¦¬
        action, action_labels, action_mask = self.act_head.get_labels(
            action, action_labels, action_mask, tok_seq=action_tokens, **kwargs
        )
        # ì•¡ì…˜ ì†ì‹¤ ê³„ì‚°
        action_loss = self.act_head.loss(action, action_labels, action_mask)
    
    return action, action_loss
```

### **12.2 End-to-End Learning Structure**
- **File**: `5.robovlms_github/feedback/action_image_text_syncing.md:295-329`
- **Implementation**: BaseRoboVLM class structure
- **Code**:
```python
class BaseRoboVLM(nn.Module):
    """ì—”ë“œíˆ¬ì—”ë“œ í•™ìŠµì„ ìœ„í•œ BaseRoboVLM í´ë˜ìŠ¤"""
    def __init__(
        self,
        configs,                    # ëª¨ë¸ ì„¤ì •
        train_setup_configs,        # í•™ìŠµ ì„¤ì •
        act_encoder_configs=None,   # ì•¡ì…˜ ì¸ì½”ë” ì„¤ì •
        act_head_configs=None,     # ì•¡ì…˜ í—¤ë“œ ì„¤ì •
        fwd_head_configs=None,     # ìˆœë°©í–¥ í—¤ë“œ ì„¤ì •
        # ... ê¸°íƒ€ ì„¤ì •ë“¤
    ):
        # VLMê³¼ ì•¡ì…˜ í—¤ë“œ ë™ì‹œ ì´ˆê¸°í™”
        self.act_head, self.fwd_head, self.clip_norm_head = self._init_heads()
```

### **12.3 Simultaneous Learning Mechanism**
- **File**: `5.robovlms_github/feedback/multimodal_sync_analysis.md:144-157`
- **Implementation**: End-to-end learning process
- **Code**:
```python
# ë™ì‹œ í•™ìŠµ ê³¼ì •
o_t = ([OBS]_t, [LRN])                           # ê´€ì°°ê°’ê³¼ í•™ìŠµ í† í°
[LRN]_t = VLM(o_t, l_prompt)                     # VLM ì²˜ë¦¬ (ë©€í‹°ëª¨ë‹¬ ì´í•´)
a_{t:t+L-1} = h([LRN]_{t-H+1}, ..., [LRN]_t)    # ì•¡ì…˜ í—¤ë“œ ì²˜ë¦¬ (íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ì•¡ì…˜ ì˜ˆì¸¡)
```

## ğŸ“Š **Simultaneous Learning Evidence**

### **12.4 VLM and Action Head Integration**
- **VLM Processing**: Image and text to multimodal representation
- **Learnable Token**: [LRN] token generation
- **Policy Head**: History information fusion for action prediction
- **End-to-End**: Entire pipeline learns simultaneously

### **12.5 Multi-task Learning**
- **Vision-Language**: VLM loss for multimodal understanding
- **Action Prediction**: Action Head loss for robot control
- **Joint Optimization**: Combined loss function
- **Gradient Flow**: Gradients flow through entire pipeline

### **12.6 Training Configuration**
- **Action Head Types**: LSTM, MLP, GPT2, Discrete
- **Loss Functions**: MSE for continuous, CrossEntropy for discrete
- **Optimization**: AdamW optimizer
- **Learning Rate**: Shared learning rate for VLM and Action Head

## ğŸ¯ **Key Findings**

1. **Simultaneous Learning**: VLM and Action Head learn together
2. **End-to-End**: Complete pipeline optimization
3. **Multi-task**: Vision-language and action prediction
4. **Unified Architecture**: Single model for all modalities

## ğŸ“ **Supporting Files**
- `RoboVLMs/robovlms/model/backbone/base_backbone.py`
- `5.robovlms_github/feedback/action_image_text_syncing.md`
- `5.robovlms_github/feedback/multimodal_sync_analysis.md`
- `RoboVLMs/robovlms/model/policy_head/`
