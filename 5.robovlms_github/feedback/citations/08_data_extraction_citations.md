# 8. Dataset Extraction and Finetuning - Citation Evidence

## ğŸ” **GitHub Code Implementation (100% Confirmed)**

### **8.1 CALVIN Dataset Loading**
- **File**: `RoboVLMs/robovlms/data/calvin_dataset.py:521-602`
- **Implementation**: `DiskCalvinDataset` class for loading CALVIN episodes from disk
- **Code**:
```python
class DiskCalvinDataset(BaseCalvinDataset):
    """ë””ìŠ¤í¬ì—ì„œ CALVIN ì—í”¼ì†Œë“œë¥¼ ë¡œë“œí•˜ëŠ” ë°ì´í„°ì…‹"""
    def __init__(
        self,
        image_fn: Callable,           # ì´ë¯¸ì§€ ì²˜ë¦¬ í•¨ìˆ˜
        tokenizer: Callable,          # í† í¬ë‚˜ì´ì € í•¨ìˆ˜
        skip_frames: int = 1,         # í”„ë ˆì„ ìŠ¤í‚µ ìˆ˜
        save_format: str = "npz",      # ì €ì¥ í˜•ì‹ (npz/pkl)
        pretrain: bool = False,       # ì‚¬ì „ í›ˆë ¨ ì—¬ë¶€
        partial_data=False,          # ë¶€ë¶„ ë°ì´í„° ì‚¬ìš© ì—¬ë¶€
        decoder_type="lstm",          # ë””ì½”ë” íƒ€ì…
        discrete_action=False,        # ì´ì‚° ì•¡ì…˜ ì‚¬ìš© ì—¬ë¶€
        action_tokenizer=None,         # ì•¡ì…˜ í† í¬ë‚˜ì´ì €
        model_name="vicuna",          # ëª¨ë¸ ì´ë¦„
        predict_stop_token=True,       # ì •ì§€ í† í° ì˜ˆì¸¡ ì—¬ë¶€
        use_mu_law=False,            # Î¼-law ì‚¬ìš© ì—¬ë¶€
        mu_val=255,                   # Î¼-law ê°’
        n_bin=256,                    # ì´ì‚°í™” ë¹ˆ ìˆ˜
        min_action=-1,                 # ì•¡ì…˜ ìµœì†Œê°’
        max_action=1,                  # ì•¡ì…˜ ìµœëŒ€ê°’
        task_type="calvin_action",     # íƒœìŠ¤í¬ íƒ€ì…
        tcp_rel=False,                # TCP ìƒëŒ€ ì¢Œí‘œ ì‚¬ìš© ì—¬ë¶€
        few_shot=False,               # Few-shot í•™ìŠµ ì—¬ë¶€
        exclude_tasks=[],             # ì œì™¸í•  íƒœìŠ¤í¬ ëª©ë¡
        **kwargs: Any,                # ì¶”ê°€ í‚¤ì›Œë“œ ì¸ìˆ˜ë“¤
    ):
```

### **8.2 Episode Loading Implementation**
- **File**: `RoboVLMs/robovlms/data/calvin_dataset.py:615-653`
- **Implementation**: `_load_episode` method for loading consecutive frames
- **Code**:
```python
def _load_episode(self, idx: int, window_size: int) -> Dict[str, np.ndarray]:
    """
    ë””ìŠ¤í¬ì— ê°œë³„ íŒŒì¼ë¡œ ì €ì¥ëœ ì—°ì† í”„ë ˆì„ë“¤ì„ ë¡œë“œí•˜ì—¬ ì—í”¼ì†Œë“œ ë”•ì…”ë„ˆë¦¬ë¡œ ê²°í•©
    Args:
        idx: ì²« ë²ˆì§¸ í”„ë ˆì„ì˜ ì¸ë±ìŠ¤
        window_size: ìƒ˜í”Œë§ëœ ì—í”¼ì†Œë“œì˜ ê¸¸ì´
    Returns:
        episode: ëª¨ë‹¬ë¦¬í‹° ì´ë¦„ì„ í‚¤ë¡œ í•˜ëŠ” ì—í”¼ì†Œë“œê°€ í¬í•¨ëœ numpy ë°°ì—´ë“¤ì˜ ë”•ì…”ë„ˆë¦¬
    """
    # ì—í”¼ì†Œë“œ ì‹œì‘/ë ì¸ë±ìŠ¤ ê³„ì‚°
    start_idx = self.episode_lookup[idx]                    # ì—í”¼ì†Œë“œ ì‹œì‘ ì¸ë±ìŠ¤
    end_idx = start_idx + window_size + self.act_step - 1    # ì—í”¼ì†Œë“œ ë ì¸ë±ìŠ¤
    right_pad = self.right_pad_lookup[idx]                  # ì˜¤ë¥¸ìª½ íŒ¨ë”© ê°’
    idx_range = np.arange(start_idx, end_idx)               # ì¸ë±ìŠ¤ ë²”ìœ„ ìƒì„±
    
    # ì•¡ì…˜ê³¼ ì´ë¯¸ì§€ ë§ˆìŠ¤í¬ ì´ˆê¸°í™”
    action_mask = np.ones_like(idx_range)                    # ì•¡ì…˜ ë§ˆìŠ¤í¬ (ëª¨ë‘ 1)
    image_mask = np.ones_like(idx_range)                    # ì´ë¯¸ì§€ ë§ˆìŠ¤í¬ (ëª¨ë‘ 1)
    
    # íŒ¨ë”© ì²˜ë¦¬
    if right_pad != 0:
        idx_range[right_pad:] = idx_range[right_pad]        # íŒ¨ë”© ë¶€ë¶„ ì¸ë±ìŠ¤ ë³µì œ
        action_mask[right_pad:] = 0                         # íŒ¨ë”© ë¶€ë¶„ ì•¡ì…˜ ë§ˆìŠ¤í¬ 0
        image_mask[right_pad:] = 0                          # íŒ¨ë”© ë¶€ë¶„ ì´ë¯¸ì§€ ë§ˆìŠ¤í¬ 0

    # ê´€ì°° ê³µê°„ í‚¤ë“¤ ìˆ˜ì§‘
    keys = list(chain(*self.observation_space.values()))    # ëª¨ë“  ê´€ì°° í‚¤ë“¤
    keys.remove("language")                                  # ì–¸ì–´ í‚¤ ì œê±°
    keys.append("scene_obs")                                # ì¥ë©´ ê´€ì°° í‚¤ ì¶”ê°€
    
    # ê° íŒŒì¼ ì¸ë±ìŠ¤ì— ëŒ€í•´ ì—í”¼ì†Œë“œ ë¡œë“œ
    episodes = [
        self.load_file(self._get_episode_name(file_idx)) for file_idx in idx_range
    ]
    # í‚¤ë³„ë¡œ ì—í”¼ì†Œë“œë“¤ ìŠ¤íƒ
    episode = {key: np.stack([ep[key] for ep in episodes]) for key in keys}
    
    # ì–¸ì–´ ë°ì´í„° ì²˜ë¦¬
    if self.with_lang:
        episode["language"] = self.lang_ann[self.lang_lookup[idx]]  # ì–¸ì–´ ì–´ë…¸í…Œì´ì…˜ ë¡œë“œ
        if self.text_aug:  # í…ìŠ¤íŠ¸ ì¦ê°• ì‚¬ìš© ì‹œ
            task = self.lang_task[self.lang_lookup[idx]]            # íƒœìŠ¤í¬ ì •ë³´
            enrich_lang = random.choice(                             # ëœë¤ ì–¸ì–´ ì„ íƒ
                self.enrich_lang[task] + [episode["language"]]
            )
            episode["language"] = enrich_lang                        # ì¦ê°•ëœ ì–¸ì–´ë¡œ êµì²´
    
    # ë§ˆìŠ¤í¬ ì •ë³´ ì¶”ê°€
    episode["action_mask"] = action_mask    # ì•¡ì…˜ ë§ˆìŠ¤í¬ ì €ì¥
    episode["image_mask"] = image_mask      # ì´ë¯¸ì§€ ë§ˆìŠ¤í¬ ì €ì¥
    return episode
```

### **8.3 Partial Data Loading**
- **File**: `RoboVLMs/robovlms/data/calvin_dataset.py:1091-1098`
- **Implementation**: `load_partial_traj_data` function for loading specific episodes
- **Code**:
```python
def load_partial_traj_data():
    """ë¶€ë¶„ ê¶¤ì  ë°ì´í„° ë¡œë“œ (data_name_list.txtì—ì„œ)"""
    # data_name_list.txt íŒŒì¼ ê²½ë¡œ ì„¤ì •
    file = open(
        f"{Path(os.path.abspath(robovlms.__path__[0])).parent.as_posix()}/configs/data/calvin/data_name_list.txt",
        "r",
    )
    lines = file.readlines()                                    # íŒŒì¼ì˜ ëª¨ë“  ì¤„ ì½ê¸°
    # ê° ì¤„ì„ íŒŒì‹±í•˜ì—¬ íŠœí”Œë¡œ ë³€í™˜ (ì²« ë²ˆì§¸ ìš”ì†Œ ì œì™¸í•˜ê³  ì •ìˆ˜ë¡œ ë³€í™˜)
    lines = [tuple([int(_) for _ in l.split()[1:]]) for l in lines]
    return lines
```

### **8.4 Data Chunking Implementation**
- **File**: `RoboVLMs/robovlms/data/data_utils.py:249-270`
- **Implementation**: `generate_chunck_data` function for creating data chunks
- **Code**:
```python
def generate_chunck_data(data, window_size, chunk_size):
    """ë°ì´í„° ì²­í‚¹ ìƒì„± í•¨ìˆ˜"""
    if data is None:
        return None
    
    bs, seq_len = data.shape[:2]           # ë°°ì¹˜ í¬ê¸°, ì‹œí€€ìŠ¤ ê¸¸ì´
    raw_data_shape = data.shape[2:]         # ì›ë³¸ ë°ì´í„° í˜•íƒœ
    data_flatten = data.flatten().view(bs, seq_len, -1)  # ë°ì´í„° í‰íƒ„í™”
    
    # ì‹œí€€ìŠ¤ ê¸¸ì´ ê²€ì¦
    assert (
        seq_len == window_size + chunk_size
    ), f"The sequence length should be {window_size + chunk_size}"
    
    # ìœˆë„ìš° í¬ê¸°ë§Œí¼ ë°ì´í„° ë°˜ë³µ
    data_flatten = repeat(data_flatten, "b s d -> b w s d", w=window_size)

    # í´ë¡œ ë§¤íŠ¸ë¦­ìŠ¤ ë§ˆìŠ¤í¬ ìƒì„±
    mask = claw_matrix(seq_len, chunk_size - 1, data_flatten.device)
    mask = mask[:window_size].bool()        # ìœˆë„ìš° í¬ê¸°ë§Œí¼ ë§ˆìŠ¤í¬ ìë¥´ê¸°

    # ë§ˆìŠ¤í¬ë¥¼ ë°°ì¹˜ ì°¨ì›ìœ¼ë¡œ í™•ì¥
    mask = repeat(mask, "w s -> b w s d", b=bs, d=data_flatten.shape[-1])
    data_flatten = torch.masked_select(data_flatten, mask)  # ë§ˆìŠ¤í¬ ì ìš©

    # ìµœì¢… ë°ì´í„° í˜•íƒœë¡œ ë³€í™˜
    data_flatten = data_flatten.view(bs, window_size, chunk_size, *raw_data_shape)
    return data_flatten
```

### **8.5 Training Pipeline**
- **File**: `RoboVLMs/robovlms/train/base_trainer.py:345-395`
- **Implementation**: `_process_batch` method for batch processing
- **Code**:
```python
def _process_batch(self, batch):
    """
    ë°°ì¹˜ ì²˜ë¦¬ ë©”ì„œë“œ (ë‹¤ì–‘í•œ íƒœìŠ¤í¬ ì§€ì›)
    
    Action Prediction:
        args: rgb, language, attention_mask, hand_rgb, action
        reformat: action to input and target (seq_len = window size + chunck size)
    Video Prediction:
        args: rgb, language, attention mask, hand_rgb
        reformat: rgb, [hand_rgb] to input and target (seq_len = window size + chunck size)
    Video Caption:
        args: rgb, language, attention_mask
        reformat: Identity
    Image Caption:
        args: rgb, language, attention_mask
        reformat: Identity
        seq_len = 1
    """
    # ë°°ì¹˜ê°€ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì²« ë²ˆì§¸ ìš”ì†Œ ì‚¬ìš©
    if isinstance(batch, list):
        batch = batch[0]
    
    # RGB ë°ì´í„°ê°€ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° GPUë¡œ ì´ë™
    if isinstance(batch["rgb"], list):
        rgb = [_.cuda() for _ in batch["rgb"]]
    else:
        rgb = batch["rgb"].cuda()
        if len(rgb.shape) == 4:
            rgb = rgb.unsqueeze(1)
        assert len(rgb.shape) == 5

    if isinstance(batch["text"], list) and isinstance(batch["text"][0], str):
        raise ValueError("The raw text data is not supported")
    else:
        seq_len = self.configs["window_size"]
        language = batch["text"].cuda()
        text_mask = batch["text_mask"].cuda()

    if batch.get("action", None) is not None:
        action = batch["action"].cuda()
    else:
        action = None

    attention_mask = batch.get("attention_mask", None)
    if attention_mask is not None:
        attention_mask = batch["attention_mask"].cuda()

    if self.use_hand_rgb and batch.get("hand_rgb", None) is not None:
        hand_rgb = batch["hand_rgb"].cuda()
    else:
        hand_rgb = None

    # Split arm and gripper action
    arm_action = None
    gripper_action = None

    if action is not None:
        arm_action = action[:, :, :6]  # b,len,act_dim-1
        gripper_action = action[:, :, 6]  # b,len
        gripper_action = (gripper_action + 1.0) / 2
        gripper_action = gripper_action.long()

    fwd_rgb_chunck = batch.get("fwd_rgb_chunck", None)
    fwd_hand_rgb_chunck = batch.get("fwd_hand_rgb_chunck", None)
    if fwd_rgb_chunck is not None:
        fwd_rgb_chunck = fwd_rgb_chunck.cuda()
    if fwd_hand_rgb_chunck is not None:
        fwd_hand_rgb_chunck = fwd_hand_rgb_chunck.cuda()

    arm_action_chunck = None
    gripper_action_chunck = None
    action_chunck = batch.get("action_chunck", None)
    if action_chunck is not None:
        action_chunck = action_chunck.cuda()
        arm_action_chunck = action_chunck[..., :6]
        gripper_action_chunck = action_chunck[..., -1]

    if isinstance(rgb, torch.Tensor):
        rgb = rgb[:, :seq_len]
        if hand_rgb is not None:
            hand_rgb = hand_rgb[:, :seq_len]

    chunck_mask = batch.get("chunck_mask", None)
    if chunck_mask is not None:
        chunck_mask = chunck_mask.cuda()

    fwd_mask = batch.get("fwd_mask", None)
    if fwd_mask is not None:
        fwd_mask = fwd_mask.bool().cuda()

    # data preparation for discrete action inputs and labels
    instr_and_action_ids = batch.get("instr_and_action_ids", None)
    if instr_and_action_ids is not None:
```

## ğŸ“Š **Data Processing Evidence**

### **8.6 Dataset Preprocessing**
- **Image Processing**: RGB image normalization and augmentation
- **Text Processing**: Language instruction tokenization
- **Action Processing**: 7-DOF action normalization and chunking
- **Window Processing**: Temporal sequence windowing

### **8.7 Training Configuration**
- **Batch Size**: Configurable through training configs
- **Learning Rate**: Configurable through training configs
- **Weight Decay**: Configurable through training configs
- **Warmup Ratio**: Configurable through training configs

### **8.8 Memory Optimization**
- **Mixed Precision**: FP16 for memory efficiency
- **Gradient Checkpointing**: Reduced memory usage
- **Gradient Accumulation**: Effective larger batch sizes
- **LoRA**: Parameter-efficient finetuning

## ğŸ¯ **Key Findings**

1. **Scalable Pipeline**: Handles large-scale CALVIN dataset
2. **Efficient Training**: LoRA-based parameter-efficient finetuning
3. **Memory Optimized**: Mixed precision and gradient checkpointing
4. **Configurable**: Flexible training hyperparameters

## ğŸ“ **Supporting Files**
- `RoboVLMs/robovlms/data/calvin_dataset.py`
- `RoboVLMs/robovlms/data/data_utils.py`
- `RoboVLMs/robovlms/train/base_trainer.py`
- `RoboVLMs/configs/calvin_finetune/*.json` (9 files)
