# =============================================================================
# ğŸš€ Mobile VLA Docker Compose - ê²€ì¦ëœ í™˜ê²½ ê¸°ë°˜
# ê¸°ì¡´ vla_app_final í™˜ê²½ì— Mobile VLA ê¸°ëŠ¥ ì¶”ê°€
# =============================================================================

version: '3.8'

services:
  # ğŸ¤– ë©”ì¸ Mobile VLA ì„œë¹„ìŠ¤ (ê²€ì¦ëœ í™˜ê²½ ê¸°ë°˜)
  mobile-vla:
    build:
      context: .
      dockerfile: Dockerfile.mobile-vla
    image: mobile_vla:verified-base
    container_name: mobile_vla_verified
    restart: unless-stopped
    
    # ğŸ”§ GPU ë° í•˜ë“œì›¨ì–´ ì ‘ê·¼ ì„¤ì •
    runtime: nvidia
    privileged: true
    
    # ğŸŒ ë„¤íŠ¸ì›Œí¬ ì„¤ì • (ROS2 DDS í†µì‹ ì„ ìœ„í•´ host ë„¤íŠ¸ì›Œí¬ ì‚¬ìš©)
    network_mode: host
    
    # ğŸ“¡ í™˜ê²½ ë³€ìˆ˜
    environment:
      # ë””ìŠ¤í”Œë ˆì´ ì„¤ì • (GUI ì•± ì§€ì›)
      - DISPLAY=${DISPLAY:-:0}
      
      # ROS2 ì„¤ì •
      - ROS_DOMAIN_ID=42
      - ROS_LOCALHOST_ONLY=0
      - RMW_IMPLEMENTATION=rmw_cyclonedx_cpp
      
      # CUDA/GPU ì„¤ì •
      - CUDA_VISIBLE_DEVICES=0
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=all
      - CUDAARCHS=87
      - CUDA_ARCHITECTURES=87
      
      # PyTorch ìµœì í™”
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
      - TORCH_DTYPE=float16
      
      # Transformers/HuggingFace ìºì‹œ
      - TRANSFORMERS_CACHE=/workspace/vla/.cache/huggingface
      - HF_HOME=/workspace/vla/.cache/huggingface
      
      # Mobile VLA ì„¤ì •
      - MOBILE_VLA_DATA_DIR=/workspace/vla/mobile_vla_dataset
      - MOBILE_VLA_LOG_LEVEL=INFO
      
      # ì‹œìŠ¤í…œ ì„¤ì •
      - PYTHONUNBUFFERED=1
      - DEBIAN_FRONTEND=noninteractive
      
      # Jetson ì „ìš© ì„¤ì • (ê¸°ì¡´ vla_app_finalê³¼ ë™ì¼)
      - TAR_INDEX_URL=http://jetson.webredirect.org:8000/jp6/cu122
      - PIP_INDEX_URL=http://jetson.webredirect.org/jp6/cu122
      - PIP_TRUSTED_HOST=jetson.webredirect.org
      
    # ğŸ“ ë³¼ë¥¨ ë§ˆìš´íŠ¸
    volumes:
      # ğŸ  í˜¸ìŠ¤íŠ¸ vla í´ë” ì „ì²´ ë§ˆìš´íŠ¸
      - ./:/workspace/vla
      
      # ğŸ¥ CSI ì¹´ë©”ë¼ ë° í•˜ë“œì›¨ì–´ ì ‘ê·¼
      - /dev:/dev
      - /sys:/sys:ro
      - /proc:/proc:ro
      
      # ğŸ–¥ï¸ X11 GUI ì§€ì›
      - /tmp/.X11-unix:/tmp/.X11-unix:rw
      - /etc/localtime:/etc/localtime:ro
      
      # ğŸ”§ NVIDIA ëŸ°íƒ€ì„ ë¼ì´ë¸ŒëŸ¬ë¦¬
      - /usr/local/cuda:/usr/local/cuda:ro
      - /usr/lib/aarch64-linux-gnu:/usr/lib/aarch64-linux-gnu:ro
      
      # ğŸ’¾ ëª¨ë¸ ìºì‹œ (í¼ì‹œìŠ¤í„´íŠ¸)
      - mobile_vla_cache:/workspace/vla/.cache
      
      # ğŸ—‚ï¸ ë°ì´í„°ì…‹ ì €ì¥ì†Œ
      - mobile_vla_data:/workspace/vla/mobile_vla_dataset
      
      # ğŸ“Š ë¡œê·¸ ì €ì¥ì†Œ
      - mobile_vla_logs:/workspace/vla/logs
      
      # ğŸ”Œ nvargus socket (CSI ì¹´ë©”ë¼ ë°ëª¬ í†µì‹ )
      - /tmp/argus_socket:/tmp/argus_socket
      
      # ğŸ¤– ê¸°ì¡´ RoboVLMs í´ë” (ìˆì„ ê²½ìš°)
      - /workspace/RoboVLMs:/workspace/RoboVLMs
      
    # ğŸš€ ì‘ì—… ë””ë ‰í† ë¦¬
    working_dir: /workspace/vla
    
    # ğŸ’» ì»¨í…Œì´ë„ˆ ì‹œì‘ ëª…ë ¹ì–´
    command: >
      bash -c "
        echo 'ğŸš€ Mobile VLA Docker ì»¨í…Œì´ë„ˆ ì‹œì‘ (ê²€ì¦ëœ í™˜ê²½ ê¸°ë°˜)' &&
        
        # ROS2 í™˜ê²½ ì„¤ì •
        source /opt/ros/humble/setup.bash &&
        export ROS_DOMAIN_ID=42 &&
        
        # ROS_action ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ë¹Œë“œ (í•„ìš”ì‹œ)
        if [ -d 'ROS_action/src' ] && [ ! -d 'ROS_action/install' ]; then
          echo 'ğŸ“¦ ROS_action ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ë¹Œë“œ ì¤‘...' &&
          cd ROS_action &&
          colcon build --packages-select camera_pub &&
          source install/setup.bash &&
          cd .. &&
          echo 'âœ… ROS_action ë¹Œë“œ ì™„ë£Œ'
        fi &&
        
        # í—¬ìŠ¤ì²´í¬ ì‹¤í–‰
        /usr/local/bin/healthcheck.sh &&
        
        # Mobile VLA ì‹œìŠ¤í…œ ëŒ€ê¸° ëª¨ë“œ
        echo 'âœ… Mobile VLA ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ (ê²€ì¦ëœ VLA í™˜ê²½)' &&
        echo 'ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´:' &&
        echo '   docker exec -it mobile_vla_verified vla-camera' &&
        echo '   docker exec -it mobile_vla_verified vla-collect' &&
        echo '   docker exec -it mobile_vla_verified torch_cuda_test' &&
        echo '   docker exec -it mobile_vla_verified bash' &&
        
        # ë¬´í•œ ëŒ€ê¸° (ë‹¤ë¥¸ í„°ë¯¸ë„ì—ì„œ ì ‘ì† ê°€ëŠ¥)
        tail -f /dev/null
      "
    
    # ğŸ” í—¬ìŠ¤ì²´í¬
    healthcheck:
      test: [
        "CMD", 
        "/usr/local/bin/healthcheck.sh"
      ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    
    # ğŸ·ï¸ ë¼ë²¨
    labels:
      - "com.nvidia.jetson.mobile-vla=true"
      - "com.nvidia.jetson.version=verified-base"
      - "com.docker.compose.project=mobile-vla"

  # ğŸ“Š ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤ (ì„ íƒì )
  monitoring:
    image: mobile_vla:verified-base
    container_name: mobile_vla_monitoring
    restart: unless-stopped
    
    network_mode: host
    runtime: nvidia
    
    environment:
      - ROS_DOMAIN_ID=42
      - NVIDIA_VISIBLE_DEVICES=all
    
    volumes:
      - ./:/workspace/vla
      - mobile_vla_logs:/workspace/vla/logs
    
    working_dir: /workspace/vla
    
    command: >
      bash -c "
        echo 'ğŸ“Š Mobile VLA ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤ ì‹œì‘ (ê²€ì¦ëœ í™˜ê²½)' &&
        
        # ëª¨ë‹ˆí„°ë§ ë£¨í”„
        while true; do
          echo '=========== Mobile VLA System Status (Verified Base) ===========' &&
          echo 'â° Time:' && date &&
          echo '' &&
          echo 'ğŸ”§ GPU Status:' &&
          nvidia-smi --query-gpu=memory.used,memory.total,utilization.gpu,temperature.gpu --format=csv,noheader,nounits &&
          echo '' &&
          echo 'ğŸ’¾ Memory Usage:' &&
          free -h &&
          echo '' &&
          echo 'ğŸ’¿ Disk Usage:' &&
          df -h /workspace/vla &&
          echo '' &&
          echo 'ğŸ¤– ROS2 Nodes:' &&
          timeout 5s ros2 node list 2>/dev/null || echo 'No ROS2 nodes active' &&
          echo '' &&
          echo 'ğŸ¥ Camera Status:' &&
          timeout 3s ros2 topic hz /camera/image_raw 2>/dev/null || echo 'Camera topic not active' &&
          echo '' &&
          echo '=================================================================' &&
          echo '' &&
          sleep 30
        done
      "
    
    depends_on:
      - mobile-vla
    
    profiles:
      - monitoring  # ì„ íƒì  ì‹¤í–‰: docker-compose --profile monitoring up

# ğŸ“ Named Volumes (í¼ì‹œìŠ¤í„´íŠ¸ ìŠ¤í† ë¦¬ì§€)
volumes:
  mobile_vla_cache:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${PWD}/docker_volumes/cache

  mobile_vla_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${PWD}/docker_volumes/dataset

  mobile_vla_logs:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${PWD}/docker_volumes/logs

# ğŸŒ ë„¤íŠ¸ì›Œí¬ ì„¤ì • (host ë„¤íŠ¸ì›Œí¬ ì‚¬ìš©ìœ¼ë¡œ ì‹¤ì œë¡œëŠ” ë¶ˆí•„ìš”)
networks:
  default:
    external: true
    name: host