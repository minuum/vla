#!/usr/bin/env python3

import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image, CompressedImage
from geometry_msgs.msg import Twist
from std_msgs.msg import String, Float32MultiArray
import cv2
import numpy as np
from PIL import Image as PILImage
import torch
from transformers import AutoProcessor, AutoModel
import json
import time
from typing import List, Optional, Dict
import threading
from queue import Queue
import sys
import tty
import termios

# ì‹¤ì œ ë¡œë´‡ ì œì–´ë¥¼ ìœ„í•œ import
try:
    from pop.driving import Driving
    from pop.Psd import Psd
    from pop.Ultrasonic import Ultrasonic
    ROBOT_AVAILABLE = True
    print("âœ… ì‹¤ì œ ë¡œë´‡ ì œì–´ ëª¨ë“œ (Driving + ì„¼ì„œ)")
except ImportError:
    ROBOT_AVAILABLE = False
    print("ğŸ® ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ (pop ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ)")

class RoboVLMsInference(Node):
    """
    RoboVLMs ë°©ì‹ì˜ ì¶”ë¡  ë…¸ë“œ
    ë‹¨ì¼ ì´ë¯¸ì§€ë¥¼ ë°›ì•„ì„œ ë‹¨ì¼ ì•¡ì…˜ì„ ìƒì„±í•˜ëŠ” ì‹¤ì‹œê°„ ë°˜ì‘í˜• ì‹œìŠ¤í…œ
    í‚¤ë³´ë“œ ì œì–´ ê¸°ëŠ¥ í¬í•¨ + ì‹¤ì œ ë¡œë´‡ ì œì–´
    """
    
    def __init__(self):
        super().__init__('robovlms_inference')
        
        # ì‹¤ì œ ë¡œë´‡ ì œì–´ ì´ˆê¸°í™”
        if ROBOT_AVAILABLE:
            self.driver = Driving()
            self.psd = Psd(dev="can0", bitrate=500000)
            self.us = Ultrasonic(dev="can0", bitrate=500000)
            self.throttle = 50  # ì†ë„ ì„¤ì •
            self.get_logger().info("âœ… ì‹¤ì œ ë¡œë´‡ í•˜ë“œì›¨ì–´ ì´ˆê¸°í™” ì™„ë£Œ")
        else:
            self.driver = None
            self.psd = None
            self.us = None
        
        # ëª¨ë¸ ì„¤ì • (ì—…ë°ì´íŠ¸ëœ ìµœì‹  ëª¨ë¸ ì‚¬ìš©)
        self.model_name = "minium/mobile-vla-omniwheel"  # MAE 0.222 ë‹¬ì„±í•œ ìµœì‹  ëª¨ë¸
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.get_logger().info(f"Using device: {self.device}")
        self.get_logger().info(f"Using updated model: {self.model_name} (MAE 0.222)")
        
        # ëª¨ë¸ ë¡œë“œ
        self.load_model()
        
        # ROS ì„¤ì •
        self.setup_ros()
        
        # ìƒíƒœ ë³€ìˆ˜
        self.is_processing = False
        self.is_system_running = False
        self.is_inference_active = False  # ì¶”ë¡  í™œì„±í™” ìƒíƒœ
        self.current_task = "Navigate around obstacles to track the target cup"
        self.inference_count = 0
        self.last_inference_time = 0.0
        
        # ì¶”ë¡  ì •ë³´ ì €ì¥
        self.last_inference_result = None
        self.inference_confidence = 0.0
        self.inference_latency = 0.0
        
        # í‚¤ë³´ë“œ ì œì–´ ì„¤ì • (simple_move_robot.pyì™€ ë™ì¼í•œ ì•¡ì…˜)
        self.WASD_TO_CONTINUOUS = {
            'w': {"linear_x": 1.25, "linear_y": 0.0, "angular_z": 0.0},      # ì•ìœ¼ë¡œ
            'a': {"linear_x": 0.0, "linear_y": 1.25, "angular_z": 0.0},      # ì™¼ìª½ìœ¼ë¡œ
            's': {"linear_x": -1.25, "linear_y": 0.0, "angular_z": 0.0},     # ë’¤ë¡œ
            'd': {"linear_x": 0.0, "linear_y": -1.25, "angular_z": 0.0},     # ì˜¤ë¥¸ìª½ìœ¼ë¡œ
            'q': {"linear_x": 1.25, "linear_y": 1.25, "angular_z": 0.0},     # ëŒ€ê°ì„  ì•ì™¼ìª½
            'e': {"linear_x": 1.25, "linear_y": -1.25, "angular_z": 0.0},    # ëŒ€ê°ì„  ì•ì˜¤ë¥¸ìª½
            'z': {"linear_x": -1.25, "linear_y": 1.25, "angular_z": 0.0},    # ëŒ€ê°ì„  ë’¤ì™¼ìª½
            'c': {"linear_x": -1.25, "linear_y": -1.25, "angular_z": 0.0},   # ëŒ€ê°ì„  ë’¤ì˜¤ë¥¸ìª½
            'r': {"linear_x": 0.0, "linear_y": 0.0, "angular_z": 1.25},      # ì™¼ìª½ íšŒì „
            't': {"linear_x": 0.0, "linear_y": 0.0, "angular_z": -1.25},     # ì˜¤ë¥¸ìª½ íšŒì „
            ' ': {"linear_x": 0.0, "linear_y": 0.0, "angular_z": 0.0}        # ì •ì§€ (ìŠ¤í˜ì´ìŠ¤ë°”)
        }
        self.STOP_ACTION = {"linear_x": 0.0, "linear_y": 0.0, "angular_z": 0.0}
        self.current_action = self.STOP_ACTION.copy()
        self.movement_timer = None
        
        # ì´ë¯¸ì§€ í
        self.image_queue = Queue(maxsize=1)  # ìµœì‹  ì´ë¯¸ì§€ë§Œ ìœ ì§€
        
        # ì¶”ë¡  ìŠ¤ë ˆë“œ ì‹œì‘
        self.inference_thread = threading.Thread(target=self.inference_worker, daemon=True)
        self.inference_thread.start()
        
        # í‚¤ë³´ë“œ ì…ë ¥ ìŠ¤ë ˆë“œ ì‹œì‘
        self.keyboard_thread = threading.Thread(target=self.keyboard_loop, daemon=True)
        self.keyboard_thread.start()
        
        # ì„¼ì„œ ëª¨ë‹ˆí„°ë§ ìŠ¤ë ˆë“œ ì‹œì‘
        if ROBOT_AVAILABLE:
            self.sensor_thread = threading.Thread(target=self.sensor_monitor, daemon=True)
            self.sensor_thread.start()
        
        self.get_logger().info("RoboVLMs Inference Node initialized")
        self.show_help()
    
    def show_help(self):
        """ë„ì›€ë§ í‘œì‹œ"""
        self.get_logger().info("ğŸ® RoboVLMs í‚¤ë³´ë“œ ì œì–´:")
        self.get_logger().info("   W/A/S/D: ì´ë™, Q/E/Z/C: ëŒ€ê°ì„ ")
        self.get_logger().info("   R/T: íšŒì „, ìŠ¤í˜ì´ìŠ¤ë°”: ì •ì§€")
        self.get_logger().info("   Enter: ì¶”ë¡  ì‹œì‘/ì¤‘ì§€")
        self.get_logger().info("   P: ì§„í–‰ ìƒí™© í™•ì¸")
        self.get_logger().info("   H: ì´ ë„ì›€ë§ í‘œì‹œ")
        self.get_logger().info("   F/G: ì†ë„ ì¡°ì ˆ")
        self.get_logger().info("   I: ì„¼ì„œ ì •ë³´ í‘œì‹œ")
        self.get_logger().info("   Ctrl+C: í”„ë¡œê·¸ë¨ ì¢…ë£Œ")
        self.get_logger().info("â³ í‚¤ë³´ë“œ ì…ë ¥ ëŒ€ê¸° ì¤‘...")
    
    def sensor_monitor(self):
        """ì„¼ì„œ ëª¨ë‹ˆí„°ë§ ìŠ¤ë ˆë“œ"""
        while rclpy.ok() and ROBOT_AVAILABLE:
            try:
                # PSD ì„¼ì„œ ì½ê¸°
                psd_values = self.psd.read()
                psd_min = min(psd_values) if psd_values else float('inf')
                
                # ì´ˆìŒíŒŒ ì„¼ì„œ ì½ê¸°
                us_values = self.us.read()
                us_min = min(us_values) if us_values else float('inf')
                
                # ì¥ì• ë¬¼ ê°ì§€ ì‹œ ì •ì§€
                if psd_min <= 20 or us_min <= 20:
                    self.get_logger().warn(f"âš ï¸ ì¥ì• ë¬¼ ê°ì§€! PSD={psd_min:.1f}cm, US={us_min:.1f}cm â†’ ìë™ ì •ì§€")
                    self.stop_robot()
                
                time.sleep(0.1)  # 10Hz ì„¼ì„œ ì²´í¬
            except Exception as e:
                self.get_logger().error(f"ì„¼ì„œ ì½ê¸° ì˜¤ë¥˜: {e}")
                time.sleep(1.0)
    
    def keyboard_loop(self):
        """í‚¤ë³´ë“œ ì…ë ¥ ì²˜ë¦¬ ìŠ¤ë ˆë“œ"""
        while rclpy.ok():
            key = self.get_key()
            self.handle_key_input(key)
            time.sleep(0.01)
    
    def get_key(self) -> str:
        """í‚¤ë³´ë“œ ì…ë ¥ ì½ê¸°"""
        fd = sys.stdin.fileno()
        old = termios.tcgetattr(fd)
        try:
            tty.setraw(fd)
            ch = sys.stdin.read(1)
        finally:
            termios.tcsetattr(fd, termios.TCSADRAIN, old)
        return ch.lower()
    
    def handle_key_input(self, key: str):
        """í‚¤ë³´ë“œ ì…ë ¥ ì²˜ë¦¬"""
        if key == '\x03':  # Ctrl+C
            self.get_logger().info("í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì¤‘...")
            self.stop_robot()
            rclpy.shutdown()
            return
        elif key == '\r' or key == '\n':  # Enter
            self.toggle_inference()
        elif key == 'p':
            self.show_progress()
        elif key == 'h':
            self.show_help()
        elif key == 'i':
            self.show_sensor_info()
        elif key == 'f':
            if ROBOT_AVAILABLE:
                self.throttle = max(10, self.throttle - 10)
                self.get_logger().info(f'ğŸ”½ ì†ë„: {self.throttle}%')
        elif key == 'g':
            if ROBOT_AVAILABLE:
                self.throttle = min(100, self.throttle + 10)
                self.get_logger().info(f'ğŸ”¼ ì†ë„: {self.throttle}%')
        elif key in self.WASD_TO_CONTINUOUS:
            self.handle_movement_key(key)
    
    def show_sensor_info(self):
        """ì„¼ì„œ ì •ë³´ í‘œì‹œ"""
        if ROBOT_AVAILABLE:
            try:
                psd_values = self.psd.read()
                us_values = self.us.read()
                
                self.get_logger().info("ğŸ“¡ ì„¼ì„œ ì •ë³´:")
                self.get_logger().info(f"   PSD ì„¼ì„œ: {psd_values}")
                self.get_logger().info(f"   ì´ˆìŒíŒŒ ì„¼ì„œ: {us_values}")
                self.get_logger().info(f"   ìµœì†Œ ê±°ë¦¬: PSD={min(psd_values) if psd_values else 'N/A'}cm, US={min(us_values) if us_values else 'N/A'}cm")
            except Exception as e:
                self.get_logger().error(f"ì„¼ì„œ ì •ë³´ ì½ê¸° ì‹¤íŒ¨: {e}")
        else:
            self.get_logger().info("ğŸ“¡ ì„¼ì„œ ì •ë³´: ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ")
    
    def toggle_inference(self):
        """ì¶”ë¡  ì‹œì‘/ì¤‘ì§€ í† ê¸€"""
        if self.is_inference_active:
            self.is_inference_active = False
            self.stop_robot()
            self.get_logger().info("ğŸ›‘ ì¶”ë¡  ì¤‘ì§€ë¨ - ìˆ˜ë™ ì œì–´ ëª¨ë“œ")
        else:
            self.is_inference_active = True
            self.get_logger().info("ğŸš€ ì¶”ë¡  ì‹œì‘ë¨ - AI ì œì–´ ëª¨ë“œ")
    
    def handle_movement_key(self, key: str):
        """ì´ë™ í‚¤ ì²˜ë¦¬"""
        if self.is_inference_active:
            self.get_logger().info("âš ï¸ ì¶”ë¡  ëª¨ë“œ ì¤‘ì…ë‹ˆë‹¤. Enterë¥¼ ëˆŒëŸ¬ ìˆ˜ë™ ì œì–´ë¡œ ì „í™˜í•˜ì„¸ìš”.")
            return
        
        action = self.WASD_TO_CONTINUOUS[key]
        
        # ì´ì „ íƒ€ì´ë¨¸ ì·¨ì†Œ
        if self.movement_timer and self.movement_timer.is_alive():
            self.movement_timer.cancel()
            if self.current_action != self.STOP_ACTION:
                self.stop_movement_internal()
        
        self.current_action = action.copy()
        self.execute_robot_action(action)  # ì‹¤ì œ ë¡œë´‡ ì œì–´
        
        # ì•¡ì…˜ ì„¤ëª… ìƒì„±
        action_desc = []
        if abs(action['linear_x']) > 0.1:
            action_desc.append(f"ì „ì§„{action['linear_x']:+.1f}")
        if abs(action['linear_y']) > 0.1:
            action_desc.append(f"íš¡ì´ë™{action['linear_y']:+.1f}")
        if abs(action['angular_z']) > 0.1:
            action_desc.append(f"íšŒì „{action['angular_z']:+.1f}")
        if not action_desc:
            action_desc.append("ì •ì§€")
        
        self.get_logger().info(f"ğŸ® ìˆ˜ë™ ì œì–´: {key.upper()} â†’ {', '.join(action_desc)}")
        
        # 0.3ì´ˆ í›„ ìë™ ì •ì§€
        self.movement_timer = threading.Timer(0.3, self.stop_movement_timed)
        self.movement_timer.start()
    
    def stop_movement_timed(self):
        """íƒ€ì´ë¨¸ì— ì˜í•œ ìë™ ì •ì§€"""
        self.stop_movement_internal()
    
    def stop_movement_internal(self):
        """ë‚´ë¶€ ì •ì§€ í•¨ìˆ˜"""
        if self.current_action == self.STOP_ACTION:
            return
        
        self.current_action = self.STOP_ACTION.copy()
        self.execute_robot_action(self.STOP_ACTION)  # ì‹¤ì œ ë¡œë´‡ ì •ì§€
        self.get_logger().info("ğŸ›‘ ì›€ì§ì„ ì™„ë£Œ")
    
    def execute_robot_action(self, action: Dict[str, float]):
        """ì‹¤ì œ ë¡œë´‡ ì•¡ì…˜ ì‹¤í–‰ (omni_controller ë°©ì‹)"""
        move_duration = 0.3  # 0.3ì´ˆê°„ ì›€ì§ì„
        
        if ROBOT_AVAILABLE and self.driver:
            try:
                # omni_controller ë°©ì‹ìœ¼ë¡œ ë¡œë´‡ ì œì–´
                if abs(action["angular_z"]) > 0.1:
                    # íšŒì „ ëª…ë ¹
                    spin_speed = int(action["angular_z"] * self.throttle)
                    self.driver.spin(spin_speed)
                    time.sleep(move_duration)
                    self.driver.stop()
                elif abs(action["linear_x"]) > 0.1 or abs(action["linear_y"]) > 0.1:
                    # ì´ë™ ëª…ë ¹ (ê°ë„ ê³„ì‚°)
                    angle = np.degrees(np.arctan2(action["linear_y"], action["linear_x"]))
                    if angle < 0:
                        angle += 360
                    
                    # ì†ë„ ê³„ì‚°
                    speed = int(np.sqrt(action["linear_x"]**2 + action["linear_y"]**2) * self.throttle)
                    
                    self.driver.move(int(angle), speed)
                    time.sleep(move_duration)
                    self.driver.stop()
                else:
                    self.driver.stop()
                    
            except Exception as e:
                self.get_logger().error(f"ë¡œë´‡ ì œì–´ ì‹¤íŒ¨: {e}")
        
        # ROS í† í”½ë„ ë°œí–‰ (ì‹œë®¬ë ˆì´ì…˜ìš©)
        self.publish_cmd_vel(action)
    
    def publish_cmd_vel(self, action: Dict[str, float]):
        """Twist ë©”ì‹œì§€ ë°œí–‰ (ROS í† í”½ìš©)"""
        twist = Twist()
        twist.linear.x = float(action["linear_x"])
        twist.linear.y = float(action["linear_y"])
        twist.angular.z = float(action["angular_z"])
        self.action_pub.publish(twist)
    
    def show_progress(self):
        """ì§„í–‰ ìƒí™© í‘œì‹œ"""
        self.get_logger().info("ğŸ“Š RoboVLMs ì‹œìŠ¤í…œ ìƒíƒœ:")
        self.get_logger().info(f"   ì‹œìŠ¤í…œ ì‹¤í–‰: {'âœ…' if self.is_system_running else 'âŒ'}")
        self.get_logger().info(f"   ì¶”ë¡  í™œì„±í™”: {'âœ…' if self.is_inference_active else 'âŒ'}")
        self.get_logger().info(f"   ì¶”ë¡  íšŸìˆ˜: {self.inference_count}")
        self.get_logger().info(f"   í˜„ì¬ íƒœìŠ¤í¬: {self.current_task}")
        if self.last_inference_time > 0:
            avg_time = (time.time() - self.last_inference_time) / max(1, self.inference_count)
            self.get_logger().info(f"   í‰ê·  ì¶”ë¡  ì‹œê°„: {avg_time:.3f}ì´ˆ")
        if ROBOT_AVAILABLE:
            self.get_logger().info(f"   ë¡œë´‡ ì†ë„: {self.throttle}%")
        
        # ì¶”ë¡  ê²°ê³¼ ì •ë³´ í‘œì‹œ
        if self.last_inference_result:
            self.get_logger().info("ğŸ¤– ë§ˆì§€ë§‰ ì¶”ë¡  ê²°ê³¼:")
            self.get_logger().info(f"   ì•¡ì…˜: {self.last_inference_result}")
            self.get_logger().info(f"   ì‹ ë¢°ë„: {self.inference_confidence:.3f}")
            self.get_logger().info(f"   ì§€ì—°ì‹œê°„: {self.inference_latency:.3f}ì´ˆ")
    
    def load_model(self):
        """Mobile VLA Omniwheel ëª¨ë¸ ë¡œë“œ (MAE 0.222) - ì§ì ‘ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ"""
        try:
            self.get_logger().info("Loading Mobile VLA model from checkpoint...")
            self.get_logger().info("Model performance: MAE 0.222 (72.5% improvement)")
            
            # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ
            model_path = "/workspace/vla/mobile-vla-omniwheel/best_simple_lstm_model.pth"
            config_path = "/workspace/vla/mobile-vla-omniwheel/config.json"
            
            # ì„¤ì • íŒŒì¼ ë¡œë“œ
            import json
            with open(config_path, 'r') as f:
                self.model_config = json.load(f)
            
            self.get_logger().info(f"Model config: {self.model_config}")
            
            # PyTorch ì²´í¬í¬ì¸íŠ¸ ì§ì ‘ ë¡œë“œ
            checkpoint = torch.load(model_path, map_location=self.device)
            
            # ì²´í¬í¬ì¸íŠ¸ êµ¬ì¡° ë¶„ì„
            if isinstance(checkpoint, dict):
                if 'model_state_dict' in checkpoint:
                    self.model_state_dict = checkpoint['model_state_dict']
                    self.model_args = checkpoint.get('args', {})
                    self.val_mae = checkpoint.get('val_mae', 0.0)
                else:
                    # ì²´í¬í¬ì¸íŠ¸ ìì²´ê°€ state_dictì¸ ê²½ìš°
                    self.model_state_dict = checkpoint
                    self.model_args = {}
                    self.val_mae = 0.222  # ê¸°ë³¸ê°’
            else:
                # ì²´í¬í¬ì¸íŠ¸ ìì²´ê°€ state_dictì¸ ê²½ìš°
                self.model_state_dict = checkpoint
                self.model_args = {}
                self.val_mae = 0.222  # ê¸°ë³¸ê°’
            
            # state_dict í‚¤ ë¶„ì„
            state_dict_keys = list(self.model_state_dict.keys())
            self.get_logger().info(f"State dict keys: {state_dict_keys[:10]}...")  # ì²˜ìŒ 10ê°œë§Œ ì¶œë ¥
            
            # Kosmos-2 ê¸°ë°˜ ëª¨ë¸ì¸ì§€ í™•ì¸
            if any('kosmos_model' in key for key in state_dict_keys):
                self.get_logger().info("ğŸ” Detected Kosmos-2 based model architecture")
                self.model = self.build_kosmos2_based_model()
            else:
                self.get_logger().info("ğŸ” Detected simple LSTM model architecture")
                self.model = self.build_mobile_vla_model()
            
            # ëª¨ë¸ ë¡œë“œ ì‹œë„
            try:
                self.model.load_state_dict(self.model_state_dict)
                self.get_logger().info("âœ… State dict loaded successfully")
            except Exception as load_error:
                self.get_logger().error(f"âŒ State dict loading failed: {load_error}")
                # í‚¤ ë§¤í•‘ ì‹œë„
                self.model = self.build_adaptive_model(state_dict_keys)
                self.model.load_state_dict(self.model_state_dict)
                self.get_logger().info("âœ… State dict loaded with adaptive architecture")
            
            self.model.to(self.device)
            self.model.eval()
            
            # í”„ë¡œì„¸ì„œëŠ” Noneìœ¼ë¡œ ì„¤ì • (ì§ì ‘ ì „ì²˜ë¦¬ ì‚¬ìš©)
            self.processor = None
            
            self.get_logger().info("âœ… Mobile VLA Omniwheel model loaded successfully from checkpoint")
            self.get_logger().info("ğŸ¯ Model optimized for omniwheel robot navigation")
            self.get_logger().info(f"ğŸ“Š Performance: MAE {self.val_mae}")
            self.get_logger().info(f"ğŸ”§ Model args: {self.model_args}")
            
        except Exception as e:
            self.get_logger().error(f"Failed to load Mobile VLA model: {e}")
            # í…ŒìŠ¤íŠ¸ ëª¨ë“œë¡œ ì „í™˜
            self.get_logger().info("Switching to test mode (no model loading)")
            self.processor = None
            self.model = None
            self.model_config = None
            self.model_state_dict = None
            self.model_args = None
            self.val_mae = None
    
    def build_mobile_vla_model(self):
        """Mobile VLA ëª¨ë¸ ì•„í‚¤í…ì²˜ ì¬êµ¬ì„±"""
        import torch.nn as nn
        
        # ê°„ë‹¨í•œ LSTM ê¸°ë°˜ ëª¨ë¸ (Mobile VLA íŠ¹ì„±ì— ë§ê²Œ)
        class MobileVLAModel(nn.Module):
            def __init__(self, input_size=224*224*3, hidden_size=128, output_size=2):
                super().__init__()
                self.feature_extractor = nn.Sequential(
                    nn.Linear(input_size, 512),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(512, 256),
                    nn.ReLU(),
                    nn.Dropout(0.2)
                )
                self.lstm = nn.LSTM(256, hidden_size, batch_first=True)
                self.action_head = nn.Sequential(
                    nn.Linear(hidden_size, 64),
                    nn.ReLU(),
                    nn.Linear(64, output_size),
                    nn.Tanh()  # ì•¡ì…˜ ë²”ìœ„ ì œí•œ
                )
                
            def forward(self, x, text_input=None):
                # ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ
                batch_size = x.size(0)
                x = x.view(batch_size, -1)  # Flatten
                features = self.feature_extractor(x)
                
                # LSTM ì²˜ë¦¬ (ì‹œí€€ìŠ¤ ê¸¸ì´ 1ë¡œ ì²˜ë¦¬)
                features = features.unsqueeze(1)  # [batch, 1, features]
                lstm_out, _ = self.lstm(features)
                
                # ì•¡ì…˜ ì˜ˆì¸¡
                actions = self.action_head(lstm_out.squeeze(1))
                return actions
        
        # ëª¨ë¸ ìƒì„±
        model = MobileVLAModel()
        return model
    
    def build_kosmos2_based_model(self):
        """Kosmos-2 ê¸°ë°˜ ëª¨ë¸ ì•„í‚¤í…ì²˜ ì¬êµ¬ì„± (ì‹¤ì œ í›ˆë ¨ ëª¨ë¸ê³¼ ë™ì¼)"""
        import torch.nn as nn
        from transformers import Kosmos2Model
        
        # ì²´í¬í¬ì¸íŠ¸ì™€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ëª¨ë¸ êµ¬ì¡°
        class MobileVLAModel(nn.Module):
            def __init__(self, model_name="microsoft/kosmos-2-patch14-224", action_dim=2, window_size=8, chunk_size=2):
                super().__init__()
                
                # Kosmos2 ëª¨ë¸ ë¡œë“œ (ì²´í¬í¬ì¸íŠ¸ í‚¤ ì´ë¦„ê³¼ ì¼ì¹˜)
                self.kosmos_model = Kosmos2Model.from_pretrained(model_name)
                
                # ëª¨ë¸ ì„¤ì • (ì²´í¬í¬ì¸íŠ¸ êµ¬ì¡°ì™€ ì •í™•íˆ ì¼ì¹˜)
                self.hidden_size = 2048  # ì²´í¬í¬ì¸íŠ¸ì˜ hidden size
                self.lstm_hidden_size = 1024  # ì²´í¬í¬ì¸íŠ¸ì˜ LSTM hidden size
                self.lstm_layers = 4  # ì²´í¬í¬ì¸íŠ¸ì˜ LSTM ì¸µìˆ˜
                self.window_size = window_size
                self.chunk_size = chunk_size
                self.action_dim = action_dim
                
                # LSTM ë ˆì´ì–´ (ì²´í¬í¬ì¸íŠ¸ì™€ ì •í™•íˆ ì¼ì¹˜)
                self.rnn = nn.LSTM(
                    input_size=self.hidden_size,
                    hidden_size=self.lstm_hidden_size,
                    num_layers=self.lstm_layers,
                    batch_first=True,
                    dropout=0.1
                )
                
                # Action Head (ì²´í¬í¬ì¸íŠ¸ì™€ ì •í™•íˆ ì¼ì¹˜)
                self.actions = nn.ModuleDict({
                    'mlp': nn.Sequential(
                        nn.Linear(self.lstm_hidden_size, 1024),
                        nn.ReLU(),
                        nn.Dropout(0.1),
                        nn.Linear(1024, 256),
                        nn.ReLU(),
                        nn.Dropout(0.1),
                        nn.Linear(256, action_dim),
                        nn.Tanh()  # ì•¡ì…˜ ë²”ìœ„ ì œí•œ
                    )
                })
                
            def forward(self, pixel_values, input_ids=None, attention_mask=None):
                # í›ˆë ¨ ì½”ë“œì™€ ë™ì¼í•œ forward pass
                batch_size = pixel_values.size(0)
                
                # 1. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (í›ˆë ¨ê³¼ ë™ì¼)
                if pixel_values.dim() == 5:  # [B, T, C, H, W]
                    last_frame = pixel_values[:, -1, :, :, :]  # ë§ˆì§€ë§‰ í”„ë ˆì„ ì‚¬ìš©
                else:
                    last_frame = pixel_values
                
                # 2. Kosmos2 Vision Encoder (ì²´í¬í¬ì¸íŠ¸ì™€ ì •í™•íˆ ì¼ì¹˜)
                try:
                    vision_outputs = self.kosmos_model.vision_model(pixel_values=last_frame)
                    if hasattr(vision_outputs, 'pooler_output') and vision_outputs.pooler_output is not None:
                        image_features = vision_outputs.pooler_output
                    else:
                        # Global average pooling over patches
                        image_features = vision_outputs.last_hidden_state.mean(dim=1)
                except Exception as e:
                    # RoboVLMs ë°©ì‹ìœ¼ë¡œ fallback
                    if input_ids is None:
                        input_ids = torch.ones((batch_size, 3), dtype=torch.long, device=last_frame.device)
                        input_ids[:, 0] = 0  # BOS token
                        input_ids[:, 1] = 1  # ë‹¨ì–´ í† í°
                        input_ids[:, 2] = 2  # EOS token
                    
                    if attention_mask is None:
                        attention_mask = torch.ones((batch_size, 3), dtype=torch.bool, device=last_frame.device)
                    
                    image_embeds_position_mask = torch.zeros((batch_size, 3), dtype=torch.bool, device=last_frame.device)
                    image_embeds_position_mask[:, 0] = True
                    
                    output = self.kosmos_model(
                        pixel_values=last_frame,
                        input_ids=input_ids,
                        attention_mask=attention_mask,
                        image_embeds_position_mask=image_embeds_position_mask,
                        output_hidden_states=True,
                    )
                    image_features = output.hidden_states[-1].mean(dim=1)
                
                # 3. ì´ë¯¸ì§€ íŠ¹ì§• í¬ê¸° ì¡°ì • (ì²´í¬í¬ì¸íŠ¸ì™€ ë™ì¼)
                if image_features.size(-1) != self.hidden_size:
                    if not hasattr(self, 'image_projection'):
                        self.image_projection = nn.Linear(image_features.size(-1), self.hidden_size)
                        self.image_projection = self.image_projection.to(image_features.device)
                    image_features = self.image_projection(image_features)
                
                # 4. ì‹œí€€ìŠ¤ í™•ì¥ (í›ˆë ¨ê³¼ ë™ì¼)
                sequence_features = image_features.unsqueeze(1).repeat(1, self.window_size, 1)
                
                # 5. LSTM ì²˜ë¦¬ (í›ˆë ¨ê³¼ ë™ì¼)
                lstm_out, (hidden, cell) = self.rnn(sequence_features)
                
                # 6. ë§ˆì§€ë§‰ chunk_sizeë§Œí¼ ì•¡ì…˜ ì˜ˆì¸¡ (í›ˆë ¨ê³¼ ë™ì¼)
                chunk_features = lstm_out[:, -self.chunk_size:, :]
                
                # 7. ê° ì‹œì ë³„ë¡œ ì•¡ì…˜ ì˜ˆì¸¡ (í›ˆë ¨ê³¼ ë™ì¼)
                action_preds = []
                for t in range(self.chunk_size):
                    action_t = self.actions['mlp'](chunk_features[:, t, :])
                    action_preds.append(action_t)
                
                action_preds = torch.stack(action_preds, dim=1)  # [B, chunk_size, action_dim]
                
                # 8. ë‹¨ì¼ ì•¡ì…˜ ë°˜í™˜ (ì¶”ë¡ ìš©)
                if self.chunk_size > 1:
                    # ë§ˆì§€ë§‰ ì•¡ì…˜ë§Œ ì‚¬ìš©
                    final_action = action_preds[:, -1, :]  # [B, action_dim]
                else:
                    final_action = action_preds.squeeze(1)  # [B, action_dim]
                
                return final_action
        
        # ëª¨ë¸ ìƒì„±
        model = MobileVLAModel()
        return model
    
    def build_adaptive_model(self, state_dict_keys):
        """state_dict í‚¤ì— ë§ëŠ” ì ì‘í˜• ëª¨ë¸ ìƒì„±"""
        import torch.nn as nn
        
        # í‚¤ ë¶„ì„
        has_kosmos = any('kosmos_model' in key for key in state_dict_keys)
        has_rnn = any('rnn' in key for key in state_dict_keys)
        has_actions = any('actions' in key for key in state_dict_keys)
        
        self.get_logger().info(f"ğŸ” Adaptive model analysis:")
        self.get_logger().info(f"   Kosmos components: {has_kosmos}")
        self.get_logger().info(f"   RNN components: {has_rnn}")
        self.get_logger().info(f"   Action components: {has_actions}")
        
        if has_kosmos:
            return self.build_kosmos2_based_model()
        else:
            return self.build_mobile_vla_model()
    
    def setup_ros(self):
        """ROS í¼ë¸”ë¦¬ì…”/ì„œë¸ŒìŠ¤í¬ë¼ì´ë²„ ì„¤ì •"""
        
        # ì´ë¯¸ì§€ ì„œë¸ŒìŠ¤í¬ë¼ì´ë²„ (ì••ì¶•ëœ ì´ë¯¸ì§€)
        self.image_sub = self.create_subscription(
            CompressedImage,
            '/camera/image/compressed',
            self.image_callback,
            10
        )
        
        # ì•¡ì…˜ í¼ë¸”ë¦¬ì…”
        self.action_pub = self.create_publisher(
            Twist,
            '/cmd_vel',
            10
        )
        
        # ì¶”ë¡  ê²°ê³¼ í¼ë¸”ë¦¬ì…”
        self.inference_result_pub = self.create_publisher(
            String,
            '/mobile_vla/inference_result',
            10
        )
        
        # ì‹ ë¢°ë„ í¼ë¸”ë¦¬ì…”
        self.confidence_pub = self.create_publisher(
            Float32MultiArray,
            '/mobile_vla/confidence',
            10
        )
        
        # íƒœìŠ¤í¬ ì„œë¸ŒìŠ¤í¬ë¼ì´ë²„
        self.task_sub = self.create_subscription(
            String,
            '/mobile_vla/task',
            self.task_callback,
            10
        )
        
        # ìƒíƒœ í¼ë¸”ë¦¬ì…”
        self.status_pub = self.create_publisher(
            String,
            '/mobile_vla/status',
            10
        )
        
        # ì‹œìŠ¤í…œ ì œì–´ ì„œë¸ŒìŠ¤í¬ë¼ì´ë²„
        self.control_sub = self.create_subscription(
            String,
            '/mobile_vla/system_control',
            self.control_callback,
            10
        )
        
        self.get_logger().info("ROS interfaces setup completed")
    
    def control_callback(self, msg):
        """ì‹œìŠ¤í…œ ì œì–´ ì½œë°±"""
        try:
            command = json.loads(msg.data)
            action = command.get('action')
            
            if action == 'start':
                self.start_system()
            elif action == 'stop':
                self.stop_system()
            elif action == 'pause':
                self.pause_system()
            elif action == 'resume':
                self.resume_system()
            
        except Exception as e:
            self.get_logger().error(f"Error processing control command: {e}")
    
    def start_system(self):
        """ì‹œìŠ¤í…œ ì‹œì‘"""
        self.is_system_running = True
        self.inference_count = 0
        self.get_logger().info("ğŸš€ RoboVLMs system started")
        self.publish_status("started")
    
    def stop_system(self):
        """ì‹œìŠ¤í…œ ì¤‘ì§€"""
        self.is_system_running = False
        self.is_inference_active = False
        # ë¡œë´‡ ì •ì§€
        self.stop_robot()
        self.get_logger().info("ğŸ›‘ RoboVLMs system stopped")
        self.publish_status("stopped")
    
    def pause_system(self):
        """ì‹œìŠ¤í…œ ì¼ì‹œì •ì§€"""
        self.is_system_running = False
        self.is_inference_active = False
        self.stop_robot()
        self.get_logger().info("â¸ï¸ RoboVLMs system paused")
        self.publish_status("paused")
    
    def resume_system(self):
        """ì‹œìŠ¤í…œ ì¬ê°œ"""
        self.is_system_running = True
        self.get_logger().info("â–¶ï¸ RoboVLMs system resumed")
        self.publish_status("running")
    
    def stop_robot(self):
        """ë¡œë´‡ ì •ì§€"""
        try:
            # ì‹¤ì œ ë¡œë´‡ ì •ì§€
            if ROBOT_AVAILABLE and self.driver:
                self.driver.stop()
            
            # ROS í† í”½ë„ ì •ì§€ ë©”ì‹œì§€ ë°œí–‰
            twist = Twist()
            twist.linear.x = 0.0
            twist.linear.y = 0.0
            twist.angular.z = 0.0
            self.action_pub.publish(twist)
            
            self.get_logger().info("ğŸ›‘ ë¡œë´‡ ì •ì§€ ì™„ë£Œ")
        except Exception as e:
            self.get_logger().error(f"Error stopping robot: {e}")
    
    def task_callback(self, msg):
        """íƒœìŠ¤í¬ ì—…ë°ì´íŠ¸ ì½œë°±"""
        self.current_task = msg.data
        self.get_logger().info(f"Task updated: {self.current_task}")
    
    def image_callback(self, msg):
        """ì´ë¯¸ì§€ ìˆ˜ì‹  ì½œë°±"""
        if not self.is_system_running or not self.is_inference_active:
            return
        
        try:
            # ì••ì¶•ëœ ì´ë¯¸ì§€ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
            np_arr = np.frombuffer(msg.data, np.uint8)
            image = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
            
            if image is not None:
                # íì— ì´ë¯¸ì§€ ì¶”ê°€ (ê¸°ì¡´ ì´ë¯¸ì§€ êµì²´)
                if not self.image_queue.empty():
                    self.image_queue.get()
                self.image_queue.put(image)
                
        except Exception as e:
            self.get_logger().error(f"Error processing image: {e}")
    
    def inference_worker(self):
        """ì¶”ë¡  ì›Œì»¤ ìŠ¤ë ˆë“œ"""
        while rclpy.ok():
            if self.is_inference_active:
                if not self.image_queue.empty():
                    try:
                        image = self.image_queue.get()
                        self.perform_inference(image)
                    except Exception as e:
                        self.get_logger().error(f"Error in inference worker: {e}")
                else:
                    # ì´ë¯¸ì§€ê°€ ì—†ì„ ë•ŒëŠ” í…ŒìŠ¤íŠ¸ ì•¡ì…˜ ì‹¤í–‰ (ë””ë²„ê¹…ìš©)
                    self.generate_test_action()
                    time.sleep(1.0)  # 1ì´ˆ ëŒ€ê¸°
            else:
                time.sleep(0.1)  # ì¶”ë¡  ë¹„í™œì„±í™” ì‹œ 0.1ì´ˆ ëŒ€ê¸°
            
            time.sleep(0.1)  # 10Hz ì¶”ë¡  ì£¼ê¸°
    
    def perform_inference(self, image: np.ndarray):
        """ì‹¤ì œ ì¶”ë¡  ìˆ˜í–‰ (Kosmos-2 + RNN + Action Head êµ¬ì¡°)"""
        if self.model is None:
            # í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ëœë¤ ì•¡ì…˜ ìƒì„±
            self.generate_test_action()
            return
        
        try:
            start_time = time.time()
            
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (Kosmos-2 ê¸°ë°˜)
            pil_image = PILImage.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
            
            # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • (Kosmos-2 ì…ë ¥ í¬ê¸°)
            target_size = (224, 224)  # Kosmos-2 patch14-224
            pil_image = pil_image.resize(target_size, PILImage.Resampling.LANCZOS)
            
            # ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜ (ì •ê·œí™” í¬í•¨)
            image_array = np.array(pil_image).astype(np.float32) / 255.0  # 0-1 ì •ê·œí™”
            image_tensor = torch.from_numpy(image_array).float()
            image_tensor = image_tensor.permute(2, 0, 1)  # HWC -> CHW
            image_tensor = image_tensor.unsqueeze(0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
            image_tensor = image_tensor.to(self.device)
            
            # ëª¨ë¸ ì¶”ë¡  (í›ˆë ¨ê³¼ ë™ì¼í•œ ë°©ì‹)
            with torch.no_grad():
                # Kosmos-2 + RNN + Action Head ëª¨ë¸ ì¶”ë¡ 
                action = self.model(image_tensor)  # [B, action_dim]
                
                # ì•¡ì…˜ ì¶”ì¶œ
                if isinstance(action, torch.Tensor):
                    action = action.cpu().numpy()[0]  # [action_dim]
                    # ì‹ ë¢°ë„ ê³„ì‚° (ì•¡ì…˜ í¬ê¸° ê¸°ë°˜)
                    confidence = min(1.0, np.linalg.norm(action) / 2.0)
                else:
                    action = np.array([0.0, 0.0, 0.0])
                    confidence = 0.0
                
                # ì•¡ì…˜ ì •ê·œí™” (2D ì•¡ì…˜: linear_x, linear_y)
                if len(action) >= 2:
                    action_dict = {
                        "linear_x": float(action[0]),
                        "linear_y": float(action[1]),
                        "angular_z": 0.0  # 2D ëª¨ë¸ì´ë¯€ë¡œ íšŒì „ì€ 0
                    }
                else:
                    action_dict = {
                        "linear_x": 0.0,
                        "linear_y": 0.0,
                        "angular_z": 0.0
                    }
            
            # ì¶”ë¡  ì‹œê°„ ê³„ì‚°
            inference_time = time.time() - start_time
            self.last_inference_time = start_time
            self.inference_count += 1
            self.inference_latency = inference_time
            self.inference_confidence = confidence
            self.last_inference_result = action_dict
            
            # ì•¡ì…˜ ì‹¤í–‰
            self.execute_action(action_dict)
            
            # ê²°ê³¼ ë°œí–‰
            result = {
                "action": action_dict,
                "inference_time": inference_time,
                "confidence": confidence,
                "timestamp": time.time()
            }
            self.publish_inference_result(result)
            
            # ì‹ ë¢°ë„ ê¸°ë°˜ ë¡œê¹…
            action_desc = []
            if abs(action_dict['linear_x']) > 0.1:
                action_desc.append(f"ì „ì§„{action_dict['linear_x']:+.1f}")
            if abs(action_dict['linear_y']) > 0.1:
                action_desc.append(f"íš¡ì´ë™{action_dict['linear_y']:+.1f}")
            if abs(action_dict['angular_z']) > 0.1:
                action_desc.append(f"íšŒì „{action_dict['angular_z']:+.1f}")
            if not action_desc:
                action_desc.append("ì •ì§€")
            
            confidence_emoji = "ğŸŸ¢" if confidence > 0.7 else "ğŸŸ¡" if confidence > 0.4 else "ğŸ”´"
            self.get_logger().info(f"ğŸ¤– Kosmos-2 ì¶”ë¡ : {', '.join(action_desc)} ({inference_time:.3f}s) {confidence_emoji} ì‹ ë¢°ë„: {confidence:.3f}")
            
        except Exception as e:
            self.get_logger().error(f"Error during inference: {e}")
            # ì—ëŸ¬ ì‹œ ì •ì§€
            self.execute_action(self.STOP_ACTION)
    
    def generate_test_action(self):
        """í…ŒìŠ¤íŠ¸ ëª¨ë“œìš© ëœë¤ ì•¡ì…˜ ìƒì„±"""
        import random
        
        # ê°„ë‹¨í•œ ëœë¤ ì•¡ì…˜ ìƒì„± (ì‹¤ì œ ì›€ì§ì„)
        actions = [
            {"linear_x": 0.8, "linear_y": 0.0, "angular_z": 0.0},   # ì „ì§„
            {"linear_x": -0.8, "linear_y": 0.0, "angular_z": 0.0},  # í›„ì§„
            {"linear_x": 0.0, "linear_y": 0.8, "angular_z": 0.0},   # ì¢Œì¸¡
            {"linear_x": 0.0, "linear_y": -0.8, "angular_z": 0.0},  # ìš°ì¸¡
            {"linear_x": 0.0, "linear_y": 0.0, "angular_z": 0.8},   # ì¢ŒíšŒì „
            {"linear_x": 0.0, "linear_y": 0.0, "angular_z": -0.8},  # ìš°íšŒì „
            {"linear_x": 0.0, "linear_y": 0.0, "angular_z": 0.0},   # ì •ì§€
        ]
        
        action = random.choice(actions)
        self.execute_action(action)
        
        action_desc = []
        if abs(action['linear_x']) > 0.1:
            action_desc.append(f"ì „ì§„{action['linear_x']:+.1f}")
        if abs(action['linear_y']) > 0.1:
            action_desc.append(f"íš¡ì´ë™{action['linear_y']:+.1f}")
        if abs(action['angular_z']) > 0.1:
            action_desc.append(f"íšŒì „{action['angular_z']:+.1f}")
        if not action_desc:
            action_desc.append("ì •ì§€")
        
        self.get_logger().info(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ: {', '.join(action_desc)}")
    
    def execute_action(self, action: dict):
        """ì•¡ì…˜ ì‹¤í–‰ (AI ì œì–´ ëª¨ë“œìš©)"""
        try:
            # ì‹¤ì œ ë¡œë´‡ ì œì–´ (AI ì•¡ì…˜ë„ ì‹¤ì œ ì›€ì§ì„ìœ¼ë¡œ)
            self.execute_robot_action(action)
            
            # ì•¡ì…˜ ì„¤ëª… ìƒì„±
            action_desc = []
            if abs(action['linear_x']) > 0.1:
                action_desc.append(f"ì „ì§„{action['linear_x']:+.1f}")
            if abs(action['linear_y']) > 0.1:
                action_desc.append(f"íš¡ì´ë™{action['linear_y']:+.1f}")
            if abs(action['angular_z']) > 0.1:
                action_desc.append(f"íšŒì „{action['angular_z']:+.1f}")
            if not action_desc:
                action_desc.append("ì •ì§€")
            
            self.get_logger().info(f"ğŸ¤– AI ì•¡ì…˜ ì‹¤í–‰: {', '.join(action_desc)}")
            
        except Exception as e:
            self.get_logger().error(f"Error executing action: {e}")
    
    def publish_inference_result(self, result: dict):
        """ì¶”ë¡  ê²°ê³¼ ë°œí–‰"""
        try:
            msg = String()
            msg.data = json.dumps(result)
            self.inference_result_pub.publish(msg)
            
            # ì‹ ë¢°ë„ë„ ë³„ë„ë¡œ ë°œí–‰
            confidence_msg = Float32MultiArray()
            confidence_msg.data = [result.get('confidence', 0.0)]
            self.confidence_pub.publish(confidence_msg)
        except Exception as e:
            self.get_logger().error(f"Error publishing inference result: {e}")
    
    def publish_status(self, status: str):
        """ìƒíƒœ ë°œí–‰"""
        try:
            msg = String()
            msg.data = json.dumps({
                "status": status,
                "timestamp": time.time(),
                "inference_count": self.inference_count
            })
            self.status_pub.publish(msg)
        except Exception as e:
            self.get_logger().error(f"Error publishing status: {e}")


def main(args=None):
    rclpy.init(args=args)
    inference_node = RoboVLMsInference()
    
    try:
        rclpy.spin(inference_node)
    except KeyboardInterrupt:
        pass
    finally:
        inference_node.destroy_node()
        rclpy.shutdown()


if __name__ == '__main__':
    main()
