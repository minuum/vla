#!/usr/bin/env python3
"""
í˜„ì¬ ë°ì´í„°ì…‹ì—ì„œ ê°€ì¥ ë§ì€ íŒ¨í„´ì„ ì¶”ì¶œí•˜ì—¬ ê°€ì´ë“œë¡œ ì—…ë°ì´íŠ¸
"""
import h5py
from pathlib import Path
from collections import defaultdict, Counter
import json
import numpy as np

def infer_key_from_action(action):
    """ì•¡ì…˜ì—ì„œ í‚¤ ì¶”ë¡ """
    lx, ly, az = action['linear_x'], action['linear_y'], action['angular_z']
    if abs(az) > 0.1:
        return 'R' if az > 0 else 'T'
    if abs(lx) < 0.1 and abs(ly) < 0.1:
        return 'SPACE'
    if lx > 0.1 and abs(ly) <= 0.1:
        return 'W'
    if lx < -0.1 and abs(ly) <= 0.1:
        return 'S'
    if ly > 0.1 and abs(lx) <= 0.1:
        return 'A'
    if ly < -0.1 and abs(lx) <= 0.1:
        return 'D'
    if lx > 0.1 and ly > 0.1:
        return 'Q'
    if lx > 0.1 and ly < -0.1:
        return 'E'
    if lx < -0.1 and ly > 0.1:
        return 'Z'
    if lx < -0.1 and ly < -0.1:
        return 'C'
    return 'UNK'

def extract_trajectory(h5_file):
    """H5 íŒŒì¼ì—ì„œ ê¶¤ì  ì¶”ì¶œ"""
    try:
        with h5py.File(h5_file, 'r') as f:
            actions = f['actions'][:]
            action_event_types = f['action_event_types'][:]
            if isinstance(action_event_types[0], bytes):
                action_event_types = [e.decode('utf-8') for e in action_event_types]
            trajectory = []
            for idx, ev in enumerate(action_event_types):
                if ev == 'start_action':
                    action = {
                        'linear_x': float(actions[idx][0]),
                        'linear_y': float(actions[idx][1]),
                        'angular_z': float(actions[idx][2])
                    }
                    key = infer_key_from_action(action)
                    trajectory.append(key)
            return ' '.join(trajectory)
    except Exception as e:
        print(f"âŒ {h5_file.name} ë¶„ì„ ì‹¤íŒ¨: {e}")
        return None

def normalize_to_18_keys(keys, target_length=17):
    """17ê°œ ì•¡ì…˜ìœ¼ë¡œ ì •ê·œí™” (ì´ˆê¸° í”„ë ˆì„ 1ê°œ + 17ê°œ ì•¡ì…˜ = 18 í”„ë ˆì„)"""
    normalized = list(keys[:target_length])
    if len(normalized) < target_length:
        normalized += ['SPACE'] * (target_length - len(normalized))
    return normalized

def main():
    dataset_dir = Path('/home/soda/vla/ROS_action/mobile_vla_dataset')
    core_pattern_file = dataset_dir / "core_patterns.json"
    
    h5_files = list(dataset_dir.glob('*.h5'))
    print(f"ğŸ“Š ì´ {len(h5_files)}ê°œ íŒŒì¼ ë¶„ì„ ì¤‘...\n")
    
    # ì¡°í•©ë³„ íŒ¨í„´ í†µê³„
    combo_pattern_stats = defaultdict(lambda: defaultdict(int))
    
    for h5_file in h5_files:
        name = h5_file.stem
        parts = name.split('_')
        
        # ì‹œë‚˜ë¦¬ì˜¤, ê±°ë¦¬, íŒ¨í„´ ì¶”ì¶œ
        scenario = None
        distance = None
        pattern = None
        
        for i, part in enumerate(parts):
            if part in ['1box', '2box']:
                if i + 2 < len(parts):
                    direction = parts[i + 2]
                    if direction in ['left', 'right']:
                        scenario = f"{part}_{direction}"
                        break
        
        for part in parts:
            if part in ['close', 'medium', 'far']:
                distance = part
                break
        
        for part in parts:
            if part in ['core', 'variant']:
                pattern = part
                break
        
        if scenario and distance and pattern:
            trajectory = extract_trajectory(h5_file)
            if trajectory:
                combo_key = f"{scenario}__{pattern}__{distance}"
                combo_pattern_stats[combo_key][trajectory] += 1
    
    # ê° ì¡°í•©ë³„ë¡œ ê°€ì¥ ë§ì€ íŒ¨í„´ ì°¾ê¸°
    print("=" * 80)
    print("ğŸ“Š ì¡°í•©ë³„ ìµœë‹¤ íŒ¨í„´ ë¶„ì„")
    print("=" * 80)
    
    updated_patterns = {}
    
    for combo_key in sorted(combo_pattern_stats.keys()):
        pattern_dict = combo_pattern_stats[combo_key]
        if not pattern_dict:
            continue
        
        sorted_patterns = sorted(pattern_dict.items(), key=lambda x: x[1], reverse=True)
        most_common = sorted_patterns[0]
        total = sum(pattern_dict.values())
        
        print(f"\n{combo_key}:")
        print(f"  ì´ {total}ê°œ íŒŒì¼")
        print(f"  ìµœë‹¤ íŒ¨í„´: {most_common[1]}ê°œ ({most_common[1]/total*100:.1f}%)")
        print(f"  ê¶¤ì : {most_common[0]}")
        
        # í‚¤ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (SPACEëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€)
        keys = most_common[0].split()
        # 17ê°œë¡œ ì •ê·œí™”
        normalized = normalize_to_18_keys(keys, target_length=17)
        # ëì— SPACEë§Œ ë‚¨ì•˜ì„ ê²½ìš° ì œê±°
        while normalized and normalized[-1] == 'SPACE':
            normalized.pop()
        
        # core íŒ¨í„´ë§Œ ì €ì¥
        if 'core' in combo_key:
            updated_patterns[combo_key] = normalized
            print(f"  âœ… ê°€ì´ë“œë¡œ ì €ì¥: {len(normalized)}ê°œ ì•¡ì…˜")
    
    # ê¸°ì¡´ ê°€ì´ë“œ ë¡œë“œ
    existing_patterns = {}
    if core_pattern_file.exists():
        try:
            with open(core_pattern_file, 'r', encoding='utf-8') as f:
                existing_patterns = json.load(f)
            print(f"\nğŸ“‹ ê¸°ì¡´ ê°€ì´ë“œ: {len(existing_patterns)}ê°œ")
        except Exception as e:
            print(f"âš ï¸ ê¸°ì¡´ ê°€ì´ë“œ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # ì—…ë°ì´íŠ¸ëœ íŒ¨í„´ê³¼ ê¸°ì¡´ íŒ¨í„´ ë³‘í•©
    final_patterns = existing_patterns.copy()
    for key, pattern in updated_patterns.items():
        old_pattern = final_patterns.get(key, [])
        if old_pattern != pattern:
            print(f"\nğŸ”„ ì—…ë°ì´íŠ¸: {key}")
            if old_pattern:
                old_str = " ".join([k.upper() for k in old_pattern])
                print(f"  ê¸°ì¡´: {old_str}")
            new_str = " ".join([k.upper() for k in pattern])
            print(f"  ì‹ ê·œ: {new_str}")
        final_patterns[key] = pattern
    
    # ì €ì¥
    print("\n" + "=" * 80)
    print("ğŸ’¾ ê°€ì´ë“œ ì €ì¥ ì¤‘...")
    print("=" * 80)
    
    try:
        core_pattern_file.parent.mkdir(parents=True, exist_ok=True)
        with open(core_pattern_file, 'w', encoding='utf-8') as f:
            json.dump(final_patterns, f, indent=2, ensure_ascii=False)
        print(f"âœ… ê°€ì´ë“œ ì €ì¥ ì™„ë£Œ: {core_pattern_file}")
        print(f"ğŸ“Š ì´ {len(final_patterns)}ê°œ ê°€ì´ë“œ ì €ì¥ë¨")
        
        print("\nğŸ“‹ ì €ì¥ëœ ê°€ì´ë“œ ëª©ë¡:")
        for key in sorted(final_patterns.keys()):
            pattern = final_patterns[key]
            pattern_str = " ".join([k.upper() for k in pattern])
            print(f"  {key}: {pattern_str} ({len(pattern)}ê°œ ì•¡ì…˜)")
    except Exception as e:
        print(f"âŒ ê°€ì´ë“œ ì €ì¥ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    main()

