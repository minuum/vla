# 📊 종합 모델 성능 비교표

## 🎯 MAE 성능 기준 순위

| 순위 | 모델명 | 모델 타입 | MAE | 데이터셋 | 에포크 | 파일 크기 | 특이사항 |
|------|--------|-----------|-----|----------|--------|-----------|----------|
| 1 | Kosmos2+CLIP Hybrid | Kosmos2+CLIP Hybrid | **0.212** | 증강 데이터 | 10 | 7.4GB | 🏆 최고 성능 |
| 2 | Pure Kosmos2 | Pure Kosmos2 | **0.247** | 증강 데이터 | 15 | 6.8GB | 🥈 2위 |
| 3 | Simple CLIP | CLIP 기반 | **0.451** | 원본 72 에피소드 | 3 | 1.7GB | 🥉 3위 |
| 4 | CLIP with LSTM | CLIP+LSTM | **0.456** | 원본 72 에피소드 | 3 | 1.7GB | 4위 |
| 5 | Original CLIP | CLIP 기반 | **0.494** | 원본 72 에피소드 | 3 | 1.7GB | 5위 |
| 6 | Original CLIP (증강) | CLIP 기반 | **0.672** | 증강 데이터 | 3 | 1.7GB | 6위 |

## 📈 상세 성능 분석

### 🏆 Top 3 모델 상세 정보

#### 1. Kosmos2+CLIP Hybrid (MAE: 0.212)
- **모델 구조**: Kosmos2 + CLIP Vision/Text + LSTM
- **데이터셋**: 증강 데이터 (대용량)
- **훈련 에포크**: 10
- **파일 크기**: 7.4GB
- **특징**: 가장 복잡한 구조, 최고 성능

#### 2. Pure Kosmos2 (MAE: 0.247)
- **모델 구조**: Kosmos2 단독 + LSTM
- **데이터셋**: 증강 데이터 (대용량)
- **훈련 에포크**: 15
- **파일 크기**: 6.8GB
- **특징**: Kosmos2의 강력한 성능

#### 3. Simple CLIP (MAE: 0.451)
- **모델 구조**: CLIP Vision + CLIP Text + Fusion
- **데이터셋**: 원본 72 에피소드
- **훈련 에포크**: 3
- **파일 크기**: 1.7GB
- **특징**: 가벼운 구조, 빠른 훈련

## 🔍 주요 발견사항

### 1. 데이터셋 영향
- **증강 데이터**: MAE 0.212~0.247 (우수)
- **원본 72 에피소드**: MAE 0.451~0.672 (보통)

### 2. 모델 복잡도 vs 성능
- **복잡한 모델**: Kosmos2+CLIP Hybrid (최고 성능)
- **중간 복잡도**: Pure Kosmos2 (우수 성능)
- **단순 모델**: CLIP 기반 (보통 성능)

### 3. 훈련 효율성
- **빠른 훈련**: CLIP 기반 모델 (3 에포크)
- **긴 훈련**: Kosmos2 모델 (10-15 에포크)

## 📊 성능 요약

| 성능 등급 | MAE 범위 | 모델 수 | 대표 모델 |
|-----------|----------|---------|-----------|
| 🏆 최고 | 0.20-0.25 | 2개 | Kosmos2+CLIP Hybrid |
| 🥈 우수 | 0.25-0.50 | 3개 | Simple CLIP |
| 🥉 보통 | 0.50-0.70 | 1개 | Original CLIP (증강) |

## 🎯 결론

1. **Kosmos2+CLIP Hybrid**가 가장 우수한 성능을 보임
2. **증강 데이터**가 성능 향상에 크게 기여
3. **모델 복잡도**와 **데이터셋 크기**가 성능에 직접적 영향
4. **CLIP 기반 모델**은 가벼우면서도 합리적인 성능 제공
