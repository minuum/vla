#!/usr/bin/env python3
"""
Enhanced Model Comparison Analysis
Vision Resamplerê°€ í¬í•¨ëœ í–¥ìƒëœ ëª¨ë¸ê³¼ ì´ì „ ëª¨ë¸ë“¤ì˜ ì¢…í•© ë¹„êµ ë¶„ì„
"""

import json
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import numpy as np

def load_model_results():
    """ëª¨ë“  ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    
    # í–¥ìƒëœ ëª¨ë¸ ê²°ê³¼
    enhanced_results = {
        "Enhanced 2D with Vision Resampler": {
            "model_type": "2D_Enhanced_VisionResampler",
            "mae": 0.8040846586227417,
            "rmse": 0.8860690295696259,
            "accuracy_10": 0.0,
            "accuracy_5": 0.0,
            "accuracy_1": 0.0,
            "total_samples": 15,
            "features": ["Vision Resampler", "2D Actions", "Kosmos2 Backbone"]
        }
    }
    
    # ì´ì „ ëª¨ë¸ ê²°ê³¼ë“¤
    previous_results = {
        "Optimized 2D Action": {
            "model_type": "2D_Optimized",
            "mae": 0.2919308894551268,
            "rmse": 0.48537490029934965,
            "accuracy_10": 24.836601307189543,
            "accuracy_5": 10.375816993464053,
            "accuracy_1": 0.16339869281045752,
            "total_samples": 1224,
            "features": ["2D Actions", "Kosmos2 Backbone"]
        },
        "Realistic (First Frame)": {
            "model_type": "3D_Realistic_First",
            "mae": 0.0013767265481874347,
            "rmse": 0.0020406664116308093,
            "accuracy_10": 100.0,
            "accuracy_5": 100.0,
            "accuracy_1": "N/A",
            "total_samples": 15,
            "features": ["3D Actions", "First Frame Only"]
        },
        "Realistic (Middle Frame)": {
            "model_type": "3D_Realistic_Middle",
            "mae": 0.5756955817341805,
            "rmse": 0.8074159473180771,
            "accuracy_10": 48.888888888888886,
            "accuracy_5": 48.888888888888886,
            "accuracy_1": "N/A",
            "total_samples": 15,
            "features": ["3D Actions", "Middle Frame Only"]
        },
        "No First Frame (Random)": {
            "model_type": "3D_NoFirstFrame_Random",
            "mae": 0.2405332587659359,
            "rmse": 0.42851802706718445,
            "accuracy_10": 60.0,
            "accuracy_5": 46.666666666666664,
            "accuracy_1": "N/A",
            "total_samples": 15,
            "features": ["3D Actions", "Random Frame", "No First Frame"]
        },
        "No First Frame (Middle)": {
            "model_type": "3D_NoFirstFrame_Middle",
            "mae": 0.2646177187561989,
            "rmse": 0.503977045416832,
            "accuracy_10": 62.22222222222222,
            "accuracy_5": 57.77777777777777,
            "accuracy_1": "N/A",
            "total_samples": 15,
            "features": ["3D Actions", "Middle Frame", "No First Frame"]
        }
    }
    
    return {**enhanced_results, **previous_results}

def create_comparison_table(results):
    """ëª¨ë¸ ë¹„êµ í…Œì´ë¸”ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    
    # ë°ì´í„°í”„ë ˆì„ ìƒì„±
    data = []
    for model_name, metrics in results.items():
        data.append({
            'Model': model_name,
            'Type': metrics['model_type'],
            'MAE': metrics['mae'],
            'RMSE': metrics['rmse'],
            'Accuracy (10%)': metrics['accuracy_10'],
            'Accuracy (5%)': metrics['accuracy_5'],
            'Accuracy (1%)': metrics['accuracy_1'],
            'Samples': metrics['total_samples'],
            'Features': ', '.join(metrics['features'])
        })
    
    df = pd.DataFrame(data)
    
    # MAE ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    df = df.sort_values('MAE')
    
    return df

def create_visualizations(results, df):
    """ì‹œê°í™”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('Enhanced Model vs Previous Models Comparison', fontsize=16, fontweight='bold')
    
    # 1. MAE ë¹„êµ
    ax1 = axes[0, 0]
    models = df['Model'].tolist()
    mae_values = df['MAE'].tolist()
    
    colors = ['red' if 'Enhanced' in model else 'blue' for model in models]
    bars = ax1.bar(range(len(models)), mae_values, color=colors, alpha=0.7)
    ax1.set_title('MAE Comparison (Lower is Better)')
    ax1.set_ylabel('MAE')
    ax1.set_xticks(range(len(models)))
    ax1.set_xticklabels(models, rotation=45, ha='right')
    
    # ê°’ í‘œì‹œ
    for i, (bar, value) in enumerate(zip(bars, mae_values)):
        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
                f'{value:.3f}', ha='center', va='bottom', fontsize=8)
    
    # 2. RMSE ë¹„êµ
    ax2 = axes[0, 1]
    rmse_values = df['RMSE'].tolist()
    
    bars = ax2.bar(range(len(models)), rmse_values, color=colors, alpha=0.7)
    ax2.set_title('RMSE Comparison (Lower is Better)')
    ax2.set_ylabel('RMSE')
    ax2.set_xticks(range(len(models)))
    ax2.set_xticklabels(models, rotation=45, ha='right')
    
    for i, (bar, value) in enumerate(zip(bars, rmse_values)):
        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
                f'{value:.3f}', ha='center', va='bottom', fontsize=8)
    
    # 3. Accuracy ë¹„êµ (10% ì„ê³„ê°’)
    ax3 = axes[1, 0]
    acc_10_values = [float(str(v).replace('%', '')) if v != 'N/A' else 0 for v in df['Accuracy (10%)'].tolist()]
    
    bars = ax3.bar(range(len(models)), acc_10_values, color=colors, alpha=0.7)
    ax3.set_title('Accuracy (10% Threshold) Comparison (Higher is Better)')
    ax3.set_ylabel('Accuracy (%)')
    ax3.set_xticks(range(len(models)))
    ax3.set_xticklabels(models, rotation=45, ha='right')
    
    for i, (bar, value) in enumerate(zip(bars, acc_10_values)):
        ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, 
                f'{value:.1f}%', ha='center', va='bottom', fontsize=8)
    
    # 4. ëª¨ë¸ íƒ€ì…ë³„ ë¶„í¬
    ax4 = axes[1, 1]
    model_types = df['Type'].value_counts()
    ax4.pie(model_types.values, labels=model_types.index, autopct='%1.1f%%', startangle=90)
    ax4.set_title('Model Types Distribution')
    
    plt.tight_layout()
    plt.savefig('enhanced_model_comparison_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()

def generate_analysis_report(df, results):
    """ë¶„ì„ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    
    report = {
        "analysis_summary": {
            "total_models": len(results),
            "enhanced_model_rank": df[df['Model'].str.contains('Enhanced')].index[0] + 1,
            "best_mae_model": df.iloc[0]['Model'],
            "best_mae_value": df.iloc[0]['MAE'],
            "worst_mae_model": df.iloc[-1]['Model'],
            "worst_mae_value": df.iloc[-1]['MAE']
        },
        "enhanced_model_analysis": {
            "mae_rank": df[df['Model'].str.contains('Enhanced')].index[0] + 1,
            "mae_value": df[df['Model'].str.contains('Enhanced')]['MAE'].iloc[0],
            "rmse_value": df[df['Model'].str.contains('Enhanced')]['RMSE'].iloc[0],
            "accuracy_10": df[df['Model'].str.contains('Enhanced')]['Accuracy (10%)'].iloc[0],
            "unique_features": ["Vision Resampler"],
            "performance_analysis": "Vision Resamplerê°€ í¬í•¨ëœ í–¥ìƒëœ ëª¨ë¸ì˜ ì„±ëŠ¥ ë¶„ì„"
        },
        "key_findings": [
            "Vision Resampler ëª¨ë¸ì´ ê°€ì¥ ë†’ì€ MAEë¥¼ ë³´ì„ (0.804)",
            "2D ìµœì í™” ëª¨ë¸ì´ ê°€ì¥ ë‚®ì€ MAEë¥¼ ë³´ì„ (0.292)",
            "ì²« í”„ë ˆì„ ëª¨ë¸ì´ 100% ì •í™•ë„ë¥¼ ë³´ì´ì§€ë§Œ ì‹¤ì œ ì˜ë¯¸ëŠ” ì œí•œì ",
            "ì¤‘ê°„ í”„ë ˆì„ ëª¨ë¸ë“¤ì´ ë” í˜„ì‹¤ì ì¸ ì„±ëŠ¥ì„ ë³´ì„",
            "Vision Resamplerì˜ ì¶”ê°€ê°€ ì˜ˆìƒê³¼ ë‹¤ë¥¸ ê²°ê³¼ë¥¼ ë³´ì„"
        ],
        "recommendations": [
            "Vision Resampler êµ¬í˜„ì„ ì¬ê²€í† í•˜ê³  ìµœì í™” í•„ìš”",
            "2D ì•¡ì…˜ ìµœì í™”ê°€ ê°€ì¥ íš¨ê³¼ì ì¸ ì ‘ê·¼ë²•ì„ì„ í™•ì¸",
            "ë” í° ë°ì´í„°ì…‹ì—ì„œ Vision Resampler íš¨ê³¼ ì¬í‰ê°€ í•„ìš”",
            "í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ìœ¼ë¡œ Vision Resampler ì„±ëŠ¥ ê°œì„  ê°€ëŠ¥ì„±",
            "ë‹¤ë¥¸ RoboVLMs ê³ ê¸‰ ê¸°ëŠ¥ë“¤ê³¼ì˜ ì¡°í•© ì‹¤í—˜ í•„ìš”"
        ]
    }
    
    return report

def main():
    """ë©”ì¸ ë¶„ì„ í•¨ìˆ˜"""
    
    print("ğŸ” Enhanced Model Comparison Analysis")
    print("=" * 50)
    
    # ê²°ê³¼ ë¡œë“œ
    results = load_model_results()
    
    # ë¹„êµ í…Œì´ë¸” ìƒì„±
    df = create_comparison_table(results)
    
    print("\nğŸ“Š Model Comparison Table:")
    print(df.to_string(index=False))
    
    # ì‹œê°í™” ìƒì„±
    print("\nğŸ“ˆ Creating visualizations...")
    create_visualizations(results, df)
    
    # ë¶„ì„ ë³´ê³ ì„œ ìƒì„±
    report = generate_analysis_report(df, results)
    
    print("\nğŸ“‹ Analysis Report:")
    print(f"Total Models: {report['analysis_summary']['total_models']}")
    print(f"Enhanced Model Rank: {report['analysis_summary']['enhanced_model_rank']}")
    print(f"Best MAE Model: {report['analysis_summary']['best_mae_model']} ({report['analysis_summary']['best_mae_value']:.3f})")
    print(f"Worst MAE Model: {report['analysis_summary']['worst_mae_model']} ({report['analysis_summary']['worst_mae_value']:.3f})")
    
    print("\nğŸ” Key Findings:")
    for finding in report['key_findings']:
        print(f"  â€¢ {finding}")
    
    print("\nğŸ’¡ Recommendations:")
    for rec in report['recommendations']:
        print(f"  â€¢ {rec}")
    
    # ê²°ê³¼ ì €ì¥
    with open('enhanced_model_comparison_results.json', 'w') as f:
        json.dump({
            'comparison_table': df.to_dict('records'),
            'analysis_report': report,
            'raw_results': results
        }, f, indent=2, default=str)
    
    print(f"\nâœ… Analysis completed! Results saved to:")
    print(f"  - enhanced_model_comparison_analysis.png")
    print(f"  - enhanced_model_comparison_results.json")

if __name__ == "__main__":
    main()
