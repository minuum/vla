#!/usr/bin/env python3
"""
Mobile VLA Omniwheel ëª¨ë¸ TensorRT ì–‘ìí™”
- í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ minium/mobile-vla-omniwheel ëª¨ë¸ì„ TensorRTë¡œ ë³€í™˜
- INT8 ì–‘ìí™”ë¡œ ì„±ëŠ¥ ìµœì í™”
- Jetson ë° GPU í™˜ê²½ì—ì„œ ê³ ì„±ëŠ¥ ì¶”ë¡ 
"""

import torch
import torch.nn as nn
from transformers import AutoProcessor, AutoModel
import numpy as np
import os
import json
import time
from typing import Dict, Any, Optional
import tensorrt as trt
import pycuda.driver as cuda
import pycuda.autoinit
from PIL import Image
import cv2

class MobileVLATensorRTConverter:
    """Mobile VLA ëª¨ë¸ì„ TensorRTë¡œ ë³€í™˜í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, model_name: str = "minium/mobile-vla-omniwheel"):
        self.model_name = model_name
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # TensorRT ì„¤ì •
        self.logger = trt.Logger(trt.Logger.WARNING)
        self.builder = trt.Builder(self.logger)
        self.config = self.builder.create_builder_config()
        self.network = self.builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
        
        # ëª¨ë¸ ë¡œë“œ
        self.load_original_model()
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬
        self.output_dir = "Robo+/Mobile_VLA/tensorrt_quantized"
        os.makedirs(self.output_dir, exist_ok=True)
        
    def load_original_model(self):
        """ì›ë³¸ ëª¨ë¸ ë¡œë“œ"""
        print(f"ğŸ”„ Loading original model: {self.model_name}")
        
        try:
            self.processor = AutoProcessor.from_pretrained(self.model_name)
            self.model = AutoModel.from_pretrained(self.model_name)
            
            if self.device.type == 'cuda':
                self.model = self.model.cuda()
            
            self.model.eval()
            print("âœ… Original model loaded successfully")
            
        except Exception as e:
            print(f"âŒ Failed to load original model: {e}")
            raise
    
    def create_calibration_dataset(self, num_samples: int = 100) -> list:
        """ì–‘ìí™”ë¥¼ ìœ„í•œ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„°ì…‹ ìƒì„±"""
        print(f"ğŸ“Š Creating calibration dataset with {num_samples} samples")
        
        calibration_data = []
        
        # ë‹¤ì–‘í•œ ì´ë¯¸ì§€ í¬ê¸°ì™€ ë‚´ìš©ìœ¼ë¡œ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„° ìƒì„±
        for i in range(num_samples):
            # ëœë¤ ì´ë¯¸ì§€ ìƒì„± (ì‹¤ì œ ì‚¬ìš© í™˜ê²½ê³¼ ìœ ì‚¬í•˜ê²Œ)
            img_size = np.random.choice([224, 256, 320])
            image = np.random.randint(0, 255, (img_size, img_size, 3), dtype=np.uint8)
            
            # PIL Imageë¡œ ë³€í™˜
            pil_image = Image.fromarray(image)
            
            # í”„ë¡œì„¸ì„œë¡œ ì „ì²˜ë¦¬
            inputs = self.processor(
                images=pil_image,
                text="Navigate around obstacles to track the target cup",
                return_tensors="pt"
            )
            
            # GPUë¡œ ì´ë™
            if self.device.type == 'cuda':
                inputs = {k: v.cuda() for k, v in inputs.items()}
            
            calibration_data.append(inputs)
        
        print(f"âœ… Calibration dataset created: {len(calibration_data)} samples")
        return calibration_data
    
    def create_tensorrt_network(self):
        """TensorRT ë„¤íŠ¸ì›Œí¬ ìƒì„±"""
        print("ğŸ”§ Creating TensorRT network")
        
        # ì…ë ¥ í…ì„œ ì •ì˜
        input_shape = (1, 3, 224, 224)  # ë°°ì¹˜, ì±„ë„, ë†’ì´, ë„ˆë¹„
        input_tensor = self.network.add_input(
            name="input_images",
            dtype=trt.float32,
            shape=input_shape
        )
        
        # í…ìŠ¤íŠ¸ ì…ë ¥ (ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜)
        text_shape = (1, 512)  # ë°°ì¹˜, ì„ë² ë”© ì°¨ì›
        text_tensor = self.network.add_input(
            name="input_text_embeddings",
            dtype=trt.float32,
            shape=text_shape
        )
        
        # ê°„ë‹¨í•œ í•©ì„±ê³± ë ˆì´ì–´ (ì‹¤ì œ ëª¨ë¸ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì • í•„ìš”)
        conv1 = self.network.add_convolution(
            input=input_tensor,
            num_output_maps=64,
            kernel_shape=(3, 3),
            kernel=torch.randn(64, 3, 3, 3).numpy(),
            bias=torch.randn(64).numpy()
        )
        conv1.stride = (1, 1)
        conv1.padding = (1, 1)
        
        # ReLU í™œì„±í™”
        relu1 = self.network.add_activation(conv1.get_output(0), trt.ActivationType.RELU)
        
        # í’€ë§ ë ˆì´ì–´
        pool1 = self.network.add_pooling(
            relu1.get_output(0),
            trt.PoolingType.MAX,
            window_size=(2, 2)
        )
        pool1.stride = (2, 2)
        
        # ì™„ì „ ì—°ê²° ë ˆì´ì–´ (ì•¡ì…˜ ì¶œë ¥)
        fc1 = self.network.add_fully_connected(
            pool1.get_output(0),
            num_outputs=512,
            kernel=torch.randn(512, 64 * 56 * 56).numpy(),
            bias=torch.randn(512).numpy()
        )
        
        # í…ìŠ¤íŠ¸ ì„ë² ë”©ê³¼ ê²°í•©
        concat = self.network.add_concatenation([fc1.get_output(0), text_tensor])
        
        # ìµœì¢… ì•¡ì…˜ ì¶œë ¥ ë ˆì´ì–´
        action_output = self.network.add_fully_connected(
            concat.get_output(0),
            num_outputs=3,  # linear_x, linear_y, angular_z
            kernel=torch.randn(3, 1024).numpy(),
            bias=torch.randn(3).numpy()
        )
        
        # ì¶œë ¥ í…ì„œ ì •ì˜
        action_output.get_output(0).name = "action_output"
        self.network.mark_output(action_output.get_output(0))
        
        print("âœ… TensorRT network created")
    
    def calibrate_int8(self, calibration_data: list) -> trt.IInt8Calibrator:
        """INT8 ì–‘ìí™” ìº˜ë¦¬ë¸Œë ˆì´ì…˜"""
        print("ğŸ¯ Starting INT8 calibration")
        
        class Int8Calibrator(trt.IInt8Calibrator):
            def __init__(self, data, cache_file):
                trt.IInt8Calibrator.__init__(self)
                self.data = data
                self.cache_file = cache_file
                self.current_index = 0
                
            def get_batch_size(self):
                return 1
            
            def get_batch(self, names):
                if self.current_index >= len(self.data):
                    return None
                
                batch_data = self.data[self.current_index]
                self.current_index += 1
                
                # ì…ë ¥ ë°ì´í„° ì¤€ë¹„
                images = batch_data['pixel_values'].cpu().numpy()
                text_embeddings = batch_data['input_ids'].float().cpu().numpy()
                
                return [images, text_embeddings]
            
            def read_calibration_cache(self):
                if os.path.exists(self.cache_file):
                    with open(self.cache_file, "rb") as f:
                        return f.read()
                return None
            
            def write_calibration_cache(self, cache):
                with open(self.cache_file, "wb") as f:
                    f.write(cache)
        
        cache_file = os.path.join(self.output_dir, "calibration.cache")
        calibrator = Int8Calibrator(calibration_data, cache_file)
        
        return calibrator
    
    def build_tensorrt_engine(self, precision: str = "fp16", use_int8: bool = False):
        """TensorRT ì—”ì§„ ë¹Œë“œ"""
        print(f"ğŸ”¨ Building TensorRT engine (precision: {precision}, INT8: {use_int8})")
        
        # ë„¤íŠ¸ì›Œí¬ ìƒì„±
        self.create_tensorrt_network()
        
        # ì„¤ì • êµ¬ì„±
        if precision == "fp16" and self.builder.platform_has_fast_fp16:
            self.config.set_flag(trt.BuilderFlag.FP16)
            print("âœ… FP16 precision enabled")
        
        if use_int8 and self.builder.platform_has_fast_int8:
            self.config.set_flag(trt.BuilderFlag.INT8)
            self.config.set_flag(trt.BuilderFlag.STRICT_TYPES)
            
            # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„° ìƒì„±
            calibration_data = self.create_calibration_dataset()
            calibrator = self.calibrate_int8(calibration_data)
            self.config.int8_calibrator = calibrator
            
            print("âœ… INT8 quantization enabled")
        
        # ìµœëŒ€ ì›Œí¬ìŠ¤í˜ì´ìŠ¤ í¬ê¸° ì„¤ì •
        self.config.max_workspace_size = 1 << 30  # 1GB
        
        # ì—”ì§„ ë¹Œë“œ
        engine = self.builder.build_engine(self.network, self.config)
        
        if engine is None:
            raise RuntimeError("Failed to build TensorRT engine")
        
        # ì—”ì§„ ì €ì¥
        engine_path = os.path.join(self.output_dir, f"mobile_vla_{precision}.engine")
        with open(engine_path, "wb") as f:
            f.write(engine.serialize())
        
        print(f"âœ… TensorRT engine saved: {engine_path}")
        return engine_path
    
    def test_tensorrt_inference(self, engine_path: str):
        """TensorRT ì¶”ë¡  í…ŒìŠ¤íŠ¸"""
        print("ğŸ§ª Testing TensorRT inference")
        
        # ì—”ì§„ ë¡œë“œ
        with open(engine_path, "rb") as f:
            engine_data = f.read()
        
        runtime = trt.Runtime(self.logger)
        engine = runtime.deserialize_cuda_engine(engine_data)
        context = engine.create_execution_context()
        
        # ì…ë ¥ ë°ì´í„° ì¤€ë¹„
        test_image = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)
        pil_image = Image.fromarray(test_image)
        
        inputs = self.processor(
            images=pil_image,
            text="Navigate around obstacles to track the target cup",
            return_tensors="pt"
        )
        
        # GPU ë©”ëª¨ë¦¬ í• ë‹¹
        input_images = inputs['pixel_values'].cuda()
        input_text = inputs['input_ids'].float().cuda()
        
        # ì¶œë ¥ ë©”ëª¨ë¦¬ í• ë‹¹
        output_shape = (1, 3)  # ë°°ì¹˜, ì•¡ì…˜ ì°¨ì›
        output = cuda.mem_alloc(output_shape[0] * output_shape[1] * 4)  # float32
        
        # ì¶”ë¡  ì‹¤í–‰
        start_time = time.time()
        
        context.execute_v2(bindings=[
            int(input_images.data_ptr()),
            int(input_text.data_ptr()),
            int(output)
        ])
        
        inference_time = time.time() - start_time
        
        # ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
        result = np.empty(output_shape, dtype=np.float32)
        cuda.memcpy_dtoh(result, output)
        
        print(f"ğŸ¯ TensorRT inference completed: {inference_time:.4f}s")
        print(f"ğŸ“Š Action output: {result[0]}")
        
        return result[0], inference_time
    
    def benchmark_performance(self, engine_path: str, num_runs: int = 100):
        """ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
        print(f"ğŸ“ˆ Running performance benchmark ({num_runs} runs)")
        
        # ì—”ì§„ ë¡œë“œ
        with open(engine_path, "rb") as f:
            engine_data = f.read()
        
        runtime = trt.Runtime(self.logger)
        engine = runtime.deserialize_cuda_engine(engine_data)
        context = engine.create_execution_context()
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
        test_images = []
        for _ in range(num_runs):
            image = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)
            pil_image = Image.fromarray(image)
            inputs = self.processor(
                images=pil_image,
                text="Navigate around obstacles to track the target cup",
                return_tensors="pt"
            )
            test_images.append(inputs)
        
        # GPU ë©”ëª¨ë¦¬ í• ë‹¹
        input_images = torch.randn(1, 3, 224, 224).cuda()
        input_text = torch.randn(1, 512).cuda()
        output = cuda.mem_alloc(1 * 3 * 4)
        
        # ì›Œë°ì—…
        for _ in range(10):
            context.execute_v2(bindings=[
                int(input_images.data_ptr()),
                int(input_text.data_ptr()),
                int(output)
            ])
        
        # ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
        times = []
        for i in range(num_runs):
            start_time = time.time()
            
            context.execute_v2(bindings=[
                int(input_images.data_ptr()),
                int(input_text.data_ptr()),
                int(output)
            ])
            
            inference_time = time.time() - start_time
            times.append(inference_time)
            
            if (i + 1) % 20 == 0:
                print(f"Progress: {i + 1}/{num_runs}")
        
        # ê²°ê³¼ ë¶„ì„
        avg_time = np.mean(times)
        std_time = np.std(times)
        min_time = np.min(times)
        max_time = np.max(times)
        fps = 1.0 / avg_time
        
        results = {
            "average_time_ms": avg_time * 1000,
            "std_time_ms": std_time * 1000,
            "min_time_ms": min_time * 1000,
            "max_time_ms": max_time * 1000,
            "fps": fps,
            "num_runs": num_runs
        }
        
        print(f"ğŸ“Š Benchmark Results:")
        print(f"  Average: {avg_time*1000:.2f} ms")
        print(f"  Std Dev: {std_time*1000:.2f} ms")
        print(f"  Min: {min_time*1000:.2f} ms")
        print(f"  Max: {max_time*1000:.2f} ms")
        print(f"  FPS: {fps:.1f}")
        
        # ê²°ê³¼ ì €ì¥
        results_path = os.path.join(self.output_dir, "tensorrt_benchmark_results.json")
        with open(results_path, "w") as f:
            json.dump(results, f, indent=2)
        
        print(f"âœ… Benchmark results saved: {results_path}")
        return results

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ Starting Mobile VLA TensorRT Quantization")
    
    # ë³€í™˜ê¸° ì´ˆê¸°í™”
    converter = MobileVLATensorRTConverter()
    
    try:
        # FP16 ì—”ì§„ ë¹Œë“œ
        print("\nğŸ”¨ Building FP16 TensorRT engine...")
        fp16_engine_path = converter.build_tensorrt_engine(precision="fp16", use_int8=False)
        
        # FP16 ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        print("\nğŸ§ª Testing FP16 inference...")
        converter.test_tensorrt_inference(fp16_engine_path)
        
        # FP16 ë²¤ì¹˜ë§ˆí¬
        print("\nğŸ“ˆ Running FP16 benchmark...")
        fp16_results = converter.benchmark_performance(fp16_engine_path, num_runs=50)
        
        # INT8 ì—”ì§„ ë¹Œë“œ (ì„ íƒì )
        try:
            print("\nğŸ”¨ Building INT8 TensorRT engine...")
            int8_engine_path = converter.build_tensorrt_engine(precision="int8", use_int8=True)
            
            # INT8 ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
            print("\nğŸ§ª Testing INT8 inference...")
            converter.test_tensorrt_inference(int8_engine_path)
            
            # INT8 ë²¤ì¹˜ë§ˆí¬
            print("\nğŸ“ˆ Running INT8 benchmark...")
            int8_results = converter.benchmark_performance(int8_engine_path, num_runs=50)
            
            # ì„±ëŠ¥ ë¹„êµ
            print("\nğŸ“Š Performance Comparison:")
            print(f"  FP16: {fp16_results['average_time_ms']:.2f} ms ({fp16_results['fps']:.1f} FPS)")
            print(f"  INT8: {int8_results['average_time_ms']:.2f} ms ({int8_results['fps']:.1f} FPS)")
            
            speedup = fp16_results['average_time_ms'] / int8_results['average_time_ms']
            print(f"  INT8 Speedup: {speedup:.2f}x")
            
        except Exception as e:
            print(f"âš ï¸ INT8 quantization failed: {e}")
            print("Continuing with FP16 only...")
        
        print("\nâœ… TensorRT quantization completed successfully!")
        
    except Exception as e:
        print(f"âŒ TensorRT quantization failed: {e}")
        raise

if __name__ == "__main__":
    main()
