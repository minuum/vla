"""
ğŸ” 2D ì•¡ì…˜ ëª¨ë¸ ì„±ê³µë¥  ë””ë²„ê¹… ìŠ¤í¬ë¦½íŠ¸
ì„±ê³µë¥  ê³„ì‚°ì´ ì •í™•í•œì§€ í™•ì¸í•˜ê³  ì‹¤ì œ ì˜ˆì¸¡ê°’ ë¶„ì„
"""

import torch
import torch.nn as nn
import numpy as np
import h5py
import os
from pathlib import Path
from transformers import AutoProcessor
from torch.utils.data import DataLoader, Dataset
from tqdm import tqdm
import json
from PIL import Image

from optimized_2d_action_model import Optimized2DActionModel, Optimized2DActionDataset

def debug_accuracy_calculation():
    """ì„±ê³µë¥  ê³„ì‚° ë””ë²„ê¹…"""
    print("ğŸ” 2D ì•¡ì…˜ ëª¨ë¸ ì„±ê³µë¥  ê³„ì‚° ë””ë²„ê¹… ì‹œì‘!")
    
    # ì„¤ì •
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    data_path = '../../ROS_action/mobile_vla_dataset'
    batch_size = 4
    
    # í”„ë¡œì„¸ì„œ ë¡œë“œ
    processor = AutoProcessor.from_pretrained("microsoft/kosmos-2-patch14-224")
    
    # ëª¨ë¸ ë¡œë“œ
    model = Optimized2DActionModel(
        processor=processor,
        action_dim=2,
        dropout=0.2,
        use_claw_matrix=True,
        use_hierarchical=True,
        use_advanced_attention=True
    )
    
    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    checkpoint_path = 'optimized_2d_action_model_best.pth'
    if os.path.exists(checkpoint_path):
        checkpoint = torch.load(checkpoint_path, map_location=device)
        
        # ë™ì  ì–´ëŒ‘í„° ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ë”ë¯¸ í¬ì›Œë“œ íŒ¨ìŠ¤
        dummy_input = torch.zeros(1, 3, 224, 224).to(device)
        with torch.no_grad():
            _ = model(dummy_input, "Navigate to target")
        
        # í˜¸í™˜ë˜ëŠ” í‚¤ë§Œ ë¡œë“œ
        model_state_dict = model.state_dict()
        checkpoint_state_dict = checkpoint['model_state_dict']
        
        compatible_state_dict = {}
        for key in checkpoint_state_dict.keys():
            if key in model_state_dict and model_state_dict[key].shape == checkpoint_state_dict[key].shape:
                compatible_state_dict[key] = checkpoint_state_dict[key]
        
        model.load_state_dict(compatible_state_dict, strict=False)
        print(f"âœ… ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì™„ë£Œ")
    
    model = model.to(device)
    model.eval()
    
    # ì†Œê·œëª¨ ë°ì´í„°ì…‹ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
    test_dataset = Optimized2DActionDataset(data_path, processor, 'val')
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
    
    # ì„±ê³µë¥  ê³„ì‚°ì„ ìœ„í•œ ì„ê³„ê°’ë“¤
    thresholds = [0.1, 0.05, 0.01]
    
    print(f"\nğŸ“Š ì„±ê³µë¥  ê³„ì‚° ë””ë²„ê¹… (ì„ê³„ê°’: {thresholds})")
    print("="*80)
    
    all_predictions = []
    all_targets = []
    all_errors = []
    
    with torch.no_grad():
        for batch_idx, batch in enumerate(test_loader):
            if batch_idx >= 5:  # ì²˜ìŒ 5ê°œ ë°°ì¹˜ë§Œ ë¶„ì„
                break
                
            images = batch['image'].float().to(device)
            actions = batch['action'].float().to(device)
            
            # ì˜ˆì¸¡
            predicted_actions = model(images, "Navigate to target")
            
            # ì˜¤ì°¨ ê³„ì‚°
            errors = torch.abs(predicted_actions - actions)
            
            print(f"\nğŸ” ë°°ì¹˜ {batch_idx + 1}:")
            print(f"   ì˜ˆì¸¡ê°’: {predicted_actions.cpu().numpy()}")
            print(f"   íƒ€ê²Ÿê°’: {actions.cpu().numpy()}")
            print(f"   ì ˆëŒ€ì˜¤ì°¨: {errors.cpu().numpy()}")
            
            # ê° ì„ê³„ê°’ë³„ ì„±ê³µë¥  ê³„ì‚°
            for threshold in thresholds:
                # ê¸°ì¡´ ë°©ì‹: ëª¨ë“  ì°¨ì›ì´ ì„ê³„ê°’ ì´ë‚´
                all_within = torch.all(errors < threshold, dim=1)
                success_rate_all = (all_within.sum().item() / all_within.shape[0]) * 100
                
                # ê°œë³„ ì°¨ì›ë³„ ì„±ê³µë¥ 
                linear_x_within = errors[:, 0] < threshold
                linear_y_within = errors[:, 1] < threshold
                
                success_rate_x = (linear_x_within.sum().item() / linear_x_within.shape[0]) * 100
                success_rate_y = (linear_y_within.sum().item() / linear_y_within.shape[0]) * 100
                
                print(f"   ì„ê³„ê°’ {threshold}:")
                print(f"     ì „ì²´ ì„±ê³µë¥ : {success_rate_all:.1f}%")
                print(f"     linear_x ì„±ê³µë¥ : {success_rate_x:.1f}%")
                print(f"     linear_y ì„±ê³µë¥ : {success_rate_y:.1f}%")
            
            all_predictions.extend(predicted_actions.cpu().numpy())
            all_targets.extend(actions.cpu().numpy())
            all_errors.extend(errors.cpu().numpy())
    
    # ì „ì²´ í†µê³„
    all_predictions = np.array(all_predictions)
    all_targets = np.array(all_targets)
    all_errors = np.array(all_errors)
    
    print(f"\nğŸ“Š ì „ì²´ í†µê³„:")
    print(f"   ì´ ìƒ˜í”Œ ìˆ˜: {len(all_predictions)}")
    print(f"   í‰ê·  MAE: {np.mean(all_errors):.4f}")
    print(f"   linear_x í‰ê·  ì˜¤ì°¨: {np.mean(all_errors[:, 0]):.4f}")
    print(f"   linear_y í‰ê·  ì˜¤ì°¨: {np.mean(all_errors[:, 1]):.4f}")
    
    # ê° ì„ê³„ê°’ë³„ ì „ì²´ ì„±ê³µë¥ 
    print(f"\nğŸ¯ ì „ì²´ ì„±ê³µë¥  (ìƒˆë¡œìš´ ê³„ì‚°):")
    for threshold in thresholds:
        # ê°œë³„ ì°¨ì›ë³„ ì„±ê³µë¥ 
        linear_x_success = np.mean(all_errors[:, 0] < threshold) * 100
        linear_y_success = np.mean(all_errors[:, 1] < threshold) * 100
        
        # ì „ì²´ ì„±ê³µë¥  (ëª¨ë“  ì°¨ì›ì´ ì„ê³„ê°’ ì´ë‚´)
        all_success = np.mean(np.all(all_errors < threshold, axis=1)) * 100
        
        print(f"   ì„ê³„ê°’ {threshold}:")
        print(f"     ì „ì²´ ì„±ê³µë¥ : {all_success:.1f}%")
        print(f"     linear_x ì„±ê³µë¥ : {linear_x_success:.1f}%")
        print(f"     linear_y ì„±ê³µë¥ : {linear_y_success:.1f}%")
    
    # ì„±ê³µë¥  ê³„ì‚° ë°©ì‹ ë¹„êµ
    print(f"\nğŸ” ì„±ê³µë¥  ê³„ì‚° ë°©ì‹ ë¹„êµ:")
    print(f"   ê¸°ì¡´ ë°©ì‹: ëª¨ë“  ì•¡ì…˜ ì°¨ì›ì´ ì„ê³„ê°’ ì´ë‚´ì—¬ì•¼ ì„±ê³µ")
    print(f"   ê°œë³„ ì°¨ì›: ê° ì°¨ì›ë³„ë¡œ ë…ë¦½ì ìœ¼ë¡œ ì„±ê³µë¥  ê³„ì‚°")
    print(f"   í‰ê·  ë°©ì‹: ëª¨ë“  ì°¨ì›ì˜ í‰ê·  ì˜¤ì°¨ê°€ ì„ê³„ê°’ ì´ë‚´")
    
    # í‰ê·  ë°©ì‹ìœ¼ë¡œ ì„±ê³µë¥  ê³„ì‚°
    print(f"\nğŸ“Š í‰ê·  ë°©ì‹ ì„±ê³µë¥ :")
    for threshold in thresholds:
        mean_errors = np.mean(all_errors, axis=1)
        mean_success = np.mean(mean_errors < threshold) * 100
        print(f"   ì„ê³„ê°’ {threshold}: {mean_success:.1f}%")

def analyze_error_distribution():
    """ì˜¤ì°¨ ë¶„í¬ ë¶„ì„"""
    print(f"\nğŸ“ˆ ì˜¤ì°¨ ë¶„í¬ ë¶„ì„:")
    
    # ì‹¤ì œ ë°ì´í„°ì—ì„œ ì˜¤ì°¨ ë¶„í¬ í™•ì¸
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    data_path = '../../ROS_action/mobile_vla_dataset'
    
    # í”„ë¡œì„¸ì„œ ë¡œë“œ
    processor = AutoProcessor.from_pretrained("microsoft/kosmos-2-patch14-224")
    
    # ëª¨ë¸ ë¡œë“œ
    model = Optimized2DActionModel(
        processor=processor,
        action_dim=2,
        dropout=0.2,
        use_claw_matrix=True,
        use_hierarchical=True,
        use_advanced_attention=True
    )
    
    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    checkpoint_path = 'optimized_2d_action_model_best.pth'
    if os.path.exists(checkpoint_path):
        checkpoint = torch.load(checkpoint_path, map_location=device)
        
        # ë™ì  ì–´ëŒ‘í„° ë¬¸ì œ í•´ê²°
        dummy_input = torch.zeros(1, 3, 224, 224).to(device)
        with torch.no_grad():
            _ = model(dummy_input, "Navigate to target")
        
        model_state_dict = model.state_dict()
        checkpoint_state_dict = checkpoint['model_state_dict']
        
        compatible_state_dict = {}
        for key in checkpoint_state_dict.keys():
            if key in model_state_dict and model_state_dict[key].shape == checkpoint_state_dict[key].shape:
                compatible_state_dict[key] = checkpoint_state_dict[key]
        
        model.load_state_dict(compatible_state_dict, strict=False)
    
    model = model.to(device)
    model.eval()
    
    # ë°ì´í„°ì…‹ ë¡œë“œ
    test_dataset = Optimized2DActionDataset(data_path, processor, 'val')
    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)
    
    all_errors = []
    
    with torch.no_grad():
        for batch in tqdm(test_loader, desc="ì˜¤ì°¨ ë¶„í¬ ë¶„ì„"):
            images = batch['image'].float().to(device)
            actions = batch['action'].float().to(device)
            
            predicted_actions = model(images, "Navigate to target")
            errors = torch.abs(predicted_actions - actions)
            
            all_errors.extend(errors.cpu().numpy())
    
    all_errors = np.array(all_errors)
    
    print(f"   ì´ ìƒ˜í”Œ ìˆ˜: {len(all_errors)}")
    print(f"   ì „ì²´ í‰ê·  ì˜¤ì°¨: {np.mean(all_errors):.4f}")
    print(f"   linear_x í‰ê·  ì˜¤ì°¨: {np.mean(all_errors[:, 0]):.4f}")
    print(f"   linear_y í‰ê·  ì˜¤ì°¨: {np.mean(all_errors[:, 1]):.4f}")
    
    # ì˜¤ì°¨ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨
    print(f"\nğŸ“Š ì˜¤ì°¨ ë¶„í¬:")
    for i, dim_name in enumerate(['linear_x', 'linear_y']):
        errors_dim = all_errors[:, i]
        
        # ë¶„ìœ„ìˆ˜ ê³„ì‚°
        percentiles = [25, 50, 75, 90, 95, 99]
        print(f"   {dim_name} ë¶„ìœ„ìˆ˜:")
        for p in percentiles:
            value = np.percentile(errors_dim, p)
            print(f"     {p}%: {value:.4f}")
        
        # ì„ê³„ê°’ë³„ ì„±ê³µë¥ 
        thresholds = [0.01, 0.05, 0.1, 0.2, 0.5]
        print(f"   {dim_name} ì„ê³„ê°’ë³„ ì„±ê³µë¥ :")
        for threshold in thresholds:
            success_rate = np.mean(errors_dim < threshold) * 100
            print(f"     {threshold}: {success_rate:.1f}%")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ” 2D ì•¡ì…˜ ëª¨ë¸ ì„±ê³µë¥  ë””ë²„ê¹… ì‹œì‘!")
    
    # ì„±ê³µë¥  ê³„ì‚° ë””ë²„ê¹…
    debug_accuracy_calculation()
    
    # ì˜¤ì°¨ ë¶„í¬ ë¶„ì„
    analyze_error_distribution()
    
    print(f"\nâœ… ë””ë²„ê¹… ì™„ë£Œ!")

if __name__ == "__main__":
    main()
