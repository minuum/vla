#!/usr/bin/env python3
"""
ğŸ¯ ì¦ê°•ëœ ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ í•™ìŠµ
"""
import sys
from pathlib import Path
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
from PIL import Image
import json
import logging
from datetime import datetime
import random
from typing import Dict, List, Tuple

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
ROOT_DIR = Path("/home/billy/25-1kp/vla/Robo+/Mobile_VLA")
AUGMENTED_DATA_DIR = ROOT_DIR / "augmented_dataset"

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AugmentedDataset(Dataset):
    """ì¦ê°•ëœ ë°ì´í„°ì…‹ í´ë˜ìŠ¤"""
    
    def __init__(self, data_dir: Path, split: str = "train", window_size: int = 8, chunk_size: int = 2):
        self.data_dir = data_dir
        self.split = split
        self.window_size = window_size
        self.chunk_size = chunk_size
        
        # ë©”íƒ€ë°ì´í„° ë¡œë“œ
        with open(data_dir / "metadata.json", 'r') as f:
            self.metadata = json.load(f)
        
        # ì—í”¼ì†Œë“œ ëª©ë¡ ìƒì„±
        self.episodes = []
        for episode_dir in sorted(data_dir.glob("episode_*")):
            if episode_dir.is_dir():
                # ì—í”¼ì†Œë“œ ë©”íƒ€ë°ì´í„° ë¡œë“œ
                with open(episode_dir / "metadata.json", 'r') as f:
                    episode_meta = json.load(f)
                
                self.episodes.append({
                    'dir': episode_dir,
                    'meta': episode_meta
                })
        
        # í›ˆë ¨/ê²€ì¦ ë¶„í• 
        total_episodes = len(self.episodes)
        if split == "train":
            self.episodes = self.episodes[:int(0.8 * total_episodes)]
        else:  # validation
            self.episodes = self.episodes[int(0.8 * total_episodes):]
        
        # ì´ë¯¸ì§€ ë³€í™˜
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        logger.info(f"ğŸ“Š {split} ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ: {len(self.episodes)} ì—í”¼ì†Œë“œ")
    
    def __len__(self):
        return len(self.episodes)
    
    def __getitem__(self, idx):
        episode = self.episodes[idx]
        episode_dir = episode['dir']
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        images = []
        image_files = sorted(episode_dir.glob("frame_*.jpg"))
        for img_file in image_files:
            image = Image.open(img_file).convert('RGB')
            image = self.transform(image)
            images.append(image)
        
        # ì•¡ì…˜ ë¡œë“œ
        actions = np.load(episode_dir / "actions.npy")
        
        # í…ì„œë¡œ ë³€í™˜
        images = torch.stack(images)  # [T, C, H, W]
        actions = torch.from_numpy(actions).float()  # [T, 3]
        
        return {
            'images': images,
            'actions': actions,
            'episode_id': episode['meta']['episode_id'],
            'augmentation_type': episode['meta']['augmentation_type']
        }

class AugmentedDataTrainer:
    """ì¦ê°•ëœ ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ í•™ìŠµê¸°"""
    
    def __init__(self, model_name: str = "microsoft/kosmos-2-patch14-224"):
        self.model_name = model_name
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self._init_model()
        
        # ì˜µí‹°ë§ˆì´ì € ë° ìŠ¤ì¼€ì¤„ëŸ¬
        self.optimizer = optim.AdamW(self.model.parameters(), lr=1e-4, weight_decay=0.01)
        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=1000)
        
        # ì†ì‹¤ í•¨ìˆ˜
        self.criterion = nn.HuberLoss()
        
        logger.info(f"ğŸ¯ ì¦ê°• ë°ì´í„° í•™ìŠµê¸° ì´ˆê¸°í™” ì™„ë£Œ (ë””ë°”ì´ìŠ¤: {self.device})")
    
    def _collate_fn(self, batch):
        """ë°°ì¹˜ ë°ì´í„°ë¥¼ ì˜¬ë°”ë¥´ê²Œ ê²°í•©í•˜ëŠ” í•¨ìˆ˜"""
        # ëª¨ë“  ì—í”¼ì†Œë“œê°€ ê°™ì€ ê¸¸ì´ì¸ì§€ í™•ì¸
        images_list = [item['images'] for item in batch]
        actions_list = [item['actions'] for item in batch]
        episode_ids = [item['episode_id'] for item in batch]
        augmentation_types = [item['augmentation_type'] for item in batch]
        
        # ë°°ì¹˜ë¡œ ìŠ¤íƒ
        images = torch.stack(images_list)
        actions = torch.stack(actions_list)
        
        return {
            'images': images,
            'actions': actions,
            'episode_id': episode_ids,
            'augmentation_type': augmentation_types
        }
    
    def _init_model(self):
        """ëª¨ë¸ ì´ˆê¸°í™”"""
        from transformers import Kosmos2Model
        
        class AugmentedVLAModel(nn.Module):
            def __init__(self, model_name, action_dim=3, window_size=8, chunk_size=2):
                super().__init__()
                
                # Kosmos2 ëª¨ë¸
                self.kosmos = Kosmos2Model.from_pretrained(model_name)
                
                # ëª¨ë¸ ì„¤ì •
                self.hidden_size = 768
                self.lstm_hidden_size = 512
                self.lstm_layers = 2
                self.window_size = window_size
                self.chunk_size = chunk_size
                self.action_dim = action_dim
                
                # LSTM ë ˆì´ì–´
                self.action_lstm = nn.LSTM(
                    input_size=self.hidden_size,
                    hidden_size=self.lstm_hidden_size,
                    num_layers=self.lstm_layers,
                    batch_first=True,
                    dropout=0.1
                )
                
                # ì•¡ì…˜ í—¤ë“œ
                self.action_head = nn.Sequential(
                    nn.Linear(self.lstm_hidden_size, 256),
                    nn.ReLU(),
                    nn.Dropout(0.1),
                    nn.Linear(256, 128),
                    nn.ReLU(),
                    nn.Dropout(0.1),
                    nn.Linear(128, action_dim)
                )
            
            def forward(self, images, input_ids=None, attention_mask=None):
                batch_size = images.shape[0]
                
                # ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ
                image_features = []
                for i in range(batch_size):
                    episode_images = images[i]  # [T, C, H, W]
                    
                    # Kosmos2ë¡œ ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ
                    try:
                        vision_outputs = self.kosmos.vision_model(pixel_values=episode_images)
                        if hasattr(vision_outputs, 'pooler_output') and vision_outputs.pooler_output is not None:
                            features = vision_outputs.pooler_output
                        else:
                            features = vision_outputs.last_hidden_state.mean(dim=1)
                        
                        # í¬ê¸° í†µì¼
                        if features.shape[-1] != self.hidden_size:
                            # ì„ í˜• ë³€í™˜ìœ¼ë¡œ í¬ê¸° ë§ì¶”ê¸°
                            if not hasattr(self, 'feature_adapter'):
                                self.feature_adapter = nn.Linear(features.shape[-1], self.hidden_size).to(features.device)
                            features = self.feature_adapter(features)
                            
                    except Exception as e:
                        # ëŒ€ì²´ ë°©ë²•
                        features = torch.randn(episode_images.shape[0], self.hidden_size, device=episode_images.device)
                    
                    image_features.append(features)
                
                # ë°°ì¹˜ë¡œ ìŠ¤íƒ
                image_features = torch.stack(image_features)  # [B, T, H]
                
                # LSTM ì²˜ë¦¬
                lstm_out, _ = self.action_lstm(image_features)
                
                # ì•¡ì…˜ ì˜ˆì¸¡
                actions = self.action_head(lstm_out)
                
                return actions
        
        self.model = AugmentedVLAModel(self.model_name).to(self.device)
    
    def train_epoch(self, dataloader):
        """í•œ ì—í¬í¬ í•™ìŠµ"""
        self.model.train()
        total_loss = 0.0
        total_mae = 0.0
        num_batches = 0
        
        for batch_idx, batch in enumerate(dataloader):
            images = batch['images'].to(self.device)  # [B, T, C, H, W]
            actions = batch['actions'].to(self.device)  # [B, T, 3]
            
            # ì…ë ¥ ì¤€ë¹„
            batch_size = images.shape[0]
            input_ids = torch.zeros(batch_size, 1, dtype=torch.long, device=self.device)
            attention_mask = torch.ones(batch_size, 1, dtype=torch.bool, device=self.device)
            
            # Forward pass
            self.optimizer.zero_grad()
            predicted_actions = self.model(images, input_ids, attention_mask)
            
            # ì†ì‹¤ ê³„ì‚°
            loss = self.criterion(predicted_actions, actions)
            
            # Backward pass
            loss.backward()
            self.optimizer.step()
            
            # ë©”íŠ¸ë¦­ ê³„ì‚°
            mae = torch.mean(torch.abs(predicted_actions - actions))
            
            total_loss += loss.item()
            total_mae += mae.item()
            num_batches += 1
            
            if batch_idx % 10 == 0:
                logger.info(f"   ë°°ì¹˜ {batch_idx}/{len(dataloader)}: Loss={loss.item():.4f}, MAE={mae.item():.4f}")
        
        self.scheduler.step()
        
        return {
            'loss': total_loss / num_batches,
            'mae': total_mae / num_batches
        }
    
    def validate(self, dataloader):
        """ê²€ì¦"""
        self.model.eval()
        total_loss = 0.0
        total_mae = 0.0
        num_batches = 0
        
        with torch.no_grad():
            for batch in dataloader:
                images = batch['images'].to(self.device)
                actions = batch['actions'].to(self.device)
                
                # ì…ë ¥ ì¤€ë¹„
                batch_size = images.shape[0]
                input_ids = torch.zeros(batch_size, 1, dtype=torch.long, device=self.device)
                attention_mask = torch.ones(batch_size, 1, dtype=torch.bool, device=self.device)
                
                # Forward pass
                predicted_actions = self.model(images, input_ids, attention_mask)
                
                # ì†ì‹¤ ê³„ì‚°
                loss = self.criterion(predicted_actions, actions)
                mae = torch.mean(torch.abs(predicted_actions - actions))
                
                total_loss += loss.item()
                total_mae += mae.item()
                num_batches += 1
        
        return {
            'loss': total_loss / num_batches,
            'mae': total_mae / num_batches
        }
    
    def train(self, num_epochs: int = 10, batch_size: int = 4):
        """ì „ì²´ í•™ìŠµ ê³¼ì •"""
        logger.info("ğŸ¯ ì¦ê°•ëœ ë°ì´í„°ë¡œ í•™ìŠµ ì‹œì‘!")
        
        # ë°ì´í„°ì…‹ ë¡œë“œ
        train_dataset = AugmentedDataset(AUGMENTED_DATA_DIR, "train")
        val_dataset = AugmentedDataset(AUGMENTED_DATA_DIR, "validation")
        
        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, collate_fn=self._collate_fn)
        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=self._collate_fn)
        
        # í•™ìŠµ ê¸°ë¡
        best_val_loss = float('inf')
        training_history = []
        
        for epoch in range(num_epochs):
            logger.info(f"\nğŸ“ˆ ì—í¬í¬ {epoch+1}/{num_epochs}")
            logger.info("-" * 50)
            
            # í›ˆë ¨
            train_metrics = self.train_epoch(train_loader)
            
            # ê²€ì¦
            val_metrics = self.validate(val_loader)
            
            # ê²°ê³¼ ì¶œë ¥
            logger.info(f"âœ… í›ˆë ¨: Loss={train_metrics['loss']:.4f}, MAE={train_metrics['mae']:.4f}")
            logger.info(f"ğŸ” ê²€ì¦: Loss={val_metrics['loss']:.4f}, MAE={val_metrics['mae']:.4f}")
            
            # ìµœê³  ëª¨ë¸ ì €ì¥
            if val_metrics['loss'] < best_val_loss:
                best_val_loss = val_metrics['loss']
                torch.save(self.model.state_dict(), ROOT_DIR / "best_augmented_model.pth")
                logger.info("ğŸ’¾ ìµœê³  ëª¨ë¸ ì €ì¥ë¨!")
            
            # ê¸°ë¡
            training_history.append({
                'epoch': epoch + 1,
                'train_loss': train_metrics['loss'],
                'train_mae': train_metrics['mae'],
                'val_loss': val_metrics['loss'],
                'val_mae': val_metrics['mae']
            })
        
        # ê²°ê³¼ ì €ì¥
        results = {
            'training_history': training_history,
            'best_val_loss': best_val_loss,
            'final_train_mae': train_metrics['mae'],
            'final_val_mae': val_metrics['mae'],
            'model_name': self.model_name,
            'num_epochs': num_epochs,
            'batch_size': batch_size,
            'augmentation_factor': train_dataset.metadata['augmentation_factor'],
            'total_episodes': train_dataset.metadata['total_episodes'],
            'completion_date': datetime.now().isoformat()
        }
        
        with open(ROOT_DIR / "augmented_training_results.json", 'w') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        logger.info("\nğŸ‰ ì¦ê°•ëœ ë°ì´í„° í•™ìŠµ ì™„ë£Œ!")
        logger.info(f"ğŸ“Š ìµœê³  ê²€ì¦ Loss: {best_val_loss:.4f}")
        logger.info(f"ğŸ“Š ìµœì¢… í›ˆë ¨ MAE: {train_metrics['mae']:.4f}")
        logger.info(f"ğŸ“Š ìµœì¢… ê²€ì¦ MAE: {val_metrics['mae']:.4f}")
        
        return results

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ¯ ì¦ê°•ëœ ë°ì´í„°ë¡œ í•™ìŠµ ì‹œì‘!")
    print("=" * 50)
    
    # ì¦ê°•ëœ ë°ì´í„° í™•ì¸
    if not AUGMENTED_DATA_DIR.exists():
        print("âŒ ì¦ê°•ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € generate_augmented_data.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return
    
    # ë©”íƒ€ë°ì´í„° í™•ì¸
    with open(AUGMENTED_DATA_DIR / "metadata.json", 'r') as f:
        metadata = json.load(f)
    
    print(f"ğŸ“Š ì¦ê°•ëœ ë°ì´í„° ì •ë³´:")
    print(f"   ì´ ì—í”¼ì†Œë“œ: {metadata['total_episodes']}")
    print(f"   ì›ë³¸ ì—í”¼ì†Œë“œ: {metadata['original_episodes']}")
    print(f"   ì¦ê°• ë°°ìˆ˜: {metadata['augmentation_factor']}x")
    print(f"   ìƒì„± ë‚ ì§œ: {metadata['generation_date']}")
    
    # í•™ìŠµê¸° ì´ˆê¸°í™” ë° í•™ìŠµ ì‹¤í–‰
    trainer = AugmentedDataTrainer()
    results = trainer.train(num_epochs=10, batch_size=4)
    
    print("\nğŸ‰ í•™ìŠµ ì™„ë£Œ!")
    print(f"ğŸ“ ê²°ê³¼ ì €ì¥: {ROOT_DIR}/augmented_training_results.json")
    print(f"ğŸ“ ëª¨ë¸ ì €ì¥: {ROOT_DIR}/best_augmented_model.pth")

if __name__ == "__main__":
    main()
