#!/usr/bin/env python3
"""
ğŸ“ ê±°ë¦¬ë³„ íŠ¹í™” ë°ì´í„° ì¦ê°•
"""
import sys
from pathlib import Path
import numpy as np
import h5py
import json
import logging
from datetime import datetime
from PIL import Image
import random
from typing import Dict, List, Tuple
import cv2

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class DistanceAwareAugmentation:
    def __init__(self):
        self.DATA_DIR = Path("/home/billy/25-1kp/vla/ROS_action/mobile_vla_dataset")
        self.OUTPUT_DIR = Path("distance_aware_augmented_dataset")
        self.OUTPUT_DIR.mkdir(exist_ok=True)
        
        # ê±°ë¦¬ë³„ ì¦ê°• ë°°ìˆ˜ (ì‹¤ì œ ë°ì´í„° ë¶„í¬ì— ë§ì¶¤)
        self.distance_augmentation_factors = {
            "close": 8,     # ì •ë°€ ì¡°ì‘ ê°•í™” (20ê°œ â†’ 160ê°œ)
            "medium": 5,    # í‘œì¤€ íŒ¨í„´ ë‹¤ì–‘í™” (32ê°œ â†’ 160ê°œ)
            "far": 8        # ë„“ì€ ì›€ì§ì„ ê°•í™” (20ê°œ â†’ 160ê°œ)
        }
        
        # ê±°ë¦¬ë³„ íŠ¹í™” ì¦ê°• ì „ëµ
        self.distance_strategies = {
            "close": {
                "description": "ì •ë°€ ì¡°ì‘ ê°•í™”",
                "noise_range": (0.05, 0.15),  # ì‘ì€ ë…¸ì´ì¦ˆ
                "space_frequency": 0.3,       # ì •ì§€ ì•¡ì…˜ ë¹ˆë„ ì¦ê°€
                "horizontal_weight": 1.5,     # A/D ì•¡ì…˜ ê°•í™”
                "precision_focus": True
            },
            "medium": {
                "description": "í‘œì¤€ íŒ¨í„´ ë‹¤ì–‘í™”",
                "noise_range": (0.1, 0.25),   # ì¤‘ê°„ ë…¸ì´ì¦ˆ
                "space_frequency": 0.2,       # í‘œì¤€ ì •ì§€ ë¹ˆë„
                "diagonal_weight": 1.3,       # Q/E ì•¡ì…˜ ê°•í™”
                "timing_variation": True
            },
            "far": {
                "description": "ë„“ì€ ì›€ì§ì„ ê°•í™”",
                "noise_range": (0.15, 0.3),   # í° ë…¸ì´ì¦ˆ
                "space_frequency": 0.1,       # ë‚®ì€ ì •ì§€ ë¹ˆë„
                "forward_weight": 1.4,        # W ì•¡ì…˜ ê°•í™”
                "speed_variation": True
            }
        }
        
        # ì‹¤ì œ ì‚¬ìš©ëœ ì•¡ì…˜ (íšŒì „, í›„ì§„, Z/C ë¯¸ì‚¬ìš©)
        self.actual_actions = {
            'w': {"linear_x": 1.15, "linear_y": 0.0, "angular_z": 0.0},      # ì „ì§„
            'a': {"linear_x": 0.0, "linear_y": 1.15, "angular_z": 0.0},      # ì¢Œì¸¡ ì´ë™
            'd': {"linear_x": 0.0, "linear_y": -1.15, "angular_z": 0.0},     # ìš°ì¸¡ ì´ë™
            'q': {"linear_x": 1.15, "linear_y": 1.15, "angular_z": 0.0},     # ì „ì§„+ì¢Œì¸¡
            'e': {"linear_x": 1.15, "linear_y": -1.15, "angular_z": 0.0},    # ì „ì§„+ìš°ì¸¡
            ' ': {"linear_x": 0.0, "linear_y": 0.0, "angular_z": 0.0}        # ì •ì§€
        }

    def extract_distance_from_filename(self, filename: str) -> str:
        """íŒŒì¼ëª…ì—ì„œ ê±°ë¦¬ ì •ë³´ ì¶”ì¶œ"""
        if "_close" in filename:
            return "close"
        elif "_far" in filename:
            return "far"
        else:
            return "medium"  # ê¸°ë³¸ê°’

    def load_original_dataset(self) -> List[Dict]:
        """ì›ë³¸ ë°ì´í„°ì…‹ ë¡œë“œ"""
        episodes = []
        
        # .h5 íŒŒì¼ë“¤ ì²˜ë¦¬ (legacy ì œì™¸)
        h5_files = [f for f in self.DATA_DIR.glob("*.h5") if "legacy" not in str(f)]
        logger.info(f"ğŸ“ ë°œê²¬ëœ .h5 íŒŒì¼: {len(h5_files)}ê°œ (legacy ì œì™¸)")
        
        for h5_file in h5_files:
            try:
                with h5py.File(h5_file, 'r') as f:
                    episode_data = {
                        'images': [],
                        'actions': [],
                        'episode_id': h5_file.stem,
                        'distance': self.extract_distance_from_filename(h5_file.stem)
                    }
                    
                    # ì´ë¯¸ì§€ ë°ì´í„° ë¡œë“œ
                    if 'images' in f:
                        images_data = f['images'][:]
                        for img_data in images_data:
                            if img_data.dtype == np.uint8:
                                image = Image.fromarray(img_data)
                            else:
                                img_data = (img_data * 255).astype(np.uint8)
                                image = Image.fromarray(img_data)
                            episode_data['images'].append(image)
                    
                    # ì•¡ì…˜ ë°ì´í„° ë¡œë“œ
                    if 'actions' in f:
                        actions = f['actions'][:]
                        episode_data['actions'] = actions
                    
                    if len(episode_data['images']) > 0 and len(episode_data['actions']) > 0:
                        episodes.append(episode_data)
                        logger.info(f"âœ… {h5_file.name} ë¡œë“œ ì™„ë£Œ: {len(episode_data['images'])} í”„ë ˆì„, ê±°ë¦¬: {episode_data['distance']}")
                        
            except Exception as e:
                logger.warning(f"âš ï¸ {h5_file.name} ë¡œë“œ ì‹¤íŒ¨: {e}")
                continue
        
        return episodes

    def apply_distance_specific_augmentation(self, episode_data: Dict, distance: str) -> List[Dict]:
        """ê±°ë¦¬ë³„ íŠ¹í™” ì¦ê°• ì ìš©"""
        strategy = self.distance_strategies[distance]
        augmentation_factor = self.distance_augmentation_factors[distance]
        
        augmented_episodes = []
        
        for i in range(augmentation_factor - 1):  # ì›ë³¸ ì œì™¸
            augmented_episode = self._create_augmented_episode(episode_data, strategy, i)
            augmented_episodes.append(augmented_episode)
        
        return augmented_episodes

    def _create_augmented_episode(self, original_episode: Dict, strategy: Dict, aug_index: int) -> Dict:
        """ê°œë³„ ì¦ê°• ì—í”¼ì†Œë“œ ìƒì„±"""
        images = original_episode['images'].copy()
        actions = original_episode['actions'].copy()
        
        # ê±°ë¦¬ë³„ íŠ¹í™” ì¦ê°• ì ìš©
        if strategy.get('precision_focus'):
            # Close ê±°ë¦¬: ì •ë°€ ì¡°ì‘ ê°•í™”
            actions = self._apply_precision_augmentation(actions, strategy)
        elif strategy.get('timing_variation'):
            # Medium ê±°ë¦¬: íƒ€ì´ë° ë³€í™”
            actions = self._apply_timing_augmentation(actions, strategy)
        elif strategy.get('speed_variation'):
            # Far ê±°ë¦¬: ì†ë„ ë³€í™”
            actions = self._apply_speed_augmentation(actions, strategy)
        
        # ì´ë¯¸ì§€ ì¦ê°• (ê±°ë¦¬ë³„ íŠ¹í™”)
        images = self._apply_distance_specific_image_augmentation(images, strategy)
        
        return {
            'images': images,
            'actions': actions,
            'episode_id': f"{original_episode['episode_id']}_aug_{aug_index:03d}",
            'distance': original_episode['distance'],
            'augmentation_type': strategy['description'],
            'original_episode': original_episode['episode_id']
        }

    def _apply_precision_augmentation(self, actions: np.ndarray, strategy: Dict) -> np.ndarray:
        """ì •ë°€ ì¡°ì‘ ê°•í™” (Close ê±°ë¦¬)"""
        noise_range = strategy['noise_range']
        space_freq = strategy['space_frequency']
        horizontal_weight = strategy['horizontal_weight']
        
        augmented_actions = actions.copy()
        
        for i in range(len(augmented_actions)):
            # ì‘ì€ ë…¸ì´ì¦ˆ ì¶”ê°€
            noise = np.random.uniform(-noise_range[0], noise_range[0], 3)
            augmented_actions[i] += noise
            
            # ì •ì§€ ì•¡ì…˜ ë¹ˆë„ ì¦ê°€
            if random.random() < space_freq:
                augmented_actions[i] = np.array([0.0, 0.0, 0.0])
            
            # A/D ì•¡ì…˜ ê°•í™” (íš¡ì´ë™)
            if abs(augmented_actions[i][1]) > 0.1:  # linear_yê°€ ìˆëŠ” ê²½ìš°
                augmented_actions[i][1] *= horizontal_weight
        
        return augmented_actions

    def _apply_timing_augmentation(self, actions: np.ndarray, strategy: Dict) -> np.ndarray:
        """íƒ€ì´ë° ë³€í™” (Medium ê±°ë¦¬)"""
        noise_range = strategy['noise_range']
        diagonal_weight = strategy['diagonal_weight']
        
        augmented_actions = actions.copy()
        
        for i in range(len(augmented_actions)):
            # ì¤‘ê°„ ë…¸ì´ì¦ˆ ì¶”ê°€
            noise = np.random.uniform(-noise_range[0], noise_range[0], 3)
            augmented_actions[i] += noise
            
            # Q/E ì•¡ì…˜ ê°•í™” (ëŒ€ê°ì„ )
            if abs(augmented_actions[i][0]) > 0.1 and abs(augmented_actions[i][1]) > 0.1:
                augmented_actions[i][0] *= diagonal_weight
                augmented_actions[i][1] *= diagonal_weight
        
        return augmented_actions

    def _apply_speed_augmentation(self, actions: np.ndarray, strategy: Dict) -> np.ndarray:
        """ì†ë„ ë³€í™” (Far ê±°ë¦¬)"""
        noise_range = strategy['noise_range']
        forward_weight = strategy['forward_weight']
        
        augmented_actions = actions.copy()
        
        for i in range(len(augmented_actions)):
            # í° ë…¸ì´ì¦ˆ ì¶”ê°€
            noise = np.random.uniform(-noise_range[0], noise_range[0], 3)
            augmented_actions[i] += noise
            
            # W ì•¡ì…˜ ê°•í™” (ì „ì§„)
            if augmented_actions[i][0] > 0.1:  # linear_xê°€ ì–‘ìˆ˜ì¸ ê²½ìš°
                augmented_actions[i][0] *= forward_weight
        
        return augmented_actions

    def _apply_distance_specific_image_augmentation(self, images: List[Image.Image], strategy: Dict) -> List[Image.Image]:
        """ê±°ë¦¬ë³„ íŠ¹í™” ì´ë¯¸ì§€ ì¦ê°•"""
        augmented_images = []
        
        for image in images:
            # ê¸°ë³¸ ì´ë¯¸ì§€ ë³€í™˜
            img_array = np.array(image)
            
            # ê±°ë¦¬ë³„ íŠ¹í™” ë³€í™˜
            if strategy.get('precision_focus'):
                # Close: ë¯¸ì„¸í•œ ë°ê¸° ì¡°ì •
                brightness = np.random.uniform(0.95, 1.05)
                img_array = np.clip(img_array * brightness, 0, 255).astype(np.uint8)
            elif strategy.get('timing_variation'):
                # Medium: ì¤‘ê°„ ì •ë„ì˜ ëŒ€ë¹„ ì¡°ì •
                contrast = np.random.uniform(0.9, 1.1)
                img_array = np.clip((img_array - 128) * contrast + 128, 0, 255).astype(np.uint8)
            elif strategy.get('speed_variation'):
                # Far: í° ë³€í™” (ë¸”ëŸ¬ íš¨ê³¼)
                if random.random() < 0.3:
                    kernel_size = random.choice([3, 5])
                    img_array = cv2.GaussianBlur(img_array, (kernel_size, kernel_size), 0)
            
            augmented_images.append(Image.fromarray(img_array))
        
        return augmented_images

    def save_augmented_episode(self, episode_data: Dict, episode_dir: Path):
        """ì¦ê°•ëœ ì—í”¼ì†Œë“œ ì €ì¥"""
        episode_dir.mkdir(exist_ok=True)
        
        # ì´ë¯¸ì§€ ì €ì¥
        for i, image in enumerate(episode_data['images']):
            image_path = episode_dir / f"frame_{i:03d}.jpg"
            image.save(image_path, "JPEG", quality=95)
        
        # ì•¡ì…˜ ì €ì¥
        actions_path = episode_dir / "actions.npy"
        np.save(actions_path, episode_data['actions'])
        
        # ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata = {
            "episode_id": episode_data['episode_id'],
            "distance": episode_data['distance'],
            "augmentation_type": episode_data.get('augmentation_type', 'original'),
            "original_episode": episode_data.get('original_episode', episode_data['episode_id']),
            "num_frames": len(episode_data['images']),
            "action_shape": list(episode_data['actions'].shape),
            "created_at": datetime.now().isoformat()
        }
        
        metadata_path = episode_dir / "metadata.json"
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)

    def generate_distance_aware_dataset(self):
        """ê±°ë¦¬ë³„ íŠ¹í™” ì¦ê°• ë°ì´í„°ì…‹ ìƒì„±"""
        logger.info("ğŸ¯ ê±°ë¦¬ë³„ íŠ¹í™” ì¦ê°• ì‹œì‘!")
        logger.info("=" * 60)
        
        # ì›ë³¸ ë°ì´í„° ë¡œë“œ
        episodes = self.load_original_dataset()
        if not episodes:
            logger.error("âŒ ë¡œë“œí•  ì—í”¼ì†Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ê±°ë¦¬ë³„ í†µê³„
        distance_stats = {}
        for episode in episodes:
            distance = episode['distance']
            if distance not in distance_stats:
                distance_stats[distance] = 0
            distance_stats[distance] += 1
        
        logger.info("ğŸ“Š ì›ë³¸ ë°ì´í„° ë¶„í¬:")
        for distance, count in distance_stats.items():
            logger.info(f"   {distance}: {count}ê°œ")
        
        # ê±°ë¦¬ë³„ ì¦ê°• ì§„í–‰
        all_augmented_episodes = []
        episode_counter = 0
        
        for episode in episodes:
            distance = episode['distance']
            augmentation_factor = self.distance_augmentation_factors[distance]
            
            logger.info(f"ğŸ“ {episode['episode_id']} ({distance}) ì¦ê°• ì¤‘... (ë°°ìˆ˜: {augmentation_factor}x)")
            
            # ì›ë³¸ ì—í”¼ì†Œë“œ ì €ì¥
            original_dir = self.OUTPUT_DIR / f"episode_{episode_counter:04d}"
            self.save_augmented_episode(episode, original_dir)
            episode_counter += 1
            
            # ì¦ê°•ëœ ì—í”¼ì†Œë“œ ìƒì„±
            augmented_episodes = self.apply_distance_specific_augmentation(episode, distance)
            
            for aug_episode in augmented_episodes:
                aug_dir = self.OUTPUT_DIR / f"episode_{episode_counter:04d}"
                self.save_augmented_episode(aug_episode, aug_dir)
                all_augmented_episodes.append(aug_episode)
                episode_counter += 1
        
        # ìµœì¢… í†µê³„
        final_stats = {}
        for episode in all_augmented_episodes:
            distance = episode['distance']
            if distance not in final_stats:
                final_stats[distance] = 0
            final_stats[distance] += 1
        
        # ì›ë³¸ë„ í¬í•¨
        for episode in episodes:
            distance = episode['distance']
            final_stats[distance] += 1
        
        logger.info("ğŸ‰ ê±°ë¦¬ë³„ íŠ¹í™” ì¦ê°• ì™„ë£Œ!")
        logger.info("ğŸ“Š ìµœì¢… ë°ì´í„° ë¶„í¬:")
        for distance, count in final_stats.items():
            original_count = distance_stats.get(distance, 0)
            augmentation_factor = self.distance_augmentation_factors[distance]
            logger.info(f"   {distance}: {count}ê°œ (ì›ë³¸: {original_count}ê°œ, ë°°ìˆ˜: {augmentation_factor}x)")
        
        # ì „ì²´ í†µê³„ ì €ì¥
        total_stats = {
            "total_episodes": len(episodes) + len(all_augmented_episodes),
            "original_episodes": len(episodes),
            "augmented_episodes": len(all_augmented_episodes),
            "distance_distribution": final_stats,
            "augmentation_factors": self.distance_augmentation_factors,
            "created_at": datetime.now().isoformat()
        }
        
        stats_path = self.OUTPUT_DIR / "augmentation_stats.json"
        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump(total_stats, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ’¾ ì¦ê°• í†µê³„ ì €ì¥: {stats_path}")
        logger.info(f"ğŸ“ ì¦ê°•ëœ ë°ì´í„°ì…‹: {self.OUTPUT_DIR}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    augmenter = DistanceAwareAugmentation()
    augmenter.generate_distance_aware_dataset()

if __name__ == "__main__":
    main()
