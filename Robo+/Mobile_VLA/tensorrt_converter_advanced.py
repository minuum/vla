#!/usr/bin/env python3
"""
Mobile VLA ëª¨ë¸ TensorRT ë³€í™˜ê¸° (ê³ ê¸‰)
- ì‹¤ì œ ëª¨ë¸ êµ¬ì¡° ë¶„ì„ ë° TensorRT ë³€í™˜
- Torch2TRT ì‚¬ìš©ìœ¼ë¡œ ê°„í¸í•œ ë³€í™˜
- ë‹¤ì–‘í•œ ì–‘ìí™” ì˜µì…˜ ì§€ì›
"""

import torch
import torch.nn as nn
from transformers import AutoProcessor, AutoModel
import numpy as np
import os
import json
import time
from typing import Dict, Any, Optional
from PIL import Image
import cv2

# Torch2TRT import (ì„¤ì¹˜ í•„ìš”: pip install torch2trt)
try:
    from torch2trt import torch2trt, TRTModule
    TORCH2TRT_AVAILABLE = True
except ImportError:
    print("Warning: torch2trt not available. Install with: pip install torch2trt")
    TORCH2TRT_AVAILABLE = False

class MobileVLAModelWrapper(nn.Module):
    """Mobile VLA ëª¨ë¸ì„ TensorRT ë³€í™˜ìš©ìœ¼ë¡œ ë˜í•‘"""
    
    def __init__(self, model, processor):
        super().__init__()
        self.model = model
        self.processor = processor
        
    def forward(self, images, text_embeddings):
        """ì „ë°© ì „íŒŒ (TensorRT ë³€í™˜ìš©)"""
        # ëª¨ë¸ì˜ forward í•¨ìˆ˜ë¥¼ ì§ì ‘ í˜¸ì¶œ
        outputs = self.model(
            pixel_values=images,
            input_ids=text_embeddings
        )
        
        # ì•¡ì…˜ ë¡œì§“ ë°˜í™˜
        return outputs.action_logits

class MobileVLATensorRTConverterAdvanced:
    """ê³ ê¸‰ TensorRT ë³€í™˜ê¸°"""
    
    def __init__(self, model_name: str = "minium/mobile-vla-omniwheel"):
        self.model_name = model_name
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬
        self.output_dir = "Robo+/Mobile_VLA/tensorrt_quantized"
        os.makedirs(self.output_dir, exist_ok=True)
        
        # ëª¨ë¸ ë¡œë“œ
        self.load_original_model()
        
    def load_original_model(self):
        """ì›ë³¸ ëª¨ë¸ ë¡œë“œ"""
        print(f"ğŸ”„ Loading original model: {self.model_name}")
        
        try:
            self.processor = AutoProcessor.from_pretrained(self.model_name)
            self.model = AutoModel.from_pretrained(self.model_name)
            
            if self.device.type == 'cuda':
                self.model = self.model.cuda()
            
            self.model.eval()
            print("âœ… Original model loaded successfully")
            
        except Exception as e:
            print(f"âŒ Failed to load original model: {e}")
            raise
    
    def create_model_wrapper(self):
        """ëª¨ë¸ ë˜í¼ ìƒì„±"""
        return MobileVLAModelWrapper(self.model, self.processor)
    
    def prepare_sample_inputs(self, batch_size: int = 1):
        """ìƒ˜í”Œ ì…ë ¥ ë°ì´í„° ì¤€ë¹„"""
        # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
        image = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)
        pil_image = Image.fromarray(image)
        
        # í”„ë¡œì„¸ì„œë¡œ ì „ì²˜ë¦¬
        inputs = self.processor(
            images=pil_image,
            text="Navigate around obstacles to track the target cup",
            return_tensors="pt"
        )
        
        # GPUë¡œ ì´ë™
        if self.device.type == 'cuda':
            inputs = {k: v.cuda() for k, v in inputs.items()}
        
        return inputs['pixel_values'], inputs['input_ids']
    
    def convert_to_tensorrt_torch2trt(self, precision: str = "fp16"):
        """Torch2TRTë¥¼ ì‚¬ìš©í•œ TensorRT ë³€í™˜"""
        if not TORCH2TRT_AVAILABLE:
            print("âŒ Torch2TRT not available")
            return None
        
        print(f"ğŸ”¨ Converting to TensorRT using Torch2TRT (precision: {precision})")
        
        # ëª¨ë¸ ë˜í¼ ìƒì„±
        model_wrapper = self.create_model_wrapper()
        model_wrapper.eval()
        
        # ìƒ˜í”Œ ì…ë ¥ ì¤€ë¹„
        sample_images, sample_text = self.prepare_sample_inputs()
        
        # TensorRT ë³€í™˜ ì„¤ì •
        fp16_mode = precision == "fp16"
        max_workspace_size = 1 << 30  # 1GB
        
        # ë³€í™˜ ì‹¤í–‰
        model_trt = torch2trt(
            model_wrapper,
            [sample_images, sample_text],
            fp16_mode=fp16_mode,
            max_workspace_size=max_workspace_size,
            use_onnx=True  # ONNXë¥¼ í†µí•œ ë³€í™˜
        )
        
        # ë³€í™˜ëœ ëª¨ë¸ ì €ì¥
        model_path = os.path.join(self.output_dir, f"mobile_vla_torch2trt_{precision}.pth")
        torch.save(model_trt.state_dict(), model_path)
        
        print(f"âœ… Torch2TRT model saved: {model_path}")
        return model_trt, model_path
    
    def test_torch2trt_inference(self, model_trt, num_runs: int = 10):
        """Torch2TRT ì¶”ë¡  í…ŒìŠ¤íŠ¸"""
        print("ğŸ§ª Testing Torch2TRT inference")
        
        model_trt.eval()
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
        test_images, test_text = self.prepare_sample_inputs()
        
        # ì›Œë°ì—…
        with torch.no_grad():
            for _ in range(5):
                _ = model_trt(test_images, test_text)
        
        # ë²¤ì¹˜ë§ˆí¬
        times = []
        for i in range(num_runs):
            start_time = time.time()
            
            with torch.no_grad():
                outputs = model_trt(test_images, test_text)
            
            inference_time = time.time() - start_time
            times.append(inference_time)
            
            if (i + 1) % 5 == 0:
                print(f"Progress: {i + 1}/{num_runs}")
        
        # ê²°ê³¼ ë¶„ì„
        avg_time = np.mean(times)
        fps = 1.0 / avg_time
        
        print(f"ğŸ¯ Torch2TRT inference: {avg_time*1000:.2f} ms ({fps:.1f} FPS)")
        print(f"ğŸ“Š Action output shape: {outputs.shape}")
        
        return avg_time, fps, outputs
    
    def convert_to_onnx_then_tensorrt(self, precision: str = "fp16"):
        """ONNXë¥¼ í†µí•œ TensorRT ë³€í™˜"""
        print(f"ğŸ”¨ Converting to ONNX then TensorRT (precision: {precision})")
        
        # ëª¨ë¸ ë˜í¼ ìƒì„±
        model_wrapper = self.create_model_wrapper()
        model_wrapper.eval()
        
        # ìƒ˜í”Œ ì…ë ¥ ì¤€ë¹„
        sample_images, sample_text = self.prepare_sample_inputs()
        
        # ONNX ëª¨ë¸ ì €ì¥
        onnx_path = os.path.join(self.output_dir, "mobile_vla_model.onnx")
        
        torch.onnx.export(
            model_wrapper,
            (sample_images, sample_text),
            onnx_path,
            export_params=True,
            opset_version=11,
            do_constant_folding=True,
            input_names=['images', 'text_embeddings'],
            output_names=['action_logits'],
            dynamic_axes={
                'images': {0: 'batch_size'},
                'text_embeddings': {0: 'batch_size'},
                'action_logits': {0: 'batch_size'}
            }
        )
        
        print(f"âœ… ONNX model saved: {onnx_path}")
        
        # ONNX ëª¨ë¸ì„ TensorRTë¡œ ë³€í™˜ (trtexec ì‚¬ìš©)
        engine_path = self.convert_onnx_to_tensorrt(onnx_path, precision)
        
        return engine_path
    
    def convert_onnx_to_tensorrt(self, onnx_path: str, precision: str = "fp16"):
        """ONNX ëª¨ë¸ì„ TensorRT ì—”ì§„ìœ¼ë¡œ ë³€í™˜"""
        print(f"ğŸ”¨ Converting ONNX to TensorRT engine (precision: {precision})")
        
        # trtexec ëª…ë ¹ì–´ êµ¬ì„±
        engine_path = os.path.join(self.output_dir, f"mobile_vla_{precision}.engine")
        
        # ê¸°ë³¸ trtexec ëª…ë ¹ì–´
        cmd = f"trtexec --onnx={onnx_path} --saveEngine={engine_path}"
        
        # ì •ë°€ë„ ì„¤ì •
        if precision == "fp16":
            cmd += " --fp16"
        elif precision == "int8":
            cmd += " --int8"
        
        # ì¶”ê°€ ì˜µì…˜
        cmd += " --workspace=1024 --verbose"
        
        print(f"Running command: {cmd}")
        
        # ëª…ë ¹ì–´ ì‹¤í–‰
        import subprocess
        try:
            result = subprocess.run(cmd.split(), capture_output=True, text=True)
            if result.returncode == 0:
                print(f"âœ… TensorRT engine created: {engine_path}")
                return engine_path
            else:
                print(f"âŒ TensorRT conversion failed: {result.stderr}")
                return None
        except Exception as e:
            print(f"âŒ Error running trtexec: {e}")
            return None
    
    def benchmark_original_vs_tensorrt(self, model_trt, num_runs: int = 50):
        """ì›ë³¸ ëª¨ë¸ vs TensorRT ì„±ëŠ¥ ë¹„êµ"""
        print("ğŸ“ˆ Benchmarking Original vs TensorRT")
        
        # ì›ë³¸ ëª¨ë¸ ì¤€ë¹„
        model_wrapper = self.create_model_wrapper()
        model_wrapper.eval()
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
        test_images, test_text = self.prepare_sample_inputs()
        
        # ì›ë³¸ ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬
        print("Testing original model...")
        original_times = []
        with torch.no_grad():
            for i in range(num_runs):
                start_time = time.time()
                outputs_orig = model_wrapper(test_images, test_text)
                inference_time = time.time() - start_time
                original_times.append(inference_time)
        
        # TensorRT ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬
        print("Testing TensorRT model...")
        trt_times = []
        with torch.no_grad():
            for i in range(num_runs):
                start_time = time.time()
                outputs_trt = model_trt(test_images, test_text)
                inference_time = time.time() - start_time
                trt_times.append(inference_time)
        
        # ê²°ê³¼ ë¶„ì„
        orig_avg = np.mean(original_times)
        trt_avg = np.mean(trt_times)
        speedup = orig_avg / trt_avg
        
        results = {
            "original": {
                "average_time_ms": orig_avg * 1000,
                "fps": 1.0 / orig_avg
            },
            "tensorrt": {
                "average_time_ms": trt_avg * 1000,
                "fps": 1.0 / trt_avg
            },
            "speedup": speedup
        }
        
        print(f"ğŸ“Š Benchmark Results:")
        print(f"  Original: {orig_avg*1000:.2f} ms ({1.0/orig_avg:.1f} FPS)")
        print(f"  TensorRT: {trt_avg*1000:.2f} ms ({1.0/trt_avg:.1f} FPS)")
        print(f"  Speedup: {speedup:.2f}x")
        
        # ê²°ê³¼ ì €ì¥
        results_path = os.path.join(self.output_dir, "benchmark_results.json")
        with open(results_path, "w") as f:
            json.dump(results, f, indent=2)
        
        print(f"âœ… Benchmark results saved: {results_path}")
        return results
    
    def create_tensorrt_inference_node(self, engine_path: str):
        """TensorRT ì¶”ë¡  ë…¸ë“œ ìƒì„±"""
        print("ğŸ”§ Creating TensorRT inference node")
        
        node_code = f'''#!/usr/bin/env python3
"""
TensorRT ì¶”ë¡  ë…¸ë“œ (ìë™ ìƒì„±)
- {engine_path} ì—”ì§„ ì‚¬ìš©
- ê³ ì„±ëŠ¥ ì‹¤ì‹œê°„ ì¶”ë¡ 
"""

import rclpy
from rclpy.node import Node
from sensor_msgs.msg import CompressedImage
from geometry_msgs.msg import Twist
from std_msgs.msg import String
import cv2
import numpy as np
from PIL import Image as PILImage
import json
import time
import tensorrt as trt
import pycuda.driver as cuda
import pycuda.autoinit

class TensorRTInferenceNode(Node):
    def __init__(self):
        super().__init__('tensorrt_inference_node')
        
        # TensorRT ì—”ì§„ ë¡œë“œ
        self.engine_path = "{engine_path}"
        self.load_tensorrt_engine()
        
        # ROS ì„¤ì •
        self.setup_ros()
        
        # ìƒíƒœ ë³€ìˆ˜
        self.inference_count = 0
        self.last_inference_time = 0.0
        
    def load_tensorrt_engine(self):
        """TensorRT ì—”ì§„ ë¡œë“œ"""
        try:
            with open(self.engine_path, "rb") as f:
                engine_data = f.read()
            
            runtime = trt.Runtime(trt.Logger(trt.Logger.WARNING))
            self.engine = runtime.deserialize_cuda_engine(engine_data)
            self.context = self.engine.create_execution_context()
            
            # ë©”ëª¨ë¦¬ í• ë‹¹
            self.input_images = cuda.mem_alloc(1 * 3 * 224 * 224 * 4)  # float32
            self.input_text = cuda.mem_alloc(1 * 512 * 4)  # float32
            self.output = cuda.mem_alloc(1 * 3 * 4)  # float32
            
            self.get_logger().info("âœ… TensorRT engine loaded successfully")
            
        except Exception as e:
            self.get_logger().error(f"âŒ Failed to load TensorRT engine: {{e}}")
            raise
    
    def setup_ros(self):
        """ROS ì„¤ì •"""
        # ì´ë¯¸ì§€ ì„œë¸ŒìŠ¤í¬ë¼ì´ë²„
        self.image_sub = self.create_subscription(
            CompressedImage,
            '/camera/image/compressed',
            self.image_callback,
            10
        )
        
        # ì•¡ì…˜ í¼ë¸”ë¦¬ì…”
        self.action_pub = self.create_publisher(
            Twist,
            '/cmd_vel',
            10
        )
        
        # ê²°ê³¼ í¼ë¸”ë¦¬ì…”
        self.result_pub = self.create_publisher(
            String,
            '/tensorrt/inference_result',
            10
        )
        
    def image_callback(self, msg):
        """ì´ë¯¸ì§€ ì½œë°±"""
        try:
            # ì´ë¯¸ì§€ ì²˜ë¦¬
            np_arr = np.frombuffer(msg.data, np.uint8)
            image = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # PIL Imageë¡œ ë³€í™˜ ë° ë¦¬ì‚¬ì´ì¦ˆ
            pil_image = PILImage.fromarray(image_rgb)
            pil_image = pil_image.resize((224, 224))
            
            # numpy ë°°ì—´ë¡œ ë³€í™˜
            image_array = np.array(pil_image, dtype=np.float32) / 255.0
            image_array = np.transpose(image_array, (2, 0, 1))  # HWC -> CHW
            image_array = np.expand_dims(image_array, axis=0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
            
            # í…ìŠ¤íŠ¸ ì„ë² ë”© (ê°„ë‹¨í•œ ë”ë¯¸ ë°ì´í„°)
            text_embedding = np.random.randn(1, 512).astype(np.float32)
            
            # TensorRT ì¶”ë¡ 
            action = self.run_tensorrt_inference(image_array, text_embedding)
            
            # ì•¡ì…˜ ì‹¤í–‰
            self.execute_action(action)
            
        except Exception as e:
            self.get_logger().error(f"âŒ Error in image callback: {{e}}")
    
    def run_tensorrt_inference(self, image_array, text_embedding):
        """TensorRT ì¶”ë¡  ì‹¤í–‰"""
        try:
            # GPU ë©”ëª¨ë¦¬ë¡œ ë°ì´í„° ë³µì‚¬
            cuda.memcpy_htod(self.input_images, image_array)
            cuda.memcpy_htod(self.input_text, text_embedding)
            
            # ì¶”ë¡  ì‹¤í–‰
            start_time = time.time()
            self.context.execute_v2(bindings=[
                int(self.input_images),
                int(self.input_text),
                int(self.output)
            ])
            inference_time = time.time() - start_time
            
            # ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            result = np.empty((1, 3), dtype=np.float32)
            cuda.memcpy_dtoh(result, self.output)
            
            self.inference_count += 1
            self.last_inference_time = inference_time
            
            # ê²°ê³¼ ë°œí–‰
            self.publish_result(result[0], inference_time)
            
            return result[0]
            
        except Exception as e:
            self.get_logger().error(f"âŒ TensorRT inference error: {{e}}")
            return np.array([0.0, 0.0, 0.0])
    
    def execute_action(self, action):
        """ì•¡ì…˜ ì‹¤í–‰"""
        try:
            twist = Twist()
            twist.linear.x = float(action[0])
            twist.linear.y = float(action[1])
            twist.angular.z = float(action[2])
            
            self.action_pub.publish(twist)
            
        except Exception as e:
            self.get_logger().error(f"âŒ Error executing action: {{e}}")
    
    def publish_result(self, action, inference_time):
        """ê²°ê³¼ ë°œí–‰"""
        try:
            result = {{
                "timestamp": time.time(),
                "inference_time": inference_time,
                "action": action.tolist(),
                "inference_count": self.inference_count,
                "engine": "{engine_path}"
            }}
            
            msg = String()
            msg.data = json.dumps(result)
            self.result_pub.publish(msg)
            
            self.get_logger().info(f"ğŸ¯ TensorRT Inference #{{self.inference_count}}: {{inference_time*1000:.2f}}ms")
            
        except Exception as e:
            self.get_logger().error(f"âŒ Error publishing result: {{e}}")

def main(args=None):
    rclpy.init(args=args)
    node = TensorRTInferenceNode()
    
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()
'''
        
        # ë…¸ë“œ íŒŒì¼ ì €ì¥
        node_path = os.path.join(self.output_dir, "tensorrt_inference_node.py")
        with open(node_path, "w") as f:
            f.write(node_code)
        
        print(f"âœ… TensorRT inference node created: {node_path}")
        return node_path

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ Starting Advanced Mobile VLA TensorRT Conversion")
    
    # ë³€í™˜ê¸° ì´ˆê¸°í™”
    converter = MobileVLATensorRTConverterAdvanced()
    
    try:
        # Torch2TRT ë³€í™˜
        if TORCH2TRT_AVAILABLE:
            print("\nğŸ”¨ Converting with Torch2TRT...")
            model_trt, model_path = converter.convert_to_tensorrt_torch2trt(precision="fp16")
            
            if model_trt is not None:
                # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
                print("\nğŸ§ª Testing Torch2TRT performance...")
                converter.test_torch2trt_inference(model_trt)
                
                # ë²¤ì¹˜ë§ˆí¬
                print("\nğŸ“ˆ Running benchmark...")
                converter.benchmark_original_vs_tensorrt(model_trt)
        
        # ONNX -> TensorRT ë³€í™˜
        print("\nğŸ”¨ Converting with ONNX -> TensorRT...")
        engine_path = converter.convert_to_onnx_then_tensorrt(precision="fp16")
        
        if engine_path:
            # TensorRT ì¶”ë¡  ë…¸ë“œ ìƒì„±
            print("\nğŸ”§ Creating TensorRT inference node...")
            converter.create_tensorrt_inference_node(engine_path)
        
        print("\nâœ… Advanced TensorRT conversion completed!")
        
    except Exception as e:
        print(f"âŒ Advanced TensorRT conversion failed: {e}")
        raise

if __name__ == "__main__":
    main()
