# III. Proposed Scheme

## 실제 논문 내용

### 1. 시스템 아키텍처

#### 1.1 전체 시스템 구조

본 연구에서 제안하는 Mobile VLA 시스템은 크게 세 가지 주요 구성 요소로 이루어진다. 첫째, Vision-Language Model (VLM) 백본이다. 이는 Kosmos-2를 기반으로 하여 시각과 언어 정보를 통합적으로 처리한다. 둘째, Policy Head이다. 이는 LSTM 기반의 정책 헤드로 시퀀스 정보를 처리하여 로봇 액션을 생성한다. 셋째, Action Generation Module이다. 이는 최종적으로 2D 연속 액션을 출력하여 모바일 로봇의 내비게이션을 제어한다.

#### 1.2 VLM 백본 구조

VLM 백본은 Kosmos-2를 기반으로 구성되며, 시각과 언어 정보를 통합적으로 처리한다. Kosmos-2는 24층의 Vision Transformer와 24층의 Text Transformer로 구성되어 있다. Vision Transformer는 입력 이미지를 224x224 크기로 처리하여 1024차원의 시각 특징을 추출한다. Text Transformer는 입력 텍스트를 처리하여 2048차원의 언어 특징을 추출한다.

#### 1.3 Policy Head 구조

Policy Head는 LSTM 기반의 정책 헤드로 구성되어 있다. LSTM은 4층으로 구성되어 있으며, 각 층은 4096개의 hidden unit을 가진다. LSTM은 시각-언어 특징을 입력으로 받아 시퀀스 정보를 처리하고, 최종적으로 로봇 액션을 생성한다. LSTM의 출력은 4096차원의 특징 벡터이며, 이는 Action Generation Module로 전달된다.

#### 1.4 Action Generation Module

Action Generation Module은 LSTM의 출력을 입력으로 받아 최종적으로 2D 연속 액션을 생성한다. 이 모듈은 4층의 fully connected layer로 구성되어 있으며, 각 층은 ReLU 활성화 함수를 사용한다. 최종 출력은 linear_x와 linear_y로 구성된 2D 연속 액션이다.

### 2. 하이브리드 아키텍처

#### 2.1 Kosmos-2 + CLIP 하이브리드 모델

본 연구에서는 Kosmos-2와 CLIP을 조합한 하이브리드 아키텍처를 제안한다. 이 하이브리드 모델은 Kosmos-2의 강력한 멀티모달 이해 능력과 CLIP의 효율적인 특징 추출 능력을 결합하여 성능을 향상시킨다.

#### 2.2 특징 융합 방법

하이브리드 모델에서는 Kosmos-2와 CLIP에서 추출한 특징을 융합한다. Kosmos-2 Vision 특징(1024차원), Kosmos-2 Text 특징(2048차원), CLIP Vision 특징(768차원), CLIP Text 특징(512차원)을 concatenation하여 4352차원의 통합 특징을 생성한다. 이 통합 특징은 linear layer를 통해 2048차원으로 압축된 후 LSTM으로 전달된다.

#### 2.3 하이브리드 모델의 장점

하이브리드 모델의 주요 장점은 다음과 같다. 첫째, 성능 향상이다. Kosmos-2와 CLIP의 장점을 결합하여 더 정확한 액션 예측이 가능하다. 둘째, 안정성 향상이다. 두 모델의 특징을 융합함으로써 더 안정적인 성능을 제공한다. 셋째, 일반화 능력 향상이다. 다양한 환경에서 더 나은 일반화 성능을 보인다.

### 3. 실행 흐름

#### 3.1 입력 처리 단계

시스템의 실행은 입력 처리 단계로 시작한다. 이 단계에서는 카메라로부터 720p 해상도의 이미지를 입력받고, 사용자로부터 자연어 명령을 입력받는다. 입력 이미지는 224x224 크기로 리사이즈되어 VLM 백본으로 전달된다.

#### 3.2 특징 추출 단계

특징 추출 단계에서는 VLM 백본이 시각과 언어 정보를 처리하여 특징을 추출한다. Kosmos-2 Vision Transformer는 이미지를 처리하여 1024차원의 시각 특징을 추출하고, Kosmos-2 Text Transformer는 텍스트를 처리하여 2048차원의 언어 특징을 추출한다.

#### 3.3 특징 융합 단계

특징 융합 단계에서는 추출된 특징들을 융합한다. 하이브리드 모델의 경우 Kosmos-2와 CLIP에서 추출한 특징들을 concatenation하여 통합 특징을 생성한다. 이 통합 특징은 linear layer를 통해 압축된 후 다음 단계로 전달된다.

#### 3.4 시퀀스 처리 단계

시퀀스 처리 단계에서는 LSTM이 융합된 특징을 입력으로 받아 시퀀스 정보를 처리한다. LSTM은 18프레임의 시퀀스를 처리하여 시간적 정보를 고려한 액션을 생성한다. 이 단계에서 과거 정보가 현재 액션 생성에 영향을 미친다.

#### 3.5 액션 생성 단계

액션 생성 단계에서는 LSTM의 출력을 입력으로 받아 최종적으로 2D 연속 액션을 생성한다. 이 액션은 linear_x와 linear_y로 구성되며, 모바일 로봇의 선속도와 각속도를 제어한다.

### 4. 시간적 구조화

#### 4.1 시퀀스 길이 설정

본 연구에서는 18프레임의 시퀀스를 사용하여 시간적 정보를 처리한다. 이 시퀀스 길이는 실시간 처리와 성능 간의 균형을 고려하여 설정되었다. 18프레임은 약 1초의 시간 정보를 포함하며, 이는 모바일 로봇 내비게이션에 충분한 시간적 컨텍스트를 제공한다.

#### 4.2 LSTM 기반 시퀀스 처리

LSTM은 시퀀스 정보를 처리하는 데 특화된 구조를 가지고 있다. LSTM의 메모리 셀은 장기 의존성을 학습할 수 있어, 과거의 중요한 정보를 현재 액션 생성에 활용할 수 있다. 본 연구에서는 4층 LSTM을 사용하여 복잡한 시퀀스 패턴을 학습한다.

#### 4.3 시간적 일관성 보장

시간적 일관성을 보장하기 위해 LSTM은 이전 프레임의 정보를 현재 프레임의 액션 생성에 반영한다. 이를 통해 급격한 액션 변화를 방지하고 부드러운 로봇 동작을 보장한다.

### 5. RoboVLMs의 한계 및 개선 방안

#### 5.1 RoboVLMs의 한계점

RoboVLMs는 우수한 VLA 아키텍처를 제공하지만 몇 가지 한계점을 가지고 있다. 첫째, 계산 복잡도가 높다. RoboVLMs는 복잡한 아키텍처로 인해 높은 계산 자원을 요구한다. 둘째, 실시간 처리가 어렵다. 복잡한 모델 구조로 인해 실시간 로봇 제어에 어려움이 있다. 셋째, 모바일 환경 부적합이다. 높은 메모리 요구사항으로 인해 모바일 환경에서의 실행이 어렵다.

#### 5.2 제안하는 개선 방안

본 연구에서는 이러한 한계점을 해결하기 위한 개선 방안을 제안한다. 첫째, 모바일 최적화이다. 2D 액션 공간을 사용하여 계산 복잡도를 줄이고, FP16 양자화를 통해 메모리 사용량을 최적화한다. 둘째, 실시간 처리 최적화이다. LSTM 기반의 효율적인 시퀀스 처리를 통해 실시간 성능을 향상시킨다. 셋째, 하이브리드 아키텍처이다. Kosmos-2와 CLIP을 조합하여 성능과 효율성을 모두 개선한다.

---

## 📊 분석 및 검토 사항

### 시스템 아키텍처 분석

**주요 구성 요소:**
1. **VLM 백본**: Kosmos-2 기반 시각-언어 처리
2. **Policy Head**: LSTM 기반 시퀀스 처리
3. **Action Generation**: 2D 연속 액션 생성

**하이브리드 모델의 특징:**
- Kosmos-2 + CLIP 조합으로 성능 향상
- 특징 융합을 통한 안정성 개선
- 다양한 환경에서의 일반화 능력 향상

### 실행 흐름 분석

**5단계 처리 과정:**
1. 입력 처리: 720p 이미지 + 자연어 명령
2. 특징 추출: VLM을 통한 멀티모달 특징 추출
3. 특징 융합: Kosmos-2 + CLIP 특징 통합
4. 시퀀스 처리: LSTM을 통한 시간적 정보 처리
5. 액션 생성: 2D 연속 액션 출력

### 시간적 구조화 분석

**시퀀스 처리 최적화:**
- 18프레임 시퀀스로 1초 시간 컨텍스트 제공
- 4층 LSTM으로 복잡한 패턴 학습
- 시간적 일관성 보장으로 부드러운 동작

### RoboVLMs 한계 및 개선

**기존 한계점:**
1. 높은 계산 복잡도
2. 실시간 처리 어려움
3. 모바일 환경 부적합

**개선 방안:**
1. 2D 액션 공간으로 단순화
2. FP16 양자화로 메모리 최적화
3. 하이브리드 아키텍처로 성능 향상

### 다음 단계

1. **실험적 검증**: 제안된 아키텍처의 성능 검증
2. **최적화**: 더 나은 성능을 위한 추가 최적화
3. **확장성**: 다양한 로봇 플랫폼에의 적용 가능성

---
*마지막 업데이트: 2024년 8월 29일*
