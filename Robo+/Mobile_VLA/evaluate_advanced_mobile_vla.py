#!/usr/bin/env python3
"""
ğŸ“Š Advanced Mobile VLA Model ì„±ëŠ¥ í‰ê°€
MAE, RMSE, ì˜ˆì¸¡ ì •í™•ë„ ê³„ì‚° ë° ì´ì „ ëª¨ë¸ê³¼ ë¹„êµ
"""
import torch
import torch.nn as nn
import numpy as np
import json
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import sys
from tqdm import tqdm
from sklearn.metrics import mean_absolute_error, mean_squared_error
import pandas as pd

# RoboVLMs ëª¨ë“ˆ ì¶”ê°€
sys.path.append(str(Path(__file__).parent / "robovlms" / "models"))
from advanced_mobile_vla_model import AdvancedMobileVLAModel
from train_advanced_mobile_vla import MobileVLADataset, collate_fn
from torch.utils.data import DataLoader

def calculate_mae_rmse(predictions, targets):
    """MAEì™€ RMSE ê³„ì‚°"""
    mae = mean_absolute_error(targets.flatten(), predictions.flatten())
    rmse = np.sqrt(mean_squared_error(targets.flatten(), predictions.flatten()))
    return mae, rmse

def calculate_prediction_accuracy(predictions, targets, threshold=0.1):
    """ì˜ˆì¸¡ ì •í™•ë„ ê³„ì‚° (ì„ê³„ê°’ ë‚´ ì˜¤ì°¨ ë¹„ìœ¨)"""
    abs_error = np.abs(predictions - targets)
    within_threshold = (abs_error <= threshold).sum()
    total_predictions = abs_error.size
    accuracy = within_threshold / total_predictions * 100
    return accuracy

def evaluate_advanced_mobile_vla():
    """Advanced Mobile VLA ëª¨ë¸ ì„±ëŠ¥ í‰ê°€"""
    print("ğŸš€ Advanced Mobile VLA ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì‹œì‘")
    
    # ì„¤ì •
    config = {
        'data_paths': [
            '../../ROS_action/mobile_vla_dataset',
            'augmented_dataset',
            'distance_aware_augmented_dataset'
        ],
        'batch_size': 1,
        'device': 'cuda' if torch.cuda.is_available() else 'cpu',
        'model_path': 'advanced_mobile_vla_best.pth'
    }
    
    print(f"ğŸ’» ë””ë°”ì´ìŠ¤: {config['device']}")
    
    # ë°ì´í„°ì…‹ ë¡œë“œ (ê²€ì¦ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©)
    print("ğŸ“Š ë°ì´í„°ì…‹ ë¡œë”© ì¤‘...")
    dataset = MobileVLADataset(config['data_paths'])
    
    # ê²€ì¦ ë°ì´í„°ì…‹ (ì „ì²´ì˜ 20%)
    val_size = max(1, int(len(dataset) * 0.2))
    train_size = len(dataset) - val_size
    _, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])
    
    val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False, collate_fn=collate_fn)
    
    print(f"ğŸ“ˆ ê²€ì¦ ë°ì´í„°: {len(val_dataset)}ê°œ ì—í”¼ì†Œë“œ")
    
    # ëª¨ë¸ ë¡œë“œ
    print("ğŸ¤– ëª¨ë¸ ë¡œë”© ì¤‘...")
    from transformers import AutoProcessor
    processor = AutoProcessor.from_pretrained("microsoft/kosmos-2-patch14-224")
    
    model = AdvancedMobileVLAModel(
        processor=processor,
        vision_dim=768,
        language_dim=768,
        action_dim=3,
        fusion_dim=512,
        plan_dim=256,
        num_claw_layers=3,
        num_subgoals=6,
        frames_per_subgoal=3,
        use_claw_matrix=True,
        use_hierarchical=True,
        use_advanced_attention=True
    ).to(config['device'])
    
    # ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
    if Path(config['model_path']).exists():
        checkpoint = torch.load(config['model_path'], map_location=config['device'])
        
        # ì²´í¬í¬ì¸íŠ¸ í˜•ì‹ í™•ì¸
        if 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
            print(f"âœ… ì²´í¬í¬ì¸íŠ¸ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {config['model_path']}")
            print(f"   ì—í¬í¬: {checkpoint.get('epoch', 'N/A')}")
            print(f"   í›ˆë ¨ ì†ì‹¤: {checkpoint.get('train_loss', 'N/A'):.4f}")
            print(f"   ê²€ì¦ ì†ì‹¤: {checkpoint.get('val_loss', 'N/A'):.4f}")
        else:
            model.load_state_dict(checkpoint)
            print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {config['model_path']}")
    else:
        print(f"âŒ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {config['model_path']}")
        return
    
    model.eval()
    
    # ì„±ëŠ¥ í‰ê°€
    print("ğŸ“Š ì„±ëŠ¥ í‰ê°€ ì¤‘...")
    all_predictions = []
    all_targets = []
    all_mae_per_episode = []
    all_rmse_per_episode = []
    all_accuracy_per_episode = []
    
    with torch.no_grad():
        for batch_idx, batch in enumerate(tqdm(val_loader, desc="í‰ê°€ ì§„í–‰")):
            try:
                images = batch['images'].to(config['device']).float()
                actions = batch['actions'].to(config['device']).float()
                
                # ê±°ë¦¬ ë¼ë²¨ ìƒì„±
                batch_size = images.shape[0]
                distance_labels = torch.randint(0, 3, (batch_size,), device=config['device']).long()
                
                # ì˜ˆì¸¡
                predicted_actions = model(
                    images=images,
                    distance_labels=distance_labels
                )
                
                # íƒ€ê²Ÿ ì•¡ì…˜ ë§ì¶”ê¸°
                target_actions = actions[:, :predicted_actions.shape[1], :predicted_actions.shape[2]]
                
                # numpyë¡œ ë³€í™˜
                pred_np = predicted_actions.cpu().numpy()
                target_np = target_actions.cpu().numpy()
                
                # ì—í”¼ì†Œë“œë³„ ì„±ëŠ¥ ê³„ì‚°
                for i in range(pred_np.shape[0]):
                    pred_episode = pred_np[i]
                    target_episode = target_np[i]
                    
                    mae, rmse = calculate_mae_rmse(pred_episode, target_episode)
                    accuracy = calculate_prediction_accuracy(pred_episode, target_episode)
                    
                    all_mae_per_episode.append(mae)
                    all_rmse_per_episode.append(rmse)
                    all_accuracy_per_episode.append(accuracy)
                    
                    all_predictions.append(pred_episode.flatten())
                    all_targets.append(target_episode.flatten())
                
            except Exception as e:
                print(f"âš ï¸ ë°°ì¹˜ {batch_idx} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                continue
    
    # ì „ì²´ ì„±ëŠ¥ ê³„ì‚°
    all_predictions = np.concatenate(all_predictions)
    all_targets = np.concatenate(all_targets)
    
    overall_mae = mean_absolute_error(all_targets, all_predictions)
    overall_rmse = np.sqrt(mean_squared_error(all_targets, all_predictions))
    overall_accuracy = calculate_prediction_accuracy(all_predictions, all_targets)
    
    # ì—í”¼ì†Œë“œë³„ í‰ê· 
    avg_mae = np.mean(all_mae_per_episode)
    avg_rmse = np.mean(all_rmse_per_episode)
    avg_accuracy = np.mean(all_accuracy_per_episode)
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*60)
    print("ğŸ“Š Advanced Mobile VLA ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ê²°ê³¼")
    print("="*60)
    print(f"ğŸ¯ ì „ì²´ MAE: {overall_mae:.6f}")
    print(f"ğŸ¯ ì „ì²´ RMSE: {overall_rmse:.6f}")
    print(f"ğŸ¯ ì „ì²´ ì˜ˆì¸¡ ì •í™•ë„ (0.1 ì„ê³„ê°’): {overall_accuracy:.2f}%")
    print(f"ğŸ“ˆ ì—í”¼ì†Œë“œë³„ í‰ê·  MAE: {avg_mae:.6f}")
    print(f"ğŸ“ˆ ì—í”¼ì†Œë“œë³„ í‰ê·  RMSE: {avg_rmse:.6f}")
    print(f"ğŸ“ˆ ì—í”¼ì†Œë“œë³„ í‰ê·  ì •í™•ë„: {avg_accuracy:.2f}%")
    print(f"ğŸ“Š í‰ê°€ ë°ì´í„° ìˆ˜: {len(val_dataset)}ê°œ ì—í”¼ì†Œë“œ")
    print(f"ğŸ“Š ì´ ì˜ˆì¸¡ ìˆ˜: {len(all_predictions)}ê°œ")
    
    # ê²°ê³¼ ì €ì¥
    results = {
        'model_name': 'Advanced Mobile VLA (Claw Matrix + Hierarchical Planning + Advanced Attention)',
        'overall_mae': float(overall_mae),
        'overall_rmse': float(overall_rmse),
        'overall_accuracy': float(overall_accuracy),
        'avg_episode_mae': float(avg_mae),
        'avg_episode_rmse': float(avg_rmse),
        'avg_episode_accuracy': float(avg_accuracy),
        'num_episodes': len(val_dataset),
        'total_predictions': len(all_predictions),
        'evaluation_date': pd.Timestamp.now().isoformat()
    }
    
    with open('advanced_mobile_vla_evaluation_results.json', 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: advanced_mobile_vla_evaluation_results.json")
    
    return results

if __name__ == "__main__":
    evaluate_advanced_mobile_vla()
