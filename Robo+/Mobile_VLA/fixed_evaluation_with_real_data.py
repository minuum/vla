"""
ğŸ” ì‹¤ì œ ì„±ëŠ¥ í‰ê°€ (ì²« í”„ë ˆì„ 0 ê³ ì • ê³ ë ¤)
ì²« í”„ë ˆì„ì´ 0ì¸ ê²ƒì´ ê³ ì •ì´ë¼ëŠ” ì ì„ ë°˜ì˜í•œ ì •í™•í•œ ì„±ëŠ¥ í‰ê°€
"""

import torch
import numpy as np
import h5py
import os
from pathlib import Path
from transformers import AutoProcessor
from torch.utils.data import DataLoader, Dataset, random_split

from fixed_robovlms_model import FixedRoboVLMStyleSingleImageModel
from train_fixed_robovlms import FixedRoboVLMStyleDataset

class RealisticRoboVLMStyleDataset(Dataset):
    """í˜„ì‹¤ì ì¸ RoboVLMs ìŠ¤íƒ€ì¼ ë°ì´í„°ì…‹ (ì²« í”„ë ˆì„ 0 ê³ ì • ê³ ë ¤)"""
    
    def __init__(self, data_path, processor, split='train', use_middle_frame=True):
        self.data_path = data_path
        self.processor = processor
        self.split = split
        self.use_middle_frame = use_middle_frame
        
        # H5 íŒŒì¼ë“¤ ë¡œë“œ
        self.episodes = []
        self._load_episodes()
        
        print(f"ğŸ“Š {split} ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ: {len(self.episodes)}ê°œ ì—í”¼ì†Œë“œ")
        print(f"   - ì¤‘ê°„ í”„ë ˆì„ ì‚¬ìš©: {use_middle_frame}")
    
    def _load_episodes(self):
        """ì—í”¼ì†Œë“œ ë¡œë“œ (ì¤‘ê°„ í”„ë ˆì„ ì‚¬ìš©)"""
        if os.path.isdir(self.data_path):
            h5_files = list(Path(self.data_path).glob("*.h5"))
        else:
            h5_files = [self.data_path]
        
        for h5_file in h5_files:
            try:
                with h5py.File(h5_file, 'r') as f:
                    if 'images' in f and 'actions' in f:
                        images = f['images'][:]  # [18, H, W, 3]
                        actions = f['actions'][:]  # [18, 3]
                        
                        if self.use_middle_frame:
                            # ì¤‘ê°„ í”„ë ˆì„ ì‚¬ìš© (í”„ë ˆì„ 9, 18ê°œ ì¤‘ 10ë²ˆì§¸)
                            frame_idx = 9
                            single_image = images[frame_idx]  # [H, W, 3]
                            single_action = actions[frame_idx]  # [3]
                        else:
                            # ì²« í”„ë ˆì„ ì‚¬ìš© (0 ê³ ì •)
                            single_image = images[0]  # [H, W, 3]
                            single_action = actions[0]  # [3]
                        
                        self.episodes.append({
                            'image': single_image,  # [H, W, 3]
                            'action': single_action,  # [3]
                            'episode_id': f"{h5_file.stem}",
                            'frame_idx': frame_idx if self.use_middle_frame else 0
                        })
            except Exception as e:
                print(f"âŒ {h5_file} ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def __len__(self):
        return len(self.episodes)
    
    def __getitem__(self, idx):
        episode = self.episodes[idx]
        
        # ì´ë¯¸ì§€: [H, W, 3] â†’ [3, H, W] (PyTorch í˜•ì‹)
        image = episode['image']  # [H, W, 3]
        image = np.transpose(image, (2, 0, 1))  # [3, H, W]
        
        # 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”
        if image.max() > 1:
            image = image.astype(np.float32) / 255.0
        
        # ì•¡ì…˜: [3]
        action = episode['action']  # [3]
        
        return {
            'image': image,  # [3, H, W]
            'action': action,  # [3]
            'episode_id': episode['episode_id'],
            'frame_idx': episode['frame_idx']
        }

def create_realistic_data_loaders(data_path, processor, batch_size=4, train_split=0.8, use_middle_frame=True):
    """í˜„ì‹¤ì ì¸ ë°ì´í„° ë¡œë” ìƒì„±"""
    
    # ì „ì²´ ë°ì´í„°ì…‹ ë¡œë“œ
    full_dataset = RealisticRoboVLMStyleDataset(data_path, processor, 'full', use_middle_frame)
    
    # í›ˆë ¨/ê²€ì¦ ë¶„í• 
    total_size = len(full_dataset)
    train_size = int(total_size * train_split)
    val_size = total_size - train_size
    
    train_dataset, val_dataset = random_split(
        full_dataset, [train_size, val_size]
    )
    
    # ë°ì´í„° ë¡œë” ìƒì„±
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=1,
        pin_memory=True
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=1,
        pin_memory=True
    )
    
    print(f"ğŸ“Š í˜„ì‹¤ì ì¸ ë°ì´í„° ë¡œë” ìƒì„± ì™„ë£Œ:")
    print(f"   - í›ˆë ¨: {len(train_dataset)}ê°œ ì—í”¼ì†Œë“œ")
    print(f"   - ê²€ì¦: {len(val_dataset)}ê°œ ì—í”¼ì†Œë“œ")
    print(f"   - ë°°ì¹˜ í¬ê¸°: {batch_size}")
    print(f"   - ì¤‘ê°„ í”„ë ˆì„ ì‚¬ìš©: {use_middle_frame}")
    
    return train_loader, val_loader

def evaluate_realistic_performance():
    """í˜„ì‹¤ì ì¸ ì„±ëŠ¥ í‰ê°€"""
    
    print("ğŸ” í˜„ì‹¤ì ì¸ ì„±ëŠ¥ í‰ê°€ ì‹œì‘")
    print("=" * 60)
    
    # ì„¤ì •
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    model_path = 'fixed_robovlms_model_best.pth'
    
    if not os.path.exists(model_path):
        print(f"âŒ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {model_path}")
        return
    
    # í”„ë¡œì„¸ì„œ ë¡œë“œ
    processor = AutoProcessor.from_pretrained("microsoft/kosmos-2-patch14-224")
    
    # ëª¨ë¸ ë¡œë“œ
    model = FixedRoboVLMStyleSingleImageModel(
        processor=processor,
        dropout=0.2,
        use_claw_matrix=True,
        use_hierarchical=True,
        use_advanced_attention=True,
        z_axis_weight=0.05
    ).to(device)
    
    checkpoint = torch.load(model_path, map_location=device)
    
    # ë™ì  ì–´ëŒ‘í„° ì´ˆê¸°í™”
    dummy_image = torch.randn(1, 3, 224, 224).to(device)
    with torch.no_grad():
        try:
            _ = model(dummy_image, "Navigate to target")
        except:
            pass
    
    # í˜¸í™˜ë˜ëŠ” í‚¤ë§Œ ë¡œë“œ
    model_dict = model.state_dict()
    checkpoint_dict = checkpoint['model_state_dict']
    compatible_dict = {k: v for k, v in checkpoint_dict.items() 
                      if k in model_dict and model_dict[k].shape == v.shape}
    model_dict.update(compatible_dict)
    model.load_state_dict(model_dict)
    
    print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    print(f"   - ì—í¬í¬: {checkpoint['epoch']}")
    print(f"   - í›ˆë ¨ ì†ì‹¤: {checkpoint['train_loss']:.6f}")
    print(f"   - ê²€ì¦ ì†ì‹¤: {checkpoint['val_loss']:.6f}")
    
    # 1. ì²« í”„ë ˆì„ í‰ê°€ (0 ê³ ì •)
    print(f"\nğŸ¯ 1. ì²« í”„ë ˆì„ í‰ê°€ (0 ê³ ì •):")
    print("-" * 40)
    
    data_path = '../../ROS_action/mobile_vla_dataset'
    _, val_loader_first = create_realistic_data_loaders(
        data_path, processor, batch_size=4, use_middle_frame=False
    )
    
    model.eval()
    first_frame_results = evaluate_model_on_loader(model, val_loader_first, device, "ì²« í”„ë ˆì„")
    
    # 2. ì¤‘ê°„ í”„ë ˆì„ í‰ê°€ (ì‹¤ì œ ì•¡ì…˜)
    print(f"\nğŸ¯ 2. ì¤‘ê°„ í”„ë ˆì„ í‰ê°€ (ì‹¤ì œ ì•¡ì…˜):")
    print("-" * 40)
    
    _, val_loader_middle = create_realistic_data_loaders(
        data_path, processor, batch_size=4, use_middle_frame=True
    )
    
    middle_frame_results = evaluate_model_on_loader(model, val_loader_middle, device, "ì¤‘ê°„ í”„ë ˆì„")
    
    # 3. ì„±ëŠ¥ ë¹„êµ
    print(f"\nğŸ“Š ì„±ëŠ¥ ë¹„êµ:")
    print("=" * 60)
    
    print(f"| í‰ê°€ ë°©ì‹ | MAE | RMSE | ì •í™•ë„(0.1) | ì •í™•ë„(0.05) |")
    print(f"|-----------|-----|------|-------------|-------------|")
    print(f"| ì²« í”„ë ˆì„ | {first_frame_results['mae']:.6f} | {first_frame_results['rmse']:.6f} | {first_frame_results['accuracy_0.1']:.2f}% | {first_frame_results['accuracy_0.05']:.2f}% |")
    print(f"| ì¤‘ê°„ í”„ë ˆì„ | {middle_frame_results['mae']:.6f} | {middle_frame_results['rmse']:.6f} | {middle_frame_results['accuracy_0.1']:.2f}% | {middle_frame_results['accuracy_0.05']:.2f}% |")
    
    # 4. ê²°ë¡ 
    print(f"\nğŸ¯ ê²°ë¡ :")
    print("=" * 60)
    
    if first_frame_results['accuracy_0.1'] > 95:
        print(f"âœ… ì²« í”„ë ˆì„ í‰ê°€: ëª¨ë¸ì´ 0ì„ ì˜ ì˜ˆì¸¡í•¨ (ì •í™•ë„: {first_frame_results['accuracy_0.1']:.2f}%)")
    else:
        print(f"âš ï¸ ì²« í”„ë ˆì„ í‰ê°€: ëª¨ë¸ì´ 0ì„ ì œëŒ€ë¡œ ì˜ˆì¸¡í•˜ì§€ ëª»í•¨ (ì •í™•ë„: {first_frame_results['accuracy_0.1']:.2f}%)")
    
    if middle_frame_results['accuracy_0.1'] > 70:
        print(f"âœ… ì¤‘ê°„ í”„ë ˆì„ í‰ê°€: ëª¨ë¸ì´ ì‹¤ì œ ì•¡ì…˜ì„ ì˜ ì˜ˆì¸¡í•¨ (ì •í™•ë„: {middle_frame_results['accuracy_0.1']:.2f}%)")
    elif middle_frame_results['accuracy_0.1'] > 50:
        print(f"âš ï¸ ì¤‘ê°„ í”„ë ˆì„ í‰ê°€: ëª¨ë¸ì´ ì‹¤ì œ ì•¡ì…˜ì„ ì–´ëŠ ì •ë„ ì˜ˆì¸¡í•¨ (ì •í™•ë„: {middle_frame_results['accuracy_0.1']:.2f}%)")
    else:
        print(f"âŒ ì¤‘ê°„ í”„ë ˆì„ í‰ê°€: ëª¨ë¸ì´ ì‹¤ì œ ì•¡ì…˜ì„ ì œëŒ€ë¡œ ì˜ˆì¸¡í•˜ì§€ ëª»í•¨ (ì •í™•ë„: {middle_frame_results['accuracy_0.1']:.2f}%)")
    
    # 5. ê²°ê³¼ ì €ì¥
    results = {
        'model_type': 'Fixed_RoboVLMs_Style_Single_Image',
        'evaluation_type': 'realistic_with_first_frame_zero',
        'first_frame_results': first_frame_results,
        'middle_frame_results': middle_frame_results,
        'conclusion': {
            'first_frame_zero_accuracy': first_frame_results['accuracy_0.1'],
            'middle_frame_real_accuracy': middle_frame_results['accuracy_0.1'],
            'model_performance': 'good' if middle_frame_results['accuracy_0.1'] > 70 else 'needs_improvement'
        }
    }
    
    import json
    with open('realistic_evaluation_results.json', 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: realistic_evaluation_results.json")

def evaluate_model_on_loader(model, data_loader, device, description):
    """ë°ì´í„° ë¡œë”ì—ì„œ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€"""
    
    model.eval()
    total_loss = 0.0
    total_mae = 0.0
    total_rmse = 0.0
    predictions = []
    targets = []
    
    print(f"   ğŸ“Š {description} í‰ê°€ ì¤‘...")
    
    with torch.no_grad():
        for batch_idx, batch in enumerate(data_loader):
            try:
                images = batch['image'].float().to(device)
                actions = batch['action'].float().to(device)
                
                # ì˜ˆì¸¡
                predicted_actions = model(images, "Navigate to target")
                
                # ì†ì‹¤ ê³„ì‚°
                z_weight = torch.tensor([1.0, 1.0, 0.05]).to(device)
                weighted_target = actions * z_weight.unsqueeze(0)
                weighted_pred = predicted_actions * z_weight.unsqueeze(0)
                
                loss = torch.nn.functional.mse_loss(weighted_pred, weighted_target)
                total_loss += loss.item()
                
                # MAE ê³„ì‚°
                mae = torch.mean(torch.abs(predicted_actions - actions))
                total_mae += mae.item()
                
                # RMSE ê³„ì‚°
                rmse = torch.sqrt(torch.mean((predicted_actions - actions) ** 2))
                total_rmse += rmse.item()
                
                # ì˜ˆì¸¡ê³¼ íƒ€ê²Ÿ ì €ì¥
                predictions.append(predicted_actions.cpu().numpy())
                targets.append(actions.cpu().numpy())
                
            except Exception as e:
                print(f"âŒ ë°°ì¹˜ {batch_idx} í‰ê°€ ì¤‘ ì˜¤ë¥˜: {e}")
                continue
    
    # í‰ê·  ê³„ì‚°
    avg_loss = total_loss / len(data_loader)
    avg_mae = total_mae / len(data_loader)
    avg_rmse = total_rmse / len(data_loader)
    
    # ì˜ˆì¸¡ ì •í™•ë„ ê³„ì‚°
    predictions = np.concatenate(predictions, axis=0)
    targets = np.concatenate(targets, axis=0)
    
    # ë‹¤ì–‘í•œ ì„ê³„ê°’ìœ¼ë¡œ ì •í™•ë„ ê³„ì‚°
    accuracy_01 = np.mean(np.abs(predictions - targets) < 0.1) * 100
    accuracy_005 = np.mean(np.abs(predictions - targets) < 0.05) * 100
    
    print(f"   ğŸ“Š {description} ê²°ê³¼:")
    print(f"      - í‰ê·  ì†ì‹¤: {avg_loss:.6f}")
    print(f"      - í‰ê·  MAE: {avg_mae:.6f}")
    print(f"      - í‰ê·  RMSE: {avg_rmse:.6f}")
    print(f"      - ì •í™•ë„(0.1): {accuracy_01:.2f}%")
    print(f"      - ì •í™•ë„(0.05): {accuracy_005:.2f}%")
    
    # ìƒ˜í”Œ ì¶œë ¥
    print(f"   ğŸ” {description} ìƒ˜í”Œ:")
    for i in range(min(3, len(predictions))):
        print(f"      ìƒ˜í”Œ {i}: ì˜ˆì¸¡={predictions[i]}, íƒ€ê²Ÿ={targets[i]}")
    
    return {
        'loss': avg_loss,
        'mae': avg_mae,
        'rmse': avg_rmse,
        'accuracy_0.1': accuracy_01,
        'accuracy_0.05': accuracy_005,
        'predictions': predictions.tolist(),
        'targets': targets.tolist()
    }

if __name__ == "__main__":
    evaluate_realistic_performance()
