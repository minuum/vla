#!/usr/bin/env python3
"""
ğŸ“Š ë°ì´í„°ì…‹ ë¶„ì„ ë° íƒœìŠ¤í¬ íŠ¹ì„± íŒŒì•…
"""
import sys
from pathlib import Path
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict
import json
from PIL import Image
import cv2

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
ROOT_DIR = Path("/home/billy/25-1kp/vla/Robo+/Mobile_VLA")
DATA_DIR = Path("/home/billy/25-1kp/vla/ROS_action/mobile_vla_dataset")
ROBOVLMS_DIR = Path("/home/billy/25-1kp/vla/RoboVLMs")

sys.path.append(str(ROOT_DIR))
sys.path.append(str(ROBOVLMS_DIR))

from robovlms.data.mobile_vla_dataset import MobileVLADataset

def analyze_dataset():
    """ë°ì´í„°ì…‹ ìƒì„¸ ë¶„ì„"""
    print("ğŸ” ë°ì´í„°ì…‹ ìƒì„¸ ë¶„ì„ ì‹œì‘...")
    
    # ë°ì´í„°ì…‹ ë¡œë“œ
    dataset = MobileVLADataset(DATA_DIR)
    print(f"ğŸ“Š ì „ì²´ ì—í”¼ì†Œë“œ ìˆ˜: {len(dataset)}")
    
    # 1. ì•¡ì…˜ ë¶„í¬ ë¶„ì„
    print("\nğŸ“ˆ ì•¡ì…˜ ë¶„í¬ ë¶„ì„...")
    all_actions = []
    action_ranges = {'linear_x': [], 'linear_y': [], 'angular_z': []}
    episode_lengths = []
    
    for i in range(len(dataset)):
        episode = dataset[i]
        actions = episode['actions']
        
        if isinstance(actions, np.ndarray):
            all_actions.append(actions)
            episode_lengths.append(len(actions))
            
            # ê° ì¶•ë³„ ë²”ìœ„ ê³„ì‚°
            action_ranges['linear_x'].extend([actions[:, 0].min(), actions[:, 0].max()])
            action_ranges['linear_y'].extend([actions[:, 1].min(), actions[:, 1].max()])
            action_ranges['angular_z'].extend([actions[:, 2].min(), actions[:, 2].max()])
    
    all_actions = np.concatenate(all_actions, axis=0)
    
    print(f"   ì´ ì•¡ì…˜ í”„ë ˆì„ ìˆ˜: {len(all_actions)}")
    print(f"   ì—í”¼ì†Œë“œ ê¸¸ì´ ë²”ìœ„: {min(episode_lengths)} ~ {max(episode_lengths)}")
    print(f"   í‰ê·  ì—í”¼ì†Œë“œ ê¸¸ì´: {np.mean(episode_lengths):.1f}")
    
    # 2. ì•¡ì…˜ í†µê³„
    print("\nğŸ“Š ì•¡ì…˜ í†µê³„:")
    for i, axis in enumerate(['linear_x', 'linear_y', 'angular_z']):
        values = all_actions[:, i]
        print(f"   {axis}:")
        print(f"     í‰ê· : {np.mean(values):.4f}")
        print(f"     í‘œì¤€í¸ì°¨: {np.std(values):.4f}")
        print(f"     ë²”ìœ„: [{np.min(values):.4f}, {np.max(values):.4f}]")
        print(f"     ì¤‘ì•™ê°’: {np.median(values):.4f}")
        print(f"     ì œë¡œ ë¹„ìœ¨: {(values == 0).sum() / len(values) * 100:.1f}%")
    
    # 3. ì•¡ì…˜ íŒ¨í„´ ë¶„ì„
    print("\nğŸ”„ ì•¡ì…˜ íŒ¨í„´ ë¶„ì„...")
    
    # ì—°ì†ëœ ê°™ì€ ê°’ íŒ¨í„´ ì°¾ê¸°
    consecutive_patterns = defaultdict(int)
    direction_changes = {'linear_x': 0, 'linear_y': 0, 'angular_z': 0}
    
    for episode_actions in all_actions.reshape(-1, len(all_actions) // len(dataset), 3):
        for i in range(1, len(episode_actions)):
            # ë°©í–¥ ë³€í™” ê°ì§€
            for j, axis in enumerate(['linear_x', 'linear_y', 'angular_z']):
                if (episode_actions[i-1, j] * episode_actions[i, j]) < 0:  # ë¶€í˜¸ ë³€í™”
                    direction_changes[axis] += 1
    
    print("   ë°©í–¥ ë³€í™” íšŸìˆ˜:")
    for axis, count in direction_changes.items():
        print(f"     {axis}: {count}íšŒ")
    
    # 4. ì´ë¯¸ì§€ íŠ¹ì„± ë¶„ì„
    print("\nğŸ–¼ï¸ ì´ë¯¸ì§€ íŠ¹ì„± ë¶„ì„...")
    
    # ìƒ˜í”Œ ì´ë¯¸ì§€ë“¤ ë¶„ì„
    sample_images = []
    brightness_values = []
    contrast_values = []
    
    for i in range(min(10, len(dataset))):  # ì²˜ìŒ 10ê°œ ì—í”¼ì†Œë“œë§Œ
        episode = dataset[i]
        images = episode['images']
        
        for j, img in enumerate(images[:5]):  # ê° ì—í”¼ì†Œë“œì˜ ì²˜ìŒ 5ì¥ë§Œ
            if isinstance(img, Image.Image):
                img_array = np.array(img)
                sample_images.append(img_array)
                
                # ë°ê¸° ê³„ì‚°
                brightness = np.mean(img_array)
                brightness_values.append(brightness)
                
                # ëŒ€ë¹„ ê³„ì‚°
                contrast = np.std(img_array)
                contrast_values.append(contrast)
    
    print(f"   ë¶„ì„í•œ ì´ë¯¸ì§€ ìˆ˜: {len(sample_images)}")
    print(f"   í‰ê·  ë°ê¸°: {np.mean(brightness_values):.1f}")
    print(f"   í‰ê·  ëŒ€ë¹„: {np.mean(contrast_values):.1f}")
    
    # 5. íƒœìŠ¤í¬ íŠ¹ì„± ì¶”ë¡ 
    print("\nğŸ¯ íƒœìŠ¤í¬ íŠ¹ì„± ì¶”ë¡ ...")
    
    # Zì¶•ì´ ëª¨ë‘ 0ì¸ì§€ í™•ì¸
    z_all_zero = np.all(all_actions[:, 2] == 0)
    print(f"   Zì¶• ëª¨ë‘ 0: {z_all_zero}")
    
    # ì£¼ìš” ì´ë™ ë°©í–¥ ë¶„ì„
    x_dominant = np.abs(all_actions[:, 0]).mean() > np.abs(all_actions[:, 1]).mean()
    print(f"   Xì¶• ìš°ì„¸ ì´ë™: {x_dominant}")
    
    # ì •ì§€ ìƒíƒœ ë¹„ìœ¨
    stationary_ratio = np.mean(np.all(np.abs(all_actions) < 0.01, axis=1))
    print(f"   ì •ì§€ ìƒíƒœ ë¹„ìœ¨: {stationary_ratio * 100:.1f}%")
    
    # 6. ì‹œê°í™”
    print("\nğŸ“Š ì‹œê°í™” ìƒì„± ì¤‘...")
    
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    
    # ì•¡ì…˜ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨
    for i, axis in enumerate(['linear_x', 'linear_y', 'angular_z']):
        axes[0, i].hist(all_actions[:, i], bins=50, alpha=0.7)
        axes[0, i].set_title(f'{axis} ë¶„í¬')
        axes[0, i].set_xlabel('ê°’')
        axes[0, i].set_ylabel('ë¹ˆë„')
    
    # ì—í”¼ì†Œë“œ ê¸¸ì´ ë¶„í¬
    axes[1, 0].hist(episode_lengths, bins=20, alpha=0.7)
    axes[1, 0].set_title('ì—í”¼ì†Œë“œ ê¸¸ì´ ë¶„í¬')
    axes[1, 0].set_xlabel('ê¸¸ì´')
    axes[1, 0].set_ylabel('ì—í”¼ì†Œë“œ ìˆ˜')
    
    # ì•¡ì…˜ í¬ê¸° ë¶„í¬
    action_magnitudes = np.linalg.norm(all_actions[:, :2], axis=1)  # linear_x, linear_yë§Œ
    axes[1, 1].hist(action_magnitudes, bins=50, alpha=0.7)
    axes[1, 1].set_title('ì´ë™ í¬ê¸° ë¶„í¬')
    axes[1, 1].set_xlabel('í¬ê¸°')
    axes[1, 1].set_ylabel('ë¹ˆë„')
    
    # ì‹œê°„ì— ë”°ë¥¸ ì•¡ì…˜ ë³€í™” (ìƒ˜í”Œ)
    sample_episode = all_actions[:episode_lengths[0]]
    axes[1, 2].plot(sample_episode[:, 0], label='linear_x', alpha=0.7)
    axes[1, 2].plot(sample_episode[:, 1], label='linear_y', alpha=0.7)
    axes[1, 2].plot(sample_episode[:, 2], label='angular_z', alpha=0.7)
    axes[1, 2].set_title('ìƒ˜í”Œ ì—í”¼ì†Œë“œ ì•¡ì…˜ ë³€í™”')
    axes[1, 2].set_xlabel('ì‹œê°„')
    axes[1, 2].set_ylabel('ì•¡ì…˜ ê°’')
    axes[1, 2].legend()
    
    plt.tight_layout()
    plt.savefig('dataset_analysis.png', dpi=300, bbox_inches='tight')
    print("   ğŸ“Š ì‹œê°í™” ì €ì¥ë¨: dataset_analysis.png")
    
    # 7. ì¦ê°• ì „ëµ ì œì•ˆ
    print("\nğŸ’¡ ë§ì¶¤í˜• ì¦ê°• ì „ëµ ì œì•ˆ...")
    
    augmentation_strategy = {
        'task_type': 'mobile_navigation',
        'action_characteristics': {
            'z_axis_zero': z_all_zero,
            'x_dominant': x_dominant,
            'stationary_ratio': stationary_ratio,
            'avg_episode_length': np.mean(episode_lengths)
        },
        'recommended_augmentations': []
    }
    
    # Zì¶•ì´ ëª¨ë‘ 0ì´ë©´ 2D ì´ë™ì— ì§‘ì¤‘
    if z_all_zero:
        augmentation_strategy['recommended_augmentations'].append({
            'type': 'horizontal_flip',
            'reason': 'Zì¶•ì´ 0ì´ë¯€ë¡œ ì¢Œìš° ëŒ€ì¹­ì´ ë¬¼ë¦¬ì ìœ¼ë¡œ íƒ€ë‹¹',
            'probability': 0.5
        })
    
    # ì •ì§€ ìƒíƒœê°€ ë§ìœ¼ë©´ ì •ì§€-ì´ë™ ì „í™˜ ì¦ê°•
    if stationary_ratio > 0.3:
        augmentation_strategy['recommended_augmentations'].append({
            'type': 'start_stop_patterns',
            'reason': 'ì •ì§€ ìƒíƒœê°€ ë§ìœ¼ë¯€ë¡œ ì‹œì‘-ì •ì§€ íŒ¨í„´ ì¦ê°•',
            'probability': 0.3
        })
    
    # ì—í”¼ì†Œë“œ ê¸¸ì´ê°€ ë‹¤ì–‘í•˜ë©´ ê¸¸ì´ ì¡°ì •
    if np.std(episode_lengths) > np.mean(episode_lengths) * 0.5:
        augmentation_strategy['recommended_augmentations'].append({
            'type': 'temporal_scaling',
            'reason': 'ì—í”¼ì†Œë“œ ê¸¸ì´ê°€ ë‹¤ì–‘í•˜ë¯€ë¡œ ì‹œê°„ì  ìŠ¤ì¼€ì¼ë§',
            'probability': 0.4
        })
    
    # ê¸°ë³¸ ì¦ê°•ë“¤
    augmentation_strategy['recommended_augmentations'].extend([
        {
            'type': 'action_noise',
            'reason': 'ì„¼ì„œ ë…¸ì´ì¦ˆ ì‹œë®¬ë ˆì´ì…˜',
            'std': 0.005,
            'probability': 1.0
        },
        {
            'type': 'brightness_variation',
            'reason': 'ì¡°ëª… ì¡°ê±´ ë³€í™”',
            'range': [0.8, 1.2],
            'probability': 0.3
        },
        {
            'type': 'temporal_jitter',
            'reason': 'ì‹œê°„ì  ë³€ë™ì„± ì¦ê°€',
            'max_shift': 2,
            'probability': 0.2
        }
    ])
    
    # ê²°ê³¼ ì €ì¥
    analysis_results = {
        'dataset_info': {
            'total_episodes': len(dataset),
            'total_frames': len(all_actions),
            'avg_episode_length': np.mean(episode_lengths),
            'episode_length_std': np.std(episode_lengths)
        },
        'action_statistics': {
            'linear_x': {
                'mean': float(np.mean(all_actions[:, 0])),
                'std': float(np.std(all_actions[:, 0])),
                'min': float(np.min(all_actions[:, 0])),
                'max': float(np.max(all_actions[:, 0])),
                'zero_ratio': float((all_actions[:, 0] == 0).sum() / len(all_actions))
            },
            'linear_y': {
                'mean': float(np.mean(all_actions[:, 1])),
                'std': float(np.std(all_actions[:, 1])),
                'min': float(np.min(all_actions[:, 1])),
                'max': float(np.max(all_actions[:, 1])),
                'zero_ratio': float((all_actions[:, 1] == 0).sum() / len(all_actions))
            },
            'angular_z': {
                'mean': float(np.mean(all_actions[:, 2])),
                'std': float(np.std(all_actions[:, 2])),
                'min': float(np.min(all_actions[:, 2])),
                'max': float(np.max(all_actions[:, 2])),
                'zero_ratio': float((all_actions[:, 2] == 0).sum() / len(all_actions))
            }
        },
        'task_characteristics': {
            'z_axis_zero': bool(z_all_zero),
            'x_dominant_movement': bool(x_dominant),
            'stationary_ratio': float(stationary_ratio),
            'direction_changes': {k: int(v) for k, v in direction_changes.items()}
        },
        'augmentation_strategy': augmentation_strategy
    }
    
    with open('dataset_analysis_results.json', 'w') as f:
        json.dump(analysis_results, f, indent=2)
    
    print("   ğŸ’¾ ë¶„ì„ ê²°ê³¼ ì €ì¥ë¨: dataset_analysis_results.json")
    
    return analysis_results

if __name__ == "__main__":
    results = analyze_dataset()
    print("\nâœ… ë°ì´í„°ì…‹ ë¶„ì„ ì™„ë£Œ!")
