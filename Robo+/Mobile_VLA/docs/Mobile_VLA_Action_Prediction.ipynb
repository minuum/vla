{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 0: 🎯 Mobile VLA + Kosmos 2B 액션 예측 시스템\n",
        "\n",
        "## 🔍 **핵심 개선사항**\n",
        "| 이전 (이벤트 분류) | 현재 (액션 예측) |\n",
        "|------------------|------------------|\n",
        "| 🔴 이벤트 99.9% → 너무 단순 | ✅ 이미지→액션 매핑 학습 |\n",
        "| 🔴 Frame-by-frame | ✅ Window/Chunk 방식 |\n",
        "| 🔴 Classification 위주 | ✅ Regression 위주 |\n",
        "| 🔴 단순 PIL 변환 | ✅ RoboVLMs 스타일 처리 |\n",
        "\n",
        "## 📊 **Window & Chunk 메커니즘**\n",
        "- **Window Size**: 16 프레임 (과거 컨텍스트)\n",
        "- **Chunk Size**: 2 프레임 (미래 예측)\n",
        "- **Total Sequence**: 18 프레임 (16+2)\n",
        "- **예측 목표**: 현재 이미지로 다음 2 프레임 액션 예측\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📁 작업 디렉토리: /home/billy/25-1kp/vla/Robo+/Mobile_VLA\n",
            "📊 실제 데이터 디렉토리: /home/billy/25-1kp/vla/ROS_action/mobile_vla_dataset\n",
            "🤖 RoboVLMs 디렉토리: /home/billy/25-1kp/vla/RoboVLMs\n",
            "✅ 데이터 디렉토리 확인됨: 72개 H5 파일 발견\n",
            "🖥️ 사용 디바이스: cuda\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: 🔧 환경 설정 및 라이브러리 임포트\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from transformers import AutoProcessor\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 프로젝트 루트 디렉토리 설정\n",
        "ROOT_DIR = Path(\"/home/billy/25-1kp/vla/Robo+/Mobile_VLA\")\n",
        "DATA_DIR = Path(\"/home/billy/25-1kp/vla/ROS_action/mobile_vla_dataset\")  # 실제 데이터셋 경로\n",
        "ROBOVLMS_DIR = Path(\"/home/billy/25-1kp/vla/RoboVLMs\")\n",
        "\n",
        "# 패키지 경로 추가\n",
        "sys.path.append(str(ROOT_DIR))\n",
        "sys.path.append(str(ROBOVLMS_DIR))\n",
        "\n",
        "print(f\"📁 작업 디렉토리: {ROOT_DIR}\")\n",
        "print(f\"📊 실제 데이터 디렉토리: {DATA_DIR}\")\n",
        "print(f\"🤖 RoboVLMs 디렉토리: {ROBOVLMS_DIR}\")\n",
        "\n",
        "# 데이터 디렉토리 존재 확인\n",
        "if DATA_DIR.exists():\n",
        "    h5_files = list(DATA_DIR.glob(\"*.h5\"))\n",
        "    print(f\"✅ 데이터 디렉토리 확인됨: {len(h5_files)}개 H5 파일 발견\")\n",
        "else:\n",
        "    print(f\"❌ 데이터 디렉토리를 찾을 수 없습니다: {DATA_DIR}\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"🖥️ 사용 디바이스: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 모든 모듈 로드 완료!\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: 📦 핵심 모듈 로드 (Window/Chunk 처리 포함)\n",
        "\n",
        "def load_class_from_file(class_name, file_path, target_class):\n",
        "    \"\"\"파일에서 클래스를 동적으로 로드\"\"\"\n",
        "    import importlib.util\n",
        "    spec = importlib.util.spec_from_file_location(class_name, file_path)\n",
        "    module = importlib.util.module_from_spec(spec)\n",
        "    spec.loader.exec_module(module)\n",
        "    return getattr(module, target_class)\n",
        "\n",
        "# 업데이트된 모듈들 로드\n",
        "WindowChunkAdapter = load_class_from_file(\n",
        "    'window_chunk_adapter', \n",
        "    str(ROOT_DIR / 'data' / 'window_chunk_adapter.py'), \n",
        "    'WindowChunkAdapter'\n",
        ")\n",
        "\n",
        "ActionPredictionTrainer = load_class_from_file(\n",
        "    'action_trainer', \n",
        "    str(ROOT_DIR / 'training' / 'action_trainer.py'), \n",
        "    'ActionPredictionTrainer'\n",
        ")\n",
        "\n",
        "# Kosmos 프로세서 초기화\n",
        "kosmos_processor = AutoProcessor.from_pretrained(\"microsoft/kosmos-2-patch14-224\")\n",
        "print(\"✅ 모든 모듈 로드 완료!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔄 업데이트된 모듈 다시 로드 중...\n",
            "📊 데이터셋 초기화 중...\n",
            "\n",
            "📊 액션 예측 데이터셋 정보:\n",
            "   총 샘플: 72개\n",
            "   Window Size: 16 프레임\n",
            "   Chunk Size: 2 프레임\n",
            "   Total Sequence: 18 프레임\n",
            "   배치 크기: 4\n",
            "   총 배치 수: 18\n",
            "\n",
            "🎯 시나리오별 분포:\n",
            "   2box_left_vertical: 10개\n",
            "   2box_right_horizontal: 6개\n",
            "   1box_left_vertical: 10개\n",
            "   1box_right_horizontal: 10개\n",
            "   2box_right_vertical: 10개\n",
            "   1box_left_horizontal: 10개\n",
            "   1box_right_vertical: 10개\n",
            "   2box_left_horizontal: 6개\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: 🗂️ Window/Chunk 데이터셋 초기화 (업데이트된 시나리오 매핑)\n",
        "\n",
        "# 먼저 업데이트된 WindowChunkAdapter 다시 로드\n",
        "print(\"🔄 업데이트된 모듈 다시 로드 중...\")\n",
        "import importlib\n",
        "import sys\n",
        "\n",
        "# 모듈 다시 로드\n",
        "if 'window_chunk_adapter' in sys.modules:\n",
        "    importlib.reload(sys.modules['window_chunk_adapter'])\n",
        "\n",
        "WindowChunkAdapter = load_class_from_file(\n",
        "    'window_chunk_adapter', \n",
        "    str(ROOT_DIR / 'data' / 'window_chunk_adapter.py'), \n",
        "    'WindowChunkAdapter'\n",
        ")\n",
        "\n",
        "# 액션 예측 중심 데이터셋 초기화\n",
        "print(\"📊 데이터셋 초기화 중...\")\n",
        "dataset = WindowChunkAdapter(\n",
        "    data_dir=str(DATA_DIR),\n",
        "    window_size=16,  # 과거 컨텍스트\n",
        "    chunk_size=2,    # 미래 예측\n",
        "    image_processor=kosmos_processor.image_processor,\n",
        "    normalize_actions=True\n",
        ")\n",
        "\n",
        "print(f\"\\n📊 액션 예측 데이터셋 정보:\")\n",
        "print(f\"   총 샘플: {len(dataset)}개\")\n",
        "print(f\"   Window Size: {dataset.window_size} 프레임\")\n",
        "print(f\"   Chunk Size: {dataset.chunk_size} 프레임\")\n",
        "print(f\"   Total Sequence: {dataset.window_size + dataset.chunk_size} 프레임\")\n",
        "\n",
        "if len(dataset) > 0:\n",
        "    # 데이터 로더 설정\n",
        "    dataloader = DataLoader(\n",
        "        dataset, \n",
        "        batch_size=4, \n",
        "        shuffle=True, \n",
        "        num_workers=2\n",
        "    )\n",
        "    \n",
        "    print(f\"   배치 크기: {dataloader.batch_size}\")\n",
        "    print(f\"   총 배치 수: {len(dataloader)}\")\n",
        "    \n",
        "    # 시나리오 분포 확인\n",
        "    scenarios = [dataset.samples[i]['scenario'] for i in range(len(dataset))]\n",
        "    from collections import Counter\n",
        "    scenario_counts = Counter(scenarios)\n",
        "    \n",
        "    print(f\"\\n🎯 시나리오별 분포:\")\n",
        "    for scenario, count in scenario_counts.items():\n",
        "        print(f\"   {scenario}: {count}개\")\n",
        "        \n",
        "else:\n",
        "    print(\"❌ 유효한 데이터가 없습니다. 시나리오 매핑을 확인해주세요.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 샘플 배치 데이터 구조:\n",
            "==================================================\n",
            "📊 pixel_values: torch.Size([4, 16, 3, 224, 224]) (torch.float32)\n",
            "📊 target_actions: torch.Size([4, 2, 3]) (torch.float32)\n",
            "📊 context_actions: torch.Size([4, 16, 3]) (torch.float32)\n",
            "📝 task_description: <class 'list'> - 4\n",
            "📝 scenario: <class 'list'> - 4\n",
            "📝 episode_id: <class 'list'> - 4\n",
            "\n",
            "🎯 액션 예측 타겟:\n",
            "   입력 이미지: torch.Size([4, 16, 3, 224, 224]) (Window)\n",
            "   예측 액션: torch.Size([4, 2, 3]) (Chunk)\n",
            "   액션 범위: [-1.000, 1.000]\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: 🔍 샘플 데이터 구조 분석\n",
        "\n",
        "# 첫 번째 배치로 데이터 구조 확인\n",
        "sample_batch = next(iter(dataloader))\n",
        "\n",
        "print(\"🔍 샘플 배치 데이터 구조:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for key, value in sample_batch.items():\n",
        "    if isinstance(value, torch.Tensor):\n",
        "        print(f\"📊 {key}: {value.shape} ({value.dtype})\")\n",
        "    else:\n",
        "        print(f\"📝 {key}: {type(value)} - {len(value) if hasattr(value, '__len__') else 'scalar'}\")\n",
        "\n",
        "print(\"\\n🎯 액션 예측 타겟:\")\n",
        "print(f\"   입력 이미지: {sample_batch['pixel_values'].shape} (Window)\")\n",
        "print(f\"   예측 액션: {sample_batch['target_actions'].shape} (Chunk)\")\n",
        "print(f\"   액션 범위: [{sample_batch['target_actions'].min().item():.3f}, {sample_batch['target_actions'].max().item():.3f}]\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🤖 액션 예측 모델 구성:\n",
            "========================================\n",
            "📝 VLM 백본: Kosmos 2B\n",
            "🎯 액션 차원: 3D (Mobile Navigation)\n",
            "🪟 Window Size: 16\n",
            "🧩 Chunk Size: 2\n",
            "📈 Learning Rate: 0.0001\n",
            "💾 모델 파라미터: 1,669,340,422\n",
            "✅ 액션 예측 시스템 초기화 완료!\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: 🤖 액션 예측 트레이너 초기화\n",
        "\n",
        "# 액션 예측 트레이너 초기화\n",
        "trainer = ActionPredictionTrainer(\n",
        "    model_name=\"microsoft/kosmos-2-patch14-224\",\n",
        "    action_dim=3,  # [linear_x, linear_y, angular_z]\n",
        "    window_size=16,\n",
        "    chunk_size=2,\n",
        "    learning_rate=1e-4,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "print(\"🤖 액션 예측 모델 구성:\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"📝 VLM 백본: Kosmos 2B\")\n",
        "print(f\"🎯 액션 차원: 3D (Mobile Navigation)\")\n",
        "print(f\"🪟 Window Size: {trainer.window_size}\")\n",
        "print(f\"🧩 Chunk Size: {trainer.chunk_size}\")\n",
        "print(f\"📈 Learning Rate: {trainer.learning_rate}\")\n",
        "print(f\"💾 모델 파라미터: {sum(p.numel() for p in trainer.model.parameters() if p.requires_grad):,}\")\n",
        "\n",
        "print(\"✅ 액션 예측 시스템 초기화 완료!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚡ 액션 예측 학습 준비 완료!\n"
          ]
        }
      ],
      "source": [
        "# Cell 6: 🚀 액션 예측 학습 루프\n",
        "\n",
        "def train_action_prediction(\n",
        "    trainer, \n",
        "    dataloader, \n",
        "    num_epochs=10,\n",
        "    save_interval=5,\n",
        "    log_interval=10\n",
        "):\n",
        "    \"\"\"액션 예측 중심 학습 함수\"\"\"\n",
        "    \n",
        "    # 손실 추적기\n",
        "    class ActionLossTracker:\n",
        "        def __init__(self):\n",
        "            self.losses = {\n",
        "                'steps': [],\n",
        "                'action_loss': [],\n",
        "                'total_loss': [],\n",
        "                'lr': [],\n",
        "                'mae_linear_x': [],\n",
        "                'mae_linear_y': [], \n",
        "                'mae_angular_z': [],\n",
        "                'mae_avg': [],\n",
        "                'scenarios': []\n",
        "            }\n",
        "        \n",
        "        def update(self, step, loss_dict, scenario=None):\n",
        "            self.losses['steps'].append(step)\n",
        "            for key in ['action_loss', 'total_loss', 'lr', 'mae_linear_x', 'mae_linear_y', 'mae_angular_z', 'mae_avg']:\n",
        "                if key in loss_dict:\n",
        "                    self.losses[key].append(loss_dict[key])\n",
        "                else:\n",
        "                    self.losses[key].append(0.0)\n",
        "            self.losses['scenarios'].append(scenario or 'unknown')\n",
        "    \n",
        "    loss_tracker = ActionLossTracker()\n",
        "    best_loss = float('inf')\n",
        "    global_step = 0\n",
        "    \n",
        "    print(\"🚀 액션 예측 학습 시작!\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_losses = []\n",
        "        \n",
        "        # 에포크 진행 바\n",
        "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        \n",
        "        for batch_idx, batch in enumerate(pbar):\n",
        "            try:\n",
        "                # 학습 스텝\n",
        "                loss_dict = trainer.train_step(batch)\n",
        "                epoch_losses.append(loss_dict['total_loss'])\n",
        "                global_step += 1\n",
        "                \n",
        "                # 손실 추적\n",
        "                scenario = batch.get('scenario', ['unknown'])[0] if 'scenario' in batch else 'unknown'\n",
        "                loss_tracker.update(global_step, loss_dict, scenario)\n",
        "                \n",
        "                # 로그 출력\n",
        "                if global_step % log_interval == 0:\n",
        "                    pbar.set_postfix({\n",
        "                        'Loss': f\"{loss_dict['total_loss']:.4f}\",\n",
        "                        'MAE_x': f\"{loss_dict.get('mae_linear_x', 0):.4f}\",\n",
        "                        'MAE_y': f\"{loss_dict.get('mae_linear_y', 0):.4f}\",\n",
        "                        'MAE_z': f\"{loss_dict.get('mae_angular_z', 0):.4f}\",\n",
        "                        'LR': f\"{loss_dict['lr']:.2e}\"\n",
        "                    })\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"\\n❌ 학습 스텝 실패 (Step {global_step}): {e}\")\n",
        "                continue\n",
        "        \n",
        "        # 에포크 요약\n",
        "        avg_loss = np.mean(epoch_losses) if epoch_losses else float('inf')\n",
        "        print(f\"\\n📊 Epoch {epoch+1} 완료:\")\n",
        "        print(f\"   평균 손실: {avg_loss:.4f}\")\n",
        "        print(f\"   처리된 배치: {len(epoch_losses)}/{len(dataloader)}\")\n",
        "        \n",
        "        # 체크포인트 저장\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            save_path = ROOT_DIR / f\"checkpoints/action_prediction_best.pth\"\n",
        "            save_path.parent.mkdir(exist_ok=True)\n",
        "            trainer.save_checkpoint(str(save_path), epoch, best_loss)\n",
        "            print(f\"   ✅ 최고 모델 저장: {save_path}\")\n",
        "        \n",
        "        if (epoch + 1) % save_interval == 0:\n",
        "            save_path = ROOT_DIR / f\"checkpoints/action_prediction_epoch_{epoch+1}.pth\"\n",
        "            save_path.parent.mkdir(exist_ok=True)\n",
        "            trainer.save_checkpoint(str(save_path), epoch, best_loss)\n",
        "            print(f\"   💾 체크포인트 저장: {save_path}\")\n",
        "    \n",
        "    print(\"\\n🎉 학습 완료!\")\n",
        "    print(f\"최종 최고 손실: {best_loss:.4f}\")\n",
        "    \n",
        "    return loss_tracker\n",
        "\n",
        "print(\"⚡ 액션 예측 학습 준비 완료!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Cell 7: 🎯 학습 실행\n",
        "\n",
        "# print(\"⚡ 액션 예측 학습을 시작합니다...\")\n",
        "# final_loss_tracker = train_action_prediction(\n",
        "#     trainer=trainer,\n",
        "#     dataloader=dataloader, \n",
        "#     num_epochs=15,\n",
        "#     save_interval=5,\n",
        "#     log_interval=5\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 8: 📊 액션 예측 평가 및 분석\n",
        "\n",
        "def evaluate_action_prediction(trainer, dataloader, num_samples=20):\n",
        "    \"\"\"액션 예측 성능 평가\"\"\"\n",
        "    \n",
        "    print(\"🔍 액션 예측 성능 평가 시작...\")\n",
        "    \n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "    all_scenarios = []\n",
        "    \n",
        "    trainer.model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(tqdm(dataloader, desc=\"평가 중\")):\n",
        "            if i >= num_samples:\n",
        "                break\n",
        "            \n",
        "            try:\n",
        "                # 평가 스텝\n",
        "                results = trainer.evaluate_step(batch)\n",
        "                \n",
        "                # 결과 수집\n",
        "                pred_actions = results['predictions']['predicted_actions']  # [B, T, chunk_size, action_dim]\n",
        "                target_actions = results['targets']['target_actions']  # [B, chunk_size, action_dim]\n",
        "                scenarios = results['scenarios']\n",
        "                \n",
        "                # Batch dimension으로 펼치기\n",
        "                for b in range(pred_actions.shape[0]):\n",
        "                    # 마지막 시간 스텝의 예측만 사용 (가장 관련성 높음)\n",
        "                    pred = pred_actions[b, -1, :, :].cpu()  # [chunk_size, action_dim]\n",
        "                    target = target_actions[b, :, :].cpu()  # [chunk_size, action_dim]\n",
        "                    \n",
        "                    all_predictions.append(pred)\n",
        "                    all_targets.append(target)\n",
        "                    all_scenarios.append(scenarios[b] if b < len(scenarios) else 'unknown')\n",
        "                    \n",
        "            except Exception as e:\n",
        "                print(f\"평가 중 오류: {e}\")\n",
        "                continue\n",
        "    \n",
        "    if not all_predictions:\n",
        "        print(\"❌ 평가할 데이터가 없습니다.\")\n",
        "        return None\n",
        "    \n",
        "    # 텐서로 변환\n",
        "    all_predictions = torch.stack(all_predictions)  # [N, chunk_size, action_dim]\n",
        "    all_targets = torch.stack(all_targets)  # [N, chunk_size, action_dim]\n",
        "    \n",
        "    print(f\"\\n📊 평가 완료: {len(all_predictions)}개 샘플\")\n",
        "    print(f\"예측 shape: {all_predictions.shape}\")\n",
        "    print(f\"타겟 shape: {all_targets.shape}\")\n",
        "    \n",
        "    # 성능 메트릭 계산\n",
        "    metrics = {}\n",
        "    \n",
        "    # 전체 MAE\n",
        "    mae_total = torch.abs(all_predictions - all_targets).mean()\n",
        "    metrics['mae_total'] = mae_total.item()\n",
        "    \n",
        "    # 차원별 MAE\n",
        "    mae_per_dim = torch.abs(all_predictions - all_targets).mean(dim=(0, 1))  # [action_dim]\n",
        "    dim_names = ['linear_x', 'linear_y', 'angular_z']\n",
        "    for i, name in enumerate(dim_names):\n",
        "        metrics[f'mae_{name}'] = mae_per_dim[i].item()\n",
        "    \n",
        "    # MSE\n",
        "    mse_total = ((all_predictions - all_targets) ** 2).mean()\n",
        "    metrics['mse_total'] = mse_total.item()\n",
        "    \n",
        "    # RMSE\n",
        "    metrics['rmse_total'] = torch.sqrt(mse_total).item()\n",
        "    \n",
        "    # R² Score (per dimension)\n",
        "    for i, name in enumerate(dim_names):\n",
        "        pred_dim = all_predictions[:, :, i].flatten()\n",
        "        target_dim = all_targets[:, :, i].flatten()\n",
        "        \n",
        "        ss_res = ((target_dim - pred_dim) ** 2).sum()\n",
        "        ss_tot = ((target_dim - target_dim.mean()) ** 2).sum()\n",
        "        r2 = 1 - (ss_res / ss_tot)\n",
        "        metrics[f'r2_{name}'] = r2.item()\n",
        "    \n",
        "    # 시나리오별 성능\n",
        "    scenario_metrics = {}\n",
        "    unique_scenarios = list(set(all_scenarios))\n",
        "    \n",
        "    for scenario in unique_scenarios:\n",
        "        scenario_mask = [i for i, s in enumerate(all_scenarios) if s == scenario]\n",
        "        if len(scenario_mask) > 0:\n",
        "            scenario_preds = all_predictions[scenario_mask]\n",
        "            scenario_targets = all_targets[scenario_mask]\n",
        "            scenario_mae = torch.abs(scenario_preds - scenario_targets).mean()\n",
        "            scenario_metrics[scenario] = scenario_mae.item()\n",
        "    \n",
        "    return {\n",
        "        'predictions': all_predictions,\n",
        "        'targets': all_targets,\n",
        "        'scenarios': all_scenarios,\n",
        "        'metrics': metrics,\n",
        "        'scenario_metrics': scenario_metrics\n",
        "    }\n",
        "\n",
        "# 평가 실행\n",
        "if 'final_loss_tracker' in locals():\n",
        "    print(\"🔍 학습된 모델 평가 시작...\")\n",
        "    eval_results = evaluate_action_prediction(trainer, dataloader, num_samples=30)\n",
        "    \n",
        "    if eval_results:\n",
        "        print(\"\\n📈 액션 예측 성능 결과:\")\n",
        "        print(\"=\" * 50)\n",
        "        for key, value in eval_results['metrics'].items():\n",
        "            print(f\"  {key}: {value:.4f}\")\n",
        "        \n",
        "        print(\"\\n🎯 시나리오별 MAE:\")\n",
        "        for scenario, mae in eval_results['scenario_metrics'].items():\n",
        "            print(f\"  {scenario}: {mae:.4f}\")\n",
        "else:\n",
        "    print(\"⚠️ 먼저 학습을 완료해주세요 (Cell 7 실행)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 9: 📈 결과 시각화 및 분석\n",
        "\n",
        "def plot_action_prediction_results(loss_tracker, eval_results=None):\n",
        "    \"\"\"액션 예측 결과 시각화\"\"\"\n",
        "    \n",
        "    if not hasattr(loss_tracker, 'losses') or not loss_tracker.losses['steps']:\n",
        "        print(\"❌ 시각화할 학습 데이터가 없습니다.\")\n",
        "        return\n",
        "    \n",
        "    # 플롯 설정\n",
        "    plt.style.use('default')\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "    fig.suptitle('🚀 Mobile VLA 액션 예측 학습 결과', fontsize=16, fontweight='bold')\n",
        "    \n",
        "    # 1. 총 손실 곡선\n",
        "    axes[0, 0].plot(loss_tracker.losses['steps'], loss_tracker.losses['total_loss'], 'b-', linewidth=2)\n",
        "    axes[0, 0].set_title('📊 Total Loss', fontweight='bold')\n",
        "    axes[0, 0].set_xlabel('Steps')\n",
        "    axes[0, 0].set_ylabel('Loss')\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 2. 차원별 MAE\n",
        "    if 'mae_linear_x' in loss_tracker.losses:\n",
        "        axes[0, 1].plot(loss_tracker.losses['steps'], loss_tracker.losses['mae_linear_x'], 'r-', label='linear_x', linewidth=2)\n",
        "        axes[0, 1].plot(loss_tracker.losses['steps'], loss_tracker.losses['mae_linear_y'], 'g-', label='linear_y', linewidth=2)\n",
        "        axes[0, 1].plot(loss_tracker.losses['steps'], loss_tracker.losses['mae_angular_z'], 'b-', label='angular_z', linewidth=2)\n",
        "        axes[0, 1].set_title('🎯 MAE per Dimension', fontweight='bold')\n",
        "        axes[0, 1].set_xlabel('Steps')\n",
        "        axes[0, 1].set_ylabel('MAE')\n",
        "        axes[0, 1].legend()\n",
        "        axes[0, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 3. 학습률\n",
        "    axes[0, 2].plot(loss_tracker.losses['steps'], loss_tracker.losses['lr'], 'purple', linewidth=2)\n",
        "    axes[0, 2].set_title('📈 Learning Rate', fontweight='bold')\n",
        "    axes[0, 2].set_xlabel('Steps')\n",
        "    axes[0, 2].set_ylabel('LR')\n",
        "    axes[0, 2].set_yscale('log')\n",
        "    axes[0, 2].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 4. 평가 결과 (있는 경우)\n",
        "    if eval_results and 'metrics' in eval_results:\n",
        "        metrics = eval_results['metrics']\n",
        "        \n",
        "        # MAE 비교\n",
        "        mae_names = ['mae_linear_x', 'mae_linear_y', 'mae_angular_z']\n",
        "        mae_values = [metrics.get(name, 0) for name in mae_names]\n",
        "        mae_labels = ['Linear X', 'Linear Y', 'Angular Z']\n",
        "        \n",
        "        bars = axes[1, 0].bar(mae_labels, mae_values, color=['red', 'green', 'blue'], alpha=0.7)\n",
        "        axes[1, 0].set_title('🎯 Final MAE by Dimension', fontweight='bold')\n",
        "        axes[1, 0].set_ylabel('MAE')\n",
        "        axes[1, 0].grid(True, alpha=0.3)\n",
        "        \n",
        "        # 막대 위에 값 표시\n",
        "        for bar, value in zip(bars, mae_values):\n",
        "            axes[1, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,\n",
        "                           f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
        "        \n",
        "        # R² Score\n",
        "        r2_names = ['r2_linear_x', 'r2_linear_y', 'r2_angular_z']\n",
        "        r2_values = [metrics.get(name, 0) for name in r2_names]\n",
        "        \n",
        "        bars_r2 = axes[1, 1].bar(mae_labels, r2_values, color=['red', 'green', 'blue'], alpha=0.7)\n",
        "        axes[1, 1].set_title('📊 R² Score by Dimension', fontweight='bold')\n",
        "        axes[1, 1].set_ylabel('R² Score')\n",
        "        axes[1, 1].set_ylim(0, 1)\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "        \n",
        "        # R² 값 표시\n",
        "        for bar, value in zip(bars_r2, r2_values):\n",
        "            axes[1, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                           f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
        "        \n",
        "        # 시나리오별 성능\n",
        "        if 'scenario_metrics' in eval_results:\n",
        "            scenario_data = eval_results['scenario_metrics']\n",
        "            scenarios = list(scenario_data.keys())\n",
        "            scenario_maes = list(scenario_data.values())\n",
        "            \n",
        "            bars_scenario = axes[1, 2].bar(range(len(scenarios)), scenario_maes, \n",
        "                                         color='orange', alpha=0.7)\n",
        "            axes[1, 2].set_title('🎮 Performance by Scenario', fontweight='bold')\n",
        "            axes[1, 2].set_xlabel('Scenario')\n",
        "            axes[1, 2].set_ylabel('MAE')\n",
        "            axes[1, 2].set_xticks(range(len(scenarios)))\n",
        "            axes[1, 2].set_xticklabels([s.replace('_', '\\n') for s in scenarios], \n",
        "                                      rotation=45, ha='right', fontsize=8)\n",
        "            axes[1, 2].grid(True, alpha=0.3)\n",
        "    else:\n",
        "        # 평가 결과가 없으면 빈 플롯\n",
        "        for i in range(3):\n",
        "            axes[1, i].text(0.5, 0.5, '평가 결과가 없습니다\\n(Cell 8 실행 필요)', \n",
        "                           ha='center', va='center', transform=axes[1, i].transAxes,\n",
        "                           fontsize=12, style='italic')\n",
        "            axes[1, i].set_xticks([])\n",
        "            axes[1, i].set_yticks([])\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # 텍스트 요약\n",
        "    print(\"\\n📋 학습 요약:\")\n",
        "    print(\"=\" * 50)\n",
        "    if loss_tracker.losses['total_loss']:\n",
        "        print(f\"🔹 최종 손실: {loss_tracker.losses['total_loss'][-1]:.4f}\")\n",
        "        print(f\"🔹 최저 손실: {min(loss_tracker.losses['total_loss']):.4f}\")\n",
        "        print(f\"🔹 총 스텝: {len(loss_tracker.losses['steps'])}\")\n",
        "    \n",
        "    if eval_results and 'metrics' in eval_results:\n",
        "        print(f\"🔹 평가 MAE: {eval_results['metrics']['mae_total']:.4f}\")\n",
        "        print(f\"🔹 평가 RMSE: {eval_results['metrics']['rmse_total']:.4f}\")\n",
        "\n",
        "# 시각화 실행\n",
        "if 'final_loss_tracker' in locals():\n",
        "    plot_action_prediction_results(\n",
        "        final_loss_tracker, \n",
        "        eval_results if 'eval_results' in locals() else None\n",
        "    )\n",
        "else:\n",
        "    print(\"⚠️ 먼저 학습을 완료해주세요 (Cell 7 실행)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ 먼저 학습을 완료해주세요 (Cell 7 실행)\n"
          ]
        }
      ],
      "source": [
        "# Cell 10: 💾 결과 저장 및 리포트 생성\n",
        "\n",
        "def save_action_prediction_results(loss_tracker, eval_results, save_dir=None):\n",
        "    \"\"\"액션 예측 결과를 마크다운과 JSON으로 저장\"\"\"\n",
        "    \n",
        "    if save_dir is None:\n",
        "        save_dir = ROOT_DIR / \"action_prediction_results\"\n",
        "    else:\n",
        "        save_dir = Path(save_dir)\n",
        "    \n",
        "    save_dir.mkdir(exist_ok=True)\n",
        "    \n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    \n",
        "    # 마크다운 리포트 생성\n",
        "    md_content = f\"\"\"# 🚀 Mobile VLA 액션 예측 학습 리포트\n",
        "\n",
        "**생성일시**: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
        "**시스템**: 액션 예측 중심 Mobile VLA + Kosmos 2B\n",
        "\n",
        "## 📊 **핵심 개선사항**\n",
        "\n",
        "| 항목 | 이전 (이벤트 분류) | 현재 (액션 예측) | 개선 효과 |\n",
        "|------|------------------|------------------|-----------|\n",
        "| **학습 목표** | 🔴 이벤트 99.9% (너무 단순) | ✅ 이미지→액션 매핑 | 진짜 VLA 학습 |\n",
        "| **메커니즘** | 🔴 Frame-by-frame | ✅ Window/Chunk | RoboVLMs 스타일 |\n",
        "| **손실 함수** | 🔴 CrossEntropy + MSE | ✅ Huber Loss | 회귀 중심 |\n",
        "| **메트릭** | 🔴 Accuracy, F1-Score | ✅ MAE, R², RMSE | 연속 액션 평가 |\n",
        "\n",
        "## 🎯 **학습 설정**\n",
        "\n",
        "- **Window Size**: 16 프레임 (과거 컨텍스트)\n",
        "- **Chunk Size**: 2 프레임 (미래 예측)\n",
        "- **액션 차원**: 3D [linear_x, linear_y, angular_z]\n",
        "- **모델**: Kosmos 2B + ActionPredictionHead\n",
        "- **손실**: Huber Loss (outlier robust)\n",
        "\n",
        "## 📈 **학습 결과**\n",
        "\"\"\"\n",
        "    \n",
        "    if hasattr(loss_tracker, 'losses') and loss_tracker.losses['steps']:\n",
        "        final_loss = loss_tracker.losses['total_loss'][-1]\n",
        "        min_loss = min(loss_tracker.losses['total_loss'])\n",
        "        total_steps = len(loss_tracker.losses['steps'])\n",
        "        \n",
        "        md_content += f\"\"\"\n",
        "### 🏋️ **학습 성능**\n",
        "\n",
        "- **최종 손실**: {final_loss:.4f}\n",
        "- **최저 손실**: {min_loss:.4f}  \n",
        "- **총 학습 스텝**: {total_steps:,}\n",
        "- **수렴성**: {'✅ 안정적' if final_loss < min_loss * 1.1 else '⚠️ 추가 학습 필요'}\n",
        "\"\"\"\n",
        "    \n",
        "    if eval_results and 'metrics' in eval_results:\n",
        "        metrics = eval_results['metrics']\n",
        "        md_content += f\"\"\"\n",
        "### 🎯 **평가 성능**\n",
        "\n",
        "#### 전체 메트릭\n",
        "- **Total MAE**: {metrics['mae_total']:.4f}\n",
        "- **Total MSE**: {metrics['mse_total']:.4f}\n",
        "- **Total RMSE**: {metrics['rmse_total']:.4f}\n",
        "\n",
        "#### 차원별 성능\n",
        "| 액션 차원 | MAE | R² Score | 해석 |\n",
        "|----------|-----|----------|------|\n",
        "| **Linear X** | {metrics.get('mae_linear_x', 0):.4f} | {metrics.get('r2_linear_x', 0):.3f} | {'✅ 우수' if metrics.get('mae_linear_x', 1) < 0.1 else '⚠️ 개선 필요'} |\n",
        "| **Linear Y** | {metrics.get('mae_linear_y', 0):.4f} | {metrics.get('r2_linear_y', 0):.3f} | {'✅ 우수' if metrics.get('mae_linear_y', 1) < 0.1 else '⚠️ 개선 필요'} |\n",
        "| **Angular Z** | {metrics.get('mae_angular_z', 0):.4f} | {metrics.get('r2_angular_z', 0):.3f} | {'✅ 우수' if metrics.get('mae_angular_z', 1) < 0.1 else '⚠️ 개선 필요'} |\n",
        "\"\"\"\n",
        "        \n",
        "        if 'scenario_metrics' in eval_results:\n",
        "            md_content += \"\"\"\n",
        "#### 시나리오별 성능\n",
        "| 시나리오 | MAE | 상대 성능 |\n",
        "|----------|-----|-----------|\n",
        "\"\"\"\n",
        "            scenario_data = eval_results['scenario_metrics']\n",
        "            avg_mae = metrics['mae_total']\n",
        "            for scenario, mae in scenario_data.items():\n",
        "                relative_perf = \"✅ 우수\" if mae < avg_mae else \"⚠️ 평균 이하\"\n",
        "                md_content += f\"| {scenario} | {mae:.4f} | {relative_perf} |\\n\"\n",
        "    \n",
        "    md_content += f\"\"\"\n",
        "## 🔄 **이전 vs 현재 비교**\n",
        "\n",
        "### 학습 패러다임 변화\n",
        "1. **분류 → 회귀**: 이벤트 분류에서 액션 예측으로 전환\n",
        "2. **단순 → 복잡**: 99.9% 정확도에서 진짜 어려운 문제로\n",
        "3. **프레임 → 시퀀스**: Window/Chunk 메커니즘으로 시간적 관계 학습\n",
        "4. **수동 → 자동**: 수동 특징에서 end-to-end 학습으로\n",
        "\n",
        "### 기대 효과\n",
        "- **실제 로봇 적용**: 이미지 보고 실시간 액션 생성 가능\n",
        "- **일반화 성능**: 다양한 장애물 패턴에서 robust한 네비게이션\n",
        "- **확장성**: 다른 모바일 로봇 태스크로 쉽게 확장 가능\n",
        "\n",
        "## 🚀 **다음 단계**\n",
        "\n",
        "1. **실시간 테스트**: 실제 로봇에서 inference 성능 검증\n",
        "2. **데이터 증강**: 더 다양한 시나리오와 환경 조건 추가\n",
        "3. **모델 최적화**: TensorRT, ONNX 등으로 추론 속도 개선\n",
        "4. **멀티태스크**: 컵 추적 외 다른 네비게이션 태스크 추가\n",
        "\n",
        "---\n",
        "**생성 시스템**: Mobile VLA + Kosmos 2B Action Prediction\n",
        "**보고서 버전**: v2.0 (액션 예측 중심)\n",
        "\"\"\"\n",
        "    \n",
        "    # 마크다운 파일 저장\n",
        "    md_path = save_dir / f\"Action_Prediction_Report_{timestamp}.md\"\n",
        "    with open(md_path, 'w', encoding='utf-8') as f:\n",
        "        f.write(md_content)\n",
        "    \n",
        "    # JSON 데이터 저장\n",
        "    json_data = {\n",
        "        'timestamp': timestamp,\n",
        "        'system_info': {\n",
        "            'model': 'Kosmos 2B + ActionPredictionHead',\n",
        "            'window_size': 16,\n",
        "            'chunk_size': 2,\n",
        "            'action_dim': 3,\n",
        "            'loss_function': 'Huber Loss'\n",
        "        },\n",
        "        'training_results': {},\n",
        "        'evaluation_results': {}\n",
        "    }\n",
        "    \n",
        "    # 학습 결과 추가\n",
        "    if hasattr(loss_tracker, 'losses'):\n",
        "        json_data['training_results'] = {\n",
        "            'final_loss': loss_tracker.losses['total_loss'][-1] if loss_tracker.losses['total_loss'] else None,\n",
        "            'min_loss': min(loss_tracker.losses['total_loss']) if loss_tracker.losses['total_loss'] else None,\n",
        "            'total_steps': len(loss_tracker.losses['steps']),\n",
        "            'loss_history': loss_tracker.losses['total_loss'][-100:],  # 마지막 100개만 저장\n",
        "            'mae_history': {\n",
        "                'linear_x': loss_tracker.losses['mae_linear_x'][-100:] if 'mae_linear_x' in loss_tracker.losses else [],\n",
        "                'linear_y': loss_tracker.losses['mae_linear_y'][-100:] if 'mae_linear_y' in loss_tracker.losses else [],\n",
        "                'angular_z': loss_tracker.losses['mae_angular_z'][-100:] if 'mae_angular_z' in loss_tracker.losses else []\n",
        "            }\n",
        "        }\n",
        "    \n",
        "    # 평가 결과 추가\n",
        "    if eval_results:\n",
        "        json_data['evaluation_results'] = {\n",
        "            'metrics': eval_results.get('metrics', {}),\n",
        "            'scenario_metrics': eval_results.get('scenario_metrics', {}),\n",
        "            'num_samples': len(eval_results.get('predictions', []))\n",
        "        }\n",
        "    \n",
        "    # JSON 파일 저장\n",
        "    json_path = save_dir / f\"Action_Prediction_Data_{timestamp}.json\"\n",
        "    with open(json_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(json_data, f, indent=2, ensure_ascii=False)\n",
        "    \n",
        "    print(f\"✅ 결과 저장 완료:\")\n",
        "    print(f\"   📄 마크다운: {md_path}\")\n",
        "    print(f\"   📊 JSON: {json_path}\")\n",
        "    \n",
        "    return md_path, json_path\n",
        "\n",
        "# 결과 저장 실행\n",
        "if 'final_loss_tracker' in locals():\n",
        "    print(\"💾 액션 예측 결과를 저장합니다...\")\n",
        "    md_path, json_path = save_action_prediction_results(\n",
        "        final_loss_tracker,\n",
        "        eval_results if 'eval_results' in locals() else None\n",
        "    )\n",
        "    print(\"🎉 모든 결과가 성공적으로 저장되었습니다!\")\n",
        "else:\n",
        "    print(\"⚠️ 먼저 학습을 완료해주세요 (Cell 7 실행)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 11: 🧪 빠른 테스트 및 문제 해결\n",
        "\n",
        "# 데이터셋이 제대로 로드되었는지 확인\n",
        "if 'dataset' in locals() and len(dataset) > 0:\n",
        "    print(\"✅ 데이터셋 로드 성공!\")\n",
        "    \n",
        "    # 첫 번째 샘플 테스트\n",
        "    try:\n",
        "        sample = dataset[0]\n",
        "        print(f\"\\n📊 첫 번째 샘플 확인:\")\n",
        "        for key, value in sample.items():\n",
        "            if isinstance(value, torch.Tensor):\n",
        "                print(f\"   {key}: {value.shape} ({value.dtype})\")\n",
        "            else:\n",
        "                print(f\"   {key}: {type(value)}\")\n",
        "        \n",
        "        print(f\"\\n🎯 태스크: {sample['task_description']}\")\n",
        "        print(f\"🎮 시나리오: {sample['scenario']}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"❌ 샘플 로드 오류: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "elif 'dataset' in locals() and len(dataset) == 0:\n",
        "    print(\"⚠️ 데이터셋이 비어있습니다.\")\n",
        "    print(\"\\n🔍 문제 해결 방법:\")\n",
        "    print(\"1. 파일 경로 확인: /home/billy/25-1kp/vla/ROS_action/mobile_vla_dataset/\")\n",
        "    print(\"2. HDF5 파일 존재 확인\")\n",
        "    print(\"3. 시나리오 매핑 로직 확인\")\n",
        "    \n",
        "    # 데이터 디렉토리 내용 확인\n",
        "    print(f\"\\n📁 데이터 디렉토리 내용:\")\n",
        "    h5_files = list(DATA_DIR.glob(\"*.h5\"))\n",
        "    print(f\"   총 HDF5 파일: {len(h5_files)}개\")\n",
        "    \n",
        "    if h5_files:\n",
        "        print(f\"   예시 파일: {h5_files[0].name}\")\n",
        "        \n",
        "        # 시나리오 추출 테스트\n",
        "        test_filename = h5_files[0].name\n",
        "        print(f\"\\n🧪 시나리오 추출 테스트: {test_filename}\")\n",
        "        \n",
        "        # 수동으로 시나리오 추출 로직 테스트\n",
        "        filename_lower = test_filename.lower()\n",
        "        print(f\"   소문자 변환: {filename_lower}\")\n",
        "        \n",
        "        if \"1box\" in filename_lower and \"vert\" in filename_lower and \"left\" in filename_lower:\n",
        "            result = \"1box_left_vertical\"\n",
        "        elif \"1box\" in filename_lower and \"hori\" in filename_lower and \"left\" in filename_lower:\n",
        "            result = \"1box_left_horizontal\"\n",
        "        else:\n",
        "            result = \"unknown\"\n",
        "        \n",
        "        print(f\"   추출된 시나리오: {result}\")\n",
        "\n",
        "else:\n",
        "    print(\"❌ 데이터셋이 정의되지 않았습니다. Cell 3을 먼저 실행해주세요.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🧹 GPU 메모리 정리 중...\n",
            "   할당된 메모리: 6.24 GB\n",
            "   캐시된 메모리: 6.53 GB\n",
            "\n",
            "⚙️ 메모리 효율적인 설정으로 재초기화...\n",
            "   배치 크기: 1 (메모리 절약)\n",
            "   총 배치 수: 72\n",
            "🧹 GPU 메모리 정리 중...\n",
            "   할당된 메모리: 0.01 GB\n",
            "   캐시된 메모리: 0.03 GB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   윈도우 크기: 8 (메모리 절약)\n",
            "   청크 크기: 2\n",
            "🧹 GPU 메모리 정리 중...\n",
            "   할당된 메모리: 6.24 GB\n",
            "   캐시된 메모리: 6.26 GB\n"
          ]
        }
      ],
      "source": [
        "# Cell 12: 🧹 메모리 최적화 및 정리\n",
        "\n",
        "import gc\n",
        "import torch\n",
        "\n",
        "def clear_gpu_memory():\n",
        "    \"\"\"GPU 메모리 정리\"\"\"\n",
        "    print(\"🧹 GPU 메모리 정리 중...\")\n",
        "    \n",
        "    # 캐시 정리\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()\n",
        "    \n",
        "    # 가비지 컬렉션\n",
        "    gc.collect()\n",
        "    \n",
        "    # 메모리 사용량 출력\n",
        "    if torch.cuda.is_available():\n",
        "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
        "        cached = torch.cuda.memory_reserved() / 1024**3\n",
        "        print(f\"   할당된 메모리: {allocated:.2f} GB\")\n",
        "        print(f\"   캐시된 메모리: {cached:.2f} GB\")\n",
        "\n",
        "# 메모리 정리 실행\n",
        "clear_gpu_memory()\n",
        "\n",
        "# 메모리 효율적인 설정으로 데이터셋 및 트레이너 재초기화\n",
        "print(\"\\n⚙️ 메모리 효율적인 설정으로 재초기화...\")\n",
        "\n",
        "# 1. 배치 크기 줄이기\n",
        "if 'dataloader' in locals():\n",
        "    del dataloader\n",
        "\n",
        "# 더 작은 배치 크기로 데이터로더 재생성\n",
        "dataloader = DataLoader(\n",
        "    dataset, \n",
        "    batch_size=1,  # 4 -> 1로 줄임\n",
        "    shuffle=True, \n",
        "    num_workers=0  # 메모리 절약을 위해 0으로 설정\n",
        ")\n",
        "\n",
        "print(f\"   배치 크기: {dataloader.batch_size} (메모리 절약)\")\n",
        "print(f\"   총 배치 수: {len(dataloader)}\")\n",
        "\n",
        "# 2. 트레이너 재초기화 (더 작은 윈도우 사이즈)\n",
        "if 'trainer' in locals():\n",
        "    del trainer\n",
        "\n",
        "clear_gpu_memory()\n",
        "\n",
        "# 메모리 효율적인 트레이너\n",
        "memory_efficient_trainer = ActionPredictionTrainer(\n",
        "    model_name=\"microsoft/kosmos-2-patch14-224\",\n",
        "    action_dim=3,\n",
        "    window_size=8,   # 16 -> 8로 줄임\n",
        "    chunk_size=2,\n",
        "    learning_rate=1e-4,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "print(f\"   윈도우 크기: {memory_efficient_trainer.window_size} (메모리 절약)\")\n",
        "print(f\"   청크 크기: {memory_efficient_trainer.chunk_size}\")\n",
        "\n",
        "# 메모리 사용량 재확인\n",
        "clear_gpu_memory()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔧 메모리 효율적인 데이터셋 재생성 중...\n",
            "🧹 GPU 메모리 정리 중...\n",
            "   할당된 메모리: 6.24 GB\n",
            "   캐시된 메모리: 6.26 GB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "유효한 샘플이 없습니다. 필터링 조건을 확인해주세요.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📊 메모리 효율적인 데이터셋 정보:\n",
            "   총 샘플: 0개\n",
            "   Window Size: 8 프레임\n",
            "   Chunk Size: 2 프레임\n",
            "   Total Sequence: 10 프레임\n",
            "❌ 데이터셋이 비어있습니다.\n"
          ]
        }
      ],
      "source": [
        "# Cell 13: 🔧 메모리 효율적인 데이터셋 재생성\n",
        "\n",
        "# 윈도우 크기에 맞춰 데이터셋 재생성\n",
        "print(\"🔧 메모리 효율적인 데이터셋 재생성 중...\")\n",
        "\n",
        "# 기존 데이터셋 정리\n",
        "if 'dataset' in locals():\n",
        "    del dataset\n",
        "\n",
        "clear_gpu_memory()\n",
        "\n",
        "# 메모리 효율적인 데이터셋 (윈도우 8 + 청크 2 = 10프레임)\n",
        "memory_efficient_dataset = WindowChunkAdapter(\n",
        "    data_dir=str(DATA_DIR),\n",
        "    window_size=8,   # 16 -> 8로 줄임\n",
        "    chunk_size=2,\n",
        "    image_processor=kosmos_processor.image_processor,\n",
        "    normalize_actions=True\n",
        ")\n",
        "\n",
        "print(f\"\\n📊 메모리 효율적인 데이터셋 정보:\")\n",
        "print(f\"   총 샘플: {len(memory_efficient_dataset)}개\")\n",
        "print(f\"   Window Size: {memory_efficient_dataset.window_size} 프레임\")\n",
        "print(f\"   Chunk Size: {memory_efficient_dataset.chunk_size} 프레임\")\n",
        "print(f\"   Total Sequence: {memory_efficient_dataset.window_size + memory_efficient_dataset.chunk_size} 프레임\")\n",
        "\n",
        "if len(memory_efficient_dataset) > 0:\n",
        "    # 메모리 효율적인 데이터로더\n",
        "    memory_efficient_dataloader = DataLoader(\n",
        "        memory_efficient_dataset, \n",
        "        batch_size=1,  # 최소 배치 크기\n",
        "        shuffle=True, \n",
        "        num_workers=0\n",
        "    )\n",
        "    \n",
        "    print(f\"   배치 크기: {memory_efficient_dataloader.batch_size}\")\n",
        "    print(f\"   총 배치 수: {len(memory_efficient_dataloader)}\")\n",
        "    \n",
        "    # 시나리오 분포 확인\n",
        "    scenarios = [memory_efficient_dataset.samples[i]['scenario'] for i in range(len(memory_efficient_dataset))]\n",
        "    from collections import Counter\n",
        "    scenario_counts = Counter(scenarios)\n",
        "    \n",
        "    print(f\"\\n🎯 시나리오별 분포:\")\n",
        "    for scenario, count in scenario_counts.items():\n",
        "        print(f\"   {scenario}: {count}개\")\n",
        "    \n",
        "    # 샘플 테스트\n",
        "    print(f\"\\n🧪 샘플 데이터 테스트:\")\n",
        "    sample = memory_efficient_dataset[0]\n",
        "    for key, value in sample.items():\n",
        "        if isinstance(value, torch.Tensor):\n",
        "            print(f\"   {key}: {value.shape} ({value.dtype})\")\n",
        "        else:\n",
        "            print(f\"   {key}: {type(value)}\")\n",
        "    \n",
        "    clear_gpu_memory()\n",
        "    print(\"\\n✅ 메모리 효율적인 설정 완료!\")\n",
        "    \n",
        "else:\n",
        "    print(\"❌ 데이터셋이 비어있습니다.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❌ 먼저 Cell 12-13을 실행해주세요.\n"
          ]
        }
      ],
      "source": [
        "# Cell 14: 🚀 메모리 효율적인 학습 실행\n",
        "\n",
        "def train_memory_efficient(\n",
        "    trainer, \n",
        "    dataloader, \n",
        "    num_epochs=5,  # 에포크 수 줄임\n",
        "    save_interval=2,\n",
        "    log_interval=10,\n",
        "    memory_cleanup_interval=5  # 5 배치마다 메모리 정리\n",
        "):\n",
        "    \"\"\"메모리 효율적인 학습 함수\"\"\"\n",
        "    \n",
        "    # 손실 추적기\n",
        "    class ActionLossTracker:\n",
        "        def __init__(self):\n",
        "            self.losses = {\n",
        "                'steps': [],\n",
        "                'action_loss': [],\n",
        "                'total_loss': [],\n",
        "                'lr': [],\n",
        "                'mae_linear_x': [],\n",
        "                'mae_linear_y': [], \n",
        "                'mae_angular_z': [],\n",
        "                'mae_avg': [],\n",
        "                'scenarios': []\n",
        "            }\n",
        "        \n",
        "        def update(self, step, loss_dict, scenario=None):\n",
        "            self.losses['steps'].append(step)\n",
        "            for key in ['action_loss', 'total_loss', 'lr', 'mae_linear_x', 'mae_linear_y', 'mae_angular_z', 'mae_avg']:\n",
        "                if key in loss_dict:\n",
        "                    self.losses[key].append(loss_dict[key])\n",
        "                else:\n",
        "                    self.losses[key].append(0.0)\n",
        "            self.losses['scenarios'].append(scenario or 'unknown')\n",
        "    \n",
        "    loss_tracker = ActionLossTracker()\n",
        "    best_loss = float('inf')\n",
        "    global_step = 0\n",
        "    \n",
        "    print(\"🚀 메모리 효율적인 액션 예측 학습 시작!\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"📊 설정: 배치크기={dataloader.batch_size}, 윈도우={trainer.window_size}, 에포크={num_epochs}\")\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_losses = []\n",
        "        successful_batches = 0\n",
        "        \n",
        "        # 에포크 진행 바\n",
        "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        \n",
        "        for batch_idx, batch in enumerate(pbar):\n",
        "            try:\n",
        "                # 학습 스텝\n",
        "                loss_dict = trainer.train_step(batch)\n",
        "                epoch_losses.append(loss_dict['total_loss'])\n",
        "                global_step += 1\n",
        "                successful_batches += 1\n",
        "                \n",
        "                # 손실 추적\n",
        "                scenario = batch.get('scenario', ['unknown'])[0] if 'scenario' in batch else 'unknown'\n",
        "                loss_tracker.update(global_step, loss_dict, scenario)\n",
        "                \n",
        "                # 로그 출력\n",
        "                if global_step % log_interval == 0:\n",
        "                    pbar.set_postfix({\n",
        "                        'Loss': f\"{loss_dict['total_loss']:.4f}\",\n",
        "                        'MAE_x': f\"{loss_dict.get('mae_linear_x', 0):.4f}\",\n",
        "                        'MAE_y': f\"{loss_dict.get('mae_linear_y', 0):.4f}\",\n",
        "                        'MAE_z': f\"{loss_dict.get('mae_angular_z', 0):.4f}\",\n",
        "                        'LR': f\"{loss_dict['lr']:.2e}\",\n",
        "                        'Success': f\"{successful_batches}/{batch_idx+1}\"\n",
        "                    })\n",
        "                \n",
        "                # 메모리 정리\n",
        "                if batch_idx % memory_cleanup_interval == 0:\n",
        "                    clear_gpu_memory()\n",
        "                \n",
        "            except RuntimeError as e:\n",
        "                if \"out of memory\" in str(e):\n",
        "                    print(f\"\\\\n⚠️ OOM 에러 (Step {global_step}), 메모리 정리 후 계속...\")\n",
        "                    clear_gpu_memory()\n",
        "                    continue\n",
        "                else:\n",
        "                    print(f\"\\\\n❌ 학습 스텝 실패 (Step {global_step}): {e}\")\n",
        "                    continue\n",
        "            except Exception as e:\n",
        "                print(f\"\\\\n❌ 예상치 못한 오류 (Step {global_step}): {e}\")\n",
        "                continue\n",
        "        \n",
        "        # 에포크 요약\n",
        "        avg_loss = np.mean(epoch_losses) if epoch_losses else float('inf')\n",
        "        success_rate = successful_batches / len(dataloader) * 100\n",
        "        \n",
        "        print(f\"\\\\n📊 Epoch {epoch+1} 완료:\")\n",
        "        print(f\"   평균 손실: {avg_loss:.4f}\")\n",
        "        print(f\"   성공률: {success_rate:.1f}% ({successful_batches}/{len(dataloader)})\")\n",
        "        \n",
        "        # 체크포인트 저장\n",
        "        if avg_loss < best_loss and epoch_losses:\n",
        "            best_loss = avg_loss\n",
        "            save_path = ROOT_DIR / f\"checkpoints/memory_efficient_best.pth\"\n",
        "            save_path.parent.mkdir(exist_ok=True)\n",
        "            trainer.save_checkpoint(str(save_path), epoch, best_loss)\n",
        "            print(f\"   ✅ 최고 모델 저장: {save_path}\")\n",
        "        \n",
        "        if (epoch + 1) % save_interval == 0:\n",
        "            save_path = ROOT_DIR / f\"checkpoints/memory_efficient_epoch_{epoch+1}.pth\"\n",
        "            save_path.parent.mkdir(exist_ok=True)\n",
        "            trainer.save_checkpoint(str(save_path), epoch, best_loss)\n",
        "            print(f\"   💾 체크포인트 저장: {save_path}\")\n",
        "        \n",
        "        # 에포크 끝에 메모리 정리\n",
        "        clear_gpu_memory()\n",
        "    \n",
        "    print(\"\\\\n🎉 메모리 효율적인 학습 완료!\")\n",
        "    print(f\"최종 최고 손실: {best_loss:.4f}\")\n",
        "    \n",
        "    return loss_tracker\n",
        "\n",
        "# 메모리 효율적인 학습 실행\n",
        "if 'memory_efficient_trainer' in locals() and 'memory_efficient_dataloader' in locals():\n",
        "    print(\"⚡ 메모리 효율적인 액션 예측 학습을 시작합니다...\")\n",
        "    print(f\"🔧 메모리 설정: Window={memory_efficient_trainer.window_size}, Batch={memory_efficient_dataloader.batch_size}\")\n",
        "    \n",
        "    memory_efficient_loss_tracker = train_memory_efficient(\n",
        "        trainer=memory_efficient_trainer,\n",
        "        dataloader=memory_efficient_dataloader, \n",
        "        num_epochs=5,  # 적은 에포크로 테스트\n",
        "        save_interval=2,\n",
        "        log_interval=5,\n",
        "        memory_cleanup_interval=3\n",
        "    )\n",
        "else:\n",
        "    print(\"❌ 먼저 Cell 12-13을 실행해주세요.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 15: 🛠️ 테스트용 더미 데이터 생성\n",
        "\n",
        "import h5py\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def create_dummy_mobile_vla_data(data_dir, num_episodes=10):\n",
        "    \"\"\"테스트용 더미 Mobile VLA 데이터 생성\"\"\"\n",
        "    \n",
        "    data_dir = Path(data_dir)\n",
        "    data_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    scenarios = [\n",
        "        \"1box_left_vertical\", \"1box_left_horizontal\", \n",
        "        \"1box_right_vertical\", \"1box_right_horizontal\",\n",
        "        \"2box_left_vertical\", \"2box_left_horizontal\",\n",
        "        \"2box_right_vertical\", \"2box_right_horizontal\"\n",
        "    ]\n",
        "    \n",
        "    print(f\"🛠️ {data_dir}에 더미 데이터 생성 중...\")\n",
        "    \n",
        "    for i in range(num_episodes):\n",
        "        # 시나리오 선택\n",
        "        scenario = scenarios[i % len(scenarios)]\n",
        "        \n",
        "        # 파일명 생성 (실제 패턴과 유사하게)\n",
        "        filename = f\"episode_20250820_{i:06d}_{scenario}_core_medium.h5\"\n",
        "        filepath = data_dir / filename\n",
        "        \n",
        "        # 더미 데이터 생성\n",
        "        sequence_length = np.random.randint(50, 150)  # 50-150 프레임\n",
        "        \n",
        "        # 더미 이미지 (720x1280x3 -> Mobile VLA 원본 해상도)\n",
        "        dummy_images = np.random.randint(0, 255, (sequence_length, 720, 1280, 3), dtype=np.uint8)\n",
        "        \n",
        "        # 더미 액션 ([linear_x, linear_y, angular_z])\n",
        "        dummy_actions = np.random.randn(sequence_length, 3).astype(np.float32)\n",
        "        dummy_actions[:, 0] = np.clip(dummy_actions[:, 0], -1.0, 1.0)  # linear_x\n",
        "        dummy_actions[:, 1] = np.clip(dummy_actions[:, 1], -1.0, 1.0)  # linear_y  \n",
        "        dummy_actions[:, 2] = np.clip(dummy_actions[:, 2], -2.0, 2.0)  # angular_z\n",
        "        \n",
        "        # 더미 이벤트 (0: episode_start, 1: start_action)\n",
        "        dummy_events = np.ones(sequence_length, dtype=np.int32)\n",
        "        dummy_events[0] = 0  # 첫 프레임은 episode_start\n",
        "        \n",
        "        # H5 파일로 저장\n",
        "        with h5py.File(filepath, 'w') as f:\n",
        "            f.create_dataset('images', data=dummy_images, compression='lzf')\n",
        "            f.create_dataset('actions', data=dummy_actions)\n",
        "            f.create_dataset('events', data=dummy_events)\n",
        "            \n",
        "            # 메타데이터\n",
        "            f.attrs['scenario'] = scenario\n",
        "            f.attrs['sequence_length'] = sequence_length\n",
        "            f.attrs['created_by'] = 'mobile_vla_data_collector.py'\n",
        "    \n",
        "    print(f\"✅ {num_episodes}개의 더미 에피소드 생성 완료!\")\n",
        "    print(f\"   시나리오: {scenarios}\")\n",
        "    \n",
        "    # 생성된 파일 확인\n",
        "    created_files = list(data_dir.glob(\"*.h5\"))\n",
        "    print(f\"   생성된 파일: {len(created_files)}개\")\n",
        "    for f in created_files[:3]:\n",
        "        print(f\"   - {f.name}\")\n",
        "    if len(created_files) > 3:\n",
        "        print(f\"   - ... (총 {len(created_files)}개)\")\n",
        "\n",
        "# 더미 데이터 생성\n",
        "dummy_data_dir = ROOT_DIR / \"dummy_data\"\n",
        "create_dummy_mobile_vla_data(dummy_data_dir, num_episodes=16)\n",
        "\n",
        "# 데이터 디렉터리 업데이트\n",
        "DATA_DIR = dummy_data_dir\n",
        "print(f\"\\\\n📊 데이터 디렉터리 업데이트: {DATA_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 16: 🔄 더미 데이터로 메모리 효율적인 데이터셋 재생성\n",
        "\n",
        "# WindowChunkAdapter 모듈 리로드\n",
        "import importlib\n",
        "import sys\n",
        "if 'window_chunk_adapter' in sys.modules:\n",
        "    importlib.reload(sys.modules['window_chunk_adapter'])\n",
        "\n",
        "# WindowChunkAdapter 다시 로드\n",
        "WindowChunkAdapter = load_class_from_file(\n",
        "    'window_chunk_adapter',\n",
        "    str(ROOT_DIR / 'data' / 'window_chunk_adapter.py'),\n",
        "    'WindowChunkAdapter'\n",
        ")\n",
        "\n",
        "print(\"🔄 더미 데이터로 메모리 효율적인 데이터셋 재생성 중...\")\n",
        "\n",
        "# 기존 데이터셋 정리\n",
        "if 'memory_efficient_dataset' in locals():\n",
        "    del memory_efficient_dataset\n",
        "\n",
        "clear_gpu_memory()\n",
        "\n",
        "# 더미 데이터로 메모리 효율적인 데이터셋 생성\n",
        "memory_efficient_dataset = WindowChunkAdapter(\n",
        "    data_dir=str(DATA_DIR),\n",
        "    window_size=8,   # 16 -> 8로 줄임\n",
        "    chunk_size=2,\n",
        "    image_processor=kosmos_processor.image_processor,\n",
        "    normalize_actions=True\n",
        ")\n",
        "\n",
        "print(f\"\\\\n📊 더미 데이터 기반 메모리 효율적인 데이터셋 정보:\")\n",
        "print(f\"   총 샘플: {len(memory_efficient_dataset)}개\")\n",
        "print(f\"   Window Size: {memory_efficient_dataset.window_size} 프레임\")\n",
        "print(f\"   Chunk Size: {memory_efficient_dataset.chunk_size} 프레임\")\n",
        "print(f\"   Total Sequence: {memory_efficient_dataset.window_size + memory_efficient_dataset.chunk_size} 프레임\")\n",
        "\n",
        "if len(memory_efficient_dataset) > 0:\n",
        "    # 메모리 효율적인 데이터로더\n",
        "    memory_efficient_dataloader = DataLoader(\n",
        "        memory_efficient_dataset, \n",
        "        batch_size=1,  # 최소 배치 크기\n",
        "        shuffle=True, \n",
        "        num_workers=0\n",
        "    )\n",
        "    \n",
        "    print(f\"   배치 크기: {memory_efficient_dataloader.batch_size}\")\n",
        "    print(f\"   총 배치 수: {len(memory_efficient_dataloader)}\")\n",
        "    \n",
        "    # 시나리오 분포 확인\n",
        "    scenarios = [memory_efficient_dataset.samples[i]['scenario'] for i in range(len(memory_efficient_dataset))]\n",
        "    from collections import Counter\n",
        "    scenario_counts = Counter(scenarios)\n",
        "    \n",
        "    print(f\"\\\\n🎯 시나리오별 분포:\")\n",
        "    for scenario, count in scenario_counts.items():\n",
        "        print(f\"   {scenario}: {count}개\")\n",
        "    \n",
        "    # 샘플 테스트\n",
        "    print(f\"\\\\n🧪 샘플 데이터 테스트:\")\n",
        "    sample = memory_efficient_dataset[0]\n",
        "    for key, value in sample.items():\n",
        "        if isinstance(value, torch.Tensor):\n",
        "            print(f\"   {key}: {value.shape} ({value.dtype})\")\n",
        "        else:\n",
        "            print(f\"   {key}: {type(value)}\")\n",
        "    \n",
        "    clear_gpu_memory()\n",
        "    print(\"\\\\n✅ 더미 데이터 기반 메모리 효율적인 설정 완료!\")\n",
        "    \n",
        "else:\n",
        "    print(\"❌ 더미 데이터셋도 비어있습니다. WindowChunkAdapter 로직을 확인해야 합니다.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 17: 🔄 실제 데이터로 메모리 효율적인 데이터셋 재생성\n",
        "\n",
        "# WindowChunkAdapter 모듈 리로드\n",
        "import importlib\n",
        "import sys\n",
        "if 'window_chunk_adapter' in sys.modules:\n",
        "    importlib.reload(sys.modules['window_chunk_adapter'])\n",
        "\n",
        "# WindowChunkAdapter 다시 로드\n",
        "WindowChunkAdapter = load_class_from_file(\n",
        "    'window_chunk_adapter',\n",
        "    str(ROOT_DIR / 'data' / 'window_chunk_adapter.py'),\n",
        "    'WindowChunkAdapter'\n",
        ")\n",
        "\n",
        "print(\"🔄 실제 데이터로 메모리 효율적인 데이터셋 재생성 중...\")\n",
        "print(f\"📊 데이터 경로: {DATA_DIR}\")\n",
        "\n",
        "# 기존 데이터셋 정리\n",
        "for var_name in ['memory_efficient_dataset', 'dataset']:\n",
        "    if var_name in locals():\n",
        "        del locals()[var_name]\n",
        "\n",
        "clear_gpu_memory()\n",
        "\n",
        "# 실제 데이터로 메모리 효율적인 데이터셋 생성\n",
        "try:\n",
        "    memory_efficient_dataset = WindowChunkAdapter(\n",
        "        data_dir=str(DATA_DIR),\n",
        "        window_size=8,   # 16 -> 8로 줄임 (메모리 절약)\n",
        "        chunk_size=2,\n",
        "        image_processor=kosmos_processor.image_processor,\n",
        "        normalize_actions=True\n",
        "    )\n",
        "    \n",
        "    print(f\"\\\\n📊 실제 데이터 기반 메모리 효율적인 데이터셋 정보:\")\n",
        "    print(f\"   총 샘플: {len(memory_efficient_dataset)}개\")\n",
        "    print(f\"   Window Size: {memory_efficient_dataset.window_size} 프레임\")\n",
        "    print(f\"   Chunk Size: {memory_efficient_dataset.chunk_size} 프레임\")\n",
        "    print(f\"   Total Sequence: {memory_efficient_dataset.window_size + memory_efficient_dataset.chunk_size} 프레임\")\n",
        "    \n",
        "    if len(memory_efficient_dataset) > 0:\n",
        "        # 메모리 효율적인 데이터로더\n",
        "        memory_efficient_dataloader = DataLoader(\n",
        "            memory_efficient_dataset, \n",
        "            batch_size=1,  # 최소 배치 크기 (메모리 절약)\n",
        "            shuffle=True, \n",
        "            num_workers=0  # 메모리 절약\n",
        "        )\n",
        "        \n",
        "        print(f\"   배치 크기: {memory_efficient_dataloader.batch_size}\")\n",
        "        print(f\"   총 배치 수: {len(memory_efficient_dataloader)}\")\n",
        "        \n",
        "        # 시나리오 분포 확인\n",
        "        scenarios = [memory_efficient_dataset.samples[i]['scenario'] for i in range(min(len(memory_efficient_dataset), 100))]\n",
        "        from collections import Counter\n",
        "        scenario_counts = Counter(scenarios)\n",
        "        \n",
        "        print(f\"\\\\n🎯 시나리오별 분포 (처음 100개):\")\n",
        "        for scenario, count in scenario_counts.items():\n",
        "            print(f\"   {scenario}: {count}개\")\n",
        "        \n",
        "        # 샘플 테스트\n",
        "        print(f\"\\\\n🧪 샘플 데이터 테스트:\")\n",
        "        sample = memory_efficient_dataset[0]\n",
        "        for key, value in sample.items():\n",
        "            if isinstance(value, torch.Tensor):\n",
        "                print(f\"   {key}: {value.shape} ({value.dtype})\")\n",
        "            else:\n",
        "                print(f\"   {key}: {type(value)} = {value}\")\n",
        "        \n",
        "        clear_gpu_memory()\n",
        "        print(\"\\\\n✅ 실제 데이터 기반 메모리 효율적인 설정 완료!\")\n",
        "        \n",
        "    else:\n",
        "        print(\"❌ 실제 데이터셋에서 유효한 샘플을 찾을 수 없습니다.\")\n",
        "        print(\"   WindowChunkAdapter의 필터링 로직을 확인해야 합니다.\")\n",
        "        \n",
        "        # 디버깅: 원본 H5 파일 몇 개 확인\n",
        "        h5_files = list(DATA_DIR.glob(\"*.h5\"))[:5]\n",
        "        print(f\"\\\\n🔍 디버깅: H5 파일 샘플 확인 (처음 5개):\")\n",
        "        \n",
        "        import h5py\n",
        "        for h5_file in h5_files:\n",
        "            try:\n",
        "                with h5py.File(h5_file, 'r') as f:\n",
        "                    keys = list(f.keys())\n",
        "                    attrs = dict(f.attrs)\n",
        "                    print(f\"   {h5_file.name}:\")\n",
        "                    print(f\"     Keys: {keys}\")\n",
        "                    if 'images' in keys:\n",
        "                        print(f\"     Images: {f['images'].shape}\")\n",
        "                    if 'actions' in keys:\n",
        "                        print(f\"     Actions: {f['actions'].shape}\")\n",
        "                    print(f\"     Attrs: {attrs}\")\n",
        "            except Exception as e:\n",
        "                print(f\"   {h5_file.name}: 오류 - {e}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ 데이터셋 생성 실패: {e}\")\n",
        "    print(\"\\\\n🔍 에러 상세:\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 18: 🚀 RoboVLMs 스타일 Mobile VLA 트레이닝\n",
        "\n",
        "# RoboVLMs 스타일로 리팩토링된 모듈 임포트\n",
        "print(\"🔄 RoboVLMs 스타일 Mobile VLA 모듈 로딩 중...\")\n",
        "\n",
        "# 경로 추가\n",
        "import sys\n",
        "sys.path.append(str(ROOT_DIR))\n",
        "\n",
        "# 리팩토링된 모듈 임포트\n",
        "try:\n",
        "    from robovlms.data import MobileVLADataset\n",
        "    from robovlms.train import MobileVLATrainer, ActionLossTracker\n",
        "    print(\"✅ Mobile VLA 모듈 로딩 완료!\")\n",
        "except ImportError as e:\n",
        "    print(f\"❌ 모듈 임포트 실패: {e}\")\n",
        "    print(\"   기존 RoboVLMs 환경에서 실행하거나 경로를 확인해주세요.\")\n",
        "    raise\n",
        "\n",
        "# 기존 변수 정리\n",
        "clear_gpu_memory()\n",
        "\n",
        "# MobileVLADataset 초기화 (RoboVLMs 호환)\n",
        "print(\"\\\\n📊 RoboVLMs 스타일 MobileVLADataset 초기화 중...\")\n",
        "\n",
        "try:\n",
        "    # 토크나이저 설정 (RoboVLMs 방식)\n",
        "    tokenizer_config = {\n",
        "        \"tokenizer_type\": \"kosmos\",\n",
        "        \"max_text_len\": 512,\n",
        "        \"tokenizer_id\": \"microsoft/kosmos-2-patch14-224\"\n",
        "    }\n",
        "    \n",
        "    # 데이터셋 설정\n",
        "    dataset = MobileVLADataset(\n",
        "        data_dir=str(DATA_DIR),\n",
        "        model_name=\"kosmos\",\n",
        "        mode=\"train\",\n",
        "        organize_type=\"segment\",  # RoboVLMs 호환\n",
        "        window_size=8,  # 메모리 효율성\n",
        "        fwd_pred_next_n=2,\n",
        "        discrete=False,  # 연속 액션\n",
        "        norm_action=True,\n",
        "        image_history=True,\n",
        "        action_history=True,\n",
        "        tokenizer=tokenizer_config,\n",
        "        rgb_pad=-1,  # 데이터 증강 비활성화\n",
        "        gripper_pad=-1\n",
        "    )\n",
        "    \n",
        "    print(f\"✅ MobileVLADataset 초기화 완료!\")\n",
        "    print(f\"   총 에피소드: {len(dataset)}개\")\n",
        "    \n",
        "    if len(dataset) > 0:\n",
        "        # 데이터로더 생성 (메모리 효율성)\n",
        "        from torch.utils.data import DataLoader\n",
        "        \n",
        "        dataloader = DataLoader(\n",
        "            dataset,\n",
        "            batch_size=1,  # 메모리 절약\n",
        "            shuffle=True,\n",
        "            num_workers=0,  # 멀티프로세싱 비활성화 (안정성)\n",
        "            collate_fn=dataset.collater  # RoboVLMs collater 사용\n",
        "        )\n",
        "        \n",
        "        print(f\"   배치 수: {len(dataloader)}개\")\n",
        "        \n",
        "        # 샘플 데이터 확인\n",
        "        print(f\"\\\\n🧪 첫 번째 배치 데이터 구조 확인:\")\n",
        "        sample_batch = next(iter(dataloader))\n",
        "        for key, value in sample_batch.items():\n",
        "            if isinstance(value, torch.Tensor):\n",
        "                print(f\"   {key}: {value.shape} ({value.dtype})\")\n",
        "            elif isinstance(value, list):\n",
        "                print(f\"   {key}: list[{len(value)}] - {type(value[0]) if value else 'empty'}\")\n",
        "            else:\n",
        "                print(f\"   {key}: {type(value)}\")\n",
        "        \n",
        "        print(\"\\\\n✅ RoboVLMs 스타일 데이터 로딩 완료!\")\n",
        "        \n",
        "    else:\n",
        "        print(\"❌ 데이터셋이 비어있습니다. 데이터 경로와 형식을 확인해주세요.\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"❌ 데이터셋 초기화 실패: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 19: 🎯 RoboVLMs 스타일 Mobile VLA 트레이너 초기화 및 학습\n",
        "\n",
        "if 'dataset' in locals() and len(dataset) > 0:\n",
        "    print(\"🎯 MobileVLATrainer 초기화 중...\")\n",
        "    \n",
        "    # 트레이너 설정\n",
        "    trainer = MobileVLATrainer(\n",
        "        model_name=\"microsoft/kosmos-2-patch14-224\",\n",
        "        action_dim=3,  # Mobile VLA: [linear_x, linear_y, angular_z]\n",
        "        window_size=8,\n",
        "        chunk_size=2,\n",
        "        learning_rate=1e-4,\n",
        "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "        precision=\"fp16\"  # Mixed precision\n",
        "    )\n",
        "    \n",
        "    print(f\"✅ 트레이너 초기화 완료!\")\n",
        "    print(f\"   디바이스: {trainer.device}\")\n",
        "    print(f\"   모델 파라미터: {sum(p.numel() for p in trainer.model.parameters()):,}개\")\n",
        "    \n",
        "    # 손실 추적기\n",
        "    loss_tracker = ActionLossTracker()\n",
        "    \n",
        "    print(\"\\\\n🚀 RoboVLMs 스타일 학습 시작!\")\n",
        "    \n",
        "    def train_mobile_vla_robovlms_style(\n",
        "        trainer, \n",
        "        dataloader, \n",
        "        num_epochs=3, \n",
        "        log_interval=5,\n",
        "        save_interval=50,\n",
        "        checkpoint_dir=\"checkpoints\"\n",
        "    ):\n",
        "        \\\"\\\"\\\"RoboVLMs 스타일 학습 함수\\\"\\\"\\\"\n",
        "        \n",
        "        # 체크포인트 디렉토리 생성\n",
        "        checkpoint_path = ROOT_DIR / checkpoint_dir\n",
        "        checkpoint_path.mkdir(exist_ok=True)\n",
        "        \n",
        "        print(f\"🏃‍♂️ 학습 시작: {num_epochs} 에포크, {len(dataloader)} 배치\")\n",
        "        print(f\"📁 체크포인트 저장 경로: {checkpoint_path}\")\n",
        "        \n",
        "        all_losses = []\n",
        "        best_loss = float('inf')\n",
        "        \n",
        "        try:\n",
        "            for epoch in range(num_epochs):\n",
        "                print(f\"\\\\n📅 Epoch {epoch+1}/{num_epochs}\")\n",
        "                epoch_losses = []\n",
        "                \n",
        "                for step, batch in enumerate(dataloader):\n",
        "                    try:\n",
        "                        # 학습 스텝\n",
        "                        loss_dict = trainer.train_step(batch)\n",
        "                        loss_tracker.update(loss_dict)\n",
        "                        epoch_losses.append(loss_dict[\"total_loss\"])\n",
        "                        \n",
        "                        # 로깅\n",
        "                        if (step + 1) % log_interval == 0:\n",
        "                            avg_metrics = loss_tracker.get_averages(last_n=log_interval)\n",
        "                            print(f\"  Step {step+1:3d}: \"\n",
        "                                  f\"Loss={avg_metrics['avg_total_loss']:.4f}, \"\n",
        "                                  f\"MAE={avg_metrics['avg_mae']:.4f}, \"\n",
        "                                  f\"LR={avg_metrics['current_lr']:.2e}\")\n",
        "                        \n",
        "                        # 체크포인트 저장\n",
        "                        if (step + 1) % save_interval == 0:\n",
        "                            current_loss = loss_tracker.get_averages(last_n=10)['avg_total_loss']\n",
        "                            if current_loss < best_loss:\n",
        "                                best_loss = current_loss\n",
        "                                checkpoint_file = checkpoint_path / f\"mobile_vla_best_epoch{epoch+1}_step{step+1}.pt\"\n",
        "                                trainer.save_checkpoint(\n",
        "                                    str(checkpoint_file), \n",
        "                                    epoch=epoch+1,\n",
        "                                    metrics={\"best_loss\": best_loss, \"step\": step+1}\n",
        "                                )\n",
        "                                print(f\"💾 Best 모델 저장: {checkpoint_file.name} (Loss: {best_loss:.4f})\")\n",
        "                        \n",
        "                        all_losses.append(loss_dict)\n",
        "                        \n",
        "                    except Exception as e:\n",
        "                        print(f\"⚠️ Step {step+1} 실패: {e}\")\n",
        "                        clear_gpu_memory()  # OOM 복구 시도\n",
        "                        continue\n",
        "                \n",
        "                # 에포크 종료 요약\n",
        "                if epoch_losses:\n",
        "                    epoch_avg_loss = sum(epoch_losses) / len(epoch_losses)\n",
        "                    print(f\"📊 Epoch {epoch+1} 완료: 평균 Loss = {epoch_avg_loss:.4f}\")\n",
        "                    \n",
        "                    # 에포크별 체크포인트\n",
        "                    epoch_checkpoint = checkpoint_path / f\"mobile_vla_epoch{epoch+1}.pt\"\n",
        "                    trainer.save_checkpoint(\n",
        "                        str(epoch_checkpoint),\n",
        "                        epoch=epoch+1,\n",
        "                        metrics={\"epoch_avg_loss\": epoch_avg_loss}\n",
        "                    )\n",
        "                else:\n",
        "                    print(f\"⚠️ Epoch {epoch+1}: 유효한 배치가 없었습니다.\")\n",
        "                \n",
        "                clear_gpu_memory()\n",
        "        \n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\\\n⏹️ 학습이 사용자에 의해 중단되었습니다.\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\\\n❌ 학습 중 오류 발생: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "        \n",
        "        return all_losses, loss_tracker\n",
        "    \n",
        "    # 실제 학습 실행\n",
        "    print(\"\\\\n\" + \"=\"*50)\n",
        "    print(\"🎓 Mobile VLA RoboVLMs 스타일 학습 실행\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    losses, tracker = train_mobile_vla_robovlms_style(\n",
        "        trainer=trainer,\n",
        "        dataloader=dataloader,\n",
        "        num_epochs=2,  # 빠른 테스트\n",
        "        log_interval=3,\n",
        "        save_interval=20,\n",
        "        checkpoint_dir=\"mobile_vla_checkpoints\"\n",
        "    )\n",
        "    \n",
        "    print(\"\\\\n🎉 학습 완료!\")\n",
        "    \n",
        "    # 최종 통계\n",
        "    if tracker.losses:\n",
        "        final_metrics = tracker.get_averages()\n",
        "        print(f\"\\\\n📈 최종 학습 통계:\")\n",
        "        print(f\"   평균 Loss: {final_metrics['avg_total_loss']:.4f}\")\n",
        "        print(f\"   평균 MAE: {final_metrics['avg_mae']:.4f}\")\n",
        "        print(f\"   총 스텝: {final_metrics['steps']}\")\n",
        "        print(f\"   최종 학습률: {final_metrics['current_lr']:.2e}\")\n",
        "        \n",
        "else:\n",
        "    print(\"❌ 유효한 데이터셋이 없어 학습을 실행할 수 없습니다.\")\n",
        "    print(\"   이전 셀에서 데이터셋을 먼저 초기화해주세요.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔄 완전 리셋 및 환경 재구성...\n",
            "🧹 GPU 메모리 정리 중...\n",
            "   할당된 메모리: 6.24 GB\n",
            "   캐시된 메모리: 6.26 GB\n",
            "✅ 모듈 캐시 정리 완료\n",
            "✅ PyArrow: 14.0.2\n",
            "✅ Datasets: 2.12.0\n",
            "✅ Datasets/PyArrow 호환성 확인\n",
            "\\n🔄 Mobile VLA 모듈 재로딩...\n",
            "✅ 모든 모듈 성공적으로 로드!\n",
            "\\n📊 실제 데이터셋 테스트 시작...\n",
            "   데이터 경로: /home/billy/25-1kp/vla/ROS_action/mobile_vla_dataset\n",
            "✅ 데이터셋 생성 성공!\n",
            "   총 에피소드: 72개\n",
            "\\n📋 첫 번째 샘플:\n",
            "   시나리오: 2box_left_vertical\n",
            "   태스크: Navigate around the two box obstacles by going left to track the target cup\n",
            "   이미지 수: 18\n",
            "   액션 shape: (18, 3)\n",
            "❌ 데이터셋 테스트 실패: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/home/billy/.cache/pypoetry/virtualenvs/mobile-vla-FNblWQUj-py3.10/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 182, in collate\n",
            "    clone[i] = collate(samples, collate_fn_map=collate_fn_map)\n",
            "  File \"/home/billy/.cache/pypoetry/virtualenvs/mobile-vla-FNblWQUj-py3.10/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 191, in collate\n",
            "    raise TypeError(default_collate_err_msg_format.format(elem_type))\n",
            "TypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/billy/.cache/pypoetry/virtualenvs/mobile-vla-FNblWQUj-py3.10/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 154, in collate\n",
            "    clone.update({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})\n",
            "  File \"/home/billy/.cache/pypoetry/virtualenvs/mobile-vla-FNblWQUj-py3.10/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 154, in <dictcomp>\n",
            "    clone.update({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})\n",
            "  File \"/home/billy/.cache/pypoetry/virtualenvs/mobile-vla-FNblWQUj-py3.10/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 189, in collate\n",
            "    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]\n",
            "  File \"/home/billy/.cache/pypoetry/virtualenvs/mobile-vla-FNblWQUj-py3.10/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 189, in <listcomp>\n",
            "    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]\n",
            "  File \"/home/billy/.cache/pypoetry/virtualenvs/mobile-vla-FNblWQUj-py3.10/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 191, in collate\n",
            "    raise TypeError(default_collate_err_msg_format.format(elem_type))\n",
            "TypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/billy/.cache/pypoetry/virtualenvs/mobile-vla-FNblWQUj-py3.10/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 182, in collate\n",
            "    clone[i] = collate(samples, collate_fn_map=collate_fn_map)\n",
            "  File \"/home/billy/.cache/pypoetry/virtualenvs/mobile-vla-FNblWQUj-py3.10/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 191, in collate\n",
            "    raise TypeError(default_collate_err_msg_format.format(elem_type))\n",
            "TypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_285130/993586381.py\", line 80, in <module>\n",
            "    first_batch = next(iter(dataloader))\n",
            "  File \"/home/billy/.cache/pypoetry/virtualenvs/mobile-vla-FNblWQUj-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 631, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/home/billy/.cache/pypoetry/virtualenvs/mobile-vla-FNblWQUj-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 675, in _next_data\n",
            "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
            "  File \"/home/billy/.cache/pypoetry/virtualenvs/mobile-vla-FNblWQUj-py3.10/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n",
            "    return self.collate_fn(data)\n",
            "  File \"/home/billy/.cache/pypoetry/virtualenvs/mobile-vla-FNblWQUj-py3.10/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 316, in default_collate\n",
            "    return collate(batch, collate_fn_map=default_collate_fn_map)\n",
            "  File \"/home/billy/.cache/pypoetry/virtualenvs/mobile-vla-FNblWQUj-py3.10/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 161, in collate\n",
            "    return {key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem}\n",
            "  File \"/home/billy/.cache/pypoetry/virtualenvs/mobile-vla-FNblWQUj-py3.10/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 161, in <dictcomp>\n",
            "    return {key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem}\n",
            "  File \"/home/billy/.cache/pypoetry/virtualenvs/mobile-vla-FNblWQUj-py3.10/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 189, in collate\n",
            "    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]\n",
            "  File \"/home/billy/.cache/pypoetry/virtualenvs/mobile-vla-FNblWQUj-py3.10/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 189, in <listcomp>\n",
            "    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]\n",
            "  File \"/home/billy/.cache/pypoetry/virtualenvs/mobile-vla-FNblWQUj-py3.10/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 191, in collate\n",
            "    raise TypeError(default_collate_err_msg_format.format(elem_type))\n",
            "TypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>\n"
          ]
        }
      ],
      "source": [
        "# Cell 20: 🧪 PyArrow 호환 Mobile VLA 완전 리셋 및 테스트\n",
        "\n",
        "print(\"🔄 완전 리셋 및 환경 재구성...\")\n",
        "\n",
        "# 메모리 정리\n",
        "clear_gpu_memory()\n",
        "\n",
        "# 모든 관련 모듈 언로드\n",
        "import sys\n",
        "modules_to_reload = [m for m in sys.modules.keys() if 'robovlms' in m or 'mobile_vla' in m]\n",
        "for module in modules_to_reload:\n",
        "    if module in sys.modules:\n",
        "        del sys.modules[module]\n",
        "\n",
        "print(\"✅ 모듈 캐시 정리 완료\")\n",
        "\n",
        "# 의존성 버전 최종 확인\n",
        "try:\n",
        "    import pyarrow\n",
        "    import datasets\n",
        "    print(f\"✅ PyArrow: {pyarrow.__version__}\")\n",
        "    print(f\"✅ Datasets: {datasets.__version__}\")\n",
        "    \n",
        "    # 호환성 테스트\n",
        "    test_dataset = datasets.Dataset.from_dict({\"test\": [1, 2, 3]})\n",
        "    print(\"✅ Datasets/PyArrow 호환성 확인\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"❌ 의존성 문제: {e}\")\n",
        "    raise\n",
        "\n",
        "# 경로 재설정\n",
        "sys.path.insert(0, str(ROOT_DIR))\n",
        "\n",
        "# 리팩토링된 모듈 재임포트\n",
        "print(\"\\\\n🔄 Mobile VLA 모듈 재로딩...\")\n",
        "try:\n",
        "    from robovlms.data import MobileVLADataset\n",
        "    from robovlms.train import MobileVLATrainer, ActionLossTracker\n",
        "    print(\"✅ 모든 모듈 성공적으로 로드!\")\n",
        "except ImportError as e:\n",
        "    print(f\"❌ 임포트 실패: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    raise\n",
        "\n",
        "# 실제 데이터셋 테스트\n",
        "print(f\"\\\\n📊 실제 데이터셋 테스트 시작...\")\n",
        "print(f\"   데이터 경로: {DATA_DIR}\")\n",
        "\n",
        "try:\n",
        "    # 간단한 설정으로 데이터셋 생성\n",
        "    dataset = MobileVLADataset(\n",
        "        data_dir=str(DATA_DIR),\n",
        "        model_name=\"kosmos\",\n",
        "        mode=\"train\",\n",
        "        window_size=8,\n",
        "        fwd_pred_next_n=2,\n",
        "        discrete=False,\n",
        "        tokenizer=None  # 간단히 None으로 설정\n",
        "    )\n",
        "    \n",
        "    print(f\"✅ 데이터셋 생성 성공!\")\n",
        "    print(f\"   총 에피소드: {len(dataset)}개\")\n",
        "    \n",
        "    if len(dataset) > 0:\n",
        "        # 첫 번째 샘플 테스트\n",
        "        sample = dataset[0]\n",
        "        print(f\"\\\\n📋 첫 번째 샘플:\")\n",
        "        print(f\"   시나리오: {sample['scenario']}\")\n",
        "        print(f\"   태스크: {sample['task_description']}\")\n",
        "        print(f\"   이미지 수: {len(sample['images'])}\")\n",
        "        print(f\"   액션 shape: {sample['actions'].shape}\")\n",
        "        \n",
        "        # 커스텀 collate function으로 DataLoader 생성 (PIL 이미지 처리)\n",
        "        def simple_collate_fn(batch):\n",
        "            \"\"\"간단한 PIL 이미지 처리 collate function\"\"\"\n",
        "            import torch\n",
        "            from torchvision import transforms\n",
        "            \n",
        "            transform = transforms.Compose([\n",
        "                transforms.Resize((224, 224)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "            ])\n",
        "            \n",
        "            collated = {}\n",
        "            for key in batch[0].keys():\n",
        "                if key == 'images':\n",
        "                    # PIL 이미지를 텐서로 변환\n",
        "                    all_tensors = []\n",
        "                    for item in batch:\n",
        "                        seq_tensors = []\n",
        "                        for pil_img in item[key]:\n",
        "                            tensor_img = transform(pil_img)\n",
        "                            seq_tensors.append(tensor_img)\n",
        "                        all_tensors.append(torch.stack(seq_tensors))\n",
        "                    collated[key] = torch.stack(all_tensors)\n",
        "                elif key == 'actions':\n",
        "                    collated[key] = torch.stack([torch.tensor(item[key], dtype=torch.float32) for item in batch])\n",
        "                elif key == 'episode_mask':\n",
        "                    collated[key] = torch.stack([torch.tensor(item[key], dtype=torch.bool) for item in batch])\n",
        "                else:\n",
        "                    collated[key] = [item[key] for item in batch]\n",
        "            return collated\n",
        "        \n",
        "        from torch.utils.data import DataLoader\n",
        "        dataloader = DataLoader(\n",
        "            dataset, \n",
        "            batch_size=1, \n",
        "            shuffle=False, \n",
        "            num_workers=0,\n",
        "            collate_fn=simple_collate_fn  # 커스텀 collate function 사용\n",
        "        )\n",
        "        \n",
        "        # 첫 번째 배치 테스트\n",
        "        print(\"   배치 생성 중 (PIL → Tensor 변환)...\")\n",
        "        first_batch = next(iter(dataloader))\n",
        "        print(f\"\\\\n🎯 배치 테스트:\")\n",
        "        for key, value in first_batch.items():\n",
        "            if hasattr(value, 'shape'):\n",
        "                print(f\"   {key}: {value.shape}\")\n",
        "            elif isinstance(value, (list, tuple)):\n",
        "                print(f\"   {key}: {type(value).__name__}[{len(value)}]\")\n",
        "            else:\n",
        "                print(f\"   {key}: {type(value).__name__}\")\n",
        "        \n",
        "        print(\"\\\\n🎉 모든 테스트 통과! 학습 준비 완료!\")\n",
        "        \n",
        "    else:\n",
        "        print(\"❌ 에피소드가 없습니다. 데이터 경로를 확인해주세요.\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"❌ 데이터셋 테스트 실패: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    dataset = None\n",
        "    dataloader = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "IndentationError",
          "evalue": "unindent does not match any outer indentation level (<tokenize>, line 81)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m<tokenize>:81\u001b[0;36m\u001b[0m\n\u001b[0;31m    if epoch_losses:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Cell 21: 🚀 최종 Mobile VLA 학습 실행 (PyArrow 호환)\n",
        "\n",
        "if 'dataset' in locals() and dataset is not None and len(dataset) > 0:\n",
        "    print(\"🎯 MobileVLATrainer 초기화 및 학습 시작...\")\n",
        "    \n",
        "    try:\n",
        "        # 트레이너 초기화\n",
        "        trainer = MobileVLATrainer(\n",
        "            model_name=\"microsoft/kosmos-2-patch14-224\",\n",
        "            action_dim=3,  # Mobile VLA: [linear_x, linear_y, angular_z]\n",
        "            window_size=8,\n",
        "            chunk_size=2,\n",
        "            learning_rate=1e-4,\n",
        "            device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "            precision=\"fp16\"  # Mixed precision\n",
        "        )\n",
        "        \n",
        "        print(f\"✅ 트레이너 초기화 완료!\")\n",
        "        print(f\"   디바이스: {trainer.device}\")\n",
        "        print(f\"   모델 파라미터: {sum(p.numel() for p in trainer.model.parameters()):,}개\")\n",
        "        \n",
        "        # 손실 추적기\n",
        "        loss_tracker = ActionLossTracker()\n",
        "        \n",
        "        # 학습 실행\n",
        "        print(\"\\\\n🚀 Mobile VLA 학습 시작!\")\n",
        "        \n",
        "        num_epochs = 3  # 테스트용으로 짧게\n",
        "        save_interval = 1\n",
        "        log_interval = 5\n",
        "        \n",
        "                 # 학습용 DataLoader 재생성 (collate_fn 포함)\n",
        "         print(\"   학습용 DataLoader 생성 중...\")\n",
        "         from torch.utils.data import DataLoader\n",
        "         train_dataloader = DataLoader(\n",
        "             dataset,\n",
        "             batch_size=1,\n",
        "             shuffle=True,\n",
        "             num_workers=0,\n",
        "             collate_fn=dataset.collater,  # 중요: collate_fn 사용\n",
        "             pin_memory=False,\n",
        "             drop_last=True\n",
        "         )\n",
        "         print(f\"   DataLoader 생성 완료 (총 {len(train_dataloader)}개 배치)\")\n",
        "         \n",
        "         for epoch in range(num_epochs):\n",
        "             print(f\"\\\\n📊 Epoch {epoch+1}/{num_epochs}\")\n",
        "             epoch_losses = []\n",
        "             \n",
        "             for step, batch in enumerate(train_dataloader):\n",
        "                try:\n",
        "                    # 학습 스텝 실행\n",
        "                    loss_dict = trainer.train_step(batch)\n",
        "                    \n",
        "                    # 손실 추적\n",
        "                    loss_tracker.update(loss_dict)\n",
        "                    epoch_losses.append(loss_dict['total_loss'])\n",
        "                    \n",
        "                    # 주기적 로깅\n",
        "                    if (step + 1) % log_interval == 0:\n",
        "                        current_metrics = loss_tracker.get_averages()\n",
        "                        print(f\"   Step {step+1:3d}: \"\n",
        "                              f\"Loss={loss_dict['total_loss']:.4f}, \"\n",
        "                              f\"MAE={loss_dict.get('mae_avg', 0):.4f}, \"\n",
        "                              f\"LR={current_metrics['current_lr']:.2e}\")\n",
        "                    \n",
        "                    # 메모리 관리 (주기적으로 정리)\n",
        "                    if (step + 1) % 10 == 0:\n",
        "                        clear_gpu_memory()\n",
        "                        \n",
        "                except Exception as e:\n",
        "                    print(f\"❌ 스텝 {step+1} 실패: {e}\")\n",
        "                    if \"out of memory\" in str(e).lower():\n",
        "                        print(\"   GPU 메모리 부족! 배치 크기를 줄이거나 window_size를 줄여주세요.\")\n",
        "                        clear_gpu_memory()\n",
        "                        break\n",
        "                    else:\n",
        "                        continue\n",
        "            \n",
        "            # 에포크 요약\n",
        "            if epoch_losses:\n",
        "                avg_epoch_loss = sum(epoch_losses) / len(epoch_losses)\n",
        "                print(f\"   📈 Epoch {epoch+1} 평균 Loss: {avg_epoch_loss:.4f}\")\n",
        "                \n",
        "                # 체크포인트 저장\n",
        "                if (epoch + 1) % save_interval == 0:\n",
        "                    checkpoint_path = f\"mobile_vla_epoch_{epoch+1}.pt\"\n",
        "                    trainer.save_checkpoint(checkpoint_path)\n",
        "                    print(f\"   💾 체크포인트 저장: {checkpoint_path}\")\n",
        "        \n",
        "        print(\"\\\\n🎉 학습 완료!\")\n",
        "        \n",
        "        # 최종 통계\n",
        "        if loss_tracker.losses:\n",
        "            final_metrics = loss_tracker.get_averages()\n",
        "            print(f\"\\\\n📈 최종 학습 통계:\")\n",
        "            print(f\"   평균 Total Loss: {final_metrics['avg_total_loss']:.4f}\")\n",
        "            print(f\"   평균 MAE: {final_metrics['avg_mae']:.4f}\")\n",
        "            print(f\"   총 스텝: {final_metrics['steps']}\")\n",
        "            print(f\"   최종 학습률: {final_metrics['current_lr']:.2e}\")\n",
        "            \n",
        "            # 간단한 성능 분석\n",
        "            print(f\"\\\\n🔍 성능 분석:\")\n",
        "            print(f\"   Loss 추이: {loss_tracker.losses[-10:] if len(loss_tracker.losses) >= 10 else loss_tracker.losses}\")\n",
        "            \n",
        "        # 최종 메모리 정리\n",
        "        clear_gpu_memory()\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"❌ 학습 실행 실패: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        clear_gpu_memory()\n",
        "        \n",
        "else:\n",
        "    print(\"❌ 유효한 데이터셋이 없어 학습을 실행할 수 없습니다.\")\n",
        "    print(\"   이전 셀(Cell 20)에서 데이터셋을 먼저 초기화해주세요.\")\n",
        "    print(f\"   현재 dataset 상태: {'정의됨' if 'dataset' in locals() else '정의되지 않음'}\")\n",
        "    if 'dataset' in locals():\n",
        "        print(f\"   데이터셋 길이: {len(dataset) if dataset is not None else 'None'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔧 Collate Function 문제 해결...\n",
            "❌ 데이터셋이 없습니다. 이전 셀을 먼저 실행해주세요.\n"
          ]
        }
      ],
      "source": [
        "# Cell 22: 🎯 Collate Function 문제 해결 및 최종 데이터셋 준비\n",
        "\n",
        "print(\"🔧 Collate Function 문제 해결...\")\n",
        "\n",
        "# 커스텀 collate 함수 정의 (PIL 이미지 처리 완벽 지원)\n",
        "def mobile_vla_collate_fixed(batch):\n",
        "    \"\"\"PIL 이미지를 텐서로 변환하는 커스텀 collate 함수 (완전 수정판)\"\"\"\n",
        "    import torch\n",
        "    from torchvision import transforms\n",
        "    \n",
        "    # 이미지 전처리 파이프라인 (Kosmos 호환)\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    \n",
        "    collated = {}\n",
        "    \n",
        "    for key in batch[0].keys():\n",
        "        if key == 'images':\n",
        "            # PIL 이미지들을 텐서로 변환\n",
        "            image_tensors = []\n",
        "            for item in batch:\n",
        "                seq_tensors = []\n",
        "                for pil_img in item[key]:\n",
        "                    tensor_img = transform(pil_img)\n",
        "                    seq_tensors.append(tensor_img)\n",
        "                # [T, C, H, W] 스택\n",
        "                if seq_tensors:\n",
        "                    stacked = torch.stack(seq_tensors)\n",
        "                    image_tensors.append(stacked)\n",
        "                else:\n",
        "                    # 빈 시퀀스 처리\n",
        "                    image_tensors.append(torch.empty(0, 3, 224, 224))\n",
        "            # [B, T, C, H, W] 배치\n",
        "            if image_tensors and image_tensors[0].numel() > 0:\n",
        "                collated[key] = torch.stack(image_tensors)\n",
        "            else:\n",
        "                collated[key] = torch.empty(len(batch), 0, 3, 224, 224)\n",
        "                \n",
        "        elif key == 'actions':\n",
        "            # 액션 텐서화\n",
        "            action_tensors = []\n",
        "            for item in batch:\n",
        "                if isinstance(item[key], torch.Tensor):\n",
        "                    action_tensors.append(item[key])\n",
        "                else:\n",
        "                    action_tensors.append(torch.tensor(item[key], dtype=torch.float32))\n",
        "            collated[key] = torch.stack(action_tensors)\n",
        "            \n",
        "        elif key == 'episode_mask':\n",
        "            # 마스크 텐서화  \n",
        "            mask_tensors = []\n",
        "            for item in batch:\n",
        "                if isinstance(item[key], torch.Tensor):\n",
        "                    mask_tensors.append(item[key])\n",
        "                else:\n",
        "                    mask_tensors.append(torch.tensor(item[key], dtype=torch.bool))\n",
        "            collated[key] = torch.stack(mask_tensors)\n",
        "            \n",
        "        else:\n",
        "            # 문자열 등은 리스트로 유지\n",
        "            collated[key] = [item[key] for item in batch]\n",
        "    \n",
        "    return collated\n",
        "\n",
        "# 데이터셋이 이미 로드되어 있는지 확인\n",
        "if 'dataset' in locals() and dataset is not None and len(dataset) > 0:\n",
        "    print(f\"✅ 기존 데이터셋 사용: {len(dataset)}개 에피소드\")\n",
        "    \n",
        "    # 수정된 collate 함수로 DataLoader 재생성\n",
        "    from torch.utils.data import DataLoader\n",
        "    \n",
        "    dataloader = DataLoader(\n",
        "        dataset, \n",
        "        batch_size=1, \n",
        "        shuffle=False, \n",
        "        num_workers=0,\n",
        "        collate_fn=mobile_vla_collate_fixed  # 수정된 커스텀 collate 함수\n",
        "    )\n",
        "    \n",
        "    print(\"🔄 배치 테스트 실행 중...\")\n",
        "    \n",
        "    try:\n",
        "        # 첫 번째 배치 테스트\n",
        "        first_batch = next(iter(dataloader))\n",
        "        \n",
        "        print(\"✅ 배치 로드 성공!\")\n",
        "        print(\"\\\\n🎯 최종 배치 구조:\")\n",
        "        for key, value in first_batch.items():\n",
        "            if hasattr(value, 'shape'):\n",
        "                print(f\"   {key}: {value.shape} ({value.dtype})\")\n",
        "            elif isinstance(value, (list, tuple)):\n",
        "                print(f\"   {key}: {type(value).__name__}[{len(value)}]\")\n",
        "                if len(value) > 0:\n",
        "                    print(f\"     └─ 첫 번째 항목: {value[0]}\")\n",
        "            else:\n",
        "                print(f\"   {key}: {type(value).__name__}\")\n",
        "        \n",
        "        print(\"\\\\n🎉 모든 Collate 테스트 통과! 학습 준비 완료!\")\n",
        "        \n",
        "        # 간단한 Window/Chunk 확인\n",
        "        images_shape = first_batch['images'].shape  # [B, T, C, H, W]\n",
        "        actions_shape = first_batch['actions'].shape  # [B, T, action_dim]\n",
        "        \n",
        "        window_size = 8\n",
        "        chunk_size = 2\n",
        "        \n",
        "        print(f\"\\\\n📊 Window/Chunk 분석:\")\n",
        "        print(f\"   이미지 시퀀스: {images_shape} (배치={images_shape[0]}, 시간={images_shape[1]})\")\n",
        "        print(f\"   액션 시퀀스: {actions_shape} (배치={actions_shape[0]}, 시간={actions_shape[1]})\")\n",
        "        print(f\"   Window Size: {window_size} (과거 관찰)\")\n",
        "        print(f\"   Chunk Size: {chunk_size} (미래 예측)\")\n",
        "        \n",
        "        if images_shape[1] >= window_size + chunk_size:\n",
        "            print(f\"   ✅ 충분한 시퀀스 길이: {images_shape[1]} >= {window_size + chunk_size}\")\n",
        "        else:\n",
        "            print(f\"   ⚠️ 시퀀스 길이 부족: {images_shape[1]} < {window_size + chunk_size}\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"❌ 배치 테스트 실패: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        dataloader = None\n",
        "        \n",
        "else:\n",
        "    print(\"❌ 데이터셋이 없습니다. 이전 셀을 먼저 실행해주세요.\")\n",
        "    dataloader = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔧 PIL Image 문제 해결을 위한 커스텀 DataLoader 구성...\n",
            "❌ 유효한 데이터셋이 없습니다. 이전 셀을 먼저 실행해주세요.\n"
          ]
        }
      ],
      "source": [
        "# Cell 22: 🔧 PIL Image 처리를 위한 커스텀 DataLoader\n",
        "\n",
        "print(\"🔧 PIL Image 문제 해결을 위한 커스텀 DataLoader 구성...\")\n",
        "\n",
        "if 'dataset' in locals() and dataset is not None and len(dataset) > 0:\n",
        "    \n",
        "    def mobile_vla_collate_fn(batch):\n",
        "        \"\"\"Mobile VLA용 커스텀 collate function - PIL Image 안전 처리\"\"\"\n",
        "        import torch\n",
        "        from PIL import Image\n",
        "        import numpy as np\n",
        "        \n",
        "        print(f\"🔍 배치 크기: {len(batch)}\")\n",
        "        \n",
        "        # 첫 번째 샘플 구조 확인\n",
        "        if batch:\n",
        "            sample = batch[0]\n",
        "            print(f\"📋 샘플 키: {list(sample.keys())}\")\n",
        "            for key, value in sample.items():\n",
        "                if key == 'images':\n",
        "                    print(f\"   {key}: {len(value)}개 이미지 (타입: {type(value[0]) if value else 'empty'})\")\n",
        "                elif hasattr(value, 'shape'):\n",
        "                    print(f\"   {key}: {value.shape}\")\n",
        "                else:\n",
        "                    print(f\"   {key}: {type(value).__name__}\")\n",
        "        \n",
        "        collated = {}\n",
        "        \n",
        "        for key in batch[0].keys():\n",
        "            values = [item[key] for item in batch]\n",
        "            \n",
        "            if key == 'images':\n",
        "                # PIL 이미지를 처리\n",
        "                all_image_tensors = []\n",
        "                for img_list in values:  # 각 배치의 이미지 리스트\n",
        "                    batch_images = []\n",
        "                    for img in img_list:\n",
        "                        if isinstance(img, Image.Image):\n",
        "                            # PIL -> numpy -> tensor (정규화 포함)\n",
        "                            img_array = np.array(img)\n",
        "                            if img_array.ndim == 3:  # RGB\n",
        "                                img_array = img_array.transpose(2, 0, 1)  # HWC -> CHW\n",
        "                            img_tensor = torch.from_numpy(img_array).float() / 255.0\n",
        "                            batch_images.append(img_tensor)\n",
        "                        elif isinstance(img, torch.Tensor):\n",
        "                            batch_images.append(img)\n",
        "                        else:\n",
        "                            print(f\"⚠️ 지원하지 않는 이미지 타입: {type(img)}\")\n",
        "                            continue\n",
        "                    \n",
        "                    if batch_images:\n",
        "                        all_image_tensors.append(torch.stack(batch_images))\n",
        "                \n",
        "                # 최종 배치 텐서 생성\n",
        "                if all_image_tensors:\n",
        "                    collated[key] = torch.stack(all_image_tensors)  # [B, T, C, H, W]\n",
        "                    print(f\"   ✅ {key} 처리 완료: {collated[key].shape}\")\n",
        "                else:\n",
        "                    collated[key] = torch.empty(0)\n",
        "                    print(f\"   ⚠️ {key} 비어있음\")\n",
        "                    \n",
        "            elif key == 'actions':\n",
        "                # 액션 텐서 처리\n",
        "                if isinstance(values[0], torch.Tensor):\n",
        "                    collated[key] = torch.stack(values)\n",
        "                else:\n",
        "                    collated[key] = torch.stack([torch.tensor(v, dtype=torch.float32) for v in values])\n",
        "                print(f\"   ✅ {key} 처리 완료: {collated[key].shape}\")\n",
        "                \n",
        "            elif key == 'episode_mask':\n",
        "                # 마스크 처리\n",
        "                if isinstance(values[0], torch.Tensor):\n",
        "                    collated[key] = torch.stack(values)\n",
        "                else:\n",
        "                    collated[key] = torch.stack([torch.tensor(v, dtype=torch.bool) for v in values])\n",
        "                print(f\"   ✅ {key} 처리 완료: {collated[key].shape}\")\n",
        "                \n",
        "            elif isinstance(values[0], torch.Tensor):\n",
        "                # 기타 텐서들\n",
        "                collated[key] = torch.stack(values)\n",
        "                print(f\"   ✅ {key} 처리 완료: {collated[key].shape}\")\n",
        "            else:\n",
        "                # 문자열이나 기타 객체들\n",
        "                collated[key] = values\n",
        "                print(f\"   ✅ {key} 처리 완료: {type(values).__name__}[{len(values)}]\")\n",
        "        \n",
        "        return collated\n",
        "    \n",
        "    # 커스텀 collate function을 사용하는 DataLoader 생성\n",
        "    try:\n",
        "        safe_dataloader = DataLoader(\n",
        "            dataset,\n",
        "            batch_size=1,  # 메모리 효율성\n",
        "            shuffle=False,\n",
        "            num_workers=0,  # 멀티프로세싱 비활성화\n",
        "            pin_memory=False,\n",
        "            drop_last=True,\n",
        "            collate_fn=mobile_vla_collate_fn  # 커스텀 collate function\n",
        "        )\n",
        "        \n",
        "        print(f\"\\\\n✅ 안전한 DataLoader 생성 완료!\")\n",
        "        print(f\"   배치 크기: 1\")\n",
        "        print(f\"   총 배치 수: {len(safe_dataloader)}개\")\n",
        "        \n",
        "        # 실제 배치 테스트\n",
        "        print(\"\\\\n🧪 실제 배치 로딩 테스트...\")\n",
        "        first_batch = next(iter(safe_dataloader))\n",
        "        \n",
        "        print(f\"\\\\n🎯 최종 배치 구조:\")\n",
        "        for key, value in first_batch.items():\n",
        "            if hasattr(value, 'shape'):\n",
        "                print(f\"   {key}: {value.shape} ({value.dtype})\")\n",
        "            elif isinstance(value, (list, tuple)):\n",
        "                print(f\"   {key}: {type(value).__name__}[{len(value)}]\")\n",
        "            else:\n",
        "                print(f\"   {key}: {type(value).__name__}\")\n",
        "        \n",
        "        print(\"\\\\n🎉 DataLoader 테스트 성공! 학습 준비 완료!\")\n",
        "        \n",
        "        # 전역 변수에 할당\n",
        "        dataloader = safe_dataloader\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"❌ 안전한 DataLoader 생성 실패: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        dataloader = None\n",
        "        \n",
        "else:\n",
        "    print(\"❌ 유효한 데이터셋이 없습니다. 이전 셀을 먼저 실행해주세요.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mobile-vla-FNblWQUj-py3.10",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
