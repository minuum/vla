#!/usr/bin/env python3
"""
ğŸ¤– Simple Enhanced Mobile VLA Training with Action Normalization
"""

import torch
import torch.nn as nn
import numpy as np
import json
from datetime import datetime
from pathlib import Path
import sys

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
ROOT_DIR = Path("/home/billy/25-1kp/vla/Robo+/Mobile_VLA")
DATA_DIR = Path("/home/billy/25-1kp/vla/ROS_action/mobile_vla_dataset")
ROBOVLMS_DIR = Path("/home/billy/25-1kp/vla/RoboVLMs")

sys.path.append(str(ROOT_DIR))
sys.path.append(str(ROBOVLMS_DIR))

from robovlms.data.mobile_vla_dataset import MobileVLADataset
from robovlms.train.mobile_vla_trainer import MobileVLATrainer
from torch.utils.data import DataLoader, random_split

class SimpleEnhancedTrainer(MobileVLATrainer):
    """ê¸°ì¡´ MobileVLATrainerë¥¼ í™•ì¥í•œ í–¥ìƒëœ íŠ¸ë ˆì´ë„ˆ"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        
        # ì•¡ì…˜ ì •ê·œí™” í†µê³„
        self.action_mean = None
        self.action_std = None
        
        print(f"âœ… SimpleEnhancedTrainer ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   ì•¡ì…˜ ì •ê·œí™”: í™œì„±í™”")
        
    def compute_action_statistics(self, dataset: MobileVLADataset):
        """ì•¡ì…˜ ë°ì´í„°ì˜ í†µê³„ ê³„ì‚°"""
        print("ğŸ“Š ì•¡ì…˜ í†µê³„ ê³„ì‚° ì¤‘...")
        
        all_actions = []
        for i in range(len(dataset)):
            episode = dataset[i]
            actions = episode['actions']
            if isinstance(actions, np.ndarray):
                actions = torch.from_numpy(actions)
            all_actions.append(actions)
        
        all_actions = torch.cat(all_actions, dim=0)  # [N, 3]
        
        self.action_mean = all_actions.mean(dim=0)  # [3]
        self.action_std = all_actions.std(dim=0)    # [3]
        
        # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
        self.action_std = torch.clamp(self.action_std, min=1e-6)
        
        print(f"   ì•¡ì…˜ ë²”ìœ„: {all_actions.min():.4f} ~ {all_actions.max():.4f}")
        print(f"   ì•¡ì…˜ í‰ê· : {self.action_mean}")
        print(f"   ì•¡ì…˜ í‘œì¤€í¸ì°¨: {self.action_std}")
        
    def normalize_actions(self, actions: torch.Tensor) -> torch.Tensor:
        """ì•¡ì…˜ ì •ê·œí™”"""
        if self.action_mean is None or self.action_std is None:
            return actions
        return (actions - self.action_mean.to(actions.device)) / self.action_std.to(actions.device)
        
    def denormalize_actions(self, actions: torch.Tensor) -> torch.Tensor:
        """ì•¡ì…˜ ì—­ì •ê·œí™”"""
        if self.action_mean is None or self.action_std is None:
            return actions
        return actions * self.action_std.to(actions.device) + self.action_mean.to(actions.device)
        
    def train_step(self, batch: dict) -> dict:
        """í–¥ìƒëœ í•™ìŠµ ìŠ¤í…"""
        # ê¸°ì¡´ train_step í˜¸ì¶œ
        result = super().train_step(batch)
        
        # ì•¡ì…˜ ì •ê·œí™” ì ìš©ëœ ë©”íŠ¸ë¦­ ê³„ì‚°
        if self.action_mean is not None:
            # ì˜ˆì¸¡ê³¼ íƒ€ê²Ÿì„ ì—­ì •ê·œí™”í•˜ì—¬ ì‹¤ì œ ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
            with torch.no_grad():
                # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ê¸°ì¡´ ë©”íŠ¸ë¦­ì„ ì‚¬ìš©í•˜ë˜, ì •ê·œí™” ì •ë³´ë¥¼ ì¶”ê°€
                result['action_mean'] = self.action_mean.cpu().numpy().tolist()
                result['action_std'] = self.action_std.cpu().numpy().tolist()
        
        return result

def custom_collate_fn(batch):
    """ì»¤ìŠ¤í…€ collate í•¨ìˆ˜"""
    return batch[0]  # ë°°ì¹˜ í¬ê¸°ê°€ 1ì´ë¯€ë¡œ ì²« ë²ˆì§¸ ìš”ì†Œë§Œ ë°˜í™˜

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ Simple Enhanced Mobile VLA Training ì‹œì‘!")
    
    # ë°ì´í„°ì…‹ ë¡œë“œ
    print("ğŸ“Š ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘...")
    dataset = MobileVLADataset(DATA_DIR)
    print(f"   ì´ ì—í”¼ì†Œë“œ: {len(dataset)}ê°œ")
    
    # í–¥ìƒëœ íŠ¸ë ˆì´ë„ˆ ì´ˆê¸°í™”
    trainer = SimpleEnhancedTrainer(
        model_name="microsoft/kosmos-2-patch14-224",
        action_dim=3,
        window_size=8,
        chunk_size=2,
        learning_rate=1e-4,
        device="cuda" if torch.cuda.is_available() else "cpu"
    )
    
    # ì•¡ì…˜ í†µê³„ ê³„ì‚°
    trainer.compute_action_statistics(dataset)
    
    # ë°ì´í„° ë¶„í•  (ì‹œê°„ ê¸°ë°˜)
    total_size = len(dataset)
    train_size = int(0.8 * total_size)
    val_size = total_size - train_size
    
    # ì‹œê°„ ìˆœì„œëŒ€ë¡œ ë¶„í•  (ë‚˜ì¤‘ ì—í”¼ì†Œë“œë¥¼ ê²€ì¦ìš©ìœ¼ë¡œ)
    train_dataset = torch.utils.data.Subset(dataset, range(train_size))
    val_dataset = torch.utils.data.Subset(dataset, range(train_size, total_size))
    
    print(f"   í›ˆë ¨ ë°ì´í„°: {len(train_dataset)}ê°œ")
    print(f"   ê²€ì¦ ë°ì´í„°: {len(val_dataset)}ê°œ")
    
    # DataLoader ìƒì„±
    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, collate_fn=custom_collate_fn)
    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, collate_fn=custom_collate_fn)
    
    # í•™ìŠµ ë£¨í”„
    print("\nğŸ¯ í•™ìŠµ ì‹œì‘...")
    num_epochs = 10  # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì¤„ì„
    best_val_loss = float('inf')
    train_history = []
    val_history = []
    
    for epoch in range(num_epochs):
        print(f"\nğŸ“ˆ ì—í¬í¬ {epoch+1}/{num_epochs}")
        print("-" * 40)
        
        # í•™ìŠµ
        epoch_losses = []
        epoch_maes = []
        
        for step, batch in enumerate(train_loader):
            try:
                metrics = trainer.train_step(batch)
                epoch_losses.append(metrics['total_loss'])
                epoch_maes.append(metrics['mae_avg'])
                
                if (step + 1) % 10 == 0:
                    print(f"   ë°°ì¹˜ {step+1}/{len(train_loader)}: Loss={metrics['total_loss']:.4f}, MAE={metrics['mae_avg']:.4f}")
                    
            except Exception as e:
                print(f"   ë°°ì¹˜ {step+1} ì˜¤ë¥˜: {e}")
                continue
        
        if epoch_losses:
            train_metrics = {
                'total_loss': np.mean(epoch_losses),
                'mae_avg': np.mean(epoch_maes)
            }
            train_history.append(train_metrics)
            
            print(f"âœ… í•™ìŠµ ì™„ë£Œ:")
            print(f"   Loss: {train_metrics['total_loss']:.4f}")
            print(f"   MAE: {train_metrics['mae_avg']:.4f}")
            
            # ê°„ë‹¨í•œ ê²€ì¦ (ë§ˆì§€ë§‰ ë°°ì¹˜ë¡œ)
            try:
                val_batch = next(iter(val_loader))
                val_metrics = trainer.train_step(val_batch)  # ê²€ì¦ ëª¨ë“œë¡œ ì‹¤í–‰
                val_history.append({
                    'loss': val_metrics['total_loss'],
                    'mae_avg': val_metrics['mae_avg']
                })
                
                print(f"ğŸ” ê²€ì¦ ê²°ê³¼:")
                print(f"   Loss: {val_metrics['total_loss']:.4f}")
                print(f"   MAE: {val_metrics['mae_avg']:.4f}")
                
                # ìµœê³  ëª¨ë¸ ì €ì¥
                if val_metrics['total_loss'] < best_val_loss:
                    best_val_loss = val_metrics['total_loss']
                    torch.save({
                        'model_state_dict': trainer.model.state_dict(),
                        'optimizer_state_dict': trainer.optimizer.state_dict(),
                        'epoch': epoch,
                        'val_loss': best_val_loss,
                        'action_mean': trainer.action_mean,
                        'action_std': trainer.action_std
                    }, 'best_simple_enhanced_model.pth')
                    print(f"ğŸ’¾ ìµœê³  ëª¨ë¸ ì €ì¥ë¨ (Loss: {best_val_loss:.4f})")
                    
            except Exception as e:
                print(f"ğŸ” ê²€ì¦ ì˜¤ë¥˜: {e}")
    
    # ê²°ê³¼ ì €ì¥
    results = {
        'final_metrics': {
            'best_val_loss': best_val_loss,
            'final_train_loss': train_history[-1]['total_loss'] if train_history else None,
            'final_train_mae': train_history[-1]['mae_avg'] if train_history else None
        },
        'train_history': train_history,
        'val_history': val_history,
        'action_statistics': {
            'mean': trainer.action_mean.tolist() if trainer.action_mean is not None else None,
            'std': trainer.action_std.tolist() if trainer.action_std is not None else None
        },
        'dataset_info': {
            'total_episodes': len(dataset),
            'train_episodes': len(train_dataset),
            'val_episodes': len(val_dataset)
        },
        'model_info': {
            'architecture': 'Enhanced Kosmos 2B + Action Head',
            'action_normalization': True,
            'epochs': num_epochs,
            'learning_rate': trainer.learning_rate
        },
        'created_at': datetime.now().isoformat()
    }
    
    with open('simple_enhanced_training_results.json', 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ë¨: simple_enhanced_training_results.json")
    print("ğŸ‰ ê°„ë‹¨í•œ í–¥ìƒëœ í•™ìŠµ ì™„ë£Œ!")

if __name__ == "__main__":
    main()
