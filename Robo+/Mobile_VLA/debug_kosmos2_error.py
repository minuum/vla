#!/usr/bin/env python3
"""
Kosmos2 NoneType ì—ëŸ¬ ë””ë²„ê¹… ìŠ¤í¬ë¦½íŠ¸
"""

import torch
import torch.nn as nn
from transformers import AutoProcessor, AutoModel
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def debug_kosmos2_error():
    """Kosmos2 NoneType ì—ëŸ¬ ë””ë²„ê¹…"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    logger.info(f"ğŸ”§ ë””ë°”ì´ìŠ¤: {device}")
    
    try:
        # 1. Processor ë¡œë“œ
        logger.info("1. Processor ë¡œë“œ ì¤‘...")
        processor = AutoProcessor.from_pretrained("microsoft/kosmos-2-patch14-224")
        logger.info("âœ… Processor ë¡œë“œ ì™„ë£Œ")
        
        # 2. Model ë¡œë“œ
        logger.info("2. Model ë¡œë“œ ì¤‘...")
        model = AutoModel.from_pretrained("microsoft/kosmos-2-patch14-224")
        model = model.to(device)
        model.eval()
        logger.info("âœ… Model ë¡œë“œ ì™„ë£Œ")
        
        # 3. ì…ë ¥ ë°ì´í„° ìƒì„±
        logger.info("3. ì…ë ¥ ë°ì´í„° ìƒì„±...")
        batch_size = 1
        dummy_image = torch.randn(batch_size, 3, 224, 224).to(device)
        dummy_text = ["<image>"] * batch_size
        
        logger.info(f"   ì´ë¯¸ì§€ shape: {dummy_image.shape}")
        logger.info(f"   í…ìŠ¤íŠ¸: {dummy_text}")
        
        # 4. Processor ì²˜ë¦¬
        logger.info("4. Processor ì²˜ë¦¬...")
        text_inputs = processor(
            text=dummy_text,
            return_tensors="pt",
            padding=True,
            truncation=True,
            max_length=512
        )
        
        logger.info(f"   input_ids shape: {text_inputs['input_ids'].shape}")
        logger.info(f"   attention_mask shape: {text_inputs['attention_mask'].shape}")
        
        # 5. ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
        logger.info("5. í…ì„œë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™...")
        text_inputs = {k: v.to(device) for k, v in text_inputs.items()}
        
        # 6. ëª¨ë¸ ì¶”ë¡ 
        logger.info("6. ëª¨ë¸ ì¶”ë¡  ì‹œì‘...")
        with torch.no_grad():
            logger.info("   pixel_values ì „ë‹¬...")
            logger.info(f"   pixel_values shape: {dummy_image.shape}")
            logger.info(f"   pixel_values dtype: {dummy_image.dtype}")
            
            logger.info("   input_ids ì „ë‹¬...")
            logger.info(f"   input_ids shape: {text_inputs['input_ids'].shape}")
            logger.info(f"   input_ids dtype: {text_inputs['input_ids'].dtype}")
            
            logger.info("   attention_mask ì „ë‹¬...")
            logger.info(f"   attention_mask shape: {text_inputs['attention_mask'].shape}")
            logger.info(f"   attention_mask dtype: {text_inputs['attention_mask'].dtype}")
            
            # ëª¨ë¸ í˜¸ì¶œ
            outputs = model(
                pixel_values=dummy_image,
                input_ids=text_inputs['input_ids'],
                attention_mask=text_inputs['attention_mask']
            )
            
            logger.info("âœ… ëª¨ë¸ ì¶”ë¡  ì™„ë£Œ")
            logger.info(f"   outputs type: {type(outputs)}")
            logger.info(f"   outputs keys: {outputs.keys() if hasattr(outputs, 'keys') else 'No keys'}")
            
            if hasattr(outputs, 'last_hidden_state'):
                logger.info(f"   last_hidden_state shape: {outputs.last_hidden_state.shape}")
                vision_features = outputs.last_hidden_state[:, 0]
                logger.info(f"   vision_features shape: {vision_features.shape}")
                logger.info("âœ… Vision features ì¶”ì¶œ ì„±ê³µ!")
            else:
                logger.error("âŒ last_hidden_stateê°€ ì—†ìŠµë‹ˆë‹¤!")
                
    except Exception as e:
        logger.error(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
        import traceback
        logger.error(f"ìƒì„¸ ì—ëŸ¬: {traceback.format_exc()}")

def test_kosmos2_simple():
    """ê°„ë‹¨í•œ Kosmos2 í…ŒìŠ¤íŠ¸"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    logger.info(f"ğŸ”§ ê°„ë‹¨í•œ Kosmos2 í…ŒìŠ¤íŠ¸ - ë””ë°”ì´ìŠ¤: {device}")
    
    try:
        # ê°„ë‹¨í•œ ëª¨ë¸ ë¡œë“œ
        model = AutoModel.from_pretrained("microsoft/kosmos-2-patch14-224")
        processor = AutoProcessor.from_pretrained("microsoft/kosmos-2-patch14-224")
        
        # CPUì—ì„œ í…ŒìŠ¤íŠ¸
        model = model.cpu()
        model.eval()
        
        # ê°„ë‹¨í•œ ì…ë ¥
        dummy_image = torch.randn(1, 3, 224, 224)
        dummy_text = ["<image>"]
        
        # Processor ì²˜ë¦¬
        text_inputs = processor(
            text=dummy_text,
            return_tensors="pt",
            padding=True,
            truncation=True,
            max_length=512
        )
        
        # ì¶”ë¡ 
        with torch.no_grad():
            outputs = model(
                pixel_values=dummy_image,
                input_ids=text_inputs['input_ids'],
                attention_mask=text_inputs['attention_mask']
            )
            
            logger.info("âœ… CPUì—ì„œ ì¶”ë¡  ì„±ê³µ!")
            logger.info(f"   last_hidden_state shape: {outputs.last_hidden_state.shape}")
            
    except Exception as e:
        logger.error(f"âŒ CPU í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    logger.info("ğŸš€ Kosmos2 NoneType ì—ëŸ¬ ë””ë²„ê¹… ì‹œì‘")
    
    # 1. ê°„ë‹¨í•œ CPU í…ŒìŠ¤íŠ¸
    test_kosmos2_simple()
    
    # 2. ìƒì„¸í•œ GPU í…ŒìŠ¤íŠ¸
    debug_kosmos2_error()
