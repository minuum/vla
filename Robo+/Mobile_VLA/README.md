# ğŸš€ Mobile VLA (Vision-Language-Action) Project

ëª¨ë°”ì¼ ë¡œë´‡ì„ ìœ„í•œ Vision-Language-Action (VLA) ëª¨ë¸ ê°œë°œ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.

## ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš”

**ëª©í‘œ**: ë‹¨ì¼ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ëª…ë ¹ì„ ì…ë ¥ë°›ì•„ 2D ì•¡ì…˜(linear_x, linear_y)ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ ê°œë°œ

### ì£¼ìš” íŠ¹ì§•
- **ì…ë ¥**: ë‹¨ì¼ ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ ëª…ë ¹
- **ì¶œë ¥**: 2D ì•¡ì…˜ (linear_x, linear_y)
- **ë°±ë³¸ ëª¨ë¸**: Kosmos2 (Microsoft)
- **ê³ ê¸‰ ê¸°ëŠ¥**: Claw Matrix, Hierarchical Planning, Advanced Attention
- **ìµœì í™”**: Zì¶• ì œì™¸ë¡œ ëª¨ë¸ ë³µì¡ë„ ê°ì†Œ

## ğŸ† ìµœì¢… ì„±ê³¼

### ëª¨ë¸ ì„±ëŠ¥ (ê²€ì¦ ì™„ë£Œ)
- **í‰ê·  MAE**: 0.2642
- **í‰ê·  RMSE**: 0.4655
- **Linear_X ì„±ê³µë¥  (0.1)**: 90.3% â­
- **Linear_Y ì„±ê³µë¥  (0.1)**: 26.4%
- **ê°€ì¤‘ í‰ê·  ì„±ê³µë¥  (0.1)**: 51.4%

### ì£¼ìš” ì„±ê³¼
1. âœ… **2D ì•¡ì…˜ ìµœì í™”**: Zì¶• ì œì™¸ë¡œ ëª¨ë¸ ë³µì¡ë„ ê°ì†Œ
2. âœ… **ê³ ê¸‰ RoboVLMs ê¸°ëŠ¥ í†µí•©**: Claw Matrix, Hierarchical Planning, Advanced Attention
3. âœ… **ì‹¤ìš©ì  ì„±ëŠ¥**: ì‹¤ì œ ë¡œë´‡ ì œì–´ì— ì í•©í•œ ì„±ëŠ¥ ë‹¬ì„±
4. âœ… **ì •í™•í•œ í‰ê°€**: ë‹¤ì–‘í•œ ì„±ê³µë¥  ê³„ì‚° ë°©ì‹ìœ¼ë¡œ ì •í™•í•œ ì„±ëŠ¥ ì¸¡ì •
5. âœ… **ì™„ì „í•œ í”„ë¡œì íŠ¸**: í›ˆë ¨ë¶€í„° í‰ê°€ê¹Œì§€ ì „ì²´ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### í™˜ê²½ ì„¤ì •
```bash
# Poetry ì„¤ì¹˜ (ê¶Œì¥)
curl -sSL https://install.python-poetry.org | python3 -

# ì˜ì¡´ì„± ì„¤ì¹˜
poetry install

# ê°€ìƒí™˜ê²½ í™œì„±í™”
poetry shell
```

### ëª¨ë¸ í›ˆë ¨
```bash
# 2D ì•¡ì…˜ ìµœì í™” ëª¨ë¸ í›ˆë ¨
poetry run python optimized_2d_action_model.py
```

### ëª¨ë¸ í‰ê°€
```bash
# ì •í™•í•œ 2D ëª¨ë¸ í‰ê°€
poetry run python accurate_2d_evaluation.py

# ì¢…í•© ëª¨ë¸ ë¹„êµ
poetry run python comprehensive_model_comparison.py
```

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
Mobile_VLA/
â”œâ”€â”€ ğŸ“„ optimized_2d_action_model.py          # ìµœì¢… 2D ì•¡ì…˜ ìµœì í™” ëª¨ë¸
â”œâ”€â”€ ğŸ“„ fixed_claw_matrix.py                  # ìˆ˜ì •ëœ Claw Matrix êµ¬í˜„
â”œâ”€â”€ ğŸ“„ fixed_robovlms_model.py              # ìˆ˜ì •ëœ RoboVLMs ìŠ¤íƒ€ì¼ ëª¨ë¸
â”œâ”€â”€ ğŸ“„ train_fixed_robovlms.py              # RoboVLMs ìŠ¤íƒ€ì¼ ëª¨ë¸ í›ˆë ¨
â”œâ”€â”€ ğŸ“„ train_without_first_frame.py         # ì²« í”„ë ˆì„ ì œì™¸ í›ˆë ¨
â”œâ”€â”€ ğŸ“„ accurate_2d_evaluation.py            # ì •í™•í•œ 2D ëª¨ë¸ í‰ê°€
â”œâ”€â”€ ğŸ“„ comprehensive_model_comparison.py    # ì¢…í•© ëª¨ë¸ ë¹„êµ
â”œâ”€â”€ ğŸ“„ debug_2d_accuracy.py                 # ì„±ê³µë¥  ê³„ì‚° ë””ë²„ê¹…
â”œâ”€â”€ ğŸ“„ PROJECT_SUMMARY.md                   # í”„ë¡œì íŠ¸ ì™„ì„± ìš”ì•½
â””â”€â”€ ğŸ“„ README.md                            # ì´ íŒŒì¼
```

## ğŸ”§ í•µì‹¬ ê¸°ëŠ¥

### 1. 2D ì•¡ì…˜ ìµœì í™”
```python
# Zì¶• ì œì™¸í•˜ê³  2D ì•¡ì…˜ë§Œ ì˜ˆì¸¡
action_2d = single_action[:2]  # [linear_x, linear_y]ë§Œ ì‚¬ìš©
self.action_head = nn.Sequential(
    nn.Linear(hidden_dim, hidden_dim // 2),
    nn.ReLU(),
    nn.Dropout(dropout),
    nn.Linear(hidden_dim // 2, 2)  # 2D ì•¡ì…˜
)
```

### 2. Claw Matrix ìœµí•©
```python
# Vision-Language-Action ìœµí•©
class ClawMatrixFusion(nn.Module):
    def __init__(self, vision_dim, language_dim, action_dim, hidden_dim, dropout):
        # Cross-attention ë©”ì»¤ë‹ˆì¦˜ìœ¼ë¡œ ë‹¤ì¤‘ ëª¨ë‹¬ë¦¬í‹° ìœµí•©
        self.vl_cross_attention = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=8)
        self.la_cross_attention = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=8)
        self.av_cross_attention = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=8)
```

### 3. Hierarchical Planning
```python
# ì¥ê¸° ëª©í‘œë¥¼ ë‹¨ê¸° ì•¡ì…˜ìœ¼ë¡œ ë¶„í•´
class HierarchicalPlanner(nn.Module):
    def __init__(self, hidden_dim, action_dim, dropout):
        # ëª©í‘œ ë¶„í•´ ë° ê³„íš ìˆ˜ë¦½
        self.goal_decomposer = nn.Linear(hidden_dim, hidden_dim)
        self.action_planner = nn.Linear(hidden_dim, action_dim)
```

### 4. Advanced Attention
```python
# Cross-modal, temporal, hierarchical attention
class AdvancedAttention(nn.Module):
    def __init__(self, hidden_dim, dropout):
        # ê³ ê¸‰ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜
        self.cross_modal_attention = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=8)
        self.temporal_attention = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=8)
```

## ğŸ“Š ëª¨ë¸ ë¹„êµ ê²°ê³¼

### ì„±ëŠ¥ ìˆœìœ„ (MAE ê¸°ì¤€)
1. **Realistic (First Frame)**: 0.0014 (100% ì„±ê³µë¥ ) - íŠ¹ìˆ˜ ì¼€ì´ìŠ¤
2. **No First Frame (Random)**: 0.2405 (60% ì„±ê³µë¥ )
3. **No First Frame (Middle)**: 0.2646 (62.2% ì„±ê³µë¥ )
4. **ğŸ¥‰ Optimized 2D Action**: 0.2642 (51.4% ê°€ì¤‘ í‰ê·  ì„±ê³µë¥ )
5. **Realistic (Middle Frame)**: 0.5757 (48.9% ì„±ê³µë¥ )

### 2D vs 3D ëª¨ë¸ ë¹„êµ
- **2D ëª¨ë¸**: ì‹¤ì œ ë¡œë´‡ ì œì–´ì— ì í•©, ë³µì¡ë„ ë‚®ìŒ
- **3D ëª¨ë¸**: ëª¨ë“  ì°¨ì› í¬í•¨, ë³µì¡ë„ ë†’ìŒ
- **ê²°ë¡ **: 2D ëª¨ë¸ì´ ì‹¤ìš©ì  ì„±ëŠ¥ê³¼ ë³µì¡ë„ ë©´ì—ì„œ ìš°ìˆ˜

## ğŸ¯ ì£¼ìš” í•™ìŠµ ë° ì¸ì‚¬ì´íŠ¸

### 1. ë°ì´í„° íŠ¹ì„± ì´í•´ì˜ ì¤‘ìš”ì„±
- ì²« í”„ë ˆì„ì´ 0ìœ¼ë¡œ ê³ ì •ëœ íŠ¹ì„± ë°œê²¬
- Zì¶• ì‚¬ìš©ë¥ ì´ ë‚®ë‹¤ëŠ” íŠ¹ì„± ë°œê²¬ (5% ë¯¸ë§Œ)
- ë°ì´í„° íŠ¹ì„±ì„ ë°˜ì˜í•œ ëª¨ë¸ ìµœì í™”

### 2. ì„±ê³µë¥  ê³„ì‚°ì˜ ë³µì¡ì„±
- ë‹¨ìˆœí•œ "ëª¨ë“  ì°¨ì› ë™ì‹œ ì„±ê³µ" ë°©ì‹ì˜ í•œê³„
- ê°œë³„ ì°¨ì›ë³„ ì„±ëŠ¥ê³¼ ì „ì²´ ì„±ëŠ¥ì˜ ì°¨ì´
- ë‹¤ì–‘í•œ ê³„ì‚° ë°©ì‹ì˜ í•„ìš”ì„±

### 3. ì ì§„ì  ê°œì„ ì˜ íš¨ê³¼
- ê¸°ë³¸ ëª¨ë¸ â†’ ë°ì´í„° ì¦ê°• â†’ ê³ ê¸‰ ê¸°ëŠ¥ â†’ ìµœì í™”
- ê° ë‹¨ê³„ë³„ ë¬¸ì œ í•´ê²°ê³¼ ì„±ëŠ¥ í–¥ìƒ
- ì²´ê³„ì ì¸ ì ‘ê·¼ì˜ ì¤‘ìš”ì„±

### 4. ì‹¤ìš©ì„± vs ì •í™•ì„±ì˜ ê· í˜•
- 100% ì •í™•ë„ê°€ í•­ìƒ ì¢‹ì€ ê²ƒì€ ì•„ë‹˜
- ì‹¤ì œ ì‚¬ìš© í™˜ê²½ì„ ê³ ë ¤í•œ ì„±ëŠ¥ í‰ê°€
- ì‹¤ìš©ì ì¸ ì„±ëŠ¥ ì§€í‘œì˜ ì¤‘ìš”ì„±

## ğŸš€ í–¥í›„ ê°œì„  ë°©í–¥

### 1. Linear_Y ì„±ëŠ¥ í–¥ìƒ
- í˜„ì¬ 26.4% ì„±ê³µë¥  â†’ ëª©í‘œ 50% ì´ìƒ
- ì¢Œìš° ì´ë™ ë°ì´í„° ì¦ê°•
- Yì¶• ì˜ˆì¸¡ì— íŠ¹í™”ëœ ëª¨ë¸ êµ¬ì¡°

### 2. ì•™ìƒë¸” ëª¨ë¸
- ì—¬ëŸ¬ ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°í•©
- ì„±ëŠ¥ í–¥ìƒ ë° ì•ˆì •ì„± ê°œì„ 

### 3. ì‹¤ì‹œê°„ ì¶”ë¡  ìµœì í™”
- ì¶”ë¡  ì†ë„ ê°œì„ 
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”

### 4. ì‹¤ì œ ë¡œë´‡ í…ŒìŠ¤íŠ¸
- ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½ì—ì„œ ì‹¤ì œ í…ŒìŠ¤íŠ¸
- ì‹¤ì œ í™˜ê²½ì—ì„œì˜ ì„±ëŠ¥ ê²€ì¦

## ğŸ“ ê°œë°œ ê³¼ì • ìš”ì•½

### 1ë‹¨ê³„: ì´ˆê¸° ë¬¸ì œ í•´ê²°
- í„°ë¯¸ë„ ë¡œê·¸ ë¶„ì„ â†’ Mobile VLA í›ˆë ¨ íŒŒì´í”„ë¼ì¸ ë””ë²„ê¹…
- Gradient ê³„ì‚° ë¬¸ì œ í•´ê²°
- Tensor ì°¨ì› ë¶ˆì¼ì¹˜ ìˆ˜ì •

### 2ë‹¨ê³„: ë°ì´í„° ì¦ê°• ì „ëµ
- Simple Augmentation â†’ Task-Specific Augmentation â†’ Distance-Aware Augmentation
- HDF5 â†’ Folder-based ë°ì´í„° ë³€í™˜

### 3ë‹¨ê³„: RoboVLMs ê³ ê¸‰ ê¸°ëŠ¥ í†µí•©
- Claw Matrix: Vision-Language-Action ìœµí•©
- Hierarchical Planning: ì¥ê¸° ëª©í‘œë¥¼ ë‹¨ê¸° ì•¡ì…˜ìœ¼ë¡œ ë¶„í•´
- Advanced Attention: Cross-modal, temporal, hierarchical attention

### 4ë‹¨ê³„: ëª¨ë¸ ìŠ¤íƒ€ì¼ ì •ì˜ ë° ìµœì í™”
- RoboVLMs ìŠ¤íƒ€ì¼: ë‹¨ì¼ ì´ë¯¸ì§€ â†’ ë‹¨ì¼ ì•¡ì…˜
- 100% ì •í™•ë„ ë¬¸ì œ ë°œê²¬ ë° í•´ê²°

### 5ë‹¨ê³„: 2D ì•¡ì…˜ ìµœì í™”
- Zì¶• ì‚¬ìš©ë¥  ë¶„ì„ (5% ë¯¸ë§Œ)
- 2D ì•¡ì…˜ ëª¨ë¸ë¡œ ìµœì í™”
- ì„±ê³µë¥  ê³„ì‚° ë°©ì‹ ê°œì„ 

## ğŸ” ê¸°ìˆ ì  í•´ê²°ì±…

### 1. ì°¨ì› ë¬¸ì œ í•´ê²°
```python
# ë™ì  ì–´ëŒ‘í„° ìƒì„±
if language_features.shape[-1] != self.language_dim:
    if self.language_adapter is None:
        self.language_adapter = nn.Linear(
            language_features.shape[-1], self.language_dim
        ).to(language_features.device)
```

### 2. Kosmos2 ì…ë ¥ ì²˜ë¦¬
```python
# Visionê³¼ Language ëª¨ë¸ ë¶„ë¦¬ ì‚¬ìš©
vision_outputs = self.kosmos.vision_model(inputs['pixel_values'])
language_outputs = self.kosmos.text_model(**inputs)
```

### 3. ì •í™•í•œ ì„±ê³µë¥  ê³„ì‚°
```python
# ë‹¤ì–‘í•œ ê³„ì‚° ë°©ì‹
# 1. ê°œë³„ ì°¨ì›ë³„ ì„±ê³µë¥ 
linear_x_success = np.mean(all_errors[:, 0] < threshold) * 100
linear_y_success = np.mean(all_errors[:, 1] < threshold) * 100

# 2. ì „ì²´ ì„±ê³µë¥  (ëª¨ë“  ì°¨ì› ë™ì‹œ)
all_success = np.mean(np.all(all_errors < threshold, axis=1)) * 100

# 3. ê°€ì¤‘ í‰ê·  ì„±ê³µë¥ 
weighted_errors = 0.7 * all_errors[:, 0] + 0.3 * all_errors[:, 1]
weighted_success = np.mean(weighted_errors < threshold) * 100
```

## ğŸ“Š ì„±ëŠ¥ ë¶„ì„ ê²°ê³¼

### ì°¨ì›ë³„ ìƒì„¸ ì„±ëŠ¥
**Linear_X (ì „ì§„/í›„ì§„):**
- MAE: 0.0726 (ë§¤ìš° ì •í™•!)
- RMSE: 0.1914
- 0.1 ì„ê³„ê°’ ì„±ê³µë¥ : 90.3% (ìš°ìˆ˜)
- ì¤‘ê°„ê°’ ì˜¤ì°¨: 0.0323

**Linear_Y (ì¢Œìš° ì´ë™):**
- MAE: 0.4558 (ê°œì„  í•„ìš”)
- RMSE: 0.6455
- 0.1 ì„ê³„ê°’ ì„±ê³µë¥ : 26.4% (ë‚®ìŒ)
- ì¤‘ê°„ê°’ ì˜¤ì°¨: 0.2229

### ì„±ê³µë¥  ë¹„êµ (ë‹¤ì–‘í•œ ê³„ì‚° ë°©ì‹)
| ì„ê³„ê°’ | Linear_X | Linear_Y | ì „ì²´(ë™ì‹œ) | í‰ê·  | ê°€ì¤‘í‰ê·  |
|--------|----------|----------|------------|------|----------|
| 0.01   | 18.1%    | 6.9%     | 0.0%       | 0.0% | 0.0%     |
| 0.05   | 76.4%    | 13.9%    | 12.5%      | 16.7%| 25.0%    |
| **0.1**| **90.3%**| **26.4%**| **26.4%**  | **40.3%**| **51.4%**|
| 0.2    | 94.4%    | 43.1%    | 41.7%      | 59.7%| 59.7%    |
| 0.5    | 95.8%    | 63.9%    | 61.1%      | 75.0%| 97.2%    |

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ `LICENSE` íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.

## ğŸ“ ì—°ë½ì²˜

í”„ë¡œì íŠ¸ì— ëŒ€í•œ ì§ˆë¬¸ì´ë‚˜ ì œì•ˆì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì´ìŠˆë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”.

## ğŸ“š ì°¸ê³  ìë£Œ

- [Kosmos2 Paper](https://arxiv.org/abs/2306.14824)
- [RoboVLMs Paper](https://arxiv.org/abs/2401.03792)
- [Vision-Language-Action Models](https://arxiv.org/abs/2307.15862)

---

**í”„ë¡œì íŠ¸ ì™„ë£Œì¼**: 2024ë…„ 8ì›” 21ì¼  
**ì´ ê°œë°œ ê¸°ê°„**: ì•½ 3ì£¼  
**ìµœì¢… ëª¨ë¸**: Optimized 2D Action Model with RoboVLMs Advanced Features  
**ìƒíƒœ**: âœ… **ì™„ë£Œ ë° ê²€ì¦ ì™„ë£Œ**
