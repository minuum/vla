#!/usr/bin/env python3
"""
Mobile Policy Head - mobile_vla_data_collector.pyì˜ 3D ì•¡ì…˜ ì˜ˆì¸¡ íŠ¹í™”
RoboVLMsì˜ ì •ì±… í—¤ë“œë¥¼ Mobile VLA ì•¡ì…˜ ê³µê°„ì— ì ì‘
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, Tuple, Optional
import logging

logger = logging.getLogger(__name__)


class MobilePolicyHead(nn.Module):
    """
    Mobile VLA íŠ¹í™” ì •ì±… í—¤ë“œ
    - ì…ë ¥: [B, T, hidden_size] ë©€í‹°ëª¨ë‹¬ íŠ¹ì§•
    - ì¶œë ¥: [B, T, 3] mobile_vla_data_collector.py í˜¸í™˜ ì•¡ì…˜
    - ì•¡ì…˜: [linear_x, linear_y, angular_z] + ì´ë²¤íŠ¸ ì˜ˆì¸¡
    """
    
    def __init__(
        self,
        hidden_size: int = 768,
        action_dim: int = 3,  # mobile_vla_data_collector.py ì•¡ì…˜ ì°¨ì›
        num_event_types: int = 3,  # episode_start, start_action, stop_action
        dropout: float = 0.1,
        use_lstm: bool = True,
        lstm_layers: int = 2
    ):
        super().__init__()
        
        self.hidden_size = hidden_size
        self.action_dim = action_dim
        self.num_event_types = num_event_types
        
        # mobile_vla_data_collector.pyì˜ ì•¡ì…˜ ë²”ìœ„ (WASD_TO_CONTINUOUS ê¸°ì¤€)
        self.action_bounds = {
            "linear_x": 2.0,   # ì‹¤ì œ Â±1.15, ì—¬ìœ ìˆê²Œ Â±2.0
            "linear_y": 2.0,   # ì‹¤ì œ Â±1.15, ì—¬ìœ ìˆê²Œ Â±2.0
            "angular_z": 2.0   # ì‹¤ì œ Â±1.15, ì—¬ìœ ìˆê²Œ Â±2.0
        }
        
        # ì‹œê°„ì  ì˜ì¡´ì„±ì„ ìœ„í•œ LSTM (ì˜µì…˜)
        if use_lstm:
            self.temporal_encoder = nn.LSTM(
                input_size=hidden_size,
                hidden_size=hidden_size,
                num_layers=lstm_layers,
                batch_first=True,
                dropout=dropout if lstm_layers > 1 else 0,
                bidirectional=False
            )
        else:
            self.temporal_encoder = None
        
        # ì—°ì† ì•¡ì…˜ ì˜ˆì¸¡ í—¤ë“œ (linear_x, linear_y, angular_z)
        self.action_head = nn.Sequential(
            nn.Linear(hidden_size, 512),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(256, action_dim),
            nn.Tanh()  # [-1, 1] ë²”ìœ„ë¡œ ì •ê·œí™”
        )
        
        # ì´ë²¤íŠ¸ íƒ€ì… ì˜ˆì¸¡ í—¤ë“œ (episode_start, start_action, stop_action)
        self.event_head = nn.Sequential(
            nn.Linear(hidden_size, 256),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(128, num_event_types)  # ë¶„ë¥˜ ë¡œì§“
        )
        
        # ì•¡ì…˜ ê°’ ë¶„í¬ ì˜ˆì¸¡ (ë¶ˆí™•ì‹¤ì„± ì¶”ì •ìš©)
        self.action_variance_head = nn.Sequential(
            nn.Linear(hidden_size, 256),
            nn.ReLU(),
            nn.Linear(256, action_dim),
            nn.Softplus()  # ì–‘ìˆ˜ ë¶„ì‚°
        )
        
        # ì¶œë ¥ ë ˆì´ì–´ ì •ê·œí™”
        self.layer_norm = nn.LayerNorm(hidden_size)
        
        logger.info(f"ğŸ¯ Mobile Policy Head ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info(f"   ì•¡ì…˜ ì°¨ì›: {action_dim}, ì´ë²¤íŠ¸ íƒ€ì…: {num_event_types}")
        logger.info(f"   LSTM ì‚¬ìš©: {use_lstm}, Hidden: {hidden_size}")
    
    def forward(
        self, 
        multimodal_features: torch.Tensor,
        return_uncertainty: bool = False
    ) -> Dict[str, torch.Tensor]:
        """
        Args:
            multimodal_features: [B, T, hidden_size] - ì´ë¯¸ì§€+í…ìŠ¤íŠ¸ ìœµí•© íŠ¹ì§•
            return_uncertainty: ë¶ˆí™•ì‹¤ì„± ì¶”ì • í¬í•¨ ì—¬ë¶€
            
        Returns:
            dict with:
                - actions: [B, T, 3] - ì •ê·œí™”ëœ ì•¡ì…˜ [-1, 1]
                - actions_denorm: [B, T, 3] - ì‹¤ì œ ì•¡ì…˜ ë²”ìœ„
                - event_logits: [B, T, 3] - ì´ë²¤íŠ¸ íƒ€ì… ë¡œì§“
                - event_probs: [B, T, 3] - ì´ë²¤íŠ¸ íƒ€ì… í™•ë¥ 
                - action_variance: [B, T, 3] - ì•¡ì…˜ ë¶ˆí™•ì‹¤ì„± (ì˜µì…˜)
        """
        # ì…ë ¥ ì •ê·œí™”
        features = self.layer_norm(multimodal_features)  # [B, T, hidden_size]
        
        # ì‹œê°„ì  ì¸ì½”ë”© (LSTM ì‚¬ìš©ì‹œ)
        if self.temporal_encoder is not None:
            temporal_features, (hidden, cell) = self.temporal_encoder(features)
        else:
            temporal_features = features
        
        # ì—°ì† ì•¡ì…˜ ì˜ˆì¸¡ (ì •ê·œí™”ëœ [-1, 1] ë²”ìœ„)
        normalized_actions = self.action_head(temporal_features)  # [B, T, 3]
        
        # ì‹¤ì œ ì•¡ì…˜ ë²”ìœ„ë¡œ ë³€í™˜
        denormalized_actions = self.denormalize_actions(normalized_actions)
        
        # ì´ë²¤íŠ¸ íƒ€ì… ì˜ˆì¸¡
        event_logits = self.event_head(temporal_features)  # [B, T, 3]
        event_probs = F.softmax(event_logits, dim=-1)
        
        result = {
            "actions": normalized_actions,      # [-1, 1] ì •ê·œí™”ëœ ì•¡ì…˜
            "actions_denorm": denormalized_actions,  # ì‹¤ì œ ë²”ìœ„ ì•¡ì…˜
            "event_logits": event_logits,       # ì´ë²¤íŠ¸ ë¶„ë¥˜ ë¡œì§“
            "event_probs": event_probs,         # ì´ë²¤íŠ¸ í™•ë¥ 
            "predicted_events": torch.argmax(event_logits, dim=-1)  # [B, T] ì˜ˆì¸¡ëœ ì´ë²¤íŠ¸
        }
        
        # ë¶ˆí™•ì‹¤ì„± ì¶”ì • (ì˜µì…˜)
        if return_uncertainty:
            action_variance = self.action_variance_head(temporal_features)
            result["action_variance"] = action_variance
        
        return result
    
    def denormalize_actions(self, normalized_actions: torch.Tensor) -> torch.Tensor:
        """ì •ê·œí™”ëœ ì•¡ì…˜ [-1, 1]ì„ ì‹¤ì œ ë²”ìœ„ë¡œ ë³€í™˜"""
        # normalized_actions: [B, T, 3] ë²”ìœ„ [-1, 1]
        denormalized = normalized_actions.clone()
        
        # mobile_vla_data_collector.py ë²”ìœ„ë¡œ ìŠ¤ì¼€ì¼ë§
        denormalized[..., 0] = normalized_actions[..., 0] * self.action_bounds["linear_x"]    # linear_x
        denormalized[..., 1] = normalized_actions[..., 1] * self.action_bounds["linear_y"]    # linear_y
        denormalized[..., 2] = normalized_actions[..., 2] * self.action_bounds["angular_z"]   # angular_z
        
        return denormalized
    
    def convert_to_robovlms_action(self, mobile_actions: torch.Tensor) -> torch.Tensor:
        """Mobile VLA 3D ì•¡ì…˜ì„ RoboVLMs 7D ì•¡ì…˜ìœ¼ë¡œ ë³€í™˜"""
        # mobile_actions: [B, T, 3] - [linear_x, linear_y, angular_z]
        # RoboVLMs format: [B, T, 7] - [x, y, z, rx, ry, rz, gripper]
        B, T, _ = mobile_actions.shape
        device = mobile_actions.device
        
        robovlms_actions = torch.zeros(B, T, 7, device=device, dtype=mobile_actions.dtype)
        
        # Mobile actionsì„ 6DOF poseë¡œ ë§¤í•‘ (gripper ì‚¬ìš© ì•ˆí•¨)
        robovlms_actions[..., 0] = mobile_actions[..., 0]  # linear_x â†’ x
        robovlms_actions[..., 1] = mobile_actions[..., 1]  # linear_y â†’ y  
        robovlms_actions[..., 2] = 0.0                     # z = 0 (í‰ë©´ ì´ë™)
        robovlms_actions[..., 3] = 0.0                     # rx = 0 (roll)
        robovlms_actions[..., 4] = 0.0                     # ry = 0 (pitch)
        robovlms_actions[..., 5] = mobile_actions[..., 2]  # angular_z â†’ rz (yaw)
        robovlms_actions[..., 6] = 0.0                     # gripper = 0 (ì‚¬ìš© ì•ˆí•¨)
        
        return robovlms_actions
    
    def convert_events_to_action_mask(self, event_indices: torch.Tensor) -> torch.Tensor:
        """Mobile VLA ì´ë²¤íŠ¸ë¥¼ RoboVLMs action_maskë¡œ ë³€í™˜"""
        # event_indices: [B, T] - [0: episode_start, 1: start_action, 2: stop_action]
        # action_mask: [B, T] - ì•¡ì…˜ì´ ìœ íš¨í•œì§€ (1: ìœ íš¨, 0: ë¬´íš¨)
        
        # start_action(1)ë§Œ ìœ íš¨í•œ ì•¡ì…˜ìœ¼ë¡œ ê°„ì£¼
        action_mask = (event_indices == 1).float()
        
        return action_mask
    
    def normalize_actions(self, actions: torch.Tensor) -> torch.Tensor:
        """ì‹¤ì œ ë²”ìœ„ ì•¡ì…˜ì„ [-1, 1]ë¡œ ì •ê·œí™”"""
        normalized = actions.clone()
        
        normalized[..., 0] = actions[..., 0] / self.action_bounds["linear_x"]    # linear_x
        normalized[..., 1] = actions[..., 1] / self.action_bounds["linear_y"]    # linear_y
        normalized[..., 2] = actions[..., 2] / self.action_bounds["angular_z"]   # angular_z
        
        # í´ë¨í•‘ [-1, 1]
        normalized = torch.clamp(normalized, -1.0, 1.0)
        
        return normalized
    
    def predict_single_step(
        self, 
        single_feature: torch.Tensor,
        hidden_state: Optional[Tuple[torch.Tensor, torch.Tensor]] = None
    ) -> Tuple[Dict[str, torch.Tensor], Optional[Tuple[torch.Tensor, torch.Tensor]]]:
        """ë‹¨ì¼ ìŠ¤í… ì˜ˆì¸¡ (ì‹¤ì‹œê°„ ì¶”ë¡ ìš©)"""
        # single_feature: [B, hidden_size] ë˜ëŠ” [B, 1, hidden_size]
        if single_feature.dim() == 2:
            single_feature = single_feature.unsqueeze(1)  # [B, 1, hidden_size]
        
        features = self.layer_norm(single_feature)
        
        # LSTM ìŠ¤í…ë³„ ì‹¤í–‰ (hidden_state ìœ ì§€)
        new_hidden_state = None
        if self.temporal_encoder is not None:
            if hidden_state is not None:
                temporal_features, new_hidden_state = self.temporal_encoder(features, hidden_state)
            else:
                temporal_features, new_hidden_state = self.temporal_encoder(features)
        else:
            temporal_features = features
        
        # ì•¡ì…˜ ë° ì´ë²¤íŠ¸ ì˜ˆì¸¡
        normalized_actions = self.action_head(temporal_features)  # [B, 1, 3]
        denormalized_actions = self.denormalize_actions(normalized_actions)
        event_logits = self.event_head(temporal_features)  # [B, 1, 3]
        
        result = {
            "actions": normalized_actions.squeeze(1),      # [B, 3]
            "actions_denorm": denormalized_actions.squeeze(1),  # [B, 3]
            "event_logits": event_logits.squeeze(1),       # [B, 3]
            "predicted_events": torch.argmax(event_logits, dim=-1).squeeze(1)  # [B]
        }
        
        return result, new_hidden_state
    
    def compute_action_loss(
        self, 
        predicted_actions: torch.Tensor, 
        target_actions: torch.Tensor,
        sequence_mask: Optional[torch.Tensor] = None
    ) -> torch.Tensor:
        """ì•¡ì…˜ ì˜ˆì¸¡ ì†ì‹¤ ê³„ì‚°"""
        # MSE ì†ì‹¤
        action_loss = F.mse_loss(predicted_actions, target_actions, reduction='none')  # [B, T, 3]
        
        # ì‹œí€€ìŠ¤ ë§ˆìŠ¤í‚¹ (íŒ¨ë”©ëœ ë¶€ë¶„ ì œì™¸)
        if sequence_mask is not None:
            mask = sequence_mask.unsqueeze(-1).float()  # [B, T, 1]
            action_loss = action_loss * mask
            return action_loss.sum() / mask.sum()
        
        return action_loss.mean()
    
    def compute_event_loss(
        self,
        predicted_event_logits: torch.Tensor,
        target_events: torch.Tensor,
        sequence_mask: Optional[torch.Tensor] = None
    ) -> torch.Tensor:
        """ì´ë²¤íŠ¸ ì˜ˆì¸¡ ì†ì‹¤ ê³„ì‚°"""
        # Cross-entropy ì†ì‹¤
        B, T, num_classes = predicted_event_logits.shape
        event_loss = F.cross_entropy(
            predicted_event_logits.view(B * T, num_classes),
            target_events.view(B * T),
            reduction='none'
        ).view(B, T)
        
        # ì‹œí€€ìŠ¤ ë§ˆìŠ¤í‚¹
        if sequence_mask is not None:
            mask = sequence_mask.float()  # [B, T]
            event_loss = event_loss * mask
            return event_loss.sum() / mask.sum()
        
        return event_loss.mean()


class MobilePolicyHeadLite(nn.Module):
    """
    ê²½ëŸ‰í™”ëœ Mobile Policy Head (Jetsonìš©)
    LSTM ì—†ì´ ë” ë‹¨ìˆœí•œ MLPë§Œ ì‚¬ìš©
    """
    
    def __init__(
        self,
        hidden_size: int = 512,
        action_dim: int = 3,
        dropout: float = 0.1
    ):
        super().__init__()
        
        self.hidden_size = hidden_size
        self.action_dim = action_dim
        
        # ì•¡ì…˜ ë²”ìœ„
        self.action_bounds = {
            "linear_x": 2.0, "linear_y": 2.0, "angular_z": 2.0
        }
        
        # ê°„ë‹¨í•œ ì•¡ì…˜ í—¤ë“œ
        self.action_head = nn.Sequential(
            nn.Linear(hidden_size, 256),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(256, action_dim),
            nn.Tanh()
        )
        
        # ê°„ë‹¨í•œ ì´ë²¤íŠ¸ í—¤ë“œ
        self.event_head = nn.Sequential(
            nn.Linear(hidden_size, 128),
            nn.ReLU(),
            nn.Linear(128, 3)
        )
        
        logger.info(f"ğŸš€ Mobile Policy Head Lite ì´ˆê¸°í™” (Hidden: {hidden_size})")
    
    def forward(self, features: torch.Tensor) -> Dict[str, torch.Tensor]:
        normalized_actions = self.action_head(features)
        denormalized_actions = self.denormalize_actions(normalized_actions)
        event_logits = self.event_head(features)
        
        return {
            "actions": normalized_actions,
            "actions_denorm": denormalized_actions,
            "event_logits": event_logits,
            "predicted_events": torch.argmax(event_logits, dim=-1)
        }
    
    def denormalize_actions(self, normalized_actions: torch.Tensor) -> torch.Tensor:
        denormalized = normalized_actions.clone()
        denormalized[..., 0] *= self.action_bounds["linear_x"]
        denormalized[..., 1] *= self.action_bounds["linear_y"]
        denormalized[..., 2] *= self.action_bounds["angular_z"]
        return denormalized


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    print("ğŸ§ª Mobile Policy Head í…ŒìŠ¤íŠ¸")
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    policy_head = MobilePolicyHead(hidden_size=768)
    policy_head_lite = MobilePolicyHeadLite(hidden_size=512)
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    batch_size, seq_len, hidden_size = 2, 18, 768
    test_features = torch.randn(batch_size, seq_len, hidden_size)
    test_features_lite = torch.randn(batch_size, seq_len, 512)
    
    print(f"ğŸ“Š ì…ë ¥ íŠ¹ì§•: {test_features.shape}")
    
    # ì¼ë°˜ ì •ì±… í—¤ë“œ í…ŒìŠ¤íŠ¸
    with torch.no_grad():
        result = policy_head(test_features, return_uncertainty=True)
        print(f"ğŸ¯ ì•¡ì…˜ ì¶œë ¥: {result['actions'].shape}")
        print(f"ğŸ¯ ì‹¤ì œ ì•¡ì…˜: {result['actions_denorm'].shape}")
        print(f"âš¡ ì´ë²¤íŠ¸ ë¡œì§“: {result['event_logits'].shape}")
        print(f"ğŸ“Š ì•¡ì…˜ ë¶„ì‚°: {result['action_variance'].shape}")
        
        # Lite ì •ì±… í—¤ë“œ í…ŒìŠ¤íŠ¸
        result_lite = policy_head_lite(test_features_lite)
        print(f"ğŸš€ Lite ì•¡ì…˜: {result_lite['actions'].shape}")
    
    # ì•¡ì…˜ ë²”ìœ„ í™•ì¸
    sample_actions = result['actions_denorm'][0, :3]  # ì²« 3í”„ë ˆì„
    print(f"ğŸ“ˆ ìƒ˜í”Œ ì•¡ì…˜ (ì‹¤ì œ ë²”ìœ„): {sample_actions}")
    print(f"   Linear X: {sample_actions[:, 0].min():.2f} ~ {sample_actions[:, 0].max():.2f}")
    print(f"   Linear Y: {sample_actions[:, 1].min():.2f} ~ {sample_actions[:, 1].max():.2f}")
    print(f"   Angular Z: {sample_actions[:, 2].min():.2f} ~ {sample_actions[:, 2].max():.2f}")
    
    # íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°
    total_params = sum(p.numel() for p in policy_head.parameters())
    lite_params = sum(p.numel() for p in policy_head_lite.parameters())
    
    print(f"ğŸ“Š ì¼ë°˜ ì •ì±… í—¤ë“œ íŒŒë¼ë¯¸í„°: {total_params:,}ê°œ ({total_params/1e6:.1f}M)")
    print(f"ğŸš€ Lite ì •ì±… í—¤ë“œ íŒŒë¼ë¯¸í„°: {lite_params:,}ê°œ ({lite_params/1e6:.1f}M)")
    print(f"ğŸ’¡ íŒŒë¼ë¯¸í„° ê°ì†Œìœ¨: {(1 - lite_params/total_params)*100:.1f}%")
