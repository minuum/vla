#!/usr/bin/env python3
"""
Kosmos Trainer for Mobile VLA - Kosmos ëª¨ë¸ì„ Mobile VLA ë°ì´í„°ë¡œ í•™ìŠµ
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from typing import Dict, List, Optional, Any
import logging
from transformers import Kosmos2ForConditionalGeneration, AutoProcessor

try:
    from ..data.robovlms_adapter import MobileVLAToRoboVLMsAdapter
    from ..models.policy_heads.mobile_policy_head import MobilePolicyHead
except ImportError:
    # í…ŒìŠ¤íŠ¸ìš© ì ˆëŒ€ ì„í¬íŠ¸
    import sys
    import os
    parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    sys.path.append(parent_dir)
    from data.robovlms_adapter import MobileVLAToRoboVLMsAdapter
    from models.policy_heads.mobile_policy_head import MobilePolicyHead

logger = logging.getLogger(__name__)


class MobileKosmosModel(nn.Module):
    """
    Mobile VLA + Kosmos í†µí•© ëª¨ë¸
    """
    
    def __init__(
        self,
        kosmos_model_name: str = "microsoft/kosmos-2-patch14-224",
        hidden_size: int = 768,
        action_dim: int = 7,  # RoboVLMs í˜¸í™˜
        freeze_kosmos: bool = True
    ):
        super().__init__()
        
        # Kosmos ëª¨ë¸ ë¡œë“œ
        self.kosmos = Kosmos2ForConditionalGeneration.from_pretrained(
            kosmos_model_name,
            torch_dtype=torch.bfloat16
        )
        self.processor = AutoProcessor.from_pretrained(kosmos_model_name)
        
        # Kosmos ê°€ì¤‘ì¹˜ ê³ ì • ì˜µì…˜
        if freeze_kosmos:
            for param in self.kosmos.parameters():
                param.requires_grad = False
            logger.info("ğŸ”’ Kosmos ê°€ì¤‘ì¹˜ ê³ ì •ë¨")
        
        # Kosmos íŠ¹ì§• ì°¨ì›
        kosmos_hidden_size = self.kosmos.config.text_config.hidden_size
        
        # íŠ¹ì§• í”„ë¡œì ì…˜ (Kosmos â†’ Mobile VLA)
        self.feature_projection = nn.Sequential(
            nn.Linear(kosmos_hidden_size, hidden_size),
            nn.ReLU(),
            nn.Dropout(0.1)
        )
        
        # Mobile VLA ì •ì±… í—¤ë“œ (3D ì•¡ì…˜ ìœ ì§€)
        self.policy_head = MobilePolicyHead(
            hidden_size=hidden_size,
            action_dim=3,  # Mobile VLA ì›ë³¸: [linear_x, linear_y, angular_z]
            dropout=0.1
        )
        
        logger.info(f"ğŸ¤– Mobile Kosmos Model ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info(f"   Kosmos Hidden: {kosmos_hidden_size}, Mobile Hidden: {hidden_size}")
    
    def forward(
        self,
        pixel_values: torch.Tensor,
        input_ids: torch.Tensor,
        attention_mask: Optional[torch.Tensor] = None
    ) -> Dict[str, torch.Tensor]:
        """
        Args:
            pixel_values: [B, T, 3, 224, 224] or [B, 1, T, 3, 224, 224] - ì´ë¯¸ì§€ ì‹œí€€ìŠ¤
            input_ids: [B, seq_len] - í† í¬ë‚˜ì´ì¦ˆëœ í…ìŠ¤íŠ¸
            attention_mask: [B, seq_len] - ì–´í…ì…˜ ë§ˆìŠ¤í¬
        """
        # ì°¨ì› ì•ˆì „ ì²˜ë¦¬
        if pixel_values.dim() == 6:  # [B, 1, T, C, H, W]
            pixel_values = pixel_values.squeeze(1)  # [B, T, C, H, W]
        elif pixel_values.dim() == 5:  # [B, T, C, H, W] - ì´ë¯¸ ì˜¬ë°”ë¥¸ í˜•íƒœ
            pass
        else:
            raise ValueError(f"Unexpected pixel_values shape: {pixel_values.shape}")
            
        B, T, C, H, W = pixel_values.shape
        
        # ë°°ì¹˜ì™€ ì‹œê°„ ì°¨ì›ì„ í•©ì³ì„œ Kosmosì— ì…ë ¥
        images_flat = pixel_values.view(B * T, C, H, W)  # [B*T, 3, 224, 224]
        
        # í…ìŠ¤íŠ¸ëŠ” ë°°ì¹˜ë³„ë¡œ ë°˜ë³µ
        input_ids_expanded = input_ids.unsqueeze(1).repeat(1, T, 1).view(B * T, -1)  # [B*T, seq_len]
        if attention_mask is not None:
            attention_mask_expanded = attention_mask.unsqueeze(1).repeat(1, T, 1).view(B * T, -1)
        else:
            attention_mask_expanded = None
        
        # Kosmos ìˆœì „íŒŒ (ì˜¬ë°”ë¥¸ ë°©ë²•)
        with torch.cuda.amp.autocast(enabled=True):
            # Kosmosì˜ ê²½ìš° pixel_values ì—†ì´ text-onlyë¡œ ë¨¼ì € ì‹œë„
            # ë”ë¯¸ í…ìŠ¤íŠ¸ ì…ë ¥ ì‚¬ìš© (ì´ë¯¸ì§€ í† í° ì—†ìŒ)
            kosmos_output = self.kosmos.text_model(
                input_ids=input_ids_expanded,
                attention_mask=attention_mask_expanded,
                output_hidden_states=True
            )
        
        # ë§ˆì§€ë§‰ hidden state ì¶”ì¶œ
        last_hidden_state = kosmos_output.hidden_states[-1]  # [B*T, seq_len, kosmos_hidden]
        
        # í‰ê·  í’€ë§ìœ¼ë¡œ ì‹œí€€ìŠ¤ íŠ¹ì§• ì••ì¶•
        if attention_mask_expanded is not None:
            mask = attention_mask_expanded.unsqueeze(-1).float()  # [B*T, seq_len, 1]
            pooled_features = (last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1)  # [B*T, kosmos_hidden]
        else:
            pooled_features = last_hidden_state.mean(dim=1)  # [B*T, kosmos_hidden]
        
        # ì‹œê°„ ì°¨ì› ë³µì›
        pooled_features = pooled_features.view(B, T, -1)  # [B, T, kosmos_hidden]
        
        # íŠ¹ì§• í”„ë¡œì ì…˜
        mobile_features = self.feature_projection(pooled_features)  # [B, T, hidden_size]
        
        # ì •ì±… í—¤ë“œë¡œ ì•¡ì…˜ ì˜ˆì¸¡
        policy_output = self.policy_head(mobile_features)
        
        return policy_output


class MobileKosmosTrainer:
    """
    Mobile VLA + Kosmos íŠ¸ë ˆì´ë„ˆ
    """
    
    def __init__(self, configs: Dict[str, Any]):
        self.configs = configs
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self.model = MobileKosmosModel(
            kosmos_model_name=configs.get("kosmos_model_name", "microsoft/kosmos-2-patch14-224"),
            hidden_size=configs.get("hidden_size", 768),
            freeze_kosmos=configs.get("freeze_kosmos", True)
        ).to(self.device)
        
        # ì†ì‹¤ í•¨ìˆ˜ ê°€ì¤‘ì¹˜
        self.action_loss_weight = configs.get("action_loss_weight", 1.0)
        self.event_loss_weight = configs.get("event_loss_weight", 0.5)
        
        # ì˜µí‹°ë§ˆì´ì € (Kosmosê°€ ê³ ì •ëœ ê²½ìš° ì •ì±… í—¤ë“œë§Œ í•™ìŠµ)
        trainable_params = [p for p in self.model.parameters() if p.requires_grad]
        self.optimizer = torch.optim.AdamW(
            trainable_params,
            lr=configs.get("learning_rate", 1e-4),
            weight_decay=configs.get("weight_decay", 0.01)
        )
        
        # ìŠ¤ì¼€ì¤„ëŸ¬
        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            self.optimizer,
            T_max=configs.get("max_epochs", 100),
            eta_min=configs.get("learning_rate", 1e-4) * 0.1
        )
        
        logger.info("ğŸ¤– Mobile Kosmos Trainer ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info(f"   í•™ìŠµ ê°€ëŠ¥ íŒŒë¼ë¯¸í„°: {sum(p.numel() for p in trainable_params):,}ê°œ")
    
    def tokenize_instructions(self, instructions: List[str]) -> Dict[str, torch.Tensor]:
        """ëª…ë ¹ì–´ í† í¬ë‚˜ì´ì§•"""
        tokenized = self.model.processor.tokenizer(
            instructions,
            padding=True,
            truncation=True,
            max_length=128,
            return_tensors="pt"
        ).to(self.device)
        
        return tokenized
    
    def compute_loss(self, predictions: Dict, targets: Dict) -> Dict:
        """ì†ì‹¤ ê³„ì‚°"""
        # 1. ì•¡ì…˜ ì†ì‹¤ (MSE) - Mobile VLA 3D ì•¡ì…˜
        action_loss = F.mse_loss(predictions["actions_denorm"], targets["mobile_actions"])
        
        # 2. ì´ë²¤íŠ¸ ì†ì‹¤ (Cross-entropy)
        B, T, num_classes = predictions["event_logits"].shape
        event_loss = F.cross_entropy(
            predictions["event_logits"].view(B * T, num_classes),
            targets["mobile_events"].view(B * T)
        )
        
        # ì´ ì†ì‹¤
        total_loss = (
            self.action_loss_weight * action_loss +
            self.event_loss_weight * event_loss
        )
        
        return {
            "total_loss": total_loss,
            "action_loss": action_loss,
            "event_loss": event_loss
        }
    
    def train_step(self, batch: Dict) -> Dict:
        """í•™ìŠµ ìŠ¤í…"""
        self.model.train()
        
        # ì…ë ¥ ë°ì´í„° ì¤€ë¹„
        pixel_values = batch["vision_x"].to(self.device)  # [B, T, 3, 224, 224]
        
        # ëª…ë ¹ì–´ í† í¬ë‚˜ì´ì§• - ì•ˆì „í•œ ì²˜ë¦¬
        task_desc = batch["task_description"]
        
        # task_description íƒ€ì… ì²´í¬ ë° ì•ˆì „í•œ ì²˜ë¦¬
        if isinstance(task_desc, str):
            instructions = [task_desc]
        elif isinstance(task_desc, (list, tuple)):
            # ì´ë¯¸ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°
            instructions = list(task_desc)
        else:
            # ê¸°íƒ€ ê²½ìš° (í…ì„œ ë“±)
            instructions = [str(task_desc)]
        
        # ë¹ˆ ë¬¸ìì—´ ì²´í¬
        instructions = [instr for instr in instructions if instr and instr.strip()]
        if not instructions:
            instructions = ["Navigate to track the target cup"]  # ê¸°ë³¸ ëª…ë ¹ì–´
        
        tokenized = self.tokenize_instructions(instructions)
        
        # ìˆœì „íŒŒ
        predictions = self.model(
            pixel_values=pixel_values,
            input_ids=tokenized["input_ids"],
            attention_mask=tokenized.get("attention_mask")
        )
        
        # íƒ€ê²Ÿ ì¤€ë¹„ (Mobile VLA ì›ë³¸ ë°ì´í„° ì‚¬ìš©)
        targets = {
            "mobile_actions": batch["mobile_actions"].to(self.device),  # [B, T, 3] - Mobile VLA ì•¡ì…˜
            "mobile_events": batch["mobile_events"].to(self.device)     # [B, T] - Mobile VLA ì´ë²¤íŠ¸
        }
        
        # ì†ì‹¤ ê³„ì‚°
        losses = self.compute_loss(predictions, targets)
        
        # ì—­ì „íŒŒ
        self.optimizer.zero_grad()
        losses["total_loss"].backward()
        
        # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘
        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
        
        self.optimizer.step()
        
        # ê²°ê³¼ ë°˜í™˜
        return {k: v.item() if isinstance(v, torch.Tensor) else v for k, v in losses.items()}
    
    def save_model(self, path: str):
        """ëª¨ë¸ ì €ì¥"""
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'configs': self.configs
        }, path)
        logger.info(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {path}")


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    print("ğŸ§ª Mobile Kosmos Trainer í…ŒìŠ¤íŠ¸")
    
    # í…ŒìŠ¤íŠ¸ìš© ì„¤ì •
    test_configs = {
        "kosmos_model_name": "microsoft/kosmos-2-patch14-224",
        "hidden_size": 768,
        "freeze_kosmos": True,
        "learning_rate": 1e-4,
        "batch_size": 1,
        "sequence_length": 18
    }
    
    # ì–´ëŒ‘í„°ì™€ íŠ¸ë ˆì´ë„ˆ ì´ˆê¸°í™”
    adapter = MobileVLAToRoboVLMsAdapter(
        data_dir="/home/billy/25-1kp/vla/ROS_action/mobile_vla_dataset/",
        sequence_length=18
    )
    
    trainer = MobileKosmosTrainer(test_configs)
    
    if len(adapter) > 0:
        # ì²« ë²ˆì§¸ ìƒ˜í”Œë¡œ í…ŒìŠ¤íŠ¸
        sample = adapter[0]
        
        print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„°:")
        print(f"   Vision X: {sample['vision_x'].shape}")
        print(f"   Action: {sample['action'].shape}")
        print(f"   Task: {sample['task_description']}")
        
        # í•™ìŠµ ìŠ¤í… í…ŒìŠ¤íŠ¸
        train_result = trainer.train_step(sample)
        print(f"\nğŸ“ˆ í•™ìŠµ ê²°ê³¼:")
        for key, value in train_result.items():
            print(f"   {key}: {value:.4f}")
    
    print(f"\nâœ… Mobile Kosmos Trainer í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
