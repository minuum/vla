"""
ğŸ” ì²« í”„ë ˆì„ ì œì™¸ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
ì²« í”„ë ˆì„ì„ ì œì™¸í•˜ê³  í›ˆë ¨ëœ ëª¨ë¸ì˜ ì‹¤ì œ ì„±ëŠ¥ì„ í‰ê°€
"""

import torch
import numpy as np
import h5py
import os
from pathlib import Path
from transformers import AutoProcessor
from torch.utils.data import DataLoader, Dataset, random_split

from fixed_robovlms_model import FixedRoboVLMStyleSingleImageModel

class NoFirstFrameEvaluationDataset(Dataset):
    """ì²« í”„ë ˆì„ ì œì™¸ í‰ê°€ìš© ë°ì´í„°ì…‹"""
    
    def __init__(self, data_path, processor, split='train', frame_selection='random'):
        self.data_path = data_path
        self.processor = processor
        self.split = split
        self.frame_selection = frame_selection
        
        # H5 íŒŒì¼ë“¤ ë¡œë“œ
        self.episodes = []
        self._load_episodes()
        
        print(f"ğŸ“Š {split} í‰ê°€ ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ: {len(self.episodes)}ê°œ ì—í”¼ì†Œë“œ")
        print(f"   - í”„ë ˆì„ ì„ íƒ: {frame_selection}")
        print(f"   - ì²« í”„ë ˆì„ ì œì™¸: True")
    
    def _load_episodes(self):
        """ì—í”¼ì†Œë“œ ë¡œë“œ (ì²« í”„ë ˆì„ ì œì™¸)"""
        if os.path.isdir(self.data_path):
            h5_files = list(Path(self.data_path).glob("*.h5"))
        else:
            h5_files = [self.data_path]
        
        for h5_file in h5_files:
            try:
                with h5py.File(h5_file, 'r') as f:
                    if 'images' in f and 'actions' in f:
                        images = f['images'][:]  # [18, H, W, 3]
                        actions = f['actions'][:]  # [18, 3]
                        
                        # ì²« í”„ë ˆì„ ì œì™¸ (í”„ë ˆì„ 1-17ë§Œ ì‚¬ìš©)
                        valid_frames = list(range(1, 18))  # 1, 2, 3, ..., 17
                        
                        if self.frame_selection == 'random':
                            # ëœë¤í•˜ê²Œ í”„ë ˆì„ ì„ íƒ
                            frame_idx = np.random.choice(valid_frames)
                        elif self.frame_selection == 'middle':
                            # ì¤‘ê°„ í”„ë ˆì„ ì„ íƒ
                            frame_idx = valid_frames[len(valid_frames)//2]  # 9
                        elif self.frame_selection == 'all':
                            # ëª¨ë“  ìœ íš¨í•œ í”„ë ˆì„ì„ ê°œë³„ ì—í”¼ì†Œë“œë¡œ ìƒì„±
                            for frame_idx in valid_frames:
                                single_image = images[frame_idx]  # [H, W, 3]
                                single_action = actions[frame_idx]  # [3]
                                
                                self.episodes.append({
                                    'image': single_image,
                                    'action': single_action,
                                    'episode_id': f"{h5_file.stem}_frame_{frame_idx}",
                                    'frame_idx': frame_idx,
                                    'original_file': h5_file.name
                                })
                            continue
                        
                        # ë‹¨ì¼ í”„ë ˆì„ ì„ íƒ
                        single_image = images[frame_idx]  # [H, W, 3]
                        single_action = actions[frame_idx]  # [3]
                        
                        self.episodes.append({
                            'image': single_image,
                            'action': single_action,
                            'episode_id': f"{h5_file.stem}_frame_{frame_idx}",
                            'frame_idx': frame_idx,
                            'original_file': h5_file.name
                        })
                        
            except Exception as e:
                print(f"âŒ {h5_file} ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def __len__(self):
        return len(self.episodes)
    
    def __getitem__(self, idx):
        episode = self.episodes[idx]
        
        # ì´ë¯¸ì§€: [H, W, 3] â†’ [3, H, W] (PyTorch í˜•ì‹)
        image = episode['image']  # [H, W, 3]
        image = np.transpose(image, (2, 0, 1))  # [3, H, W]
        
        # 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”
        if image.max() > 1:
            image = image.astype(np.float32) / 255.0
        
        # ì•¡ì…˜: [3]
        action = episode['action']  # [3]
        
        return {
            'image': image,  # [3, H, W]
            'action': action,  # [3]
            'episode_id': episode['episode_id'],
            'frame_idx': episode['frame_idx']
        }

def create_evaluation_loaders(data_path, processor, batch_size=4, train_split=0.8, frame_selection='random'):
    """í‰ê°€ìš© ë°ì´í„° ë¡œë” ìƒì„±"""
    
    # ì „ì²´ ë°ì´í„°ì…‹ ë¡œë“œ
    full_dataset = NoFirstFrameEvaluationDataset(data_path, processor, 'full', frame_selection)
    
    # í›ˆë ¨/ê²€ì¦ ë¶„í• 
    total_size = len(full_dataset)
    train_size = int(total_size * train_split)
    val_size = total_size - train_size
    
    train_dataset, val_dataset = random_split(
        full_dataset, [train_size, val_size]
    )
    
    # ë°ì´í„° ë¡œë” ìƒì„±
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=1,
        pin_memory=True
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=1,
        pin_memory=True
    )
    
    print(f"ğŸ“Š í‰ê°€ìš© ë°ì´í„° ë¡œë” ìƒì„± ì™„ë£Œ:")
    print(f"   - í›ˆë ¨: {len(train_dataset)}ê°œ ì—í”¼ì†Œë“œ")
    print(f"   - ê²€ì¦: {len(val_dataset)}ê°œ ì—í”¼ì†Œë“œ")
    print(f"   - ë°°ì¹˜ í¬ê¸°: {batch_size}")
    print(f"   - í”„ë ˆì„ ì„ íƒ: {frame_selection}")
    
    return train_loader, val_loader

def evaluate_model_on_loader(model, data_loader, device, description):
    """ë°ì´í„° ë¡œë”ì—ì„œ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€"""
    
    model.eval()
    total_loss = 0.0
    total_mae = 0.0
    total_rmse = 0.0
    predictions = []
    targets = []
    
    print(f"   ğŸ“Š {description} í‰ê°€ ì¤‘...")
    
    with torch.no_grad():
        for batch_idx, batch in enumerate(data_loader):
            try:
                images = batch['image'].float().to(device)
                actions = batch['action'].float().to(device)
                
                # ì˜ˆì¸¡
                predicted_actions = model(images, "Navigate to target")
                
                # ì†ì‹¤ ê³„ì‚°
                z_weight = torch.tensor([1.0, 1.0, 0.05]).to(device)
                weighted_target = actions * z_weight.unsqueeze(0)
                weighted_pred = predicted_actions * z_weight.unsqueeze(0)
                
                loss = torch.nn.functional.mse_loss(weighted_pred, weighted_target)
                total_loss += loss.item()
                
                # MAE ê³„ì‚°
                mae = torch.mean(torch.abs(predicted_actions - actions))
                total_mae += mae.item()
                
                # RMSE ê³„ì‚°
                rmse = torch.sqrt(torch.mean((predicted_actions - actions) ** 2))
                total_rmse += rmse.item()
                
                # ì˜ˆì¸¡ê³¼ íƒ€ê²Ÿ ì €ì¥
                predictions.append(predicted_actions.cpu().numpy())
                targets.append(actions.cpu().numpy())
                
            except Exception as e:
                print(f"âŒ ë°°ì¹˜ {batch_idx} í‰ê°€ ì¤‘ ì˜¤ë¥˜: {e}")
                continue
    
    # í‰ê·  ê³„ì‚°
    avg_loss = total_loss / len(data_loader)
    avg_mae = total_mae / len(data_loader)
    avg_rmse = total_rmse / len(data_loader)
    
    # ì˜ˆì¸¡ ì •í™•ë„ ê³„ì‚°
    predictions = np.concatenate(predictions, axis=0)
    targets = np.concatenate(targets, axis=0)
    
    # ë‹¤ì–‘í•œ ì„ê³„ê°’ìœ¼ë¡œ ì •í™•ë„ ê³„ì‚°
    accuracy_01 = np.mean(np.abs(predictions - targets) < 0.1) * 100
    accuracy_005 = np.mean(np.abs(predictions - targets) < 0.05) * 100
    accuracy_02 = np.mean(np.abs(predictions - targets) < 0.2) * 100
    
    print(f"   ğŸ“Š {description} ê²°ê³¼:")
    print(f"      - í‰ê·  ì†ì‹¤: {avg_loss:.6f}")
    print(f"      - í‰ê·  MAE: {avg_mae:.6f}")
    print(f"      - í‰ê·  RMSE: {avg_rmse:.6f}")
    print(f"      - ì •í™•ë„(0.1): {accuracy_01:.2f}%")
    print(f"      - ì •í™•ë„(0.05): {accuracy_005:.2f}%")
    print(f"      - ì •í™•ë„(0.2): {accuracy_02:.2f}%")
    
    # ì¶•ë³„ ë¶„ì„
    axis_names = ['Xì¶•', 'Yì¶•', 'Zì¶•']
    for i, axis_name in enumerate(axis_names):
        axis_mae = np.mean(np.abs(predictions[:, i] - targets[:, i]))
        axis_rmse = np.sqrt(np.mean((predictions[:, i] - targets[:, i]) ** 2))
        print(f"      - {axis_name} MAE: {axis_mae:.6f}, RMSE: {axis_rmse:.6f}")
    
    # ìƒ˜í”Œ ì¶œë ¥
    print(f"   ğŸ” {description} ìƒ˜í”Œ:")
    for i in range(min(3, len(predictions))):
        print(f"      ìƒ˜í”Œ {i}: ì˜ˆì¸¡={predictions[i]}, íƒ€ê²Ÿ={targets[i]}")
    
    return {
        'loss': avg_loss,
        'mae': avg_mae,
        'rmse': avg_rmse,
        'accuracy_0.1': accuracy_01,
        'accuracy_0.05': accuracy_005,
        'accuracy_0.2': accuracy_02,
        'predictions': predictions.tolist(),
        'targets': targets.tolist()
    }

def main():
    """ë©”ì¸ í‰ê°€ í•¨ìˆ˜"""
    
    print("ğŸ” ì²« í”„ë ˆì„ ì œì™¸ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì‹œì‘!")
    print("=" * 60)
    
    # ì„¤ì •
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    model_path = 'no_first_frame_model_best.pth'
    
    if not os.path.exists(model_path):
        print(f"âŒ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {model_path}")
        return
    
    # í”„ë¡œì„¸ì„œ ë¡œë“œ
    processor = AutoProcessor.from_pretrained("microsoft/kosmos-2-patch14-224")
    
    # ëª¨ë¸ ë¡œë“œ
    model = FixedRoboVLMStyleSingleImageModel(
        processor=processor,
        dropout=0.2,
        use_claw_matrix=True,
        use_hierarchical=True,
        use_advanced_attention=True,
        z_axis_weight=0.05
    ).to(device)
    
    checkpoint = torch.load(model_path, map_location=device)
    
    # ë™ì  ì–´ëŒ‘í„° ì´ˆê¸°í™”
    dummy_image = torch.randn(1, 3, 224, 224).to(device)
    with torch.no_grad():
        try:
            _ = model(dummy_image, "Navigate to target")
        except:
            pass
    
    # í˜¸í™˜ë˜ëŠ” í‚¤ë§Œ ë¡œë“œ
    model_dict = model.state_dict()
    checkpoint_dict = checkpoint['model_state_dict']
    compatible_dict = {k: v for k, v in checkpoint_dict.items() 
                      if k in model_dict and model_dict[k].shape == v.shape}
    model_dict.update(compatible_dict)
    model.load_state_dict(model_dict)
    
    print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    print(f"   - ì—í¬í¬: {checkpoint['epoch']}")
    print(f"   - í›ˆë ¨ ì†ì‹¤: {checkpoint['train_loss']:.6f}")
    print(f"   - ê²€ì¦ ì†ì‹¤: {checkpoint['val_loss']:.6f}")
    print(f"   - í›ˆë ¨ íƒ€ì…: {checkpoint['config']['training_type']}")
    
    # ë°ì´í„° ë¡œë” ìƒì„±
    data_path = '../../ROS_action/mobile_vla_dataset'
    
    # 1. ëœë¤ í”„ë ˆì„ í‰ê°€
    print(f"\nğŸ¯ 1. ëœë¤ í”„ë ˆì„ í‰ê°€:")
    print("-" * 40)
    
    _, val_loader_random = create_evaluation_loaders(
        data_path, processor, batch_size=4, frame_selection='random'
    )
    
    random_results = evaluate_model_on_loader(model, val_loader_random, device, "ëœë¤ í”„ë ˆì„")
    
    # 2. ì¤‘ê°„ í”„ë ˆì„ í‰ê°€
    print(f"\nğŸ¯ 2. ì¤‘ê°„ í”„ë ˆì„ í‰ê°€:")
    print("-" * 40)
    
    _, val_loader_middle = create_evaluation_loaders(
        data_path, processor, batch_size=4, frame_selection='middle'
    )
    
    middle_results = evaluate_model_on_loader(model, val_loader_middle, device, "ì¤‘ê°„ í”„ë ˆì„")
    
    # 3. ì„±ëŠ¥ ë¹„êµ
    print(f"\nğŸ“Š ì„±ëŠ¥ ë¹„êµ:")
    print("=" * 60)
    
    print(f"| í‰ê°€ ë°©ì‹ | MAE | RMSE | ì •í™•ë„(0.1) | ì •í™•ë„(0.05) | ì •í™•ë„(0.2) |")
    print(f"|-----------|-----|------|-------------|-------------|-------------|")
    print(f"| ëœë¤ í”„ë ˆì„ | {random_results['mae']:.6f} | {random_results['rmse']:.6f} | {random_results['accuracy_0.1']:.2f}% | {random_results['accuracy_0.05']:.2f}% | {random_results['accuracy_0.2']:.2f}% |")
    print(f"| ì¤‘ê°„ í”„ë ˆì„ | {middle_results['mae']:.6f} | {middle_results['rmse']:.6f} | {middle_results['accuracy_0.1']:.2f}% | {middle_results['accuracy_0.05']:.2f}% | {middle_results['accuracy_0.2']:.2f}% |")
    
    # 4. ì´ì „ ëª¨ë¸ê³¼ ë¹„êµ
    print(f"\nğŸ“Š ì´ì „ ëª¨ë¸ê³¼ ë¹„êµ:")
    print("=" * 60)
    
    previous_models = {
        "ì²« í”„ë ˆì„ í¬í•¨ (ì´ì „)": {"mae": 0.576, "accuracy_0.1": 48.89, "accuracy_0.2": 48.89},
        "ì²« í”„ë ˆì„ ì œì™¸ (í˜„ì¬)": {"mae": random_results['mae'], "accuracy_0.1": random_results['accuracy_0.1'], "accuracy_0.2": random_results['accuracy_0.2']}
    }
    
    print(f"| ëª¨ë¸ | MAE | ì •í™•ë„(0.1) | ì •í™•ë„(0.2) | ê°œì„ ë„ |")
    print(f"|------|-----|-------------|-------------|--------|")
    
    for model_name, metrics in previous_models.items():
        print(f"| {model_name} | {metrics['mae']:.6f} | {metrics['accuracy_0.1']:.2f}% | {metrics['accuracy_0.2']:.2f}% | - |")
    
    # ê°œì„ ë„ ê³„ì‚°
    mae_improvement = float((0.576 - random_results['mae']) / 0.576 * 100)
    accuracy_improvement = float((random_results['accuracy_0.1'] - 48.89) / 48.89 * 100)
    
    print(f"| ê°œì„ ë„ | {mae_improvement:+.1f}% | {accuracy_improvement:+.1f}% | - | - |")
    
    # 5. ê²°ë¡ 
    print(f"\nğŸ¯ ê²°ë¡ :")
    print("=" * 60)
    
    if random_results['accuracy_0.1'] > 70:
        print(f"âœ… ì²« í”„ë ˆì„ ì œì™¸ í›ˆë ¨ ì„±ê³µ: ì‹¤ì œ ì•¡ì…˜ ì˜ˆì¸¡ ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë¨")
        print(f"   - ì •í™•ë„(0.1): {random_results['accuracy_0.1']:.2f}% (ì´ì „: 48.89%)")
        print(f"   - MAE: {random_results['mae']:.6f} (ì´ì „: 0.576)")
    elif random_results['accuracy_0.1'] > 50:
        print(f"âš ï¸ ì²« í”„ë ˆì„ ì œì™¸ í›ˆë ¨ ë¶€ë¶„ì  ì„±ê³µ: ì„±ëŠ¥ì´ ì–´ëŠ ì •ë„ í–¥ìƒë¨")
        print(f"   - ì •í™•ë„(0.1): {random_results['accuracy_0.1']:.2f}% (ì´ì „: 48.89%)")
    else:
        print(f"âŒ ì²« í”„ë ˆì„ ì œì™¸ í›ˆë ¨ ì‹¤íŒ¨: ì„±ëŠ¥ í–¥ìƒì´ ë¯¸ë¯¸í•¨")
        print(f"   - ì •í™•ë„(0.1): {random_results['accuracy_0.1']:.2f}% (ì´ì „: 48.89%)")
    
    # 6. ê²°ê³¼ ì €ì¥
    results = {
        'model_type': 'Fixed_RoboVLMs_Style_Without_First_Frame',
        'evaluation_type': 'no_first_frame_evaluation',
        'random_frame_results': random_results,
        'middle_frame_results': middle_results,
        'improvement': {
            'mae_improvement_percent': mae_improvement,
            'accuracy_improvement_percent': accuracy_improvement,
            'previous_mae': 0.576,
            'previous_accuracy': 48.89
        },
        'conclusion': {
            'training_success': bool(random_results['accuracy_0.1'] > 70),
            'performance_level': 'good' if random_results['accuracy_0.1'] > 70 else 'needs_improvement'
        }
    }
    
    import json
    with open('no_first_frame_evaluation_results.json', 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\nğŸ’¾ í‰ê°€ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: no_first_frame_evaluation_results.json")

if __name__ == "__main__":
    main()
