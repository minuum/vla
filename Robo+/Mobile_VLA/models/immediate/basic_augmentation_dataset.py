#!/usr/bin/env python3
"""
ğŸ¯ Case 1: ì¦‰ì‹œ ì ìš© - ê¸°ë³¸ ë°ì´í„° ì¦ê°•
ëª©í‘œ: MAE 0.8 â†’ 0.5, ì •í™•ë„ 0% â†’ 15%
íŠ¹ì§•: ê¸°ë³¸ì ì¸ ì´ë¯¸ì§€/ì•¡ì…˜ ì¦ê°•ìœ¼ë¡œ ë°ì´í„° ë‹¤ì–‘ì„± ì¦ê°€
"""

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import h5py
import numpy as np
from PIL import Image
import torchvision.transforms as transforms
import random
import logging
from pathlib import Path

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class BasicAugmentationDataset(Dataset):
    """
    ê¸°ë³¸ ë°ì´í„° ì¦ê°• ë°ì´í„°ì…‹
    - ì´ë¯¸ì§€ ë°ê¸°/ëŒ€ë¹„ ì¡°ì •
    - ì•¡ì…˜ ë…¸ì´ì¦ˆ ì¶”ê°€
    - ê¸°ë³¸ì ì¸ ë³€í˜•ìœ¼ë¡œ ë°ì´í„° ë‹¤ì–‘ì„± ì¦ê°€
    """
    
    def __init__(self, data_path, processor, frame_selection='random', 
                 brightness_range=(0.8, 1.2), contrast_range=(0.8, 1.2),
                 action_noise_std=0.05, augmentation_prob=0.7):
        self.data_path = data_path
        self.processor = processor
        self.frame_selection = frame_selection
        self.brightness_range = brightness_range
        self.contrast_range = contrast_range
        self.action_noise_std = action_noise_std
        self.augmentation_prob = augmentation_prob
        
        # ë°ì´í„° ë¡œë“œ
        self.data = self._load_data()
        
        # ê¸°ë³¸ ì´ë¯¸ì§€ ë³€í™˜
        self.basic_transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        logger.info(f"âœ… Basic Augmentation Dataset ì´ˆê¸°í™” ì™„ë£Œ:")
        logger.info(f"   - ë°ì´í„° ê²½ë¡œ: {data_path}")
        logger.info(f"   - ìƒ˜í”Œ ìˆ˜: {len(self.data)}")
        logger.info(f"   - ë°ê¸° ë²”ìœ„: {brightness_range}")
        logger.info(f"   - ëŒ€ë¹„ ë²”ìœ„: {contrast_range}")
        logger.info(f"   - ì•¡ì…˜ ë…¸ì´ì¦ˆ: {action_noise_std}")
        logger.info(f"   - ì¦ê°• í™•ë¥ : {augmentation_prob}")
    
    def _load_data(self):
        """ë°ì´í„° ë¡œë“œ"""
        data = []
        
        if isinstance(self.data_path, str):
            data_paths = [self.data_path]
        else:
            data_paths = self.data_path
        
        for path in data_paths:
            if path.endswith('.h5'):
                # H5 íŒŒì¼ ì²˜ë¦¬
                with h5py.File(path, 'r') as f:
                    images = f['images'][:]
                    actions = f['actions'][:]
                    
                    for i in range(len(images)):
                        if self.frame_selection == 'first':
                            frame_idx = 0
                        elif self.frame_selection == 'random':
                            frame_idx = random.randint(0, len(images[i]) - 1)
                        else:
                            frame_idx = 0
                        
                        data.append({
                            'image': images[i][frame_idx],
                            'action': actions[i][frame_idx][:2],  # 2D ì•¡ì…˜ë§Œ
                            'episode_id': i
                        })
            elif Path(path).is_dir():
                # í´ë” ë‚´ì˜ H5 íŒŒì¼ë“¤ë„ ì²˜ë¦¬
                h5_files = list(Path(path).glob("*.h5"))
                for h5_file in h5_files:
                    with h5py.File(h5_file, 'r') as f:
                        images = f['images'][:]
                        actions = f['actions'][:]
                        
                        for i in range(len(images)):
                            if self.frame_selection == 'first':
                                frame_idx = 0
                            elif self.frame_selection == 'random':
                                frame_idx = random.randint(0, len(images[i]) - 1)
                            else:
                                frame_idx = 0
                            
                                                    # ì¸ë±ìŠ¤ ë²”ìœ„ í™•ì¸
                        if frame_idx < len(images[i]) and frame_idx < len(actions[i]):
                            data.append({
                                'image': images[i][frame_idx],
                                'action': actions[i][frame_idx][:2],  # 2D ì•¡ì…˜ë§Œ
                                'episode_id': len(data)  # ê³ ìœ í•œ ID
                            })
                
                # í´ë” êµ¬ì¡° ì²˜ë¦¬ (ê¸°ì¡´ ì½”ë“œ)
                # í´ë” êµ¬ì¡° ì²˜ë¦¬
                path = Path(path)
                for episode_dir in path.iterdir():
                    if episode_dir.is_dir():
                        # ì—í”¼ì†Œë“œ IDë¥¼ ë¬¸ìì—´ì—ì„œ ìˆ«ìë¡œ ë³€í™˜ (ì‹¤íŒ¨í•˜ë©´ ì¸ë±ìŠ¤ ì‚¬ìš©)
                        try:
                            episode_id = int(episode_dir.name)
                        except ValueError:
                            # ë¬¸ìì—´ì¸ ê²½ìš° í•´ì‹œê°’ì„ ì‚¬ìš©í•˜ê±°ë‚˜ ì¸ë±ìŠ¤ ì‚¬ìš©
                            episode_id = hash(episode_dir.name) % 10000  # í•´ì‹œê°’ì„ 4ìë¦¬ ìˆ«ìë¡œ ë³€í™˜
                        
                        # ì´ë¯¸ì§€ íŒŒì¼ë“¤
                        image_files = sorted(list(episode_dir.glob('*.png')))
                        action_file = episode_dir / 'actions.npy'
                        
                        if len(image_files) > 0 and action_file.exists():
                            actions = np.load(action_file)
                            
                            for frame_idx, img_file in enumerate(image_files):
                                if frame_idx < len(actions):
                                    data.append({
                                        'image_path': str(img_file),
                                        'action': actions[frame_idx][:2],  # 2D ì•¡ì…˜ë§Œ
                                        'episode_id': episode_id
                                    })
        
        logger.info(f"ğŸ“Š ë¡œë“œëœ ë°ì´í„°: {len(data)} ìƒ˜í”Œ")
        return data
    
    def _augment_image(self, image):
        """ì´ë¯¸ì§€ ì¦ê°•"""
        if random.random() > self.augmentation_prob:
            return image
        
        # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
        if isinstance(image, np.ndarray):
            image = Image.fromarray(image)
        
        # ë°ê¸° ì¡°ì •
        brightness_factor = random.uniform(*self.brightness_range)
        image = transforms.functional.adjust_brightness(image, brightness_factor)
        
        # ëŒ€ë¹„ ì¡°ì •
        contrast_factor = random.uniform(*self.contrast_range)
        image = transforms.functional.adjust_contrast(image, contrast_factor)
        
        # ë…¸ì´ì¦ˆ ì¶”ê°€ (ê°€ìš°ì‹œì•ˆ)
        if random.random() < 0.3:
            noise_std = random.uniform(0.01, 0.05)
            img_array = np.array(image).astype(np.float32) / 255.0
            noise = np.random.normal(0, noise_std, img_array.shape)
            img_array = np.clip(img_array + noise, 0, 1)
            image = Image.fromarray((img_array * 255).astype(np.uint8))
        
        return image
    
    def _augment_action(self, action):
        """ì•¡ì…˜ ì¦ê°•"""
        if random.random() > self.augmentation_prob:
            return action
        
        # ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ì¶”ê°€
        noise = np.random.normal(0, self.action_noise_std, action.shape)
        augmented_action = action + noise
        
        # ì•¡ì…˜ ë²”ìœ„ ì œí•œ (ì„ í˜• ì†ë„ ì œí•œ)
        augmented_action = np.clip(augmented_action, -1.0, 1.0)
        
        return augmented_action
    
    def __getitem__(self, idx):
        """ë°ì´í„° ìƒ˜í”Œ ë°˜í™˜"""
        item = self.data[idx]
        
        # ì´ë¯¸ì§€ ì²˜ë¦¬
        if 'image_path' in item:
            # í´ë” êµ¬ì¡°ì—ì„œ ì´ë¯¸ì§€ ë¡œë“œ
            image = Image.open(item['image_path']).convert('RGB')
        else:
            # H5 íŒŒì¼ì—ì„œ ì´ë¯¸ì§€ ë¡œë“œ
            image = Image.fromarray(item['image']).convert('RGB')
        
        # ì´ë¯¸ì§€ ì¦ê°•
        image = self._augment_image(image)
        
        # ì•¡ì…˜ ì¦ê°•
        action = self._augment_action(item['action'])
        
        # í…ìŠ¤íŠ¸ (ê¸°ë³¸ í”„ë¡¬í”„íŠ¸)
        text = "Navigate the robot to the target location."
        
        return {
            'image': image,
            'action': torch.tensor(action, dtype=torch.float32),
            'text': text,
            'episode_id': item['episode_id']
        }
    
    def __len__(self):
        return len(self.data)

def create_basic_augmentation_data_loaders(data_path, processor, batch_size=2, 
                                          train_split=0.7, val_split=0.15, test_split=0.15):
    """
    ê¸°ë³¸ ì¦ê°• ë°ì´í„° ë¡œë” ìƒì„±
    - batch_size: 4 â†’ 2 (ì ì€ ë°ì´í„°ì— ë§ê²Œ ê°ì†Œ)
    - train/val/test split: 70/15/15 (ê¸°ì¡´ 80/20ì—ì„œ ì¡°ì •)
    """
    
    # ì „ì²´ ë°ì´í„°ì…‹ ìƒì„±
    full_dataset = BasicAugmentationDataset(
        data_path=data_path,
        processor=processor,
        frame_selection='random',
        brightness_range=(0.8, 1.2),
        contrast_range=(0.8, 1.2),
        action_noise_std=0.05,
        augmentation_prob=0.7
    )
    
    # ë°ì´í„°ì…‹ ë¶„í• 
    total_size = len(full_dataset)
    train_size = int(total_size * train_split)
    val_size = int(total_size * val_split)
    test_size = total_size - train_size - val_size
    
    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
        full_dataset, [train_size, val_size, test_size]
    )
    
    # ë°ì´í„° ë¡œë” ìƒì„±
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=2,
        pin_memory=True
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=2,
        pin_memory=True
    )
    
    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=2,
        pin_memory=True
    )
    
    logger.info(f"âœ… Basic Augmentation Data Loaders ìƒì„± ì™„ë£Œ:")
    logger.info(f"   - ì „ì²´ ìƒ˜í”Œ: {total_size}")
    logger.info(f"   - í›ˆë ¨ ìƒ˜í”Œ: {len(train_dataset)} ({len(train_dataset)/total_size*100:.1f}%)")
    logger.info(f"   - ê²€ì¦ ìƒ˜í”Œ: {len(val_dataset)} ({len(val_dataset)/total_size*100:.1f}%)")
    logger.info(f"   - í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ: {len(test_dataset)} ({len(test_dataset)/total_size*100:.1f}%)")
    logger.info(f"   - ë°°ì¹˜ í¬ê¸°: {batch_size}")
    
    return train_loader, val_loader, test_loader

def analyze_augmentation_effects(dataset, num_samples=10):
    """ì¦ê°• íš¨ê³¼ ë¶„ì„"""
    logger.info(f"ğŸ” ì¦ê°• íš¨ê³¼ ë¶„ì„ (ìƒ˜í”Œ {num_samples}ê°œ):")
    
    for i in range(min(num_samples, len(dataset))):
        sample = dataset[i]
        
        # ì›ë³¸ê³¼ ì¦ê°•ëœ ë°ì´í„° ë¹„êµ
        original_action = sample['action']
        
        logger.info(f"   ìƒ˜í”Œ {i+1}:")
        logger.info(f"     - ì•¡ì…˜: {original_action.numpy()}")
        logger.info(f"     - ì´ë¯¸ì§€ í¬ê¸°: {sample['image'].size}")
        logger.info(f"     - ì—í”¼ì†Œë“œ ID: {sample['episode_id']}")

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    from transformers import AutoProcessor
    
    processor = AutoProcessor.from_pretrained("microsoft/kosmos-2-patch14-224")
    
    # ë°ì´í„° ê²½ë¡œ ì„¤ì •
    data_path = "../../../../ROS_action/mobile_vla_dataset/"
    
    # ë°ì´í„°ì…‹ ìƒì„±
    dataset = BasicAugmentationDataset(
        data_path=data_path,
        processor=processor,
        frame_selection='random',
        brightness_range=(0.8, 1.2),
        contrast_range=(0.8, 1.2),
        action_noise_std=0.05,
        augmentation_prob=0.7
    )
    
    # ì¦ê°• íš¨ê³¼ ë¶„ì„
    analyze_augmentation_effects(dataset, num_samples=5)
    
    # ë°ì´í„° ë¡œë” ìƒì„±
    train_loader, val_loader, test_loader = create_basic_augmentation_data_loaders(
        data_path=data_path,
        processor=processor,
        batch_size=2,
        train_split=0.7,
        val_split=0.15,
        test_split=0.15
    )
    
    # ë°°ì¹˜ í…ŒìŠ¤íŠ¸
    for batch in train_loader:
        logger.info(f"ğŸ“¦ ë°°ì¹˜ ì •ë³´:")
        logger.info(f"   - ì´ë¯¸ì§€: {batch['image'].shape}")
        logger.info(f"   - ì•¡ì…˜: {batch['action'].shape}")
        logger.info(f"   - í…ìŠ¤íŠ¸: {len(batch['text'])}")
        break
