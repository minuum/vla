#!/usr/bin/env python3
"""
ê°„ë‹¨í•œ ë°ì´í„° ë¡œë” - H5 íŒŒì¼ë§Œ ì²˜ë¦¬
"""

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import h5py
import numpy as np
from PIL import Image
import random
import logging
from pathlib import Path

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SimpleDataset(Dataset):
    """ê°„ë‹¨í•œ ë°ì´í„°ì…‹ - H5 íŒŒì¼ë§Œ ì²˜ë¦¬"""
    
    def __init__(self, data_path, processor, frame_selection='first'):
        self.data_path = data_path
        self.processor = processor
        self.frame_selection = frame_selection
        
        # ë°ì´í„° ë¡œë“œ
        self.data = self._load_data()
        
        logger.info(f"âœ… Simple Dataset ì´ˆê¸°í™” ì™„ë£Œ:")
        logger.info(f"   - ë°ì´í„° ê²½ë¡œ: {data_path}")
        logger.info(f"   - ìƒ˜í”Œ ìˆ˜: {len(self.data)}")
    
    def _load_data(self):
        """H5 íŒŒì¼ë“¤ì—ì„œ ë°ì´í„° ë¡œë“œ"""
        data = []
        data_path = Path(self.data_path)
        
        # H5 íŒŒì¼ë“¤ ì°¾ê¸°
        h5_files = list(data_path.glob("*.h5"))
        logger.info(f"ğŸ“ H5 íŒŒì¼ ìˆ˜: {len(h5_files)}")
        
        for h5_file in h5_files:
            try:
                with h5py.File(h5_file, 'r') as f:
                    if 'images' in f and 'actions' in f:
                        images = f['images'][:]
                        actions = f['actions'][:]
                        
                        # ë‹¨ì¼ ì—í”¼ì†Œë“œì˜ ê° í”„ë ˆì„ì„ ìƒ˜í”Œë¡œ ì¶”ê°€
                        # images shape: (18, 720, 1280, 3)
                        # actions shape: (18, 3)
                        
                        for frame_idx in range(len(images)):
                            if self.frame_selection == 'first' and frame_idx != 0:
                                continue
                            elif self.frame_selection == 'random' and frame_idx != random.randint(0, len(images) - 1):
                                continue
                            
                            data.append({
                                'image': images[frame_idx],
                                'action': actions[frame_idx][:2],  # 2D ì•¡ì…˜ë§Œ
                                'episode_id': len(data),  # ê³ ìœ  ID
                                'frame_id': frame_idx
                            })
                            
                            # first ëª¨ë“œì—ì„œëŠ” ì²« í”„ë ˆì„ë§Œ ì¶”ê°€
                            if self.frame_selection == 'first':
                                break
                                    
            except Exception as e:
                logger.error(f"âŒ {h5_file} ë¡œë“œ ì˜¤ë¥˜: {e}")
                continue
        
        logger.info(f"ğŸ“Š ë¡œë“œëœ ìƒ˜í”Œ ìˆ˜: {len(data)}")
        return data
    
    def __getitem__(self, idx):
        """ë°ì´í„° ìƒ˜í”Œ ë°˜í™˜"""
        item = self.data[idx]
        
        # ì´ë¯¸ì§€ ì²˜ë¦¬
        image = Image.fromarray(item['image']).convert('RGB')
        
        # ì•¡ì…˜
        action = torch.tensor(item['action'], dtype=torch.float32)
        
        # í…ìŠ¤íŠ¸ (ê¸°ë³¸ í”„ë¡¬í”„íŠ¸)
        text = "Navigate the robot to the target location."
        
        return {
            'image': image,
            'action': action,
            'text': text,
            'episode_id': item['episode_id']
        }
    
    def __len__(self):
        return len(self.data)

def custom_collate_fn(batch):
    """PIL ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì»¤ìŠ¤í…€ collate í•¨ìˆ˜"""
    images = [item['image'] for item in batch]
    actions = torch.stack([item['action'] for item in batch])
    texts = [item['text'] for item in batch]
    episode_ids = [item['episode_id'] for item in batch]
    
    return {
        'image': images,  # PIL ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸
        'action': actions,
        'text': texts,
        'episode_id': episode_ids
    }

def create_simple_data_loaders(data_path, processor, batch_size=2, 
                              train_split=0.7, val_split=0.15, test_split=0.15):
    """ê°„ë‹¨í•œ ë°ì´í„° ë¡œë” ìƒì„±"""
    
    # ì „ì²´ ë°ì´í„°ì…‹ ìƒì„±
    full_dataset = SimpleDataset(
        data_path=data_path,
        processor=processor,
        frame_selection='random'  # ëœë¤ í”„ë ˆì„ ì‚¬ìš©
    )
    
    # ë°ì´í„°ì…‹ ë¶„í• 
    total_size = len(full_dataset)
    train_size = int(total_size * train_split)
    val_size = int(total_size * val_split)
    test_size = total_size - train_size - val_size
    
    logger.info(f"ğŸ“Š ë°ì´í„°ì…‹ ë¶„í• :")
    logger.info(f"   - ì „ì²´: {total_size}")
    logger.info(f"   - í›ˆë ¨: {train_size}")
    logger.info(f"   - ê²€ì¦: {val_size}")
    logger.info(f"   - í…ŒìŠ¤íŠ¸: {test_size}")
    
    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
        full_dataset, [train_size, val_size, test_size]
    )
    
    # ë°ì´í„° ë¡œë” ìƒì„± (ì»¤ìŠ¤í…€ collate í•¨ìˆ˜ ì‚¬ìš©)
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=0,
        pin_memory=True,
        collate_fn=custom_collate_fn
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=0,
        pin_memory=True,
        collate_fn=custom_collate_fn
    )
    
    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=0,
        pin_memory=True,
        collate_fn=custom_collate_fn
    )
    
    logger.info(f"âœ… Simple Data Loaders ìƒì„± ì™„ë£Œ")
    
    return train_loader, val_loader, test_loader

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    from transformers import AutoProcessor
    
    processor = AutoProcessor.from_pretrained("microsoft/kosmos-2-patch14-224")
    
    # ë°ì´í„°ì…‹ ìƒì„±
    dataset = SimpleDataset(
        data_path="../../../../ROS_action/mobile_vla_dataset/",
        processor=processor,
        frame_selection='first'
    )
    
    # ë°ì´í„° ë¡œë” ìƒì„±
    train_loader, val_loader, test_loader = create_simple_data_loaders(
        data_path="../../../../ROS_action/mobile_vla_dataset/",
        processor=processor,
        batch_size=2
    )
    
    # ë°°ì¹˜ í…ŒìŠ¤íŠ¸
    for batch in train_loader:
        logger.info(f"ğŸ“¦ ë°°ì¹˜ ì •ë³´:")
        logger.info(f"   - ì´ë¯¸ì§€: {batch['image'][0].size}")
        logger.info(f"   - ì•¡ì…˜: {batch['action'].shape}")
        logger.info(f"   - í…ìŠ¤íŠ¸: {len(batch['text'])}")
        break
