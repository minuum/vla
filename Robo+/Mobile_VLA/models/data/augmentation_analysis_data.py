#!/usr/bin/env python3
"""
ğŸ“Š ë°ì´í„°ì…‹ ì¦ê°• í˜„í™© ë¶„ì„ ë° í‘œ ìƒì„±
"""
import sys
from pathlib import Path
import numpy as np
import pandas as pd
import json
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
ROOT_DIR = Path("/home/billy/25-1kp/vla/Robo+/Mobile_VLA")
DATA_DIR = Path("/home/billy/25-1kp/vla/ROS_action/mobile_vla_dataset")

def analyze_augmentation_status():
    """ë°ì´í„°ì…‹ ì¦ê°• í˜„í™© ë¶„ì„"""
    print("ğŸ“Š ë°ì´í„°ì…‹ ì¦ê°• í˜„í™© ë¶„ì„ ì‹œì‘...")
    
    # ì›ë³¸ ë°ì´í„°ì…‹ ì •ë³´
    original_info = {
        'total_episodes': 72,
        'total_frames': 1296,
        'avg_episode_length': 18.0,
        'action_dimensions': 3,
        'z_axis_zero_ratio': 1.0,
        'x_dominant': True
    }
    
    # ì¦ê°• ë°©ë²•ë³„ í˜„í™©
    augmentation_methods = {
        'original': {
            'name': 'ì›ë³¸ ë°ì´í„°',
            'episodes': 72,
            'frames': 1296,
            'description': 'ìˆ˜ì§‘ëœ ì›ë³¸ ë°ì´í„°',
            'augmentation_factor': 1.0,
            'method': 'None'
        },
        'current_training': {
            'name': 'í˜„ì¬ í•™ìŠµìš© (ì‹¤ì‹œê°„ ì¦ê°•)',
            'episodes': 72,
            'frames': 1296,
            'description': 'ì‹¤ì‹œê°„ìœ¼ë¡œ ì¦ê°• ì ìš©',
            'augmentation_factor': 1.0,
            'method': 'In-batch augmentation'
        },
        'horizontal_flip': {
            'name': 'ì¢Œìš° ëŒ€ì¹­',
            'episodes': 72,
            'frames': 1296,
            'description': '50% í™•ë¥ ë¡œ ì¢Œìš° ëŒ€ì¹­',
            'augmentation_factor': 1.5,
            'method': 'Horizontal flip + Y-axis sign change'
        },
        'forward_backward_flip': {
            'name': 'ì „ì§„/í›„ì§„ ë’¤ì§‘ê¸°',
            'episodes': 72,
            'frames': 1296,
            'description': '30% í™•ë¥ ë¡œ ì „ì§„/í›„ì§„ ë’¤ì§‘ê¸°',
            'augmentation_factor': 1.3,
            'method': 'Temporal flip + X-axis sign change'
        },
        'action_noise': {
            'name': 'ì•¡ì…˜ ë…¸ì´ì¦ˆ',
            'episodes': 72,
            'frames': 1296,
            'description': '80% í™•ë¥ ë¡œ ì„¼ì„œ ë…¸ì´ì¦ˆ ì‹œë®¬ë ˆì´ì…˜',
            'augmentation_factor': 1.8,
            'method': 'X-axis: Ïƒ=0.005, Y-axis: Ïƒ=0.0025'
        },
        'speed_variation': {
            'name': 'ì†ë„ ë³€í™”',
            'episodes': 72,
            'frames': 1296,
            'description': '30% í™•ë¥ ë¡œ ì†ë„ ìŠ¤ì¼€ì¼ë§ (0.8-1.2)',
            'augmentation_factor': 1.3,
            'method': 'X-axis scaling'
        },
        'start_stop_patterns': {
            'name': 'ì‹œì‘-ì •ì§€ íŒ¨í„´',
            'episodes': 72,
            'frames': 1296,
            'description': '20% í™•ë¥ ë¡œ ì •ì§€ íŒ¨í„´ ì¶”ê°€',
            'augmentation_factor': 1.2,
            'method': 'Zero action insertion'
        }
    }
    
    # ì‹¤ì œ ì €ì¥ëœ íŒŒì¼ë“¤ í™•ì¸
    saved_files = {
        'final_fixed_results.json': 'í˜„ì¬ í•™ìŠµ ê²°ê³¼',
        'dataset_analysis_results.json': 'ë°ì´í„°ì…‹ ë¶„ì„ ê²°ê³¼',
        'dataset_analysis.png': 'ë°ì´í„°ì…‹ ì‹œê°í™”'
    }
    
    # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    existing_files = {}
    for filename, description in saved_files.items():
        file_path = ROOT_DIR / filename
        existing_files[filename] = {
            'exists': file_path.exists(),
            'description': description,
            'size_mb': file_path.stat().st_size / (1024*1024) if file_path.exists() else 0
        }
    
    # ì¦ê°• íš¨ê³¼ ë¶„ì„
    augmentation_effects = {
        'task_specific': {
            'name': 'íƒœìŠ¤í¬ íŠ¹ì„± ê¸°ë°˜',
            'effectiveness': 'High',
            'reason': 'Zì¶• 0, Xì¶• ìš°ì„¸ íŠ¹ì„± ë°˜ì˜',
            'physical_validity': 'High',
            'implementation': 'In-batch'
        },
        'traditional': {
            'name': 'ì „í†µì  ì¦ê°•',
            'effectiveness': 'Medium',
            'reason': 'ì¼ë°˜ì ì¸ ì´ë¯¸ì§€ ì¦ê°•',
            'physical_validity': 'Low',
            'implementation': 'Pre-generation'
        },
        'robotics_specific': {
            'name': 'ë¡œë´‡ íŠ¹í™”',
            'effectiveness': 'High',
            'reason': 'ì„¼ì„œ ë…¸ì´ì¦ˆ, ë¬¼ë¦¬ì  ì œì•½ ë°˜ì˜',
            'physical_validity': 'High',
            'implementation': 'Hybrid'
        }
    }
    
    # í‘œ ìƒì„±
    print("\nğŸ“‹ ë°ì´í„°ì…‹ ì¦ê°• í˜„í™© í‘œ")
    print("=" * 80)
    
    # 1. ì›ë³¸ ë°ì´í„° í˜„í™©
    print("\n1ï¸âƒ£ ì›ë³¸ ë°ì´í„° í˜„í™©")
    print("-" * 50)
    original_df = pd.DataFrame([original_info])
    print(original_df.to_string(index=False))
    
    # 2. ì¦ê°• ë°©ë²•ë³„ í˜„í™©
    print("\n2ï¸âƒ£ ì¦ê°• ë°©ë²•ë³„ í˜„í™©")
    print("-" * 50)
    aug_data = []
    for key, info in augmentation_methods.items():
        aug_data.append({
            'ì¦ê°• ë°©ë²•': info['name'],
            'ì—í”¼ì†Œë“œ ìˆ˜': info['episodes'],
            'í”„ë ˆì„ ìˆ˜': info['frames'],
            'ì¦ê°• ë°°ìˆ˜': info['augmentation_factor'],
            'ì ìš© í™•ë¥ ': get_probability(info['method']),
            'ì„¤ëª…': info['description']
        })
    
    aug_df = pd.DataFrame(aug_data)
    print(aug_df.to_string(index=False))
    
    # 3. ì €ì¥ëœ íŒŒì¼ í˜„í™©
    print("\n3ï¸âƒ£ ì €ì¥ëœ íŒŒì¼ í˜„í™©")
    print("-" * 50)
    file_data = []
    for filename, info in existing_files.items():
        file_data.append({
            'íŒŒì¼ëª…': filename,
            'ì¡´ì¬ ì—¬ë¶€': 'âœ…' if info['exists'] else 'âŒ',
            'í¬ê¸° (MB)': f"{info['size_mb']:.2f}" if info['exists'] else 'N/A',
            'ì„¤ëª…': info['description']
        })
    
    file_df = pd.DataFrame(file_data)
    print(file_df.to_string(index=False))
    
    # 4. ì¦ê°• íš¨ê³¼ ë¹„êµ
    print("\n4ï¸âƒ£ ì¦ê°• íš¨ê³¼ ë¹„êµ")
    print("-" * 50)
    effect_data = []
    for key, info in augmentation_effects.items():
        effect_data.append({
            'ì¦ê°• ìœ í˜•': info['name'],
            'íš¨ê³¼ì„±': info['effectiveness'],
            'ë¬¼ë¦¬ì  íƒ€ë‹¹ì„±': info['physical_validity'],
            'êµ¬í˜„ ë°©ì‹': info['implementation'],
            'ì ìš© ì´ìœ ': info['reason']
        })
    
    effect_df = pd.DataFrame(effect_data)
    print(effect_df.to_string(index=False))
    
    # 5. í†µí•© ìš”ì•½ í‘œ
    print("\n5ï¸âƒ£ í†µí•© ìš”ì•½")
    print("-" * 50)
    summary_data = [
        {
            'êµ¬ë¶„': 'ì›ë³¸ ë°ì´í„°',
            'ì—í”¼ì†Œë“œ': 72,
            'í”„ë ˆì„': 1296,
            'ì¦ê°• ë°°ìˆ˜': 1.0,
            'ìƒíƒœ': 'ì™„ë£Œ'
        },
        {
            'êµ¬ë¶„': 'ì‹¤ì‹œê°„ ì¦ê°• (í˜„ì¬)',
            'ì—í”¼ì†Œë“œ': 72,
            'í”„ë ˆì„': 1296,
            'ì¦ê°• ë°°ìˆ˜': '~2.5',
            'ìƒíƒœ': 'í™œì„±í™”'
        },
        {
            'êµ¬ë¶„': 'ì¢Œìš° ëŒ€ì¹­',
            'ì—í”¼ì†Œë“œ': 36,
            'í”„ë ˆì„': 648,
            'ì¦ê°• ë°°ìˆ˜': 0.5,
            'ìƒíƒœ': 'ì‹¤ì‹œê°„ ì ìš©'
        },
        {
            'êµ¬ë¶„': 'ì „ì§„/í›„ì§„ ë’¤ì§‘ê¸°',
            'ì—í”¼ì†Œë“œ': 22,
            'í”„ë ˆì„': 396,
            'ì¦ê°• ë°°ìˆ˜': 0.3,
            'ìƒíƒœ': 'ì‹¤ì‹œê°„ ì ìš©'
        },
        {
            'êµ¬ë¶„': 'ì•¡ì…˜ ë…¸ì´ì¦ˆ',
            'ì—í”¼ì†Œë“œ': 58,
            'í”„ë ˆì„': 1044,
            'ì¦ê°• ë°°ìˆ˜': 0.8,
            'ìƒíƒœ': 'ì‹¤ì‹œê°„ ì ìš©'
        },
        {
            'êµ¬ë¶„': 'ì†ë„ ë³€í™”',
            'ì—í”¼ì†Œë“œ': 22,
            'í”„ë ˆì„': 396,
            'ì¦ê°• ë°°ìˆ˜': 0.3,
            'ìƒíƒœ': 'ì‹¤ì‹œê°„ ì ìš©'
        },
        {
            'êµ¬ë¶„': 'ì‹œì‘-ì •ì§€ íŒ¨í„´',
            'ì—í”¼ì†Œë“œ': 14,
            'í”„ë ˆì„': 252,
            'ì¦ê°• ë°°ìˆ˜': 0.2,
            'ìƒíƒœ': 'ì‹¤ì‹œê°„ ì ìš©'
        }
    ]
    
    summary_df = pd.DataFrame(summary_data)
    print(summary_df.to_string(index=False))
    
    # 6. ì‹œê°í™”
    print("\nğŸ“Š ì‹œê°í™” ìƒì„± ì¤‘...")
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    # ì¦ê°• ë°°ìˆ˜ ë¶„í¬
    aug_factors = [info['augmentation_factor'] for info in augmentation_methods.values()]
    aug_names = [info['name'] for info in augmentation_methods.values()]
    
    axes[0, 0].bar(aug_names, aug_factors, color='skyblue', alpha=0.7)
    axes[0, 0].set_title('ì¦ê°• ë°©ë²•ë³„ ë°°ìˆ˜')
    axes[0, 0].set_ylabel('ì¦ê°• ë°°ìˆ˜')
    axes[0, 0].tick_params(axis='x', rotation=45)
    
    # ì—í”¼ì†Œë“œ ë¶„í¬
    episodes = [info['episodes'] for info in augmentation_methods.values()]
    axes[0, 1].pie(episodes, labels=aug_names, autopct='%1.1f%%', startangle=90)
    axes[0, 1].set_title('ì—í”¼ì†Œë“œ ë¶„í¬')
    
    # íš¨ê³¼ì„± ë¹„êµ
    effectiveness_scores = {'High': 3, 'Medium': 2, 'Low': 1}
    effect_scores = [effectiveness_scores[info['effectiveness']] for info in augmentation_effects.values()]
    effect_names = [info['name'] for info in augmentation_effects.values()]
    
    axes[1, 0].bar(effect_names, effect_scores, color='lightgreen', alpha=0.7)
    axes[1, 0].set_title('ì¦ê°• íš¨ê³¼ì„± ë¹„êµ')
    axes[1, 0].set_ylabel('íš¨ê³¼ì„± ì ìˆ˜')
    axes[1, 0].tick_params(axis='x', rotation=45)
    
    # íŒŒì¼ í¬ê¸° ë¶„í¬
    file_sizes = [info['size_mb'] for info in existing_files.values() if info['exists']]
    file_names = [name for name, info in existing_files.items() if info['exists']]
    
    if file_sizes:
        axes[1, 1].bar(file_names, file_sizes, color='orange', alpha=0.7)
        axes[1, 1].set_title('ì €ì¥ëœ íŒŒì¼ í¬ê¸°')
        axes[1, 1].set_ylabel('í¬ê¸° (MB)')
        axes[1, 1].tick_params(axis='x', rotation=45)
    
    plt.tight_layout()
    plt.savefig('augmentation_analysis.png', dpi=300, bbox_inches='tight')
    print("   ğŸ“Š ì‹œê°í™” ì €ì¥ë¨: augmentation_analysis.png")
    
    # ê²°ê³¼ ì €ì¥
    analysis_results = {
        'original_dataset': original_info,
        'augmentation_methods': augmentation_methods,
        'existing_files': existing_files,
        'augmentation_effects': augmentation_effects,
        'summary': summary_data,
        'analysis_date': datetime.now().isoformat()
    }
    
    with open('augmentation_analysis_results.json', 'w') as f:
        json.dump(analysis_results, f, indent=2, ensure_ascii=False)
    
    print("   ğŸ’¾ ë¶„ì„ ê²°ê³¼ ì €ì¥ë¨: augmentation_analysis_results.json")
    
    return analysis_results

def get_probability(method):
    """ì¦ê°• ë°©ë²•ì—ì„œ í™•ë¥  ì¶”ì¶œ"""
    if '50%' in method or '0.5' in method:
        return '50%'
    elif '30%' in method or '0.3' in method:
        return '30%'
    elif '80%' in method or '0.8' in method:
        return '80%'
    elif '20%' in method or '0.2' in method:
        return '20%'
    else:
        return 'N/A'

if __name__ == "__main__":
    results = analyze_augmentation_status()
    print("\nâœ… ì¦ê°• í˜„í™© ë¶„ì„ ì™„ë£Œ!")
