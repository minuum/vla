#!/usr/bin/env python3
"""
ğŸš€ Case 2: ë‹¨ê¸° ì ìš© - ìµœì í™”ëœ ëª¨ë¸ í›ˆë ¨
ëª©í‘œ: MAE 0.5 â†’ 0.3, ì •í™•ë„ 15% â†’ 35%
íŠ¹ì§•: Vision Resampler ìµœì í™” + CLIP Normalization
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from transformers import AutoProcessor
import numpy as np
import logging
import argparse
from pathlib import Path
import json
from tqdm import tqdm
import matplotlib.pyplot as plt

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
import sys
sys.path.append('..')
from clip_normalized_model_v2 import CLIPNormalized2DActionModelV2, CLIPNormalizedTrainerV2
from enhanced_dataset import create_enhanced_data_loaders

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class EarlyStopping:
    """ì¡°ê¸° ì¢…ë£Œ í´ë˜ìŠ¤"""
    
    def __init__(self, patience=5, min_delta=0.001, restore_best_weights=True):
        self.patience = patience
        self.min_delta = min_delta
        self.restore_best_weights = restore_best_weights
        self.best_loss = None
        self.counter = 0
        self.best_weights = None
        
    def __call__(self, val_loss, model):
        if self.best_loss is None:
            self.best_loss = val_loss
            self.best_weights = model.state_dict().copy()
        elif val_loss < self.best_loss - self.min_delta:
            self.best_loss = val_loss
            self.counter = 0
            self.best_weights = model.state_dict().copy()
        else:
            self.counter += 1
            
        if self.counter >= self.patience:
            if self.restore_best_weights:
                model.load_state_dict(self.best_weights)
            return True
        return False

def train_optimized_model(data_path, output_dir, num_epochs=50, batch_size=2, 
                         learning_rate=3e-5, weight_decay=1e-3, patience=5,
                         use_clip_normalization=True, use_vision_resampler=True):
    """
    ìµœì í™”ëœ ëª¨ë¸ í›ˆë ¨
    - CLIP Normalization ì ìš©
    - Vision Resampler ìµœì í™”
    - ê³ ê¸‰ ë°ì´í„° ì¦ê°•
    """
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    logger.info(f"ğŸš€ Case 2 í›ˆë ¨ ì‹œì‘ - ë””ë°”ì´ìŠ¤: {device}")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # í”„ë¡œì„¸ì„œ ë¡œë“œ
    logger.info("ğŸ“¥ Kosmos2 í”„ë¡œì„¸ì„œ ë¡œë“œ ì¤‘...")
    processor = AutoProcessor.from_pretrained("microsoft/kosmos-2-patch14-224")
    
    # ë°ì´í„° ë¡œë” ìƒì„±
    logger.info("ğŸ“Š ê³ ê¸‰ ë°ì´í„° ë¡œë” ìƒì„± ì¤‘...")
    train_loader, val_loader, test_loader = create_enhanced_data_loaders(
        data_path=data_path,
        processor=processor,
        batch_size=batch_size,
        train_split=0.7,
        val_split=0.15,
        test_split=0.15
    )
    
    # ëª¨ë¸ ë° í›ˆë ¨ê¸° ìƒì„±
    logger.info("ğŸ¤– CLIP Normalized ëª¨ë¸ ìƒì„± ì¤‘...")
    model = CLIPNormalized2DActionModelV2(
        processor=processor,
        vision_dim=1024,
        language_dim=2048,  # Kosmos2 text ëª¨ë¸ ì¶œë ¥ ì°¨ì›
        action_dim=2,
        hidden_dim=256,  # Case 1ê³¼ ë™ì¼
        dropout=0.3,     # 0.4 â†’ 0.3 (ì•½ê°„ ê°ì†Œ)
        use_vision_resampler=use_vision_resampler,
        use_clip_normalization=use_clip_normalization
    )
    
    trainer = CLIPNormalizedTrainerV2(
        model=model,
        device=device,
        learning_rate=learning_rate,  # 3e-5 (ë” ë‚®ì€ í•™ìŠµë¥ )
        weight_decay=weight_decay
    )
    
    # ì¡°ê¸° ì¢…ë£Œ ì„¤ì •
    early_stopping = EarlyStopping(patience=patience, min_delta=0.001)
    
    # í›ˆë ¨ ê¸°ë¡
    train_losses = []
    val_losses = []
    val_maes = []
    best_mae = float('inf')
    
    logger.info(f"ğŸ¯ Case 2 í›ˆë ¨ ì„¤ì •:")
    logger.info(f"   - ì—í¬í¬: {num_epochs}")
    logger.info(f"   - ë°°ì¹˜ í¬ê¸°: {batch_size}")
    logger.info(f"   - í•™ìŠµë¥ : {learning_rate}")
    logger.info(f"   - Weight Decay: {weight_decay}")
    logger.info(f"   - CLIP Normalization: {use_clip_normalization}")
    logger.info(f"   - Vision Resampler: {use_vision_resampler}")
    logger.info(f"   - ì¡°ê¸° ì¢…ë£Œ ì¸ë‚´ì‹¬: {patience}")
    
    # í›ˆë ¨ ë£¨í”„
    for epoch in range(num_epochs):
        logger.info(f"\nğŸ“ˆ Epoch {epoch+1}/{num_epochs}")
        
        # í›ˆë ¨ ë‹¨ê³„
        model.train()
        train_loss = 0.0
        train_batches = 0
        
        train_pbar = tqdm(train_loader, desc=f"Training Epoch {epoch+1}")
        for batch in train_pbar:
            loss = trainer.train_step(batch)
            train_loss += loss
            train_batches += 1
            train_pbar.set_postfix({'Loss': f'{loss:.6f}'})
        
        avg_train_loss = train_loss / train_batches
        train_losses.append(avg_train_loss)
        
        # ê²€ì¦ ë‹¨ê³„
        model.eval()
        val_loss = 0.0
        val_mae = 0.0
        val_batches = 0
        
        val_pbar = tqdm(val_loader, desc=f"Validation Epoch {epoch+1}")
        with torch.no_grad():
            for batch in val_pbar:
                loss, mae = trainer.validate_step(batch)
                val_loss += loss
                val_mae += mae
                val_batches += 1
                val_pbar.set_postfix({'Loss': f'{loss:.6f}', 'MAE': f'{mae:.6f}'})
        
        avg_val_loss = val_loss / val_batches
        avg_val_mae = val_mae / val_batches
        val_losses.append(avg_val_loss)
        val_maes.append(avg_val_mae)
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸
        trainer.scheduler.step()
        
        # ë¡œê·¸ ì¶œë ¥
        logger.info(f"   ğŸ“Š í›ˆë ¨ ì†ì‹¤: {avg_train_loss:.6f}")
        logger.info(f"   ğŸ“Š ê²€ì¦ ì†ì‹¤: {avg_val_loss:.6f}")
        logger.info(f"   ğŸ“Š ê²€ì¦ MAE: {avg_val_mae:.6f}")
        logger.info(f"   ğŸ“Š í•™ìŠµë¥ : {trainer.optimizer.param_groups[0]['lr']:.2e}")
        
        # ìµœê³  ì„±ëŠ¥ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        if avg_val_mae < best_mae:
            best_mae = avg_val_mae
            best_checkpoint_path = output_path / f"best_case2_model_epoch_{epoch+1}.pth"
            trainer.save_checkpoint(best_checkpoint_path, epoch+1, avg_val_loss, avg_val_mae)
            logger.info(f"   ğŸ† ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! MAE: {best_mae:.6f}")
        
        # ì •ê¸° ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        if (epoch + 1) % 10 == 0:
            checkpoint_path = output_path / f"case2_model_epoch_{epoch+1}.pth"
            trainer.save_checkpoint(checkpoint_path, epoch+1, avg_val_loss, avg_val_mae)
        
        # ì¡°ê¸° ì¢…ë£Œ ì²´í¬
        if early_stopping(avg_val_mae, model):
            logger.info(f"   â¹ï¸ ì¡°ê¸° ì¢…ë£Œ! {patience} ì—í¬í¬ ë™ì•ˆ ê°œì„  ì—†ìŒ")
            break
    
    # ìµœì¢… ëª¨ë¸ ì €ì¥
    final_checkpoint_path = output_path / "final_case2_model.pth"
    trainer.save_checkpoint(final_checkpoint_path, epoch+1, avg_val_loss, avg_val_mae)
    
    # í›ˆë ¨ ê²°ê³¼ ì‹œê°í™”
    plot_training_results(train_losses, val_losses, val_maes, output_path)
    
    # í›ˆë ¨ ê²°ê³¼ ì €ì¥
    save_training_results(train_losses, val_losses, val_maes, best_mae, output_path, 
                         use_clip_normalization, use_vision_resampler)
    
    # ìµœì¢… ì„±ëŠ¥ í‰ê°€
    evaluate_final_performance(model, test_loader, device, output_path)
    
    logger.info(f"âœ… Case 2 í›ˆë ¨ ì™„ë£Œ!")
    logger.info(f"   - ìµœê³  MAE: {best_mae:.6f}")
    logger.info(f"   - ëª©í‘œ ë‹¬ì„±: {'âœ…' if best_mae < 0.5 else 'âŒ'} (ëª©í‘œ: < 0.5)")
    logger.info(f"   - ìµœì¢… ì—í¬í¬: {epoch+1}")
    logger.info(f"   - ê²°ê³¼ ì €ì¥: {output_path}")
    
    return model, trainer

def plot_training_results(train_losses, val_losses, val_maes, output_path):
    """í›ˆë ¨ ê²°ê³¼ ì‹œê°í™”"""
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    
    # ì†ì‹¤ ê·¸ë˜í”„
    epochs = range(1, len(train_losses) + 1)
    ax1.plot(epochs, train_losses, 'b-', label='Training Loss', linewidth=2)
    ax1.plot(epochs, val_losses, 'r-', label='Validation Loss', linewidth=2)
    ax1.set_title('Case 2: Training and Validation Loss', fontsize=14, fontweight='bold')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # MAE ê·¸ë˜í”„ + ëª©í‘œì„ 
    ax2.plot(epochs, val_maes, 'g-', label='Validation MAE', linewidth=2)
    ax2.axhline(y=0.5, color='orange', linestyle='--', label='Case 1 Target (0.5)', alpha=0.7)
    ax2.axhline(y=0.3, color='red', linestyle='--', label='Case 2 Target (0.3)', alpha=0.7)
    ax2.set_title('Case 2: Validation MAE Progress', fontsize=14, fontweight='bold')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('MAE')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(output_path / 'case2_training_results.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    logger.info(f"ğŸ“ˆ Case 2 í›ˆë ¨ ê²°ê³¼ ì‹œê°í™” ì €ì¥: {output_path / 'case2_training_results.png'}")

def save_training_results(train_losses, val_losses, val_maes, best_mae, output_path, 
                         use_clip_norm, use_vision_resampler):
    """í›ˆë ¨ ê²°ê³¼ ì €ì¥"""
    
    results = {
        'case': 'Case 2: ë‹¨ê¸° ì ìš©',
        'target': 'MAE 0.5 â†’ 0.3, ì •í™•ë„ 15% â†’ 35%',
        'train_losses': train_losses,
        'val_losses': val_losses,
        'val_maes': val_maes,
        'best_mae': best_mae,
        'final_epoch': len(train_losses),
        'target_achieved': best_mae < 0.3,
        'training_config': {
            'model_type': 'CLIPNormalized2DActionModel',
            'hidden_dim': 256,
            'action_dim': 2,
            'dropout': 0.3,
            'learning_rate': 3e-5,
            'weight_decay': 1e-3,
            'batch_size': 2,
            'use_clip_normalization': use_clip_norm,
            'use_vision_resampler': use_vision_resampler
        },
        'features': {
            'optimized_vision_resampler': 'latents 64â†’16, heads 8â†’4',
            'clip_normalization': 'feature alignment ê°œì„ ',
            'enhanced_augmentation': 'ì‹œê°„ì /ê³µê°„ì /ê³ ê¸‰ ì¦ê°•',
            'improved_hyperparameters': 'í•™ìŠµë¥  ìµœì í™”'
        }
    }
    
    with open(output_path / 'case2_training_results.json', 'w') as f:
        json.dump(results, f, indent=2)
    
    logger.info(f"ğŸ’¾ Case 2 í›ˆë ¨ ê²°ê³¼ ì €ì¥: {output_path / 'case2_training_results.json'}")

def evaluate_final_performance(model, test_loader, device, output_path):
    """ìµœì¢… ì„±ëŠ¥ í‰ê°€"""
    
    model.eval()
    test_loss = 0.0
    test_mae = 0.0
    test_batches = 0
    all_predictions = []
    all_targets = []
    
    logger.info("ğŸ” Case 2 ìµœì¢… ì„±ëŠ¥ í‰ê°€ ì¤‘...")
    
    with torch.no_grad():
        for batch in tqdm(test_loader, desc="Testing Case 2"):
            images = batch['image']  # PIL ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸
            actions = batch['action'].to(device)
            texts = batch['text']
            
            predicted_actions = model(images, texts)
            
            # ì†ì‹¤ ê³„ì‚°
            criterion = nn.HuberLoss(delta=0.1)
            loss = criterion(predicted_actions, actions)
            mae = torch.mean(torch.abs(predicted_actions - actions))
            
            test_loss += loss.item()
            test_mae += mae.item()
            test_batches += 1
            
            # ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
            all_predictions.extend(predicted_actions.cpu().numpy())
            all_targets.extend(actions.cpu().numpy())
    
    avg_test_loss = test_loss / test_batches
    avg_test_mae = test_mae / test_batches
    
    # ì •í™•ë„ ê³„ì‚° (ì‹¤ì œ ë¡œë´‡ ì œì–´ ê´€ì )
    all_predictions = np.array(all_predictions)
    all_targets = np.array(all_targets)
    
    # ì‹¤ì œ ë¡œë´‡ ì œì–´ì— ì í•©í•œ ì„ê³„ê°’ (ë” ê´€ëŒ€)
    thresholds = [0.3, 0.2, 0.15]  # 0.3m/s, 0.2m/s, 0.15m/s
    accuracies = {}
    
    for threshold in thresholds:
        # ì „ì²´ ì •í™•ë„ (ëª¨ë“  ì¶•ì´ ì„ê³„ê°’ ë‚´)
        all_axes_success = np.all(np.abs(all_predictions - all_targets) < threshold, axis=1)
        accuracies[f'accuracy_{threshold}'] = np.mean(all_axes_success) * 100
        
        # ê°œë³„ ì¶• ì •í™•ë„
        for i, axis_name in enumerate(['linear_x', 'linear_y']):
            axis_success = np.abs(all_predictions[:, i] - all_targets[:, i]) < threshold
            accuracies[f'{axis_name}_{threshold}'] = np.mean(axis_success) * 100
    
    # ì‹¤ì œ ë¡œë´‡ ì œì–´ ì„±ëŠ¥ ì§€í‘œ ì¶”ê°€
    # 1. ì¶”ì  ì„±ëŠ¥ (ëª©í‘œ ì§€ì  ê·¼ì²˜ ë„ë‹¬ë¥ )
    tracking_threshold = 0.5  # 0.5m/s ì´ë‚´ë©´ ì„±ê³µ
    tracking_success = np.all(np.abs(all_predictions - all_targets) < tracking_threshold, axis=1)
    tracking_accuracy = np.mean(tracking_success) * 100
    
    # 2. ë°©í–¥ ì •í™•ë„ (ë¶€í˜¸ê°€ ë§ëŠ”ì§€)
    direction_correct_x = np.sign(all_predictions[:, 0]) == np.sign(all_targets[:, 0])
    direction_correct_y = np.sign(all_predictions[:, 1]) == np.sign(all_targets[:, 1])
    direction_accuracy_x = np.mean(direction_correct_x) * 100
    direction_accuracy_y = np.mean(direction_correct_y) * 100
    
    # 3. í¬ê¸° ìˆœì„œ ì •í™•ë„ (ìƒëŒ€ì  í¬ê¸°ê°€ ë§ëŠ”ì§€)
    magnitude_order_correct = (
        (all_predictions[:, 0] > all_predictions[:, 1]) == (all_targets[:, 0] > all_targets[:, 1])
    )
    magnitude_order_accuracy = np.mean(magnitude_order_correct) * 100
    
    # ê²°ê³¼ ì¶œë ¥
    logger.info(f"ğŸ“Š Case 2 ìµœì¢… ì„±ëŠ¥ ê²°ê³¼:")
    logger.info(f"   - í…ŒìŠ¤íŠ¸ ì†ì‹¤: {avg_test_loss:.6f}")
    logger.info(f"   - í…ŒìŠ¤íŠ¸ MAE: {avg_test_mae:.6f}")
    logger.info(f"   - ëª©í‘œ ë‹¬ì„±: {'âœ…' if avg_test_mae < 0.3 else 'âŒ'} (ëª©í‘œ: < 0.3)")
    
    # ì‹¤ì œ ë¡œë´‡ ì œì–´ ì„±ëŠ¥
    logger.info(f"   - ì¶”ì  ì„±ëŠ¥ (0.5m/s): {tracking_accuracy:.2f}%")
    logger.info(f"   - ë°©í–¥ ì •í™•ë„:")
    logger.info(f"     - linear_x: {direction_accuracy_x:.2f}%")
    logger.info(f"     - linear_y: {direction_accuracy_y:.2f}%")
    logger.info(f"   - í¬ê¸° ìˆœì„œ ì •í™•ë„: {magnitude_order_accuracy:.2f}%")
    
    for threshold in thresholds:
        logger.info(f"   - ì •í™•ë„ ({threshold}): {accuracies[f'accuracy_{threshold}']:.2f}%")
        logger.info(f"     - linear_x: {accuracies[f'linear_x_{threshold}']:.2f}%")
        logger.info(f"     - linear_y: {accuracies[f'linear_y_{threshold}']:.2f}%")
    
    # ê²°ê³¼ ì €ì¥
    test_results = {
        'test_loss': avg_test_loss,
        'test_mae': avg_test_mae,
        'target_achieved': avg_test_mae < 0.3,
        'accuracies': accuracies,
        'tracking_accuracy': tracking_accuracy,
        'direction_accuracy': {
            'linear_x': direction_accuracy_x,
            'linear_y': direction_accuracy_y
        },
        'magnitude_order_accuracy': magnitude_order_accuracy,
        'predictions': all_predictions.tolist(),
        'targets': all_targets.tolist()
    }
    
    with open(output_path / 'case2_test_results.json', 'w') as f:
        json.dump(test_results, f, indent=2)
    
    logger.info(f"ğŸ’¾ Case 2 í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥: {output_path / 'case2_test_results.json'}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='Train Case 2: Optimized 2D Action Model')
    parser.add_argument('--data_path', type=str, required=True, help='Path to dataset')
    parser.add_argument('--output_dir', type=str, default='case2_results', help='Output directory')
    parser.add_argument('--num_epochs', type=int, default=50, help='Number of epochs')
    parser.add_argument('--batch_size', type=int, default=2, help='Batch size')
    parser.add_argument('--learning_rate', type=float, default=3e-5, help='Learning rate')
    parser.add_argument('--weight_decay', type=float, default=1e-3, help='Weight decay')
    parser.add_argument('--patience', type=int, default=5, help='Early stopping patience')
    parser.add_argument('--no_clip_norm', action='store_true', help='Disable CLIP normalization')
    parser.add_argument('--no_vision_resampler', action='store_true', help='Disable Vision Resampler')
    
    args = parser.parse_args()
    
    # í›ˆë ¨ ì‹¤í–‰
    model, trainer = train_optimized_model(
        data_path=args.data_path,
        output_dir=args.output_dir,
        num_epochs=args.num_epochs,
        batch_size=args.batch_size,
        learning_rate=args.learning_rate,
        weight_decay=args.weight_decay,
        patience=args.patience,
        use_clip_normalization=not args.no_clip_norm,
        use_vision_resampler=not args.no_vision_resampler
    )

if __name__ == "__main__":
    main()
