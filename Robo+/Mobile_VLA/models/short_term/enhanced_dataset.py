#!/usr/bin/env python3
"""
ğŸš€ Case 2: ë‹¨ê¸° ì ìš© - ê³ ê¸‰ ë°ì´í„° ì¦ê°•
ëª©í‘œ: MAE 0.5 â†’ 0.3, ì •í™•ë„ 15% â†’ 35%
íŠ¹ì§•: ì‹œê°„ì /ê³µê°„ì  ì¦ê°• + ê³ ê¸‰ ë³€í˜•
"""

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import h5py
import numpy as np
from PIL import Image, ImageEnhance, ImageFilter
import torchvision.transforms as transforms
import random
import logging
from pathlib import Path
import cv2

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class EnhancedAugmentationDataset(Dataset):
    """
    ê³ ê¸‰ ë°ì´í„° ì¦ê°• ë°ì´í„°ì…‹
    - ì‹œê°„ì  ì¦ê°• (í”„ë ˆì„ ìˆœì„œ ë³€ê²½)
    - ê³µê°„ì  ì¦ê°• (íšŒì „, í¬ë¡­, ì™œê³¡)
    - ê³ ê¸‰ ì´ë¯¸ì§€ ì²˜ë¦¬ (ë¸”ëŸ¬, ìƒ¤í”„ë‹, ì±„ë„ ì¡°ì •)
    - ì•¡ì…˜ ì‹œí€€ìŠ¤ ë³€í˜•
    """
    
    def __init__(self, data_path, processor, frame_selection='random',
                 spatial_aug_prob=0.6, temporal_aug_prob=0.4, 
                 advanced_aug_prob=0.3, action_noise_std=0.08):
        self.data_path = data_path
        self.processor = processor
        self.frame_selection = frame_selection
        self.spatial_aug_prob = spatial_aug_prob
        self.temporal_aug_prob = temporal_aug_prob
        self.advanced_aug_prob = advanced_aug_prob
        self.action_noise_std = action_noise_std
        
        # ë°ì´í„° ë¡œë“œ
        self.data = self._load_data()
        
        logger.info(f"âœ… Enhanced Augmentation Dataset ì´ˆê¸°í™” ì™„ë£Œ:")
        logger.info(f"   - ë°ì´í„° ê²½ë¡œ: {data_path}")
        logger.info(f"   - ìƒ˜í”Œ ìˆ˜: {len(self.data)}")
        logger.info(f"   - ê³µê°„ì  ì¦ê°• í™•ë¥ : {spatial_aug_prob}")
        logger.info(f"   - ì‹œê°„ì  ì¦ê°• í™•ë¥ : {temporal_aug_prob}")
        logger.info(f"   - ê³ ê¸‰ ì¦ê°• í™•ë¥ : {advanced_aug_prob}")
        logger.info(f"   - ì•¡ì…˜ ë…¸ì´ì¦ˆ í‘œì¤€í¸ì°¨: {action_noise_std}")
    
    def _load_data(self):
        """H5 íŒŒì¼ë“¤ì—ì„œ ë°ì´í„° ë¡œë“œ"""
        data = []
        data_path = Path(self.data_path)
        
        # H5 íŒŒì¼ë“¤ ì°¾ê¸°
        h5_files = list(data_path.glob("*.h5"))
        logger.info(f"ğŸ“ H5 íŒŒì¼ ìˆ˜: {len(h5_files)}")
        
        for h5_file in h5_files:
            try:
                with h5py.File(h5_file, 'r') as f:
                    if 'images' in f and 'actions' in f:
                        images = f['images'][:]
                        actions = f['actions'][:]
                        
                        # ê° í”„ë ˆì„ì„ ìƒ˜í”Œë¡œ ì¶”ê°€ (ì‹œê°„ì  ì¦ê°•ì„ ìœ„í•´ ì—¬ëŸ¬ í”„ë ˆì„ ì €ì¥)
                        if self.frame_selection == 'all':
                            # ëª¨ë“  í”„ë ˆì„ ì‚¬ìš©
                            for frame_idx in range(len(images)):
                                data.append({
                                    'image': images[frame_idx],
                                    'action': actions[frame_idx][:2],
                                    'episode_id': len(data),
                                    'frame_id': frame_idx,
                                    'all_images': images,  # ì‹œê°„ì  ì¦ê°•ìš©
                                    'all_actions': actions  # ì‹œê°„ì  ì¦ê°•ìš©
                                })
                        else:
                            # ì²« í”„ë ˆì„ë§Œ ì‚¬ìš©
                            frame_idx = 0 if self.frame_selection == 'first' else random.randint(0, len(images) - 1)
                            data.append({
                                'image': images[frame_idx],
                                'action': actions[frame_idx][:2],
                                'episode_id': len(data),
                                'frame_id': frame_idx,
                                'all_images': images,
                                'all_actions': actions
                            })
                            
            except Exception as e:
                logger.error(f"âŒ {h5_file} ë¡œë“œ ì˜¤ë¥˜: {e}")
                continue
        
        logger.info(f"ğŸ“Š ë¡œë“œëœ ìƒ˜í”Œ ìˆ˜: {len(data)}")
        return data
    
    def _spatial_augmentation(self, image):
        """ê³µê°„ì  ì¦ê°•"""
        if random.random() > self.spatial_aug_prob:
            return image
        
        # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
        if isinstance(image, np.ndarray):
            image = Image.fromarray(image)
        
        # 1. ì‘ì€ íšŒì „ (-5ë„ ~ 5ë„)
        if random.random() < 0.4:
            angle = random.uniform(-5, 5)
            image = image.rotate(angle, resample=Image.BILINEAR, fillcolor=(0, 0, 0))
        
        # 2. í¬ë¡­ ë° ë¦¬ì‚¬ì´ì¦ˆ (90~100% í¬ê¸°)
        if random.random() < 0.3:
            w, h = image.size
            crop_ratio = random.uniform(0.9, 1.0)
            new_w, new_h = int(w * crop_ratio), int(h * crop_ratio)
            left = random.randint(0, w - new_w)
            top = random.randint(0, h - new_h)
            image = image.crop((left, top, left + new_w, top + new_h))
            image = image.resize((w, h), Image.BILINEAR)
        
        # 3. ìˆ˜í‰ í”Œë¦½ (ë¡œë´‡ ì œì–´ì— ì í•©í•˜ë„ë¡ ë‚®ì€ í™•ë¥ )
        if random.random() < 0.2:
            image = image.transpose(Image.FLIP_LEFT_RIGHT)
        
        return image
    
    def _temporal_augmentation(self, item):
        """ì‹œê°„ì  ì¦ê°• - ì¸ì ‘ í”„ë ˆì„ ì‚¬ìš©"""
        if random.random() > self.temporal_aug_prob:
            return item['image'], item['action']
        
        all_images = item['all_images']
        all_actions = item['all_actions']
        current_frame = item['frame_id']
        
        # ì¸ì ‘ í”„ë ˆì„ ì„ íƒ (Â±1~2 í”„ë ˆì„)
        max_offset = min(2, len(all_images) - 1)
        if max_offset > 0:
            offset = random.randint(-max_offset, max_offset)
            new_frame = max(0, min(len(all_images) - 1, current_frame + offset))
            
            return all_images[new_frame], all_actions[new_frame][:2]
        
        return item['image'], item['action']
    
    def _advanced_augmentation(self, image):
        """ê³ ê¸‰ ì´ë¯¸ì§€ ì¦ê°•"""
        if random.random() > self.advanced_aug_prob:
            return image
        
        # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
        if isinstance(image, np.ndarray):
            image = Image.fromarray(image)
        
        # 1. ì±„ë„ ì¡°ì •
        if random.random() < 0.4:
            enhancer = ImageEnhance.Color(image)
            factor = random.uniform(0.8, 1.3)
            image = enhancer.enhance(factor)
        
        # 2. ìƒ¤í”„ë‹/ë¸”ëŸ¬
        if random.random() < 0.3:
            if random.random() < 0.5:
                # ìƒ¤í”„ë‹
                enhancer = ImageEnhance.Sharpness(image)
                factor = random.uniform(1.0, 1.5)
                image = enhancer.enhance(factor)
            else:
                # ë¸”ëŸ¬
                radius = random.uniform(0.5, 1.5)
                image = image.filter(ImageFilter.GaussianBlur(radius=radius))
        
        # 3. ë°ê¸° ì¡°ì • (ë¯¸ì„¸)
        if random.random() < 0.5:
            enhancer = ImageEnhance.Brightness(image)
            factor = random.uniform(0.9, 1.1)
            image = enhancer.enhance(factor)
        
        return image
    
    def _action_augmentation(self, action):
        """ì•¡ì…˜ ì¦ê°•"""
        # ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ì¶”ê°€
        if random.random() < 0.7:
            noise = np.random.normal(0, self.action_noise_std, action.shape)
            action = action + noise
        
        # ì•¡ì…˜ ìŠ¤ì¼€ì¼ë§ (ë¯¸ì„¸ ì¡°ì •)
        if random.random() < 0.3:
            scale_factor = random.uniform(0.95, 1.05)
            action = action * scale_factor
        
        # ì•¡ì…˜ ë²”ìœ„ ì œí•œ
        action = np.clip(action, -1.0, 1.0)
        
        return action
    
    def __getitem__(self, idx):
        """ë°ì´í„° ìƒ˜í”Œ ë°˜í™˜"""
        item = self.data[idx]
        
        # ì‹œê°„ì  ì¦ê°• ì ìš©
        image, action = self._temporal_augmentation(item)
        
        # ê³µê°„ì  ì¦ê°• ì ìš©
        image = self._spatial_augmentation(image)
        
        # ê³ ê¸‰ ì¦ê°• ì ìš©
        image = self._advanced_augmentation(image)
        
        # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜ (ìµœì¢…)
        if isinstance(image, np.ndarray):
            image = Image.fromarray(image).convert('RGB')
        
        # ì•¡ì…˜ ì¦ê°• ì ìš©
        action = self._action_augmentation(action)
        
        # í…ìŠ¤íŠ¸ (ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸)
        prompts = [
            "Navigate the robot to the target location.",
            "Move the robot forward to reach the goal.",
            "Control the robot to complete the task.",
            "Guide the robot to the destination.",
            "Navigate to the target point."
        ]
        text = random.choice(prompts)
        
        return {
            'image': image,
            'action': torch.tensor(action, dtype=torch.float32),
            'text': text,
            'episode_id': item['episode_id']
        }
    
    def __len__(self):
        return len(self.data)

def custom_collate_fn(batch):
    """PIL ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì»¤ìŠ¤í…€ collate í•¨ìˆ˜"""
    images = [item['image'] for item in batch]
    actions = torch.stack([item['action'] for item in batch])
    texts = [item['text'] for item in batch]
    episode_ids = [item['episode_id'] for item in batch]
    
    return {
        'image': images,  # PIL ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸
        'action': actions,
        'text': texts,
        'episode_id': episode_ids
    }

def create_enhanced_data_loaders(data_path, processor, batch_size=2, 
                                train_split=0.7, val_split=0.15, test_split=0.15):
    """ê³ ê¸‰ ì¦ê°• ë°ì´í„° ë¡œë” ìƒì„±"""
    
    # ì „ì²´ ë°ì´í„°ì…‹ ìƒì„±
    full_dataset = EnhancedAugmentationDataset(
        data_path=data_path,
        processor=processor,
        frame_selection='random',  # ëœë¤ í”„ë ˆì„ ì‚¬ìš©
        spatial_aug_prob=0.6,
        temporal_aug_prob=0.4,
        advanced_aug_prob=0.3,
        action_noise_std=0.08
    )
    
    # ë°ì´í„°ì…‹ ë¶„í• 
    total_size = len(full_dataset)
    train_size = int(total_size * train_split)
    val_size = int(total_size * val_split)
    test_size = total_size - train_size - val_size
    
    logger.info(f"ğŸ“Š Enhanced Dataset ë¶„í• :")
    logger.info(f"   - ì „ì²´: {total_size}")
    logger.info(f"   - í›ˆë ¨: {train_size}")
    logger.info(f"   - ê²€ì¦: {val_size}")
    logger.info(f"   - í…ŒìŠ¤íŠ¸: {test_size}")
    
    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
        full_dataset, [train_size, val_size, test_size]
    )
    
    # ë°ì´í„° ë¡œë” ìƒì„± (custom_collate_fn ì‚¬ìš©)
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=0,
        pin_memory=True,
        collate_fn=custom_collate_fn
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=0,
        pin_memory=True,
        collate_fn=custom_collate_fn
    )
    
    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=0,
        pin_memory=True,
        collate_fn=custom_collate_fn
    )
    
    logger.info(f"âœ… Enhanced Data Loaders ìƒì„± ì™„ë£Œ")
    
    return train_loader, val_loader, test_loader

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    from transformers import AutoProcessor
    
    processor = AutoProcessor.from_pretrained("microsoft/kosmos-2-patch14-224")
    
    # ë°ì´í„°ì…‹ ìƒì„±
    dataset = EnhancedAugmentationDataset(
        data_path="../../../../ROS_action/mobile_vla_dataset/",
        processor=processor,
        frame_selection='first'
    )
    
    # ë°ì´í„° ë¡œë” ìƒì„±
    train_loader, val_loader, test_loader = create_enhanced_data_loaders(
        data_path="../../../../ROS_action/mobile_vla_dataset/",
        processor=processor,
        batch_size=2
    )
    
    # ë°°ì¹˜ í…ŒìŠ¤íŠ¸
    for batch in train_loader:
        logger.info(f"ğŸ“¦ Enhanced ë°°ì¹˜ ì •ë³´:")
        logger.info(f"   - ì´ë¯¸ì§€: {batch['image'][0].size}")
        logger.info(f"   - ì•¡ì…˜: {batch['action'].shape}")
        logger.info(f"   - í…ìŠ¤íŠ¸: {len(batch['text'])}")
        break
