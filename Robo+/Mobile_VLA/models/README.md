# Models Directory Structure

## ğŸ“ ëª¨ë¸ ë¶„ë¥˜ ì²´ê³„

### ğŸ¯ **Case 1: ì¦‰ì‹œ ì ìš© (Immediate Optimization)**
**ëª©í‘œ**: MAE 0.8 â†’ 0.5, ì •í™•ë„ 0% â†’ 15%
**íŠ¹ì§•**: ê¸°ì¡´ ëª¨ë¸ êµ¬ì¡° ë‹¨ìˆœí™” + ê¸°ë³¸ ë°ì´í„° ì¦ê°•

```
models/immediate/
â”œâ”€â”€ simplified_2d_model.py          # ëª¨ë¸ êµ¬ì¡° ë‹¨ìˆœí™”
â”œâ”€â”€ basic_augmentation_dataset.py   # ê¸°ë³¸ ë°ì´í„° ì¦ê°•
â”œâ”€â”€ train_simplified_model.py       # í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ evaluate_simplified_model.py    # í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
```

### ğŸš€ **Case 2: ë‹¨ê¸° ì ìš© (Short-term Optimization)**
**ëª©í‘œ**: MAE 0.5 â†’ 0.3, ì •í™•ë„ 15% â†’ 35%
**íŠ¹ì§•**: Vision Resampler ìµœì í™” + CLIP Normalization

```
models/short_term/
â”œâ”€â”€ optimized_vision_resampler.py   # Vision Resampler ìµœì í™” (latents 64â†’16)
â”œâ”€â”€ clip_normalized_model.py        # CLIP Normalization ì¶”ê°€
â”œâ”€â”€ enhanced_dataset.py             # ê³ ê¸‰ ë°ì´í„° ì¦ê°•
â”œâ”€â”€ train_optimized_model.py        # í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ evaluate_optimized_model.py     # í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
```

### ğŸ”¬ **Case 3: ì¤‘ê¸° ì ìš© (Medium-term Optimization)**
**ëª©í‘œ**: MAE 0.3 â†’ 0.2, ì •í™•ë„ 35% â†’ 50%
**íŠ¹ì§•**: Hierarchical Planning + Advanced Attention

```
models/medium_term/
â”œâ”€â”€ hierarchical_planning.py        # Hierarchical Planning êµ¬í˜„
â”œâ”€â”€ advanced_attention.py           # Advanced Attention êµ¬í˜„
â”œâ”€â”€ transfer_learning_model.py      # Transfer Learning ì ìš©
â”œâ”€â”€ ensemble_model.py               # ì•™ìƒë¸” ëª¨ë¸
â”œâ”€â”€ train_advanced_model.py         # í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ evaluate_advanced_model.py      # í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
```

### ğŸŒŸ **Case 4: ì¥ê¸° ì ìš© (Long-term Optimization)**
**ëª©í‘œ**: MAE 0.2 â†’ 0.15, ì •í™•ë„ 50% â†’ 65%
**íŠ¹ì§•**: Meta Learning + Curriculum Learning

```
models/long_term/
â”œâ”€â”€ meta_learning_model.py          # Meta Learning êµ¬í˜„
â”œâ”€â”€ curriculum_learning.py          # Curriculum Learning êµ¬í˜„
â”œâ”€â”€ self_supervised_model.py        # Self-supervised Learning
â”œâ”€â”€ real_robot_test.py              # ì‹¤ì œ ë¡œë´‡ í…ŒìŠ¤íŠ¸
â”œâ”€â”€ train_meta_model.py             # í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ evaluate_meta_model.py          # í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
```

### ğŸ”® **Case 5: ë¯¸ë˜ ì ìš© (Future Optimization)**
**ëª©í‘œ**: MAE 0.15 â†’ 0.1, ì •í™•ë„ 65% â†’ 80%
**íŠ¹ì§•**: Active Learning + í•˜ì´ë¸Œë¦¬ë“œ ì¦ê°•

```
models/future/
â”œâ”€â”€ active_learning_model.py        # Active Learning êµ¬í˜„
â”œâ”€â”€ hybrid_augmentation.py          # í•˜ì´ë¸Œë¦¬ë“œ ì¦ê°•
â”œâ”€â”€ real_time_adaptation.py         # ì‹¤ì‹œê°„ ì ì‘
â”œâ”€â”€ large_scale_dataset.py          # ëŒ€ê·œëª¨ ë°ì´í„°ì…‹
â”œâ”€â”€ train_active_model.py           # í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ evaluate_active_model.py        # í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
```

### ğŸ“Š **Case 6: ë¹„êµ ë¶„ì„ (Comparison Analysis)**
**ëª©ì **: ëª¨ë“  ì¼€ì´ìŠ¤ì˜ ì„±ëŠ¥ ë¹„êµ ë° ë¶„ì„

```
models/comparison/
â”œâ”€â”€ performance_comparison.py       # ì„±ëŠ¥ ë¹„êµ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ model_comparison_table.py       # ëª¨ë¸ ë¹„êµ í…Œì´ë¸”
â”œâ”€â”€ visualization_tools.py          # ì‹œê°í™” ë„êµ¬
â”œâ”€â”€ statistical_analysis.py         # í†µê³„ ë¶„ì„
â””â”€â”€ generate_report.py              # ë³´ê³ ì„œ ìƒì„±
```

## ğŸ¯ **ê° ì¼€ì´ìŠ¤ë³„ í•µì‹¬ íŠ¹ì§•**

### Case 1 (ì¦‰ì‹œ ì ìš©)
- **ëª¨ë¸ êµ¬ì¡°**: hidden_dim 512â†’256, action_head 2ì¸µâ†’1ì¸µ
- **í•™ìŠµ ì „ëµ**: lr 1e-4â†’5e-5, weight_decay 1e-4â†’1e-3
- **ë°ì´í„° ì¦ê°•**: ê¸°ë³¸ì ì¸ ì´ë¯¸ì§€/ì•¡ì…˜ ë…¸ì´ì¦ˆ
- **ì˜ˆìƒ íš¨ê³¼**: ì¦‰ì‹œ ì„±ëŠ¥ í–¥ìƒ, êµ¬í˜„ ë‚œì´ë„ ë‚®ìŒ

### Case 2 (ë‹¨ê¸° ì ìš©)
- **Vision Resampler**: latents 64â†’16, heads 8â†’4, FFN 2xâ†’1.5x
- **CLIP Normalization**: Feature alignment ì¶”ê°€
- **ê³ ê¸‰ ì¦ê°•**: ì‹œê°„ì /ê³µê°„ì  ì¦ê°•
- **ì˜ˆìƒ íš¨ê³¼**: ì¤‘ê°„ ìˆ˜ì¤€ ì„±ëŠ¥ í–¥ìƒ, ê²€ì¦ëœ ë°©ë²•

### Case 3 (ì¤‘ê¸° ì ìš©)
- **Hierarchical Planning**: ëª©í‘œ ë¶„í•´ ë° ê³„íš
- **Advanced Attention**: Multi-modal attention
- **Transfer Learning**: ì‚¬ì „ ì§€ì‹ í™œìš©
- **ì˜ˆìƒ íš¨ê³¼**: ê³ ê¸‰ ê¸°ëŠ¥ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ

### Case 4 (ì¥ê¸° ì ìš©)
- **Meta Learning**: ì ì‘ë ¥ í–¥ìƒ
- **Curriculum Learning**: í•™ìŠµ ìˆœì„œ ìµœì í™”
- **Self-supervised**: í‘œí˜„ í•™ìŠµ
- **ì˜ˆìƒ íš¨ê³¼**: í˜ì‹ ì  ë°©ë²•ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ

### Case 5 (ë¯¸ë˜ ì ìš©)
- **Active Learning**: íš¨ìœ¨ì  í•™ìŠµ
- **í•˜ì´ë¸Œë¦¬ë“œ ì¦ê°•**: ì¢…í•©ì  ë°ì´í„° ì¦ê°•
- **ì‹¤ì‹œê°„ ì ì‘**: ë™ì  í™˜ê²½ ëŒ€ì‘
- **ì˜ˆìƒ íš¨ê³¼**: ë¯¸ë˜ ê¸°ìˆ ë¡œ ìµœê³  ì„±ëŠ¥

## ğŸ“ˆ **ì„±ëŠ¥ ì˜ˆìƒ ê·¸ë˜í”„**

```
MAE ë³€í™” ì¶”ì´:
í˜„ì¬: 0.804
Case 1: 0.5    (ì¦‰ì‹œ ì ìš©)
Case 2: 0.3    (ë‹¨ê¸° ì ìš©)
Case 3: 0.2    (ì¤‘ê¸° ì ìš©)
Case 4: 0.15   (ì¥ê¸° ì ìš©)
Case 5: 0.1    (ë¯¸ë˜ ì ìš©)

ì •í™•ë„ ë³€í™” ì¶”ì´:
í˜„ì¬: 0%
Case 1: 15%    (ì¦‰ì‹œ ì ìš©)
Case 2: 35%    (ë‹¨ê¸° ì ìš©)
Case 3: 50%    (ì¤‘ê¸° ì ìš©)
Case 4: 65%    (ì¥ê¸° ì ìš©)
Case 5: 80%    (ë¯¸ë˜ ì ìš©)
```

## ğŸš€ **êµ¬í˜„ ìš°ì„ ìˆœìœ„**

1. **Case 1**: ì¦‰ì‹œ êµ¬í˜„ (1ì£¼)
2. **Case 2**: ë‹¨ê¸° êµ¬í˜„ (2-4ì£¼)
3. **Case 3**: ì¤‘ê¸° êµ¬í˜„ (1-2ê°œì›”)
4. **Case 4**: ì¥ê¸° êµ¬í˜„ (3-6ê°œì›”)
5. **Case 5**: ë¯¸ë˜ êµ¬í˜„ (6ê°œì›”+)
6. **Case 6**: ì§€ì†ì  ë¹„êµ ë¶„ì„

## ğŸ“ **ê° ì¼€ì´ìŠ¤ë³„ êµ¬í˜„ ì²´í¬ë¦¬ìŠ¤íŠ¸**

### Case 1 ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] ëª¨ë¸ êµ¬ì¡° ë‹¨ìˆœí™”
- [ ] ê¸°ë³¸ ë°ì´í„° ì¦ê°• êµ¬í˜„
- [ ] í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§
- [ ] ì •ê·œí™” ê°•í™”
- [ ] ì„±ëŠ¥ í‰ê°€ ë° ë¹„êµ

### Case 2 ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] Vision Resampler ìµœì í™”
- [ ] CLIP Normalization ì¶”ê°€
- [ ] State Embedding êµ¬í˜„
- [ ] ê³ ê¸‰ ë°ì´í„° ì¦ê°•
- [ ] ì„±ëŠ¥ í‰ê°€ ë° ë¹„êµ

### Case 3 ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] Hierarchical Planning êµ¬í˜„
- [ ] Advanced Attention êµ¬í˜„
- [ ] Transfer Learning ì ìš©
- [ ] ì•™ìƒë¸” ëª¨ë¸ êµ¬í˜„
- [ ] ì„±ëŠ¥ í‰ê°€ ë° ë¹„êµ

### Case 4 ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] Meta Learning êµ¬í˜„
- [ ] Curriculum Learning êµ¬í˜„
- [ ] Self-supervised Learning
- [ ] ì‹¤ì œ ë¡œë´‡ í…ŒìŠ¤íŠ¸
- [ ] ì„±ëŠ¥ í‰ê°€ ë° ë¹„êµ

### Case 5 ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] Active Learning êµ¬í˜„
- [ ] í•˜ì´ë¸Œë¦¬ë“œ ì¦ê°•
- [ ] ì‹¤ì‹œê°„ ì ì‘
- [ ] ëŒ€ê·œëª¨ ë°ì´í„°ì…‹
- [ ] ì„±ëŠ¥ í‰ê°€ ë° ë¹„êµ
