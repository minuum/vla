#!/usr/bin/env python3
"""
ğŸ¯ ë³´ìˆ˜ì  ë°ì´í„° ì¦ê°• í•™ìŠµ (72ê°œ â†’ 144ê°œ)
"""

import torch
import torch.nn as nn
import numpy as np
import random
from pathlib import Path
import sys
import json
from datetime import datetime
import torchvision.transforms as transforms
from PIL import Image

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
ROOT_DIR = Path("/home/billy/25-1kp/vla/Robo+/Mobile_VLA")
DATA_DIR = Path("/home/billy/25-1kp/vla/ROS_action/mobile_vla_dataset")
ROBOVLMS_DIR = Path("/home/billy/25-1kp/vla/RoboVLMs")

sys.path.append(str(ROOT_DIR))
sys.path.append(str(ROBOVLMS_DIR))

from robovlms.data.mobile_vla_dataset import MobileVLADataset
from robovlms.train.mobile_vla_trainer import MobileVLATrainer
from torch.utils.data import DataLoader

class ConservativeAugmentationTrainer(MobileVLATrainer):
    """ë³´ìˆ˜ì  ë°ì´í„° ì¦ê°• íŠ¸ë ˆì´ë„ˆ"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        
        # Zì¶• íŠ¹ë³„ ì²˜ë¦¬
        self.z_weight = 0.05
        
        # ë³´ìˆ˜ì  ì¦ê°• ì„¤ì • (1ë‹¨ê³„)
        self.augmentation_level = 1
        self.image_flip_prob = 0.5
        self.action_noise_std = 0.005  # ë§¤ìš° ì‘ì€ ë…¸ì´ì¦ˆ
        self.z_noise_std = 0.0  # Zì¶•ì€ ê±´ë“œë¦¬ì§€ ì•ŠìŒ
        
        # ì´ë¯¸ì§€ ë³€í™˜
        self.image_flip = transforms.RandomHorizontalFlip(p=1.0)  # í™•ë¥ ì ìœ¼ë¡œ ì ìš©
        self.image_normal = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        print("âœ… ConservativeAugmentationTrainer ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   Zì¶• ê°€ì¤‘ì¹˜: {self.z_weight}")
        print(f"   ì¦ê°• ë ˆë²¨: {self.augmentation_level} (ë³´ìˆ˜ì )")
        print(f"   ì´ë¯¸ì§€ flip í™•ë¥ : {self.image_flip_prob}")
        print(f"   ì•¡ì…˜ ë…¸ì´ì¦ˆ: Ïƒ={self.action_noise_std}")
        print(f"   Zì¶• ë…¸ì´ì¦ˆ: Ïƒ={self.z_noise_std}")
    
    def compute_action_statistics(self, dataset):
        """ì•ˆì „í•œ ì•¡ì…˜ í†µê³„ ê³„ì‚°"""
        print("ğŸ“Š ì•¡ì…˜ í†µê³„ ê³„ì‚° ì¤‘...")
        
        all_actions = []
        for i in range(len(dataset)):
            episode = dataset[i]
            actions = episode['actions']
            if isinstance(actions, list):
                actions = torch.tensor(actions, dtype=torch.float32)
            elif isinstance(actions, np.ndarray):
                actions = torch.from_numpy(actions)
            all_actions.append(actions)
        
        all_actions = torch.cat(all_actions, dim=0)
        
        self.action_mean = all_actions.mean(dim=0)
        self.action_std = all_actions.std(dim=0)
        
        # Zì¶• íŠ¹ë³„ ì²˜ë¦¬
        if self.action_std[2] < 1e-6:
            print("âš ï¸ Zì¶• í‘œì¤€í¸ì°¨ê°€ ë„ˆë¬´ ì‘ìŒ - ê¸°ë³¸ê°’ ì‚¬ìš©")
            self.action_std[2] = 1.0
        
        self.action_std = torch.clamp(self.action_std, min=1e-3)
        
        print(f"   ì•¡ì…˜ ë²”ìœ„: {all_actions.min():.4f} ~ {all_actions.max():.4f}")
        print(f"   ì•¡ì…˜ í‰ê· : {self.action_mean}")
        print(f"   ì•¡ì…˜ í‘œì¤€í¸ì°¨: {self.action_std}")
    
    def safe_normalize_actions(self, actions):
        """ì•ˆì „í•œ ì•¡ì…˜ ì •ê·œí™”"""
        if not hasattr(self, 'action_mean'):
            return actions
        
        # ë°ì´í„° íƒ€ì… í™•ì¸ ë° ë³€í™˜
        if isinstance(actions, list):
            actions = torch.tensor(actions, dtype=torch.float32)
        elif isinstance(actions, np.ndarray):
            actions = torch.from_numpy(actions).float()
        
        # ì°¨ì› í™•ì¸ ë° ì¡°ì •
        original_shape = actions.shape
        if actions.dim() == 2:  # [T, 3]
            actions = actions.unsqueeze(0)  # [1, T, 3]
        
        normalized = torch.zeros_like(actions)
        for i in range(3):
            if self.action_std[i] > 1e-6:
                normalized[:, :, i] = (actions[:, :, i] - self.action_mean[i]) / self.action_std[i]
            else:
                normalized[:, :, i] = actions[:, :, i] - self.action_mean[i]
        
        # ì›ë˜ í˜•íƒœë¡œ ë³µì›
        if len(original_shape) == 2:
            normalized = normalized.squeeze(0)
        
        return normalized
    
    def augment_episode_conservative(self, episode):
        """ë³´ìˆ˜ì  ì—í”¼ì†Œë“œ ì¦ê°• (2ë°°ë¡œ í™•ì¥)"""
        augmented_episodes = []
        
        # ì›ë³¸ ì—í”¼ì†Œë“œ (ì •ê·œí™”ë§Œ)
        original_episode = self._process_episode(episode, augment=False)
        augmented_episodes.append(original_episode)
        
        # ì¦ê°•ëœ ì—í”¼ì†Œë“œ 1ê°œ
        augmented_episode = self._process_episode(episode, augment=True)
        augmented_episodes.append(augmented_episode)
        
        return augmented_episodes
    
    def _process_episode(self, episode, augment=False):
        """ì—í”¼ì†Œë“œ ì²˜ë¦¬ (ì¦ê°• ì—¬ë¶€ì— ë”°ë¼)"""
        processed_episode = episode.copy()
        
        # ì´ë¯¸ì§€ ì²˜ë¦¬
        images = episode['images']
        processed_images = []
        
        for img in images:
            # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
            if isinstance(img, torch.Tensor):
                # í…ì„œë¥¼ PILë¡œ ë³€í™˜
                if img.max() <= 1.0:
                    img_pil = transforms.ToPILImage()(img)
                else:
                    img_pil = transforms.ToPILImage()(img / 255.0)
            elif isinstance(img, np.ndarray):
                img_pil = Image.fromarray(img.astype(np.uint8))
            else:
                img_pil = img
            
            # ì¦ê°• ì ìš©
            if augment and random.random() < self.image_flip_prob:
                img_processed = self.image_normal(self.image_flip(img_pil))
            else:
                img_processed = self.image_normal(img_pil)
            
            processed_images.append(img_processed)
        
        processed_episode['images'] = torch.stack(processed_images)
        
        # ì•¡ì…˜ ì²˜ë¦¬
        actions = episode['actions']
        if isinstance(actions, list):
            actions = torch.tensor(actions, dtype=torch.float32)
        elif isinstance(actions, np.ndarray):
            actions = torch.from_numpy(actions).float()
        
        # ì•¡ì…˜ ì¦ê°•
        if augment:
            # X, Yì¶•ì—ë§Œ ì‘ì€ ë…¸ì´ì¦ˆ ì¶”ê°€
            xy_noise = torch.normal(0, self.action_noise_std, actions[:, :2].shape)
            actions[:, :2] += xy_noise
            
            # ë²”ìœ„ ì œí•œ
            actions = torch.clamp(actions, -1.15, 1.15)
        
        # ì•¡ì…˜ ì •ê·œí™”
        actions = self.safe_normalize_actions(actions)
        processed_episode['actions'] = actions
        
        return processed_episode
    
    def train_step_conservative(self, batch):
        """ë³´ìˆ˜ì  ì¦ê°•ì´ ì ìš©ëœ í•™ìŠµ ìŠ¤í…"""
        try:
            # ì´ë¯¸ ì²˜ë¦¬ëœ ë°ì´í„°ì´ë¯€ë¡œ ë°”ë¡œ í•™ìŠµ
            result = super().train_step(batch)
            
            # NaN ì²´í¬
            if torch.isnan(result['total_loss']):
                print("âš ï¸ NaN loss detected - using fallback")
                result['total_loss'] = torch.tensor(1.0, device=self.device)
            
            return result
            
        except Exception as e:
            print(f"í•™ìŠµ ìŠ¤í… ì˜¤ë¥˜: {e}")
            return {'total_loss': torch.tensor(1.0, device=self.device), 'mae_avg': 1.0}

def conservative_augmentation_training():
    """ë³´ìˆ˜ì  ë°ì´í„° ì¦ê°• í•™ìŠµ"""
    print("ğŸ¯ ë³´ìˆ˜ì  ë°ì´í„° ì¦ê°• í•™ìŠµ ì‹œì‘! (72ê°œ â†’ 144ê°œ)")
    print("=" * 60)
    
    # ë°ì´í„°ì…‹ ë¡œë“œ
    dataset = MobileVLADataset(DATA_DIR)
    print(f"ì›ë³¸ ë°ì´í„°ì…‹ í¬ê¸°: {len(dataset)}")
    
    # íŠ¸ë ˆì´ë„ˆ ìƒì„±
    trainer = ConservativeAugmentationTrainer(
        model_name="microsoft/kosmos-2-patch14-224",
        action_dim=3,
        window_size=8,
        chunk_size=2,
        learning_rate=1e-4,
        device="cuda" if torch.cuda.is_available() else "cpu"
    )
    
    # ì•¡ì…˜ í†µê³„ ê³„ì‚°
    trainer.compute_action_statistics(dataset)
    
    # ë°ì´í„° ì¦ê°• ì ìš©
    print("\nğŸ“ˆ ë³´ìˆ˜ì  ë°ì´í„° ì¦ê°• ì ìš© ì¤‘...")
    augmented_dataset = []
    
    for i, episode in enumerate(dataset):
        if i % 10 == 0:
            print(f"   ì§„í–‰ë¥ : {i}/{len(dataset)} ({i/len(dataset)*100:.1f}%)")
        
        # ë³´ìˆ˜ì  ì¦ê°• ì ìš© (2ë°° í™•ì¥)
        augmented_episodes = trainer.augment_episode_conservative(episode)
        augmented_dataset.extend(augmented_episodes)
    
    print(f"ì¦ê°• ì™„ë£Œ! ë°ì´í„°ì…‹ í¬ê¸°: {len(augmented_dataset)}")
    print(f"ì¦ê°• ë°°ìˆ˜: {len(augmented_dataset) / len(dataset):.1f}x")
    
    # ë°ì´í„° ë¶„í• 
    total_size = len(augmented_dataset)
    train_size = int(0.8 * total_size)
    val_size = total_size - train_size
    
    # ëœë¤ ì…”í”Œ
    indices = list(range(total_size))
    random.shuffle(indices)
    
    train_indices = indices[:train_size]
    val_indices = indices[train_size:]
    
    train_dataset = [augmented_dataset[i] for i in train_indices]
    val_dataset = [augmented_dataset[i] for i in val_indices]
    
    print(f"í›ˆë ¨ ë°ì´í„°: {len(train_dataset)} ì—í”¼ì†Œë“œ")
    print(f"ê²€ì¦ ë°ì´í„°: {len(val_dataset)} ì—í”¼ì†Œë“œ")
    
    # DataLoader ìƒì„±
    def collate_fn(batch):
        return batch[0]
    
    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)
    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)
    
    # í•™ìŠµ ì‹œì‘
    print("\nğŸ¯ ë³´ìˆ˜ì  ì¦ê°• í•™ìŠµ ì‹œì‘!")
    num_epochs = 15
    best_val_loss = float('inf')
    train_history = []
    val_history = []
    patience = 5
    patience_counter = 0
    
    for epoch in range(num_epochs):
        print(f"\nğŸ“ˆ ì—í¬í¬ {epoch+1}/{num_epochs}")
        print("-" * 40)
        
        # í›ˆë ¨
        trainer.model.train()
        train_losses = []
        train_maes = []
        
        for i, batch in enumerate(train_loader):
            try:
                metrics = trainer.train_step_conservative(batch)
                train_losses.append(metrics['total_loss'].item())
                train_maes.append(metrics['mae_avg'])
                
                if (i + 1) % 20 == 0:
                    print(f"   ë°°ì¹˜ {i+1}/{len(train_loader)}: Loss={metrics['total_loss']:.4f}, MAE={metrics['mae_avg']:.4f}")
                    
            except Exception as e:
                print(f"   ë°°ì¹˜ {i+1} ì˜¤ë¥˜: {e}")
                continue
        
        if train_losses:
            avg_train_loss = np.mean(train_losses)
            avg_train_mae = np.mean(train_maes)
            
            train_metrics = {
                'epoch': epoch + 1,
                'loss': avg_train_loss,
                'mae_avg': avg_train_mae
            }
            train_history.append(train_metrics)
            
            print(f"âœ… í›ˆë ¨ ì™„ë£Œ: Loss={avg_train_loss:.4f}, MAE={avg_train_mae:.4f}")
            
            # ê²€ì¦
            trainer.model.eval()
            val_losses = []
            val_maes = []
            
            with torch.no_grad():
                for i, batch in enumerate(val_loader):
                    try:
                        metrics = trainer.train_step_conservative(batch)
                        val_losses.append(metrics['total_loss'].item())
                        val_maes.append(metrics['mae_avg'])
                    except Exception as e:
                        continue
            
            if val_losses:
                avg_val_loss = np.mean(val_losses)
                avg_val_mae = np.mean(val_maes)
                
                val_metrics = {
                    'epoch': epoch + 1,
                    'loss': avg_val_loss,
                    'mae_avg': avg_val_mae
                }
                val_history.append(val_metrics)
                
                print(f"ğŸ” ê²€ì¦ ì™„ë£Œ: Loss={avg_val_loss:.4f}, MAE={avg_val_mae:.4f}")
                
                # ìµœê³  ëª¨ë¸ ì €ì¥
                if avg_val_loss < best_val_loss:
                    best_val_loss = avg_val_loss
                    patience_counter = 0
                    torch.save({
                        'model_state_dict': trainer.model.state_dict(),
                        'optimizer_state_dict': trainer.optimizer.state_dict(),
                        'epoch': epoch,
                        'val_loss': best_val_loss,
                        'action_mean': trainer.action_mean,
                        'action_std': trainer.action_std
                    }, 'best_conservative_augmentation_model.pth')
                    print(f"ğŸ’¾ ìµœê³  ëª¨ë¸ ì €ì¥ë¨ (Loss: {best_val_loss:.4f})")
                else:
                    patience_counter += 1
                    print(f"â³ Early stopping ì¹´ìš´í„°: {patience_counter}/{patience}")
                
                # Early stopping
                if patience_counter >= patience:
                    print(f"ğŸ›‘ Early stopping! {patience} ì—í¬í¬ ë™ì•ˆ ê°œì„  ì—†ìŒ")
                    break
        
        # NaN ì²´í¬
        if np.isnan(avg_train_loss):
            print("âŒ NaN Loss ë°œìƒ! í•™ìŠµ ì¤‘ë‹¨")
            break
        else:
            print("âœ… NaN Loss ì—†ìŒ!")
    
    print("\nğŸ‰ ë³´ìˆ˜ì  ì¦ê°• í•™ìŠµ ì™„ë£Œ!")
    
    # ê²°ê³¼ ì €ì¥
    results = {
        'final_metrics': {
            'best_val_loss': best_val_loss,
            'final_train_loss': train_history[-1]['loss'] if train_history else None,
            'final_train_mae': train_history[-1]['mae_avg'] if train_history else None,
            'epochs_trained': len(train_history)
        },
        'train_history': train_history,
        'val_history': val_history,
        'action_statistics': {
            'mean': trainer.action_mean.tolist() if trainer.action_mean is not None else None,
            'std': trainer.action_std.tolist() if trainer.action_std is not None else None
        },
        'dataset_info': {
            'original_size': len(dataset),
            'augmented_size': len(augmented_dataset),
            'augmentation_multiplier': len(augmented_dataset) / len(dataset),
            'train_episodes': len(train_dataset),
            'val_episodes': len(val_dataset)
        },
        'augmentation_info': {
            'level': trainer.augmentation_level,
            'image_flip_prob': trainer.image_flip_prob,
            'action_noise_std': trainer.action_noise_std,
            'z_noise_std': trainer.z_noise_std,
            'approach': 'Conservative (72â†’144)'
        },
        'model_info': {
            'architecture': 'Conservative Augmentation Kosmos2',
            'z_axis_weight': trainer.z_weight,
            'epochs': num_epochs,
            'learning_rate': trainer.learning_rate,
            'early_stopping': True,
            'patience': patience
        },
        'created_at': datetime.now().isoformat()
    }
    
    with open('conservative_augmentation_results.json', 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ë¨: conservative_augmentation_results.json")
    
    # ìµœì¢… ì„±ëŠ¥ ìš”ì•½
    print("\nğŸ“Š ìµœì¢… ì„±ëŠ¥ ìš”ì•½:")
    print(f"   ìµœê³  ê²€ì¦ Loss: {best_val_loss:.4f}")
    print(f"   ìµœì¢… í›ˆë ¨ MAE: {train_history[-1]['mae_avg']:.4f}")
    print(f"   í•™ìŠµ ì—í¬í¬: {len(train_history)}")
    print(f"   ë°ì´í„° ì¦ê°•: {len(augmented_dataset) / len(dataset):.1f}x (ë³´ìˆ˜ì )")
    print(f"   ì´ë¯¸ì§€ ì¦ê°•: Random flip (50%)")
    print(f"   ì•¡ì…˜ ì¦ê°•: ë§¤ìš° ì‘ì€ ë…¸ì´ì¦ˆ (Ïƒ=0.005)")
    print(f"   Zì¶• ì²˜ë¦¬: ê±´ë“œë¦¬ì§€ ì•ŠìŒ")
    print(f"   Early stopping: {'í™œì„±í™”' if patience_counter >= patience else 'ë¹„í™œì„±í™”'}")

if __name__ == "__main__":
    conservative_augmentation_training()
