#!/usr/bin/env python3
"""
ğŸš€ Mobile VLA ê°œì„ ëœ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸

- LSTM Action Head
- Weighted Loss
- ì¦ê°•ëœ ë°ì´í„°ì…‹ (432ê°œ ì—í”¼ì†Œë“œ)
- ë” ê¸´ í•™ìŠµ (20 ì—í¬í¬)
- í–¥ìƒëœ í‰ê°€ ë©”íŠ¸ë¦­
"""

import os
import sys
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
import numpy as np
from pathlib import Path
import json
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import warnings
warnings.filterwarnings('ignore')

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.append(str(Path(__file__).parent))

from robovlms.train.mobile_vla_trainer import MobileVLATrainer
from robovlms.data.mobile_vla_dataset import MobileVLADataset

def convert_numpy_types(obj):
    """NumPy íƒ€ì…ì„ Python íƒ€ì…ìœ¼ë¡œ ë³€í™˜"""
    import numpy as np
    
    if isinstance(obj, (np.float32, np.float64)):
        return float(obj)
    elif isinstance(obj, (np.int32, np.int64)):
        return int(obj)
    elif isinstance(obj, np.bool_):
        return bool(obj)
    elif isinstance(obj, dict):
        return {k: convert_numpy_types(v) for k, v in obj.items()}
    elif isinstance(obj, (list, tuple)):
        return [convert_numpy_types(v) for v in obj]
    else:
        return obj

class ImprovedMobileVLATrainer(MobileVLATrainer):
    """ê°œì„ ëœ Mobile VLA íŠ¸ë ˆì´ë„ˆ"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        
        # í•™ìŠµ íŒŒë¼ë¯¸í„° ê°œì„ 
        self.learning_rate = 1e-4  # ë” ë‚®ì€ í•™ìŠµë¥ 
        self.num_epochs = 20       # ë” ê¸´ í•™ìŠµ
        self.gradient_clip_val = 1.0  # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘
        
        # ì˜µí‹°ë§ˆì´ì € ê°œì„ 
        self.optimizer = torch.optim.AdamW(
            self.model.parameters(),
            lr=self.learning_rate,
            weight_decay=0.01
        )
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ ì¶”ê°€
        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            self.optimizer, T_max=self.num_epochs
        )
    
    def compute_loss(self, predictions, targets):
        """ê°œì„ ëœ ì†ì‹¤ ê³„ì‚° (Weighted Loss)"""
        predicted_actions = predictions["predicted_actions"]
        target_actions = targets["action_chunk"]
        
        if target_actions.dim() == 4:
            target_actions = target_actions[:, -1, :, :]
        
        # Weighted Huber Loss (linear_yì— ë” ë†’ì€ ê°€ì¤‘ì¹˜)
        weights = torch.tensor([1.0, 2.0, 1.5], device=predicted_actions.device)
        
        per_dim_loss = F.huber_loss(predicted_actions, target_actions, reduction='none')
        weighted_loss = per_dim_loss * weights.unsqueeze(0).unsqueeze(0)
        action_loss = weighted_loss.mean()
        
        # ê° ì°¨ì›ë³„ MAE ê³„ì‚°
        mae_per_dim = torch.abs(predicted_actions - target_actions).mean(dim=(0, 1))
        
        return {
            "total_loss": action_loss,
            "action_loss": action_loss,
            "mae_linear_x": mae_per_dim[0].item(),
            "mae_linear_y": mae_per_dim[1].item(),
            "mae_angular_z": mae_per_dim[2].item(),
            "mae_avg": mae_per_dim.mean().item()
        }
    
    def train_epoch(self, train_loader):
        """ê°œì„ ëœ ì—í¬í¬ í•™ìŠµ"""
        self.model.train()
        total_loss = 0
        epoch_metrics = {
            'mae_linear_x': [], 'mae_linear_y': [], 'mae_angular_z': [],
            'mae_avg': [], 'loss': []
        }
        
        for batch_idx, batch in enumerate(train_loader):
            try:
                # ë°ì´í„°ë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
                images = batch["images"].to(self.device)
                actions = batch["actions"].to(self.device)
                
                # í…ìŠ¤íŠ¸ í† í° ìƒì„± (ë”ë¯¸)
                batch_size = images.size(0)
                input_ids = torch.zeros(batch_size, 10, dtype=torch.long).to(self.device)
                attention_mask = torch.ones(batch_size, 10, dtype=torch.long).to(self.device)
                
                # Window/Chunk ì²˜ë¦¬ (ì§ì ‘ êµ¬í˜„)
                sequence_length = images.size(1)
                window_images = images[:, :min(sequence_length, self.window_size)]
                chunk_actions = actions[:, :min(sequence_length, self.chunk_size)]
                
                # Forward pass
                predictions = self.model(
                    pixel_values=window_images,
                    input_ids=input_ids,
                    attention_mask=attention_mask
                )
                
                # ì†ì‹¤ ê³„ì‚°
                targets = {"action_chunk": chunk_actions}
                loss_dict = self.compute_loss(predictions, targets)
                
                # Backward pass
                self.optimizer.zero_grad()
                loss_dict["total_loss"].backward()
                
                # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.gradient_clip_val)
                
                self.optimizer.step()
                
                # ë©”íŠ¸ë¦­ ìˆ˜ì§‘
                total_loss += loss_dict["total_loss"].item()
                for key in epoch_metrics:
                    if key in loss_dict:
                        epoch_metrics[key].append(loss_dict[key])
                
                if batch_idx % 10 == 0:
                    print(f"  ë°°ì¹˜ {batch_idx}/{len(train_loader)}: "
                          f"Loss={loss_dict['total_loss']:.4f}, "
                          f"MAE={loss_dict['mae_avg']:.4f}")
                
            except Exception as e:
                print(f"ë°°ì¹˜ {batch_idx} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue
        
        # ì—í¬í¬ í‰ê·  ê³„ì‚°
        avg_metrics = {key: np.mean(values) for key, values in epoch_metrics.items()}
        avg_metrics['total_loss'] = total_loss / len(train_loader)
        
        return avg_metrics
    
    def evaluate_model(self, val_loader):
        """ê°œì„ ëœ ëª¨ë¸ í‰ê°€"""
        self.model.eval()
        all_predictions = []
        all_targets = []
        val_metrics = {
            'mae_linear_x': [], 'mae_linear_y': [], 'mae_angular_z': [],
            'mae_avg': [], 'loss': []
        }
        
        with torch.no_grad():
            for batch_idx, batch in enumerate(val_loader):
                try:
                    images = batch["images"].to(self.device)
                    actions = batch["actions"].to(self.device)
                    
                    batch_size = images.size(0)
                    input_ids = torch.zeros(batch_size, 10, dtype=torch.long).to(self.device)
                    attention_mask = torch.ones(batch_size, 10, dtype=torch.long).to(self.device)
                    
                    window_images = images[:, :min(images.size(1), self.window_size)]
                    chunk_actions = actions[:, :min(actions.size(1), self.chunk_size)]
                    
                    predictions = self.model(
                        pixel_values=window_images,
                        input_ids=input_ids,
                        attention_mask=attention_mask
                    )
                    
                    targets = {"action_chunk": chunk_actions}
                    loss_dict = self.compute_loss(predictions, targets)
                    
                    # ì˜ˆì¸¡ê³¼ íƒ€ê²Ÿ ìˆ˜ì§‘
                    pred_actions = predictions["predicted_actions"].cpu().numpy()
                    target_actions = chunk_actions.cpu().numpy()
                    
                    all_predictions.append(pred_actions)
                    all_targets.append(target_actions)
                    
                    # ë©”íŠ¸ë¦­ ìˆ˜ì§‘
                    for key in val_metrics:
                        if key in loss_dict:
                            val_metrics[key].append(loss_dict[key])
                    
                except Exception as e:
                    print(f"í‰ê°€ ë°°ì¹˜ {batch_idx} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                    continue
        
        # ì „ì²´ ë©”íŠ¸ë¦­ ê³„ì‚°
        all_predictions = np.concatenate(all_predictions, axis=0)
        all_targets = np.concatenate(all_targets, axis=0)
        
        # ê° ì°¨ì›ë³„ RÂ² ì ìˆ˜ ê³„ì‚°
        r2_scores = {}
        for i, dim_name in enumerate(['linear_x', 'linear_y', 'angular_z']):
            pred_flat = all_predictions[:, :, i].flatten()
            target_flat = all_targets[:, :, i].flatten()
            r2_scores[f'r2_{dim_name}'] = r2_score(target_flat, pred_flat)
        
        # ì„ê³„ê°’ ì •í™•ë„ ê³„ì‚°
        threshold_accuracies = {}
        for threshold in [0.1, 0.2, 0.3]:
            within_threshold = np.abs(all_predictions - all_targets) < threshold
            threshold_accuracies[f'threshold_{threshold}'] = within_threshold.mean()
        
        # í‰ê·  ë©”íŠ¸ë¦­
        avg_metrics = {key: np.mean(values) for key, values in val_metrics.items()}
        avg_metrics.update(r2_scores)
        avg_metrics.update(threshold_accuracies)
        
        return avg_metrics, all_predictions, all_targets

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ Mobile VLA ê°œì„ ëœ í•™ìŠµ ì‹œì‘")
    print("=" * 60)
    
    # ì„¤ì •
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ“± ë””ë°”ì´ìŠ¤: {device}")
    
    # ë°ì´í„°ì…‹ ê²½ë¡œ (ì¦ê°•ëœ ë°ì´í„°ì…‹)
    data_dir = "/home/billy/25-1kp/vla/ROS_action/mobile_vla_dataset_augmented"
    print(f"ğŸ“ ë°ì´í„°ì…‹: {data_dir}")
    
    # ë°ì´í„°ì…‹ ë¡œë“œ
    print("ğŸ“Š ë°ì´í„°ì…‹ ë¡œë”© ì¤‘...")
    dataset = MobileVLADataset(data_dir)
    print(f"   ì´ ì—í”¼ì†Œë“œ: {len(dataset)}ê°œ")
    
    # Train/Validation ë¶„í• 
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = torch.utils.data.random_split(
        dataset, [train_size, val_size]
    )
    
    print(f"   í•™ìŠµ ë°ì´í„°: {len(train_dataset)}ê°œ")
    print(f"   ê²€ì¦ ë°ì´í„°: {len(val_dataset)}ê°œ")
    
    # ë°ì´í„° ë¡œë” ìƒì„±
    train_loader = DataLoader(
        train_dataset, batch_size=4, shuffle=True, num_workers=2,
        collate_fn=dataset.collater_fn
    )
    val_loader = DataLoader(
        val_dataset, batch_size=4, shuffle=False, num_workers=2,
        collate_fn=dataset.collater_fn
    )
    
    # íŠ¸ë ˆì´ë„ˆ ì´ˆê¸°í™”
    trainer = ImprovedMobileVLATrainer(
        model_name="microsoft/kosmos-2-patch14-224",
        action_dim=3,
        window_size=8,
        chunk_size=2
    )
    
    # í•™ìŠµ ë£¨í”„
    print("ğŸ¯ í•™ìŠµ ì‹œì‘...")
    best_val_loss = float('inf')
    train_history = []
    val_history = []
    
    for epoch in range(trainer.num_epochs):
        print(f"\nğŸ“ˆ ì—í¬í¬ {epoch+1}/{trainer.num_epochs}")
        print("-" * 40)
        
        # í•™ìŠµ
        train_metrics = trainer.train_epoch(train_loader)
        train_history.append(train_metrics)
        
        # ê²€ì¦
        val_metrics, _, _ = trainer.evaluate_model(val_loader)
        val_history.append(val_metrics)
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"âœ… í•™ìŠµ ì™„ë£Œ:")
        print(f"   Loss: {train_metrics['total_loss']:.4f}")
        print(f"   MAE: {train_metrics['mae_avg']:.4f}")
        print(f"   Linear X MAE: {train_metrics['mae_linear_x']:.4f}")
        print(f"   Linear Y MAE: {train_metrics['mae_linear_y']:.4f}")
        print(f"   Angular Z MAE: {train_metrics['mae_angular_z']:.4f}")
        
        print(f"ğŸ” ê²€ì¦ ê²°ê³¼:")
        print(f"   Loss: {val_metrics['loss']:.4f}")
        print(f"   MAE: {val_metrics['mae_avg']:.4f}")
        print(f"   RÂ² Linear X: {val_metrics['r2_linear_x']:.4f}")
        print(f"   RÂ² Linear Y: {val_metrics['r2_linear_y']:.4f}")
        print(f"   RÂ² Angular Z: {val_metrics['r2_angular_z']:.4f}")
        print(f"   ì„ê³„ê°’ ì •í™•ë„ (0.1): {val_metrics['threshold_0.1']:.4f}")
        
        # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§
        trainer.scheduler.step()
        
        # ìµœê³  ëª¨ë¸ ì €ì¥
        if val_metrics['loss'] < best_val_loss:
            best_val_loss = val_metrics['loss']
            torch.save({
                'model_state_dict': trainer.model.state_dict(),
                'optimizer_state_dict': trainer.optimizer.state_dict(),
                'epoch': epoch,
                'val_loss': best_val_loss,
                'train_metrics': train_metrics,
                'val_metrics': val_metrics
            }, 'best_improved_model.pth')
            print(f"ğŸ’¾ ìµœê³  ëª¨ë¸ ì €ì¥ë¨ (Loss: {best_val_loss:.4f})")
    
    # ìµœì¢… í‰ê°€
    print("\nğŸ¯ ìµœì¢… í‰ê°€...")
    try:
        trainer.model.load_state_dict(torch.load('best_improved_model.pth')['model_state_dict'])
        final_metrics, final_preds, final_targets = trainer.evaluate_model(val_loader)
        
        print(f"\nğŸ† ìµœì¢… ì„±ëŠ¥:")
        print(f"   ì „ì²´ MAE: {final_metrics['mae_avg']:.4f}")
        print(f"   ì„ê³„ê°’ ì •í™•ë„ (0.1): {final_metrics['threshold_0.1']:.4f}")
        print(f"   Linear X RÂ²: {final_metrics['r2_linear_x']:.4f}")
        print(f"   Linear Y RÂ²: {final_metrics['r2_linear_y']:.4f}")
        print(f"   Angular Z RÂ²: {final_metrics['r2_angular_z']:.4f}")
        
    except FileNotFoundError:
        print("âŒ ìµœê³  ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ ê²€ì¦ ê²°ê³¼ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        final_metrics = val_metrics
    
    # ê²°ê³¼ ì €ì¥
    results = {
        'final_metrics': convert_numpy_types(final_metrics),
        'train_history': convert_numpy_types(train_history),
        'val_history': convert_numpy_types(val_history),
        'dataset_info': {
            'total_episodes': len(dataset),
            'train_episodes': len(train_dataset),
            'val_episodes': len(val_dataset),
            'augmentation_multiplier': 6.0
        },
        'model_info': {
            'architecture': 'LSTM Action Head',
            'loss_function': 'Weighted Huber Loss',
            'optimizer': 'AdamW with Cosine Annealing',
            'epochs': trainer.num_epochs,
            'learning_rate': trainer.learning_rate
        },
        'created_at': datetime.now().isoformat()
    }
    
    with open('improved_training_results.json', 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ë¨: improved_training_results.json")
    print("ğŸ‰ ê°œì„ ëœ í•™ìŠµ ì™„ë£Œ!")

if __name__ == "__main__":
    main()
