#!/usr/bin/env python3
"""
ğŸ› ï¸ ê³¼ì í•© ë°©ì§€ ë° ë°ì´í„° ì¦ê°• ì†”ë£¨ì…˜
"""

import torch
import torch.nn as nn
import torchvision.transforms as transforms
import numpy as np
import random
from pathlib import Path
import sys

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
ROOT_DIR = Path("/home/billy/25-1kp/vla/Robo+/Mobile_VLA")
DATA_DIR = Path("/home/billy/25-1kp/vla/ROS_action/mobile_vla_dataset")
ROBOVLMS_DIR = Path("/home/billy/25-1kp/vla/RoboVLMs")

sys.path.append(str(ROOT_DIR))
sys.path.append(str(ROBOVLMS_DIR))

from robovlms.data.mobile_vla_dataset import MobileVLADataset
from robovlms.train.mobile_vla_trainer import MobileVLATrainer
from torch.utils.data import DataLoader

class AdvancedDataAugmentation:
    """ê³ ê¸‰ ë°ì´í„° ì¦ê°• í´ë˜ìŠ¤"""
    
    def __init__(self):
        # ì´ë¯¸ì§€ ì¦ê°•
        self.image_augment = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((224, 224)),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomRotation(degrees=15),
            transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),
            transforms.RandomPerspective(distortion_scale=0.2, p=0.5),
            transforms.RandomErasing(p=0.3, scale=(0.02, 0.33)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        self.image_normal = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
    def augment_episode(self, episode, augment_prob=0.7):
        """ì—í”¼ì†Œë“œ ë°ì´í„° ì¦ê°•"""
        images = episode['images']
        actions = episode['actions'].copy()
        
        # numpy to tensor ë³€í™˜
        if isinstance(actions, np.ndarray):
            actions = torch.from_numpy(actions).float()
        
        augmented_images = []
        
        for img in images:
            if isinstance(img, torch.Tensor):
                # [C, H, W] to [H, W, C] for PIL
                img = img.permute(1, 2, 0).numpy()
                img = (img * 255).astype(np.uint8)
            
            if random.random() < augment_prob:
                aug_img = self.image_augment(img)
            else:
                aug_img = self.image_normal(img)
                
            augmented_images.append(aug_img)
        
        # ì•¡ì…˜ ë…¸ì´ì¦ˆ ì¶”ê°€ (ë¯¸ì„¸ ì¡°ì •)
        if random.random() < 0.3:
            noise = torch.normal(0, 0.01, actions.shape)
            actions = actions + noise
            actions = torch.clamp(actions, -1.15, 1.15)
        
        # ì‹œê°„ ì‹œí”„íŠ¸ (temporal augmentation)
        if random.random() < 0.2 and len(augmented_images) > 2:
            shift = random.randint(-1, 1)
            if shift != 0:
                if shift > 0:
                    augmented_images = augmented_images[shift:] + [augmented_images[-1]] * shift
                    actions = actions[shift:]
                else:
                    augmented_images = [augmented_images[0]] * abs(shift) + augmented_images[:shift]
                    actions = torch.cat([actions[:abs(shift)], actions])
        
        return {
            'images': torch.stack(augmented_images),
            'actions': actions,
            'task_description': episode['task_description'],
            'scenario': episode['scenario']
        }

class RegularizedMobileVLATrainer(MobileVLATrainer):
    """ì •ê·œí™”ê°€ ê°•í™”ëœ Mobile VLA íŠ¸ë ˆì´ë„ˆ"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        
        # ë°ì´í„° ì¦ê°•ê¸°
        self.augmenter = AdvancedDataAugmentation()
        
        # ì¡°ê¸° ì¢…ë£Œ ì„¤ì •
        self.patience = 5
        self.best_val_loss = float('inf')
        self.patience_counter = 0
        
        # ì•¡ì…˜ ì •ê·œí™” í†µê³„
        self.action_mean = None
        self.action_std = None
        
        # ê°•í™”ëœ ì •ê·œí™” ì ìš©
        self._enhance_regularization()
        
        print("âœ… RegularizedMobileVLATrainer ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   ë°ì´í„° ì¦ê°•: í™œì„±í™”")
        print(f"   ì¡°ê¸° ì¢…ë£Œ: {self.patience} ì—í¬í¬")
        print(f"   ì •ê·œí™” ê°•í™”: í™œì„±í™”")
    
    def _enhance_regularization(self):
        """ì •ê·œí™” ê°•í™”"""
        # ê¸°ì¡´ ëª¨ë¸ì— ë“œë¡­ì•„ì›ƒ ì¶”ê°€
        for name, module in self.model.named_modules():
            if isinstance(module, nn.Linear) and 'action_head' in name:
                # ì•¡ì…˜ í—¤ë“œì— ë” ê°•í•œ ë“œë¡­ì•„ì›ƒ ì ìš©
                module.register_forward_hook(self._dropout_hook)
        
        # ê°€ì¤‘ì¹˜ ê°ì‡  ì¦ê°€
        for param_group in self.optimizer.param_groups:
            param_group['weight_decay'] = 0.01
    
    def _dropout_hook(self, module, input, output):
        """ë“œë¡­ì•„ì›ƒ í›…"""
        if self.model.training:
            return nn.functional.dropout(output, p=0.3, training=True)
        return output
    
    def compute_action_statistics(self, dataset):
        """ì•¡ì…˜ í†µê³„ ê³„ì‚°"""
        print("ğŸ“Š ì•¡ì…˜ í†µê³„ ê³„ì‚° ì¤‘...")
        
        all_actions = []
        for i in range(len(dataset)):
            episode = dataset[i]
            actions = episode['actions']
            if isinstance(actions, np.ndarray):
                actions = torch.from_numpy(actions)
            all_actions.append(actions)
        
        all_actions = torch.cat(all_actions, dim=0)
        
        self.action_mean = all_actions.mean(dim=0)
        self.action_std = all_actions.std(dim=0)
        self.action_std = torch.clamp(self.action_std, min=1e-6)
        
        print(f"   ì•¡ì…˜ ë²”ìœ„: {all_actions.min():.4f} ~ {all_actions.max():.4f}")
        print(f"   ì•¡ì…˜ í‰ê· : {self.action_mean}")
        print(f"   ì•¡ì…˜ í‘œì¤€í¸ì°¨: {self.action_std}")
    
    def normalize_actions(self, actions):
        """ì•¡ì…˜ ì •ê·œí™”"""
        if self.action_mean is None:
            return actions
        return (actions - self.action_mean.to(actions.device)) / self.action_std.to(actions.device)
    
    def denormalize_actions(self, actions):
        """ì•¡ì…˜ ì—­ì •ê·œí™”"""
        if self.action_mean is None:
            return actions
        return actions * self.action_std.to(actions.device) + self.action_mean.to(actions.device)
    
    def train_step_with_augmentation(self, batch):
        """ë°ì´í„° ì¦ê°•ì´ ì ìš©ëœ í•™ìŠµ ìŠ¤í…"""
        # ë°ì´í„° ì¦ê°• ì ìš©
        augmented_batch = self.augmenter.augment_episode(batch)
        
        # ì•¡ì…˜ ì •ê·œí™”
        if self.action_mean is not None:
            augmented_batch['actions'] = self.normalize_actions(augmented_batch['actions'])
        
        # ê¸°ì¡´ train_step í˜¸ì¶œ
        try:
            result = super().train_step(augmented_batch)
            
            # ì¶•ë³„ ê°€ì¤‘ì¹˜ ì ìš© (Y, Zì¶• ê°•í™”)
            if 'mae_linear_y' in result and 'mae_angular_z' in result:
                result['weighted_loss'] = (
                    result['total_loss'] + 
                    2.0 * result.get('mae_linear_y', 0) +  # Yì¶• ê°€ì¤‘ì¹˜ 2ë°°
                    2.0 * result.get('mae_angular_z', 0)   # Zì¶• ê°€ì¤‘ì¹˜ 2ë°°
                )
            
            return result
            
        except Exception as e:
            print(f"í•™ìŠµ ìŠ¤í… ì˜¤ë¥˜: {e}")
            return {'total_loss': float('inf'), 'mae_avg': float('inf')}
    
    def validate(self, val_loader):
        """ê²€ì¦ í•¨ìˆ˜"""
        self.model.eval()
        val_losses = []
        val_maes = []
        
        with torch.no_grad():
            for batch in val_loader:
                try:
                    # ì¦ê°• ì—†ì´ ê²€ì¦
                    if self.action_mean is not None:
                        batch['actions'] = self.normalize_actions(batch['actions'])
                    
                    result = super().train_step(batch)
                    val_losses.append(result['total_loss'])
                    val_maes.append(result['mae_avg'])
                except:
                    continue
        
        if val_losses:
            avg_loss = np.mean(val_losses)
            avg_mae = np.mean(val_maes)
            
            # ì¡°ê¸° ì¢…ë£Œ ì²´í¬
            if avg_loss < self.best_val_loss:
                self.best_val_loss = avg_loss
                self.patience_counter = 0
                return avg_loss, avg_mae, False  # ì¢…ë£Œí•˜ì§€ ì•ŠìŒ
            else:
                self.patience_counter += 1
                early_stop = self.patience_counter >= self.patience
                return avg_loss, avg_mae, early_stop
        
        return float('inf'), float('inf'), False

def demonstrate_overfitting_solution():
    """ê³¼ì í•© í•´ê²° ì†”ë£¨ì…˜ ì‹œì—°"""
    print("ğŸš€ ê³¼ì í•© í•´ê²° ì†”ë£¨ì…˜ ì‹œì—°")
    print("=" * 50)
    
    # ë°ì´í„°ì…‹ ë¡œë“œ
    dataset = MobileVLADataset(DATA_DIR)
    print(f"ë°ì´í„°ì…‹ í¬ê¸°: {len(dataset)}")
    
    # í–¥ìƒëœ íŠ¸ë ˆì´ë„ˆ ìƒì„±
    trainer = RegularizedMobileVLATrainer(
        model_name="microsoft/kosmos-2-patch14-224",
        action_dim=3,
        window_size=8,
        chunk_size=2,
        learning_rate=5e-5,  # ë‚®ì€ í•™ìŠµë¥ 
        device="cuda" if torch.cuda.is_available() else "cpu"
    )
    
    # ì•¡ì…˜ í†µê³„ ê³„ì‚°
    trainer.compute_action_statistics(dataset)
    
    # ë°ì´í„° ë¶„í•  (ë” ì—„ê²©í•œ ì‹œê°„ ê¸°ë°˜)
    total_size = len(dataset)
    train_size = int(0.7 * total_size)  # 70% í›ˆë ¨
    val_size = total_size - train_size  # 30% ê²€ì¦
    
    train_indices = list(range(train_size))
    val_indices = list(range(train_size, total_size))
    
    # ë¬´ì‘ìœ„ ì…”í”Œ (ê³¼ì í•© ë°©ì§€)
    random.shuffle(train_indices)
    
    train_dataset = torch.utils.data.Subset(dataset, train_indices)
    val_dataset = torch.utils.data.Subset(dataset, val_indices)
    
    print(f"í›ˆë ¨ ë°ì´í„°: {len(train_dataset)} ì—í”¼ì†Œë“œ")
    print(f"ê²€ì¦ ë°ì´í„°: {len(val_dataset)} ì—í”¼ì†Œë“œ")
    
    # DataLoader ìƒì„±
    def collate_fn(batch):
        return batch[0]
    
    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)
    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)
    
    # í•™ìŠµ ë£¨í”„ (3 ì—í¬í¬ë§Œ ì‹œì—°)
    print("\nğŸ¯ ê°œì„ ëœ í•™ìŠµ ì‹œì‘...")
    for epoch in range(3):
        print(f"\nğŸ“ˆ ì—í¬í¬ {epoch+1}/3")
        print("-" * 30)
        
        # í›ˆë ¨
        trainer.model.train()
        train_losses = []
        train_maes = []
        
        for i, batch in enumerate(train_loader):
            if i >= 10:  # ì‹œì—°ìš©ìœ¼ë¡œ 10ë°°ì¹˜ë§Œ
                break
                
            try:
                metrics = trainer.train_step_with_augmentation(batch)
                train_losses.append(metrics['total_loss'])
                train_maes.append(metrics['mae_avg'])
                
                if (i + 1) % 5 == 0:
                    print(f"   ë°°ì¹˜ {i+1}: Loss={metrics['total_loss']:.4f}, MAE={metrics['mae_avg']:.4f}")
                    
            except Exception as e:
                print(f"   ë°°ì¹˜ {i+1} ì˜¤ë¥˜: {e}")
                continue
        
        if train_losses:
            avg_train_loss = np.mean(train_losses)
            avg_train_mae = np.mean(train_maes)
            
            print(f"âœ… í›ˆë ¨ ì™„ë£Œ: Loss={avg_train_loss:.4f}, MAE={avg_train_mae:.4f}")
            
            # ê²€ì¦
            val_loss, val_mae, early_stop = trainer.validate(val_loader)
            print(f"ğŸ” ê²€ì¦ ê²°ê³¼: Loss={val_loss:.4f}, MAE={val_mae:.4f}")
            
            if early_stop:
                print("â¹ï¸ ì¡°ê¸° ì¢…ë£Œ íŠ¸ë¦¬ê±°ë¨")
                break
    
    print("\nâœ… ê³¼ì í•© í•´ê²° ì†”ë£¨ì…˜ ì‹œì—° ì™„ë£Œ!")
    
    # í•´ê²°ëœ ë¶€ë¶„ ìš”ì•½
    print("\nğŸ“‹ í•´ê²°ëœ ê³¼ì í•© ë¬¸ì œ:")
    print("1. âœ… ê³ ê¸‰ ë°ì´í„° ì¦ê°• (ì´ë¯¸ì§€ + ì‹œê°„ì )")
    print("2. âœ… ê°•í™”ëœ ì •ê·œí™” (ë“œë¡­ì•„ì›ƒ, ê°€ì¤‘ì¹˜ ê°ì‡ )")
    print("3. âœ… ì¡°ê¸° ì¢…ë£Œ")
    print("4. âœ… ì¶•ë³„ ê°€ì¤‘ì¹˜ ì¡°ì •")
    print("5. âœ… ì•¡ì…˜ ì •ê·œí™”")
    print("6. âœ… ë” ì—„ê²©í•œ ë°ì´í„° ë¶„í• ")

if __name__ == "__main__":
    demonstrate_overfitting_solution()
