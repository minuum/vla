#!/usr/bin/env python3
"""
Korean Text Encoder - í•œêµ­ì–´ ë„¤ë¹„ê²Œì´ì…˜ ëª…ë ¹ì–´ ì¸ì½”ë”©
mobile_vla_data_collector.pyì˜ ì‹œë‚˜ë¦¬ì˜¤ë³„ í•œêµ­ì–´ ëª…ë ¹ì–´ ì²˜ë¦¬
"""

import torch
import torch.nn as nn
from transformers import AutoTokenizer, AutoModel
from typing import List, Dict, Optional
import logging

logger = logging.getLogger(__name__)


class KoreanTextEncoder(nn.Module):
    """
    í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì¸ì½”ë” (Mobile VLA ì‹œë‚˜ë¦¬ì˜¤ë³„ ëª…ë ¹ì–´ íŠ¹í™”)
    - KLUE RoBERTa ê¸°ë°˜ í•œêµ­ì–´ ì´í•´
    - ì‹œë‚˜ë¦¬ì˜¤ë³„ ëª…ë ¹ì–´ ë§¤í•‘
    - mobile_vla_data_collector.py ì‹œë‚˜ë¦¬ì˜¤ì™€ ì™„ì „ í˜¸í™˜
    """
    
    def __init__(
        self,
        model_name: str = "klue/roberta-base",
        hidden_size: int = 768,
        max_length: int = 128,
        freeze_encoder: bool = False
    ):
        super().__init__()
        
        self.model_name = model_name
        self.hidden_size = hidden_size
        self.max_length = max_length
        
        # í•œêµ­ì–´ í† í¬ë‚˜ì´ì € ë° ëª¨ë¸ ë¡œë“œ
        try:
            self.tokenizer = AutoTokenizer.from_pretrained(model_name)
            self.text_encoder = AutoModel.from_pretrained(model_name)
            logger.info(f"âœ… í•œêµ­ì–´ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_name}")
        except Exception as e:
            logger.warning(f"âš ï¸ KLUE ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨, DistilBERTë¡œ ëŒ€ì²´: {e}")
            self.tokenizer = AutoTokenizer.from_pretrained("distilbert-base-multilingual-cased")
            self.text_encoder = AutoModel.from_pretrained("distilbert-base-multilingual-cased")
        
        # ì¸ì½”ë” ê°€ì¤‘ì¹˜ ê³ ì • ì˜µì…˜
        if freeze_encoder:
            for param in self.text_encoder.parameters():
                param.requires_grad = False
            logger.info("ğŸ”’ í…ìŠ¤íŠ¸ ì¸ì½”ë” ê°€ì¤‘ì¹˜ ê³ ì •ë¨")
        
        # mobile_vla_data_collector.py ì‹œë‚˜ë¦¬ì˜¤ë³„ í•œêµ­ì–´ ëª…ë ¹ì–´
        self.scenario_instructions = {
            "1box_vert_left": "ë°•ìŠ¤ë¥¼ ì™¼ìª½ìœ¼ë¡œ ëŒì•„ì„œ ì»µê¹Œì§€ ê°€ì„¸ìš”",
            "1box_vert_right": "ë°•ìŠ¤ë¥¼ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ëŒì•„ì„œ ì»µê¹Œì§€ ê°€ì„¸ìš”", 
            "1box_hori_left": "ë°•ìŠ¤ë¥¼ ì™¼ìª½ìœ¼ë¡œ í”¼í•´ì„œ ì»µê¹Œì§€ ê°€ì„¸ìš”",
            "1box_hori_right": "ë°•ìŠ¤ë¥¼ ì˜¤ë¥¸ìª½ìœ¼ë¡œ í”¼í•´ì„œ ì»µê¹Œì§€ ê°€ì„¸ìš”",
            "2box_vert_left": "ë‘ ë°•ìŠ¤ ì‚¬ì´ ì™¼ìª½ ê²½ë¡œë¡œ ì»µê¹Œì§€ ê°€ì„¸ìš”",
            "2box_vert_right": "ë‘ ë°•ìŠ¤ ì‚¬ì´ ì˜¤ë¥¸ìª½ ê²½ë¡œë¡œ ì»µê¹Œì§€ ê°€ì„¸ìš”",
            "2box_hori_left": "ë‘ ë°•ìŠ¤ë¥¼ ì™¼ìª½ìœ¼ë¡œ ìš°íšŒí•´ì„œ ì»µê¹Œì§€ ê°€ì„¸ìš”", 
            "2box_hori_right": "ë‘ ë°•ìŠ¤ë¥¼ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ìš°íšŒí•´ì„œ ì»µê¹Œì§€ ê°€ì„¸ìš”"
        }
        
        # ì‹œë‚˜ë¦¬ì˜¤ ì„ë² ë”© (8ê°€ì§€ ì‹œë‚˜ë¦¬ì˜¤)
        self.scenario_embedding = nn.Embedding(8, hidden_size)
        
        # ì‹œë‚˜ë¦¬ì˜¤ ID ë§¤í•‘
        self.scenario_to_id = {
            scenario: idx for idx, scenario in enumerate(self.scenario_instructions.keys())
        }
        
        # í…ìŠ¤íŠ¸ íŠ¹ì§• í”„ë¡œì ì…˜ (KLUE RoBERTa: 768 â†’ hidden_size)
        encoder_dim = self.text_encoder.config.hidden_size
        if encoder_dim != hidden_size:
            self.text_projection = nn.Linear(encoder_dim, hidden_size)
        else:
            self.text_projection = nn.Identity()
        
        # ì‹œë‚˜ë¦¬ì˜¤ì™€ í…ìŠ¤íŠ¸ ìœµí•©
        self.fusion_layer = nn.MultiheadAttention(
            embed_dim=hidden_size,
            num_heads=8,
            dropout=0.1,
            batch_first=True
        )
        
        self.layer_norm = nn.LayerNorm(hidden_size)
        
        logger.info(f"ğŸ—£ï¸ Korean Text Encoder ì´ˆê¸°í™” ì™„ë£Œ (Hidden: {hidden_size})")
    
    def forward(
        self, 
        instructions: List[str], 
        scenarios: Optional[List[str]] = None
    ) -> Dict[str, torch.Tensor]:
        """
        Args:
            instructions: í•œêµ­ì–´ ëª…ë ¹ì–´ ë¦¬ìŠ¤íŠ¸ ["ë°•ìŠ¤ë¥¼ ì™¼ìª½ìœ¼ë¡œ...", ...]
            scenarios: ì‹œë‚˜ë¦¬ì˜¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸ ["1box_vert_left", ...] (ì˜µì…˜)
            
        Returns:
            dict with:
                - text_features: [B, seq_len, hidden_size] - í…ìŠ¤íŠ¸ íŠ¹ì§•
                - scenario_features: [B, hidden_size] - ì‹œë‚˜ë¦¬ì˜¤ íŠ¹ì§• (scenarios ì œê³µì‹œ)
                - fused_features: [B, hidden_size] - ìœµí•©ëœ íŠ¹ì§•
        """
        batch_size = len(instructions)
        device = next(self.parameters()).device
        
        # 1. í…ìŠ¤íŠ¸ í† í¬ë‚˜ì´ì§•
        tokenized = self.tokenizer(
            instructions,
            padding=True,
            truncation=True,
            max_length=self.max_length,
            return_tensors="pt"
        ).to(device)
        
        # 2. í…ìŠ¤íŠ¸ ì¸ì½”ë”©
        with torch.cuda.amp.autocast(enabled=True):
            text_outputs = self.text_encoder(**tokenized)
        
        # í…ìŠ¤íŠ¸ íŠ¹ì§• ì¶”ì¶œ ë° í”„ë¡œì ì…˜
        text_features = text_outputs.last_hidden_state  # [B, seq_len, encoder_dim]
        text_features = self.text_projection(text_features)  # [B, seq_len, hidden_size]
        
        # í…ìŠ¤íŠ¸ í’€ë§ (í‰ê· )
        attention_mask = tokenized['attention_mask'].unsqueeze(-1)  # [B, seq_len, 1]
        text_pooled = (text_features * attention_mask).sum(dim=1) / attention_mask.sum(dim=1)  # [B, hidden_size]
        
        result = {
            "text_features": text_features,
            "text_pooled": text_pooled
        }
        
        # 3. ì‹œë‚˜ë¦¬ì˜¤ ì¸ì½”ë”© (ì œê³µëœ ê²½ìš°)
        if scenarios is not None:
            scenario_ids = []
            for scenario in scenarios:
                scenario_id = self.scenario_to_id.get(scenario, 0)  # unknownì€ 0ë²ˆ
                scenario_ids.append(scenario_id)
            
            scenario_ids = torch.tensor(scenario_ids, device=device)  # [B]
            scenario_features = self.scenario_embedding(scenario_ids)  # [B, hidden_size]
            
            # 4. í…ìŠ¤íŠ¸-ì‹œë‚˜ë¦¬ì˜¤ ìœµí•©
            # ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì¿¼ë¦¬ë¡œ, í…ìŠ¤íŠ¸ë¥¼ í‚¤-ë°¸ë¥˜ë¡œ ì‚¬ìš©
            scenario_query = scenario_features.unsqueeze(1)  # [B, 1, hidden_size]
            fused_features, attention_weights = self.fusion_layer(
                query=scenario_query,      # [B, 1, hidden_size]
                key=text_features,         # [B, seq_len, hidden_size]
                value=text_features,       # [B, seq_len, hidden_size]
                key_padding_mask=~tokenized['attention_mask'].bool()  # íŒ¨ë”© ë§ˆìŠ¤í¬
            )
            
            fused_features = fused_features.squeeze(1)  # [B, hidden_size]
            fused_features = self.layer_norm(fused_features)
            
            result.update({
                "scenario_features": scenario_features,
                "fused_features": fused_features,
                "attention_weights": attention_weights
            })
        else:
            # ì‹œë‚˜ë¦¬ì˜¤ ì—†ì´ëŠ” í…ìŠ¤íŠ¸ í’€ë§ë§Œ ì‚¬ìš©
            result["fused_features"] = self.layer_norm(text_pooled)
        
        return result
    
    def encode_scenarios_only(self, scenarios: List[str]) -> torch.Tensor:
        """ì‹œë‚˜ë¦¬ì˜¤ë§Œìœ¼ë¡œ ì„ë² ë”© ìƒì„± (ë¹ ë¥¸ ì¶”ë¡ ìš©)"""
        device = next(self.parameters()).device
        
        scenario_ids = []
        for scenario in scenarios:
            scenario_id = self.scenario_to_id.get(scenario, 0)
            scenario_ids.append(scenario_id)
        
        scenario_ids = torch.tensor(scenario_ids, device=device)
        scenario_features = self.scenario_embedding(scenario_ids)
        
        return scenario_features
    
    def get_instruction_for_scenario(self, scenario: str) -> str:
        """ì‹œë‚˜ë¦¬ì˜¤ì— ëŒ€ì‘í•˜ëŠ” í•œêµ­ì–´ ëª…ë ¹ì–´ ë°˜í™˜"""
        return self.scenario_instructions.get(scenario, "ì»µê¹Œì§€ ê°€ì„¸ìš”")
    
    def batch_encode_scenarios(self, scenarios: List[str]) -> Dict[str, torch.Tensor]:
        """ì‹œë‚˜ë¦¬ì˜¤ ë°°ì¹˜ë¥¼ í•œêµ­ì–´ ëª…ë ¹ì–´ë¡œ ë³€í™˜í•˜ì—¬ ì¸ì½”ë”©"""
        instructions = [self.get_instruction_for_scenario(scenario) for scenario in scenarios]
        return self.forward(instructions, scenarios)


class KoreanTextEncoderLite(nn.Module):
    """
    ê²½ëŸ‰í™”ëœ í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì¸ì½”ë” (Jetsonìš©)
    ì‚¬ì „ ì •ì˜ëœ ì‹œë‚˜ë¦¬ì˜¤ ì„ë² ë”©ë§Œ ì‚¬ìš©
    """
    
    def __init__(self, hidden_size: int = 512):
        super().__init__()
        
        self.hidden_size = hidden_size
        
        # ì‹œë‚˜ë¦¬ì˜¤ë³„ ì‚¬ì „ ì •ì˜ëœ ì„ë² ë”© (í•™ìŠµ ê°€ëŠ¥)
        self.scenario_embedding = nn.Embedding(8, hidden_size)
        
        # mobile_vla_data_collector.py ì‹œë‚˜ë¦¬ì˜¤ ë§¤í•‘
        self.scenario_to_id = {
            "1box_vert_left": 0, "1box_vert_right": 1,
            "1box_hori_left": 2, "1box_hori_right": 3,
            "2box_vert_left": 4, "2box_vert_right": 5,
            "2box_hori_left": 6, "2box_hori_right": 7
        }
        
        logger.info(f"ğŸš€ Korean Text Encoder Lite ì´ˆê¸°í™” (Hidden: {hidden_size})")
    
    def forward(self, scenarios: List[str]) -> torch.Tensor:
        """ì‹œë‚˜ë¦¬ì˜¤ ì´ë¦„ë§Œìœ¼ë¡œ ì„ë² ë”© ìƒì„±"""
        device = next(self.parameters()).device
        
        scenario_ids = []
        for scenario in scenarios:
            scenario_id = self.scenario_to_id.get(scenario, 0)
            scenario_ids.append(scenario_id)
        
        scenario_ids = torch.tensor(scenario_ids, device=device)
        scenario_features = self.scenario_embedding(scenario_ids)
        
        return scenario_features


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    print("ğŸ§ª Korean Text Encoder í…ŒìŠ¤íŠ¸")
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    encoder = KoreanTextEncoder(hidden_size=768)
    encoder_lite = KoreanTextEncoderLite(hidden_size=512)
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    test_instructions = [
        "ë°•ìŠ¤ë¥¼ ì™¼ìª½ìœ¼ë¡œ ëŒì•„ì„œ ì»µê¹Œì§€ ê°€ì„¸ìš”",
        "ë‘ ë°•ìŠ¤ ì‚¬ì´ ì˜¤ë¥¸ìª½ ê²½ë¡œë¡œ ì»µê¹Œì§€ ê°€ì„¸ìš”"
    ]
    test_scenarios = ["1box_vert_left", "2box_vert_right"]
    
    print(f"ğŸ“Š ì…ë ¥ ëª…ë ¹ì–´: {test_instructions}")
    print(f"ğŸ¯ ì…ë ¥ ì‹œë‚˜ë¦¬ì˜¤: {test_scenarios}")
    
    # ì¼ë°˜ ì¸ì½”ë” í…ŒìŠ¤íŠ¸
    with torch.no_grad():
        result = encoder(test_instructions, test_scenarios)
        print(f"ğŸ—£ï¸ í…ìŠ¤íŠ¸ íŠ¹ì§•: {result['text_features'].shape}")
        print(f"ğŸ¯ ì‹œë‚˜ë¦¬ì˜¤ íŠ¹ì§•: {result['scenario_features'].shape}")
        print(f"ğŸ”„ ìœµí•© íŠ¹ì§•: {result['fused_features'].shape}")
        
        # Lite ì¸ì½”ë” í…ŒìŠ¤íŠ¸
        lite_result = encoder_lite(test_scenarios)
        print(f"ğŸš€ Lite íŠ¹ì§•: {lite_result.shape}")
    
    # íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°
    total_params = sum(p.numel() for p in encoder.parameters())
    lite_params = sum(p.numel() for p in encoder_lite.parameters())
    
    print(f"ğŸ“Š ì¼ë°˜ ì¸ì½”ë” íŒŒë¼ë¯¸í„°: {total_params:,}ê°œ ({total_params/1e6:.1f}M)")
    print(f"ğŸš€ Lite ì¸ì½”ë” íŒŒë¼ë¯¸í„°: {lite_params:,}ê°œ ({lite_params/1e6:.1f}M)")
    print(f"ğŸ’¡ íŒŒë¼ë¯¸í„° ê°ì†Œìœ¨: {(1 - lite_params/total_params)*100:.1f}%")
