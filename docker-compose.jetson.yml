# =============================================================================
# 🚀 Jetson Orin NX 최적화 Mobile VLA Docker Compose
# CSI 카메라 + ROS2 + Mobile VLA 통합 환경
# =============================================================================

version: '3.8'

services:
  # 🤖 메인 Mobile VLA 서비스
  mobile-vla:
    build:
      context: .
      dockerfile: Dockerfile.jetson
    image: mobile-vla:jetson-latest
    container_name: mobile_vla_jetson
    restart: unless-stopped
    
    # 🔧 GPU 및 하드웨어 접근 설정
    runtime: nvidia
    privileged: true
    
    # 🌐 네트워크 설정 (ROS2 DDS 통신을 위해 host 네트워크 사용)
    network_mode: host
    
    # 📡 환경 변수
    environment:
      # 디스플레이 설정 (GUI 앱 지원)
      - DISPLAY=${DISPLAY:-:0}
      
      # ROS2 설정
      - ROS_DOMAIN_ID=42
      - ROS_LOCALHOST_ONLY=0
      - RMW_IMPLEMENTATION=rmw_cyclonedx_cpp
      
      # CUDA/GPU 설정
      - CUDA_VISIBLE_DEVICES=0
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=all
      
      # PyTorch 최적화
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
      - TORCH_DTYPE=float16
      
      # Transformers/HuggingFace 캐시
      - TRANSFORMERS_CACHE=/workspace/vla/.cache/huggingface
      - HF_HOME=/workspace/vla/.cache/huggingface
      
      # Mobile VLA 설정
      - MOBILE_VLA_DATA_DIR=/workspace/vla/mobile_vla_dataset
      - MOBILE_VLA_LOG_LEVEL=INFO
      
      # 시스템 설정
      - PYTHONUNBUFFERED=1
      - DEBIAN_FRONTEND=noninteractive
      
    # 📁 볼륨 마운트
    volumes:
      # 🏠 호스트 vla 폴더 전체 마운트
      - ./:/workspace/vla
      
      # 🎥 CSI 카메라 및 하드웨어 접근
      - /dev:/dev
      - /sys:/sys:ro
      - /proc:/proc:ro
      
      # 🖥️ X11 GUI 지원
      - /tmp/.X11-unix:/tmp/.X11-unix:rw
      - /etc/localtime:/etc/localtime:ro
      
      # 🔧 NVIDIA 런타임 라이브러리
      - /usr/local/cuda:/usr/local/cuda:ro
      - /usr/lib/aarch64-linux-gnu:/usr/lib/aarch64-linux-gnu:ro
      
      # 💾 모델 캐시 (퍼시스턴트)
      - mobile_vla_cache:/workspace/vla/.cache
      
      # 🗂️ 데이터셋 저장소
      - mobile_vla_data:/workspace/vla/mobile_vla_dataset
      
      # 📊 로그 저장소
      - mobile_vla_logs:/workspace/vla/logs
      
      # 🔌 nvargus socket (CSI 카메라 데몬 통신)
      - /tmp/argus_socket:/tmp/argus_socket
      
    # 🚀 작업 디렉토리
    working_dir: /workspace/vla
    
    # 💻 컨테이너 시작 명령어
    command: >
      bash -c "
        echo '🚀 Mobile VLA Jetson Docker 컨테이너 시작' &&
        
        # ROS2 환경 설정
        source /opt/ros/humble/setup.bash &&
        export ROS_DOMAIN_ID=42 &&
        
        # ROS_action 워크스페이스 빌드 (필요시)
        if [ -d 'ROS_action/src' ] && [ ! -d 'ROS_action/install' ]; then
          echo '📦 ROS_action 워크스페이스 빌드 중...' &&
          cd ROS_action &&
          colcon build --packages-select camera_pub &&
          source install/setup.bash &&
          cd .. &&
          echo '✅ ROS_action 빌드 완료'
        fi &&
        
        # 헬스체크 실행
        /usr/local/bin/healthcheck.sh &&
        
        # Mobile VLA 시스템 대기 모드
        echo '✅ Mobile VLA 시스템 준비 완료' &&
        echo '📋 사용 가능한 명령어:' &&
        echo '   docker exec -it mobile_vla_jetson vla-camera' &&
        echo '   docker exec -it mobile_vla_jetson vla-collect' &&
        echo '   docker exec -it mobile_vla_jetson bash' &&
        
        # 무한 대기 (다른 터미널에서 접속 가능)
        tail -f /dev/null
      "
    
    # 🔍 헬스체크
    healthcheck:
      test: [
        "CMD", 
        "python3", "-c", 
        "import torch, cv2, transformers; print('OK')"
      ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    
    # 🏷️ 라벨
    labels:
      - "com.nvidia.jetson.mobile-vla=true"
      - "com.nvidia.jetson.version=orin-nx"
      - "com.docker.compose.project=mobile-vla"

  # 📊 모니터링 서비스 (선택적)
  monitoring:
    image: mobile-vla:jetson-latest
    container_name: mobile_vla_monitoring
    restart: unless-stopped
    
    network_mode: host
    runtime: nvidia
    
    environment:
      - ROS_DOMAIN_ID=42
      - NVIDIA_VISIBLE_DEVICES=all
    
    volumes:
      - ./:/workspace/vla
      - mobile_vla_logs:/workspace/vla/logs
    
    working_dir: /workspace/vla
    
    command: >
      bash -c "
        echo '📊 Mobile VLA 모니터링 서비스 시작' &&
        
        # 모니터링 루프
        while true; do
          echo '==================== Mobile VLA System Status ====================' &&
          echo '⏰ Time:' && date &&
          echo '' &&
          echo '🔧 GPU Status:' &&
          nvidia-smi --query-gpu=memory.used,memory.total,utilization.gpu,temperature.gpu --format=csv,noheader,nounits &&
          echo '' &&
          echo '💾 Memory Usage:' &&
          free -h &&
          echo '' &&
          echo '💿 Disk Usage:' &&
          df -h /workspace/vla &&
          echo '' &&
          echo '🤖 ROS2 Nodes:' &&
          timeout 5s ros2 node list 2>/dev/null || echo 'No ROS2 nodes active' &&
          echo '' &&
          echo '🎥 Camera Status:' &&
          timeout 3s ros2 topic hz /camera/image_raw 2>/dev/null || echo 'Camera topic not active' &&
          echo '' &&
          echo '====================================================================' &&
          echo '' &&
          sleep 30
        done
      "
    
    depends_on:
      - mobile-vla
    
    profiles:
      - monitoring  # 선택적 실행: docker-compose --profile monitoring up

# 📁 Named Volumes (퍼시스턴트 스토리지)
volumes:
  mobile_vla_cache:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${PWD}/docker_volumes/cache

  mobile_vla_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${PWD}/docker_volumes/dataset

  mobile_vla_logs:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${PWD}/docker_volumes/logs

# 🌐 네트워크 설정 (host 네트워크 사용으로 실제로는 불필요)
networks:
  default:
    external: true
    name: host