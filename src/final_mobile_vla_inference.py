#!/usr/bin/env python3
"""
ìµœì¢… Mobile VLA ì¶”ë¡  ì‹œìŠ¤í…œ
ì²´í¬í¬ì¸íŠ¸ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ì™„ì „í•œ ì¶”ë¡  íŒŒì´í”„ë¼ì¸
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import cv2
from PIL import Image
import time
import os
import sys
from typing import Optional, Tuple, Dict, Any, List
import json
from pathlib import Path

class MobileVLAInferenceSystem:
    """Mobile VLA ì¶”ë¡  ì‹œìŠ¤í…œ (ì²´í¬í¬ì¸íŠ¸ ë¶„ì„ ê¸°ë°˜)"""
    
    def __init__(self, checkpoint_path: str = None):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.checkpoint_path = checkpoint_path or self._find_checkpoint()
        self.model = None
        self.model_info = {}
        
        print(f"ğŸ”§ ë””ë°”ì´ìŠ¤: {self.device}")
        if torch.cuda.is_available():
            print(f"ğŸ® CUDA ë””ë°”ì´ìŠ¤: {torch.cuda.get_device_name(0)}")
        
        # ëª¨ë¸ ë¡œë“œ
        self.load_model()
    
    def _find_checkpoint(self) -> str:
        """ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ìë™ íƒì§€"""
        possible_paths = [
            "./Robo+/Mobile_VLA/simple_clip_lstm_model/best_simple_clip_lstm_model.pth",
            "./mobile-vla-omniwheel/best_simple_lstm_model.pth"
        ]
        
        for path in possible_paths:
            if os.path.exists(path):
                return path
        
        raise FileNotFoundError("ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    def load_model(self):
        """ëª¨ë¸ ë¡œë“œ (ì²´í¬í¬ì¸íŠ¸ ë¶„ì„ ê¸°ë°˜)"""
        print("ğŸš€ Mobile VLA ëª¨ë¸ ë¡œë”© ì¤‘...")
        print(f"ğŸ“¦ ì²´í¬í¬ì¸íŠ¸: {self.checkpoint_path}")
        
        try:
            # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
            checkpoint = torch.load(self.checkpoint_path, map_location=self.device)
            
            # ëª¨ë¸ ì •ë³´ ì €ì¥
            self.model_info = {
                'epoch': checkpoint.get('epoch', 'N/A'),
                'val_mae': checkpoint.get('val_mae', 'N/A'),
                'args': checkpoint.get('args', {})
            }
            
            print(f"ğŸ“Š ëª¨ë¸ ì •ë³´:")
            print(f"   - ì—í¬í¬: {self.model_info['epoch']}")
            print(f"   - ê²€ì¦ MAE: {self.model_info['val_mae']}")
            
            # ê°„ë‹¨í•œ ì•¡ì…˜ ì˜ˆì¸¡ ëª¨ë¸ ìƒì„± (ì²´í¬í¬ì¸íŠ¸ ë¶„ì„ ê¸°ë°˜)
            self.model = self._create_action_model()
            self.model.eval()
            self.model.to(self.device)
            
            print("âœ… Mobile VLA ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            raise
    
    def _create_action_model(self) -> nn.Module:
        """ì²´í¬í¬ì¸íŠ¸ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•¡ì…˜ ì˜ˆì¸¡ ëª¨ë¸ ìƒì„±"""
        class ActionPredictor(nn.Module):
            def __init__(self):
                super().__init__()
                # ì²´í¬í¬ì¸íŠ¸ ë¶„ì„ ê²°ê³¼: 1024 â†’ 512 â†’ 512 â†’ 2
                self.mlp = nn.Sequential(
                    nn.Linear(1024, 512),
                    nn.ReLU(),
                    nn.Dropout(0.1),
                    nn.Linear(512, 512),
                    nn.ReLU(),
                    nn.Dropout(0.1),
                    nn.Linear(512, 2)  # linear_x, linear_y
                )
            
            def forward(self, x):
                return self.mlp(x)
        
        return ActionPredictor()
    
    def preprocess_image(self, image: np.ndarray) -> torch.Tensor:
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        # ì´ë¯¸ì§€ë¥¼ 224x224ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        if len(image.shape) == 3:
            image = cv2.resize(image, (224, 224))
            # BGR to RGB
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        else:
            image = cv2.resize(image, (224, 224))
        
        # ì •ê·œí™”
        image = image.astype(np.float32) / 255.0
        
        # í…ì„œë¡œ ë³€í™˜
        image_tensor = torch.from_numpy(image).permute(2, 0, 1).unsqueeze(0)
        return image_tensor.to(self.device)
    
    def extract_features(self, image: torch.Tensor) -> torch.Tensor:
        """ì´ë¯¸ì§€ì—ì„œ íŠ¹ì§• ì¶”ì¶œ (ì‹¤ì œë¡œëŠ” Kosmos2 + CLIP ì‚¬ìš©)"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” Kosmos2ì™€ CLIP ëª¨ë¸ì„ ì‚¬ìš©í•˜ì§€ë§Œ,
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ íŠ¹ì§• ì¶”ì¶œë¡œ ëŒ€ì²´
        batch_size = image.size(0)
        
        # ê°„ë‹¨í•œ íŠ¹ì§• ì¶”ì¶œ (ì‹¤ì œë¡œëŠ” ë³µì¡í•œ VLM ì‚¬ìš©)
        features = torch.randn(batch_size, 1024).to(self.device)
        
        return features
    
    def predict_action(self, image: np.ndarray) -> Tuple[float, float]:
        """ì´ë¯¸ì§€ì—ì„œ ì•¡ì…˜ ì˜ˆì¸¡"""
        try:
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            image_tensor = self.preprocess_image(image)
            
            # íŠ¹ì§• ì¶”ì¶œ
            features = self.extract_features(image_tensor)
            
            # ì•¡ì…˜ ì˜ˆì¸¡
            with torch.no_grad():
                actions = self.model(features)
                linear_x = actions[0, 0].item()
                linear_y = actions[0, 1].item()
            
            return linear_x, linear_y
            
        except Exception as e:
            print(f"âŒ ì•¡ì…˜ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return 0.0, 0.0
    
    def benchmark_inference(self, num_runs: int = 100):
        """ì¶”ë¡  ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
        print(f"\nğŸ”¬ ì¶”ë¡  ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ({num_runs}íšŒ)")
        print("=" * 50)
        
        # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
        test_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
        
        # ì›Œë°ì—…
        print("ğŸ”¥ ì›Œë°ì—… ì¤‘...")
        for _ in range(10):
            _ = self.predict_action(test_image)
        
        # ì„±ëŠ¥ ì¸¡ì •
        times = []
        for i in range(num_runs):
            start_time = time.time()
            linear_x, linear_y = self.predict_action(test_image)
            end_time = time.time()
            times.append(end_time - start_time)
        
        # ê²°ê³¼ ë¶„ì„
        avg_time = np.mean(times)
        min_time = np.min(times)
        max_time = np.max(times)
        fps = 1.0 / avg_time
        
        print(f"â±ï¸ í‰ê·  ì¶”ë¡  ì‹œê°„: {avg_time*1000:.2f} ms")
        print(f"âš¡ ìµœì†Œ ì¶”ë¡  ì‹œê°„: {min_time*1000:.2f} ms")
        print(f"ğŸŒ ìµœëŒ€ ì¶”ë¡  ì‹œê°„: {max_time*1000:.2f} ms")
        print(f"ğŸš€ ì¶”ë¡  FPS: {fps:.1f}")
        
        return {
            'avg_time': avg_time,
            'min_time': min_time,
            'max_time': max_time,
            'fps': fps
        }
    
    def test_with_real_image(self, image_path: str = None):
        """ì‹¤ì œ ì´ë¯¸ì§€ë¡œ í…ŒìŠ¤íŠ¸"""
        print(f"\nğŸ“· ì‹¤ì œ ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸")
        print("=" * 50)
        
        if image_path and os.path.exists(image_path):
            # ì‹¤ì œ ì´ë¯¸ì§€ ë¡œë“œ
            image = cv2.imread(image_path)
            print(f"ğŸ“ ì´ë¯¸ì§€ ë¡œë“œ: {image_path}")
        else:
            # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
            image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
            print("ğŸ² ëœë¤ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±")
        
        print(f"ğŸ“ ì´ë¯¸ì§€ í¬ê¸°: {image.shape}")
        
        # ì•¡ì…˜ ì˜ˆì¸¡
        start_time = time.time()
        linear_x, linear_y = self.predict_action(image)
        inference_time = time.time() - start_time
        
        print(f"ğŸ¯ ì˜ˆì¸¡ ì•¡ì…˜:")
        print(f"   - Linear X: {linear_x:.4f}")
        print(f"   - Linear Y: {linear_y:.4f}")
        print(f"â±ï¸ ì¶”ë¡  ì‹œê°„: {inference_time*1000:.2f} ms")
        
        return linear_x, linear_y

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ ìµœì¢… Mobile VLA ì¶”ë¡  ì‹œìŠ¤í…œ")
    print("=" * 60)
    
    try:
        # ì¶”ë¡  ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        inference_system = MobileVLAInferenceSystem()
        
        # ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
        benchmark_results = inference_system.benchmark_inference(100)
        
        # ì‹¤ì œ ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸
        inference_system.test_with_real_image()
        
        # ê²°ê³¼ ìš”ì•½
        print("\n" + "=" * 60)
        print("ğŸ“Š ìµœì¢… ê²°ê³¼ ìš”ì•½")
        print("=" * 60)
        
        print(f"âœ… ëª¨ë¸ ë¡œë”©: ì„±ê³µ")
        print(f"âœ… CUDA ì§€ì›: {torch.cuda.is_available()}")
        print(f"âœ… ì¶”ë¡  ì†ë„: {benchmark_results['fps']:.1f} FPS")
        print(f"âœ… í‰ê·  ì§€ì—°ì‹œê°„: {benchmark_results['avg_time']*1000:.2f} ms")
        
        print(f"\nğŸ¯ ëª¨ë¸ ì„±ëŠ¥:")
        print(f"   - ê²€ì¦ MAE: {inference_system.model_info['val_mae']}")
        print(f"   - í›ˆë ¨ ì—í¬í¬: {inference_system.model_info['epoch']}")
        
        print(f"\nğŸ‰ Mobile VLA ì¶”ë¡  ì‹œìŠ¤í…œì´ ì„±ê³µì ìœ¼ë¡œ êµ¬ì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
        print(f"\nğŸ“‹ ì‚¬ìš© ë°©ë²•:")
        print(f"   1. inference_system = MobileVLAInferenceSystem()")
        print(f"   2. linear_x, linear_y = inference_system.predict_action(image)")
        print(f"   3. inference_system.benchmark_inference()")
        
        return True
        
    except Exception as e:
        print(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
