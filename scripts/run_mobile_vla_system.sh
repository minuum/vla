#!/bin/bash
# =============================================================================
# ğŸš€ Mobile VLA ì‹œìŠ¤í…œ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
# PyTorch 2.3.0 + ROS2 + VLA ì¶”ë¡  ì‹œìŠ¤í…œ
# =============================================================================

set -e  # ì˜¤ë¥˜ ì‹œ ìŠ¤í¬ë¦½íŠ¸ ì¤‘ë‹¨

# ìƒ‰ìƒ ì •ì˜
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# ë¡œê·¸ í•¨ìˆ˜
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# í—¤ë” ì¶œë ¥
echo "=============================================================================="
echo "ğŸš€ Mobile VLA ì‹œìŠ¤í…œ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸"
echo "=============================================================================="
echo "ğŸ“‹ ì‹œìŠ¤í…œ êµ¬ì„±:"
echo "   â€¢ PyTorch 2.3.0 (CUDA ê°€ì†)"
echo "   â€¢ ROS2 Humble"
echo "   â€¢ VLA ì¶”ë¡  ë…¸ë“œ"
echo "   â€¢ ë¡œë´‡ ì œì–´ ë…¸ë“œ"
echo "   â€¢ ì¹´ë©”ë¼ ì„œë¹„ìŠ¤ ë…¸ë“œ"
echo "=============================================================================="

# 1. í™˜ê²½ í™•ì¸
log_info "ğŸ” ì‹œìŠ¤í…œ í™˜ê²½ í™•ì¸ ì¤‘..."

# Docker í™•ì¸
if ! command -v docker &> /dev/null; then
    log_error "Dockerê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    exit 1
fi

# NVIDIA Container Toolkit í™•ì¸
if ! docker info | grep -q "nvidia"; then
    log_warning "NVIDIA Container Toolkitì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    log_warning "GPU ê°€ì†ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
fi

# X11 ê¶Œí•œ í™•ì¸
if [ -z "$DISPLAY" ]; then
    log_warning "DISPLAY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    log_warning "GUI ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
else
    log_success "X11 ë””ìŠ¤í”Œë ˆì´ ì„¤ì • í™•ì¸ë¨: $DISPLAY"
fi

# 2. ì´ë¯¸ì§€ ë¹Œë“œ í™•ì¸
log_info "ğŸ” Docker ì´ë¯¸ì§€ í™•ì¸ ì¤‘..."

if ! docker images | grep -q "mobile_vla:pytorch-2.3.0-cuda"; then
    log_warning "Mobile VLA ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ë¹Œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤..."
    
    # Dockerfile í™•ì¸
    if [ ! -f "docker/Dockerfile.mobile-vla" ]; then
        log_error "docker/Dockerfile.mobile-vlaì´ ì—†ìŠµë‹ˆë‹¤."
        exit 1
    fi
    
    # ì´ë¯¸ì§€ ë¹Œë“œ
    log_info "ğŸ”¨ Docker ì´ë¯¸ì§€ ë¹Œë“œ ì¤‘... (ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)"
    docker build -t mobile_vla:pytorch-2.3.0-cuda -f docker/Dockerfile.mobile-vla .
    
    if [ $? -eq 0 ]; then
        log_success "Docker ì´ë¯¸ì§€ ë¹Œë“œ ì™„ë£Œ"
    else
        log_error "Docker ì´ë¯¸ì§€ ë¹Œë“œ ì‹¤íŒ¨"
        exit 1
    fi
else
    log_success "Mobile VLA ì´ë¯¸ì§€ í™•ì¸ë¨"
fi

# 3. ì‹œìŠ¤í…œ ì‹¤í–‰
log_info "ğŸš€ Mobile VLA ì‹œìŠ¤í…œ ì‹œì‘ ì¤‘..."

# ê¸°ì¡´ ì»¨í…Œì´ë„ˆ ì •ë¦¬
log_info "ğŸ§¹ ê¸°ì¡´ ì»¨í…Œì´ë„ˆ ì •ë¦¬ ì¤‘..."
docker stop mobile_vla_main 2>/dev/null || true
docker rm mobile_vla_main 2>/dev/null || true

# X11 ê¶Œí•œ ì„¤ì •
log_info "ğŸ–¥ï¸ X11 ê¶Œí•œ ì„¤ì • ì¤‘..."
xhost +local:docker 2>/dev/null || log_warning "X11 ê¶Œí•œ ì„¤ì • ì‹¤íŒ¨"

# ì»¨í…Œì´ë„ˆ ì‹¤í–‰
log_info "ğŸ³ Docker ì»¨í…Œì´ë„ˆ ì‹¤í–‰ ì¤‘..."

docker run -d \
    --name mobile_vla_main \
    --runtime=nvidia \
    --network=host \
    --privileged \
    --gpus all \
    -e DISPLAY=$DISPLAY \
    -e QT_X11_NO_MITSHM=1 \
    -e XAUTHORITY=$XAUTHORITY \
    -e NVIDIA_VISIBLE_DEVICES=all \
    -e NVIDIA_DRIVER_CAPABILITIES=all \
    -v /usr/local/cuda:/usr/local/cuda:ro \
    -v /usr/lib/aarch64-linux-gnu:/usr/lib/aarch64-linux-gnu:ro \
    -v $(pwd)/vla:/workspace/vla \
    -v $(pwd)/ROS_action:/workspace/vla/ROS_action \
    -v /tmp/.X11-unix:/tmp/.X11-unix:rw \
    -v /dev/video0:/dev/video0:rw \
    -v /dev/ttyUSB0:/dev/ttyUSB0:rw \
    -v /dev/ttyUSB1:/dev/ttyUSB1:rw \
    -v /dev/input:/dev/input:ro \
    -p 8888:8888 \
    -p 6006:6006 \
    mobile_vla:pytorch-2.3.0-cuda

if [ $? -eq 0 ]; then
    log_success "ì»¨í…Œì´ë„ˆ ì‹¤í–‰ ì„±ê³µ"
else
    log_error "ì»¨í…Œì´ë„ˆ ì‹¤í–‰ ì‹¤íŒ¨"
    exit 1
fi

# 4. ì‹œìŠ¤í…œ ì´ˆê¸°í™” ëŒ€ê¸°
log_info "â³ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ëŒ€ê¸° ì¤‘... (30ì´ˆ)"
sleep 30

# 5. ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
log_info "ğŸ” ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ ì¤‘..."

# ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸
if docker ps | grep -q "mobile_vla_main"; then
    log_success "ì»¨í…Œì´ë„ˆ ì‹¤í–‰ ì¤‘"
else
    log_error "ì»¨í…Œì´ë„ˆê°€ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    docker logs mobile_vla_main
    exit 1
fi

# í—¬ìŠ¤ì²´í¬ ì‹¤í–‰
log_info "ğŸ¥ í—¬ìŠ¤ì²´í¬ ì‹¤í–‰ ì¤‘..."
docker exec mobile_vla_main /usr/local/bin/healthcheck.sh

if [ $? -eq 0 ]; then
    log_success "ì‹œìŠ¤í…œ í—¬ìŠ¤ì²´í¬ í†µê³¼"
else
    log_warning "ì‹œìŠ¤í…œ í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨ (ì¼ë¶€ ê¸°ëŠ¥ ì œí•œë  ìˆ˜ ìˆìŒ)"
fi

# 6. ROS2 í™˜ê²½ ì„¤ì • ë° ë…¸ë“œ ì‹¤í–‰
log_info "ğŸ¤– ROS2 ë…¸ë“œ ì‹¤í–‰ ì¤€ë¹„ ì¤‘..."

# ROS2 í™˜ê²½ ì„¤ì •
docker exec mobile_vla_main bash -c "
    source /opt/ros/humble/setup.bash
    source /workspace/vla/ROS_action/install/setup.bash
    echo 'âœ… ROS2 í™˜ê²½ ì„¤ì • ì™„ë£Œ'
"

# 7. ì‚¬ìš©ë²• ì•ˆë‚´
echo ""
echo "=============================================================================="
echo "ğŸ‰ Mobile VLA ì‹œìŠ¤í…œ ì‹¤í–‰ ì™„ë£Œ!"
echo "=============================================================================="
echo "ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´:"
echo ""
echo "ğŸ” ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸:"
echo "   docker logs mobile_vla_main"
echo "   docker exec mobile_vla_main nvidia-smi"
echo ""
echo "ğŸ¤– ROS2 ë…¸ë“œ ì‹¤í–‰:"
echo "   docker exec -it mobile_vla_main bash"
echo "   # ì»¨í…Œì´ë„ˆ ë‚´ì—ì„œ:"
echo "   source /opt/ros/humble/setup.bash"
echo "   source /workspace/vla/ROS_action/install/setup.bash"
echo "   ros2 run camera_pub camera_publisher_continuous"
echo "   ros2 run vla_inference vla_inference_node"
echo "   ros2 run robot_control robot_control_node"
echo ""
echo "ğŸ® ì œì–´ ëª¨ë“œ:"
echo "   M: ìˆ˜ë™ ëª¨ë“œ (WASD)"
echo "   V: VLA ìë™ ëª¨ë“œ"
echo "   H: í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ"
echo "   F/G: ì†ë„ ì¡°ì ˆ"
echo ""
echo "ğŸ›‘ ì‹œìŠ¤í…œ ì¢…ë£Œ:"
echo "   docker stop mobile_vla_main"
echo "   docker rm mobile_vla_main"
echo ""
echo "ğŸ“Š ëª¨ë‹ˆí„°ë§:"
echo "   docker stats mobile_vla_main"
echo "   ros2 topic list"
echo "   ros2 topic echo /vla_inference_result"
echo "=============================================================================="

# 8. ìë™ ì‹¤í–‰ ì˜µì…˜
read -p "ğŸš€ ìë™ìœ¼ë¡œ ëª¨ë“  ë…¸ë“œë¥¼ ì‹¤í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    log_info "ğŸ¤– ëª¨ë“  ë…¸ë“œ ìë™ ì‹¤í–‰ ì¤‘..."
    
    docker exec -d mobile_vla_main bash -c "
        source /opt/ros/humble/setup.bash
        source /workspace/vla/ROS_action/install/setup.bash
        python3 /workspace/vla/launch_mobile_vla_system.py
    "
    
    log_success "ìë™ ì‹¤í–‰ ì‹œì‘ë¨"
    log_info "ë¡œê·¸ í™•ì¸: docker logs -f mobile_vla_main"
else
    log_info "ìˆ˜ë™ ì‹¤í–‰ ëª¨ë“œ - ìœ„ì˜ ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ë…¸ë“œë¥¼ ì‹¤í–‰í•˜ì„¸ìš”."
fi

echo ""
log_success "Mobile VLA ì‹œìŠ¤í…œì´ ì„±ê³µì ìœ¼ë¡œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤! ğŸš€"
