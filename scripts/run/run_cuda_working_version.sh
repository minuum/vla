#!/bin/bash

# ğŸš€ CUDA Trueë¡œ ì‘ë™í–ˆë˜ ë²„ì „ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
# ê³¼ê±° ê¸°ë¡ì—ì„œ í™•ì¸ëœ mobile_vla:pytorch-2.3.0-cuda ì‚¬ìš©

set -e

echo "ğŸš€ CUDA Trueë¡œ ì‘ë™í–ˆë˜ ë²„ì „ ì‹¤í–‰"
echo "ğŸ”§ ê³¼ê±° ê¸°ë¡ì—ì„œ í™•ì¸ëœ mobile_vla:pytorch-2.3.0-cuda ì‚¬ìš©"

# ê¸°ì¡´ ì»¨í…Œì´ë„ˆ ì •ë¦¬
echo "ğŸ§¹ ê¸°ì¡´ ì»¨í…Œì´ë„ˆ ì •ë¦¬ ì¤‘..."
docker stop mobile_vla_cuda_working 2>/dev/null || true
docker rm mobile_vla_cuda_working 2>/dev/null || true

# ì‚¬ìš© ê°€ëŠ¥í•œ ì´ë¯¸ì§€ í™•ì¸
echo "ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ì´ë¯¸ì§€ í™•ì¸:"
docker images | grep pytorch || echo "âš ï¸  pytorch ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤"

# CUDA Trueë¡œ ì‘ë™í–ˆë˜ ì„¤ì •ìœ¼ë¡œ ì»¨í…Œì´ë„ˆ ì‹¤í–‰
echo "ğŸš€ CUDA Trueë¡œ ì‘ë™í–ˆë˜ ì„¤ì •ìœ¼ë¡œ ì»¨í…Œì´ë„ˆ ì‹¤í–‰ ì¤‘..."
docker run -d \
    --name mobile_vla_cuda_working \
    --gpus all \
    -v /usr/local/cuda:/usr/local/cuda \
    -v /usr/lib/aarch64-linux-gnu:/usr/lib/aarch64-linux-gnu \
    -v /dev/bus/usb:/dev/bus/usb \
    -e NVIDIA_VISIBLE_DEVICES=all \
    -e NVIDIA_DRIVER_CAPABILITIES=compute,utility \
    -e PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512 \
    mobile_vla:pytorch-2.3.0-cuda \
    sleep infinity

# ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸
echo "ğŸ“‹ ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸:"
sleep 3
docker ps | grep mobile_vla_cuda_working

if docker ps | grep -q mobile_vla_cuda_working; then
    echo "âœ… ì»¨í…Œì´ë„ˆê°€ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤!"
    echo ""
    echo "ğŸ” CUDA í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘..."
    
    # CUDA í…ŒìŠ¤íŠ¸
    echo "ğŸ“Š GPU ì •ë³´:"
    docker exec mobile_vla_cuda_working nvidia-smi || echo "âš ï¸  nvidia-smi ì‹¤í–‰ ì‹¤íŒ¨"
    
    echo "ğŸ“Š PyTorch CUDA í…ŒìŠ¤íŠ¸:"
    docker exec mobile_vla_cuda_working python3 -c "
import torch
print(f'PyTorch ë²„ì „: {torch.__version__}')
print(f'CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'CUDA ë²„ì „: {torch.version.cuda}')
    print(f'CUDA ë””ë°”ì´ìŠ¤ ìˆ˜: {torch.cuda.device_count()}')
    print(f'ë””ë°”ì´ìŠ¤ ì´ë¦„: {torch.cuda.get_device_name(0)}')
    print('âœ… CUDA Trueë¡œ ì‘ë™ ì¤‘!')
else:
    print('âŒ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤')
" || echo "âš ï¸  PyTorch CUDA í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨"
    
    echo ""
    echo "ğŸš€ ì»¨í…Œì´ë„ˆì— ì ‘ì†í•©ë‹ˆë‹¤..."
    echo ""
    
    # ì»¨í…Œì´ë„ˆì— ì ‘ì†
    docker exec -it mobile_vla_cuda_working bash
else
    echo "âŒ ì»¨í…Œì´ë„ˆ ì‹¤í–‰ ì‹¤íŒ¨"
    echo "ğŸ“‹ ì˜¤ë¥˜ ë¡œê·¸:"
    docker logs mobile_vla_cuda_working
fi
