#!/usr/bin/env python3
"""
Left vs Right Action êµ¬ë¶„ ë¶„ì„
ëª©ì : Action headê°€ left/right ë°©í–¥ì„ êµ¬ë¶„í•˜ëŠ”ì§€ í™•ì¸
"""

import torch
import numpy as np
import h5py
from pathlib import Path
from PIL import Image
import torchvision.transforms as T
import sys
import matplotlib.pyplot as plt

sys.path.insert(0, "RoboVLMs_upstream")

from robovlms.train.mobile_vla_trainer import MobileVLATrainer


def load_model(checkpoint_path, device='cuda'):
    """ëª¨ë¸ ë¡œë“œ"""
    print(f"ëª¨ë¸ ë¡œë“œ: {Path(checkpoint_path).name}")
    model = MobileVLATrainer.load_from_checkpoint(checkpoint_path, map_location='cpu')
    model.eval()
    model.to(device)
    return model


def analyze_left_right_actions(model, device='cuda'):
    """Left vs Right action ë¶„ì„"""
    print("\n" + "="*70)
    print("Left vs Right Action ë¶„ì„")
    print("="*70)
    
    h5_files = sorted(list(Path("ROS_action/mobile_vla_dataset").glob("episode_*.h5")))
    
    # Left/Right ë¶„ë¦¬
    left_files = [f for f in h5_files if 'left' in str(f)][:25]
    right_files = [f for f in h5_files if 'right' in str(f)][:25]
    
    print(f"Left samples: {len(left_files)}")
    print(f"Right samples: {len(right_files)}")
    
    transform = T.Compose([
        T.Resize((224, 224)),
        T.ToTensor()
    ])
    
    left_predictions = []
    right_predictions = []
    left_gt = []
    right_gt = []
    
    with torch.no_grad():
        # Left samples
        print("\nProcessing Left samples...")
        for h5_file in left_files[:10]:  # ì²˜ìŒ 10ê°œë§Œ
            pred, gt = predict_single(model, h5_file, transform, device)
            if pred is not None:
                left_predictions.append(pred)
                left_gt.append(gt)
        
        # Right samples
        print("Processing Right samples...")
        for h5_file in right_files[:10]:  # ì²˜ìŒ 10ê°œë§Œ
            pred, gt = predict_single(model, h5_file, transform, device)
            if pred is not None:
                right_predictions.append(pred)
                right_gt.append(gt)
    
    left_predictions = np.array(left_predictions)
    right_predictions = np.array(right_predictions)
    left_gt = np.array(left_gt)
    right_gt = np.array(right_gt)
    
    # ë¶„ì„
    print("\n" + "="*70)
    print("ğŸ“Š ê²°ê³¼ ë¶„ì„")
    print("="*70)
    
    print("\n=== Predicted Velocities ===")
    print("\n[LEFT samples] (should go left â†’ negative linear_y expected)")
    print(f"  linear_x: mean={left_predictions[:, 0].mean():.4f}, std={left_predictions[:, 0].std():.4f}")
    print(f"  linear_y: mean={left_predictions[:, 1].mean():.4f}, std={left_predictions[:, 1].std():.4f}")
    
    print("\n[RIGHT samples] (should go right â†’ positive linear_y expected)")
    print(f"  linear_x: mean={right_predictions[:, 0].mean():.4f}, std={right_predictions[:, 0].std():.4f}")
    print(f"  linear_y: mean={right_predictions[:, 1].mean():.4f}, std={right_predictions[:, 1].std():.4f}")
    
    print("\n=== Ground Truth Velocities ===")
    print("\n[LEFT samples]")
    print(f"  linear_x: mean={left_gt[:, 0].mean():.4f}, std={left_gt[:, 0].std():.4f}")
    print(f"  linear_y: mean={left_gt[:, 1].mean():.4f}, std={left_gt[:, 1].std():.4f}")
    
    print("\n[RIGHT samples]")
    print(f"  linear_x: mean={right_gt[:, 0].mean():.4f}, std={right_gt[:, 0].std():.4f}")
    print(f"  linear_y: mean={right_gt[:, 1].mean():.4f}, std={right_gt[:, 1].std():.4f}")
    
    # ë°©í–¥ êµ¬ë¶„ ë¶„ì„
    print("\n" + "="*70)
    print("ğŸ” ë°©í–¥ êµ¬ë¶„ ë¶„ì„")
    print("="*70)
    
    left_y_mean = left_predictions[:, 1].mean()
    right_y_mean = right_predictions[:, 1].mean()
    diff = right_y_mean - left_y_mean
    
    print(f"\nPredicted linear_y ì°¨ì´: {diff:.4f}")
    print(f"  Left mean: {left_y_mean:.4f}")
    print(f"  Right mean: {right_y_mean:.4f}")
    
    if diff > 0.1:
        print("\nâœ… Action headê°€ Left/Rightë¥¼ êµ¬ë¶„í•˜ê³  ìˆìŒ!")
        print("   Rightê°€ ë” positive linear_y (ì˜¬ë°”ë¦„)")
    elif diff < -0.1:
        print("\nâš ï¸ Action headê°€ ë°˜ëŒ€ë¡œ í•™ìŠµë¨!")
        print("   Leftê°€ ë” positive linear_y")
    else:
        print("\nâŒ Action headê°€ Left/Rightë¥¼ êµ¬ë¶„í•˜ì§€ ëª»í•¨")
        print("   ì°¨ì´ê°€ ë„ˆë¬´ ì‘ìŒ (< 0.1)")
    
    # Sample-wise ë¹„êµ
    print("\n=== Sample-wise ë¹„êµ ===")
    print("\nLeft samples:")
    for i, (pred, gt) in enumerate(zip(left_predictions[:5], left_gt[:5])):
        print(f"  {i}: pred=({pred[0]:.3f}, {pred[1]:.3f}), gt=({gt[0]:.3f}, {gt[1]:.3f})")
    
    print("\nRight samples:")
    for i, (pred, gt) in enumerate(zip(right_predictions[:5], right_gt[:5])):
        print(f"  {i}: pred=({pred[0]:.3f}, {pred[1]:.3f}), gt=({gt[0]:.3f}, {gt[1]:.3f})")
    
    return {
        'left_pred': left_predictions,
        'right_pred': right_predictions,
        'left_gt': left_gt,
        'right_gt': right_gt
    }


def predict_single(model, h5_file, transform, device):
    """ë‹¨ì¼ ìƒ˜í”Œ ì˜ˆì¸¡"""
    try:
        with h5py.File(h5_file, 'r') as f:
            # ì´ë¯¸ì§€ ë¡œë“œ
            images = []
            for t in range(min(8, len(f['images']))):
                img = Image.fromarray(f['images'][t].astype(np.uint8))
                images.append(transform(img))
            
            while len(images) < 8:
                images.append(torch.zeros(3, 224, 224))
            
            images_tensor = torch.stack(images).unsqueeze(0).to(device)
            
            # ì˜ˆì¸¡
            context = model.model.encode_images(images_tensor)
            batch_size = context.shape[0]
            context_flat = context.view(batch_size, -1, context.shape[-1])
            action_mask = torch.ones(batch_size, 8, dtype=torch.bool).to(device)
            
            actions = model.model.act_head(context_flat, actions=None, action_masks=action_mask)
            
            if isinstance(actions, tuple):
                actions = actions[0]
            
            # ì²« ë²ˆì§¸ ì˜ˆì¸¡ (ì²« í† í°, ì²« timestep)
            pred = actions[0, 0, 0, :2].cpu().numpy()
            
            # Ground truth (8ë²ˆì§¸ í”„ë ˆì„ì˜ action)
            gt = f['actions'][min(8, len(f['actions'])-1)][:2]
            
            return pred, gt
    except Exception as e:
        print(f"  Error with {h5_file.name}: {e}")
        return None, None


def main():
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"Device: {device}")
    
    checkpoint = "RoboVLMs_upstream/runs/mobile_vla_kosmos2_frozen_lora_leftright_20251204/kosmos/mobile_vla_finetune/2025-12-04/mobile_vla_kosmos2_frozen_lora_leftright_20251204/epoch_epoch=08-val_loss=val_loss=0.027.ckpt"
    
    model = load_model(checkpoint, device)
    results = analyze_left_right_actions(model, device)
    
    print("\n" + "="*70)
    print("âœ… ë¶„ì„ ì™„ë£Œ")
    print("="*70)


if __name__ == "__main__":
    main()
