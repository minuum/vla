#!/usr/bin/env python3
"""
H5 ì—í”¼ì†Œë“œ íŒŒì¼ ë¶„ì„ ë° í†µê³„ ìƒì„±
- Trajectory ë¶„ì„ (18í”„ë ˆì„ì˜ wasd ì•¡ì…˜)
- Taskë³„ ì¼ê´€ì„± í™•ì¸
- ì‹œê°í™”
"""

import h5py
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from collections import defaultdict
import glob
import json
from datetime import datetime

def extract_task_name(filename):
    """íŒŒì¼ëª…ì—ì„œ task ì´ë¦„ ì¶”ì¶œ (ì‹œê°„ëŒ€ ë° íƒ€ì„ìŠ¤íƒ¬í”„ ì œì™¸)"""
    # episode_20251114_142640_1box_hori_left_core_medium.h5
    # -> 1box_hori_left_core_medium
    # episode_20251114_145248_1box_hori_left_core_medium_evening.h5
    # -> 1box_hori_left_core_medium (evening ì œê±°)
    basename = Path(filename).stem
    parts = basename.split('_')
    
    # episode_ë‚ ì§œ_ì‹œê°„_task... í˜•ì‹
    # ì²˜ìŒ 3ê°œ ì œê±° (episode, ë‚ ì§œ, ì‹œê°„)
    if len(parts) >= 4 and parts[0] == 'episode':
        task_parts = parts[3:]
    # ë‚ ì§œ_ì‹œê°„_task... í˜•ì‹ (ì´ë¯¸ episode ì œê±°ë¨)
    elif len(parts) >= 3:
        # ë‚ ì§œì™€ ì‹œê°„ ë¶€ë¶„ ì œê±° (ì²˜ìŒ 2ê°œ)
        task_parts = parts[2:]
    else:
        return 'unknown'
    
    # ì‹œê°„ëŒ€ ì œê±° (evening, morning ë“±)
    if task_parts and task_parts[-1] in ['evening', 'morning', 'afternoon', 'night', 'dawn']:
        task_parts = task_parts[:-1]
    
    return '_'.join(task_parts) if task_parts else 'unknown'

def analyze_episode(h5_path):
    """ë‹¨ì¼ ì—í”¼ì†Œë“œ ë¶„ì„"""
    with h5py.File(h5_path, 'r') as f:
        # ë°ì´í„° í™•ì¸
        if 'actions' not in f:
            print(f"âš ï¸  {h5_path}: 'actions' í‚¤ ì—†ìŒ")
            return None
        
        actions = f['actions'][:]  # (N, 2) ë˜ëŠ” (N, 7)
        images = f['images'][:] if 'images' in f else None
        
        # ì•¡ì…˜ ì°¨ì› í™•ì¸
        if len(actions.shape) == 1:
            actions = actions.reshape(-1, 1)
        
        # 2D ì•¡ì…˜ë§Œ ì¶”ì¶œ (linear_x, linear_y)
        if actions.shape[1] >= 2:
            actions_2d = actions[:, :2]
        else:
            actions_2d = actions
        
        return {
            'filename': Path(h5_path).name,
            'num_frames': len(actions),
            'actions': actions_2d,
            'num_images': len(images) if images is not None else 0,
            'task_name': extract_task_name(h5_path)
        }

def analyze_trajectory(actions, window_size=18):
    """Trajectory ë¶„ì„ - 18í”„ë ˆì„ ë‹¨ìœ„ë¡œ ì•¡ì…˜ íŒ¨í„´ í™•ì¸"""
    if len(actions) < window_size:
        return None
    
    # 18í”„ë ˆì„ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê¸°
    num_windows = len(actions) // window_size
    trajectories = []
    
    for i in range(num_windows):
        window_actions = actions[i*window_size:(i+1)*window_size]
        trajectories.append(window_actions)
    
    return trajectories

def compare_trajectories(traj1, traj2, threshold=0.01):
    """ë‘ trajectoryê°€ ê°™ì€ì§€ ë¹„êµ (threshold ë‚´ì—ì„œ)"""
    if traj1.shape != traj2.shape:
        return False
    
    diff = np.abs(traj1 - traj2)
    max_diff = np.max(diff)
    return max_diff < threshold

def categorize_action(action):
    """ì•¡ì…˜ì„ wasd ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜ (ë°ì´í„° ìˆ˜ì§‘ ì½”ë“œ ê¸°ì¤€)
    
    ë°ì´í„° ìˆ˜ì§‘ ì½”ë“œ ë§¤í•‘ (mobile_vla_data_collector.py):
    - 'w': linear_x=1.15, linear_y=0.0 (ì „ì§„)
    - 'a': linear_x=0.0, linear_y=1.15 (ì¢Œ)
    - 'd': linear_x=0.0, linear_y=-1.15 (ìš°)
    - 's': linear_x=-1.15, linear_y=0.0 (í›„ì§„)
    - 'q': linear_x=1.15, linear_y=1.15 (ì „ì§„+ì¢Œ)
    - 'e': linear_x=1.15, linear_y=-1.15 (ì „ì§„+ìš°)
    - 'z': linear_x=-1.15, linear_y=1.15 (í›„ì§„+ì¢Œ)
    - 'c': linear_x=-1.15, linear_y=-1.15 (í›„ì§„+ìš°)
    - ' ': linear_x=0.0, linear_y=0.0 (ì •ì§€)
    """
    linear_x, linear_y = action[0], action[1]
    
    # ì„ê³„ê°’ ì„¤ì •
    thresh = 0.1
    
    # ì •ì§€
    if abs(linear_x) < thresh and abs(linear_y) < thresh:
        return 'S'  # Stop (ìŠ¤í˜ì´ìŠ¤ë°”)
    # ëŒ€ê°ì„  ì•¡ì…˜ ìš°ì„  ì²˜ë¦¬
    elif linear_x > thresh and linear_y > thresh:
        return 'Q'  # ì „ì§„+ì¢Œ (q í‚¤)
    elif linear_x > thresh and linear_y < -thresh:
        return 'E'  # ì „ì§„+ìš° (e í‚¤)
    elif linear_x < -thresh and linear_y > thresh:
        return 'Z'  # í›„ì§„+ì¢Œ (z í‚¤)
    elif linear_x < -thresh and linear_y < -thresh:
        return 'C'  # í›„ì§„+ìš° (c í‚¤)
    # ë‹¨ì¼ ë°©í–¥ ì•¡ì…˜
    elif linear_x > thresh and abs(linear_y) < thresh:
        return 'W'  # Forward (w í‚¤)
    elif linear_x < -thresh and abs(linear_y) < thresh:
        return 'S'  # Backward (s í‚¤, ì •ì§€ë¡œ ì²˜ë¦¬)
    elif abs(linear_x) < thresh and linear_y > thresh:
        return 'A'  # Left (a í‚¤: linear_y=1.15)
    elif abs(linear_x) < thresh and linear_y < -thresh:
        return 'D'  # Right (d í‚¤: linear_y=-1.15)
    else:
        return '?'

def trajectory_to_string(trajectory):
    """Trajectoryë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜ (WASD)"""
    return ''.join([categorize_action(a) for a in trajectory])

def main():
    data_dir = Path("ROS_action/mobile_vla_dataset")
    
    print("=" * 60)
    print("H5 ì—í”¼ì†Œë“œ íŒŒì¼ ë¶„ì„ ì‹œì‘")
    print("=" * 60)
    print()
    
    # ëª¨ë“  H5 íŒŒì¼ ì°¾ê¸°
    h5_files = sorted(glob.glob(str(data_dir / "episode_*.h5")))
    print(f"ğŸ“ ì´ {len(h5_files)}ê°œ ì—í”¼ì†Œë“œ íŒŒì¼ ë°œê²¬")
    print()
    
    # ì—í”¼ì†Œë“œ ë¶„ì„
    episodes = []
    task_groups = defaultdict(list)
    
    for h5_file in h5_files:
        result = analyze_episode(h5_file)
        if result is None:
            continue
        
        episodes.append(result)
        task_groups[result['task_name']].append(result)
    
    print(f"âœ… {len(episodes)}ê°œ ì—í”¼ì†Œë“œ ë¶„ì„ ì™„ë£Œ")
    print()
    
    # Taskë³„ í†µê³„
    print("=" * 60)
    print("Taskë³„ í†µê³„")
    print("=" * 60)
    
    task_stats = {}
    for task_name, task_episodes in task_groups.items():
        print(f"\nğŸ“‹ Task: {task_name}")
        print(f"   ì—í”¼ì†Œë“œ ìˆ˜: {len(task_episodes)}")
        
        frame_counts = [ep['num_frames'] for ep in task_episodes]
        print(f"   í”„ë ˆì„ ìˆ˜: í‰ê·  {np.mean(frame_counts):.1f}, ìµœì†Œ {min(frame_counts)}, ìµœëŒ€ {max(frame_counts)}")
        
        # Trajectory ë¶„ì„
        all_trajectories = []
        for ep in task_episodes:
            trajs = analyze_trajectory(ep['actions'], window_size=18)
            if trajs:
                all_trajectories.extend(trajs)
        
        if all_trajectories:
            # Trajectory ë¬¸ìì—´ ë³€í™˜
            traj_strings = [trajectory_to_string(traj) for traj in all_trajectories]
            unique_trajs = set(traj_strings)
            
            print(f"   ì´ Trajectory ìˆ˜: {len(traj_strings)}")
            print(f"   ê³ ìœ  Trajectory ìˆ˜: {len(unique_trajs)}")
            
            # ê°€ì¥ í”í•œ trajectory
            from collections import Counter
            traj_counts = Counter(traj_strings)
            most_common = traj_counts.most_common(5)
            print(f"   ê°€ì¥ í”í•œ Trajectory:")
            for traj, count in most_common:
                print(f"     '{traj}': {count}íšŒ ({count/len(traj_strings)*100:.1f}%)")
            
            # ì¼ê´€ì„± í™•ì¸
            consistency = len(unique_trajs) / len(traj_strings) if traj_strings else 0
            print(f"   ì¼ê´€ì„± ì ìˆ˜: {1-consistency:.2%} (ë‚®ì„ìˆ˜ë¡ ì¼ê´€ì )")
            
            task_stats[task_name] = {
                'num_episodes': len(task_episodes),
                'num_trajectories': len(traj_strings),
                'num_unique_trajectories': len(unique_trajs),
                'consistency': 1 - consistency,
                'most_common': most_common[:3]
            }
        else:
            print(f"   âš ï¸  Trajectory ë¶„ì„ ë¶ˆê°€ (í”„ë ˆì„ ìˆ˜ ë¶€ì¡±)")
    
    # ì „ì²´ í†µê³„
    print("\n" + "=" * 60)
    print("ì „ì²´ í†µê³„")
    print("=" * 60)
    
    all_frame_counts = [ep['num_frames'] for ep in episodes]
    print(f"\nì´ ì—í”¼ì†Œë“œ: {len(episodes)}")
    print(f"ì´ í”„ë ˆì„: {sum(all_frame_counts)}")
    print(f"í‰ê·  í”„ë ˆì„/ì—í”¼ì†Œë“œ: {np.mean(all_frame_counts):.1f}")
    print(f"Task ì¢…ë¥˜: {len(task_groups)}")
    
    # ì‹œê°í™”
    print("\n" + "=" * 60)
    print("ì‹œê°í™” ìƒì„± ì¤‘...")
    print("=" * 60)
    
    # 1. Taskë³„ ì—í”¼ì†Œë“œ ìˆ˜
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    # Taskë³„ ì—í”¼ì†Œë“œ ìˆ˜
    ax = axes[0, 0]
    task_names = list(task_groups.keys())
    episode_counts = [len(task_groups[t]) for t in task_names]
    ax.barh(task_names, episode_counts)
    ax.set_xlabel('ì—í”¼ì†Œë“œ ìˆ˜')
    ax.set_title('Taskë³„ ì—í”¼ì†Œë“œ ìˆ˜')
    ax.grid(axis='x', alpha=0.3)
    
    # Taskë³„ í”„ë ˆì„ ìˆ˜ ë¶„í¬
    ax = axes[0, 1]
    for task_name in task_names[:10]:  # ìƒìœ„ 10ê°œë§Œ
        frame_counts = [ep['num_frames'] for ep in task_groups[task_name]]
        ax.hist(frame_counts, alpha=0.5, label=task_name, bins=20)
    ax.set_xlabel('í”„ë ˆì„ ìˆ˜')
    ax.set_ylabel('ë¹ˆë„')
    ax.set_title('Taskë³„ í”„ë ˆì„ ìˆ˜ ë¶„í¬')
    ax.legend(fontsize=8)
    
    # Taskë³„ ì¼ê´€ì„± ì ìˆ˜
    ax = axes[1, 0]
    if task_stats:
        tasks = list(task_stats.keys())
        consistencies = [task_stats[t]['consistency'] for t in tasks]
        ax.barh(tasks, consistencies)
        ax.set_xlabel('ì¼ê´€ì„± ì ìˆ˜ (ë†’ì„ìˆ˜ë¡ ì¼ê´€ì )')
        ax.set_title('Taskë³„ Trajectory ì¼ê´€ì„±')
        ax.set_xlim(0, 1)
        ax.grid(axis='x', alpha=0.3)
    
    # ì•¡ì…˜ ë¶„í¬ (ì „ì²´)
    ax = axes[1, 1]
    all_actions = np.concatenate([ep['actions'] for ep in episodes])
    ax.scatter(all_actions[:, 0], all_actions[:, 1], alpha=0.1, s=1)
    ax.set_xlabel('linear_x (ì „ì§„/í›„ì§„)')
    ax.set_ylabel('linear_y (ì¢Œ/ìš°)')
    ax.set_title('ì „ì²´ ì•¡ì…˜ ë¶„í¬')
    ax.grid(alpha=0.3)
    ax.axhline(0, color='k', linestyle='--', linewidth=0.5)
    ax.axvline(0, color='k', linestyle='--', linewidth=0.5)
    
    plt.tight_layout()
    output_path = Path("h5_episode_analysis.png")
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"âœ… ì‹œê°í™” ì €ì¥: {output_path}")
    
    # 2. Taskë³„ Trajectory ì‹œê°í™” (ìƒìœ„ 5ê°œ task)
    top_tasks = sorted(task_stats.items(), key=lambda x: x[1]['num_episodes'], reverse=True)[:5]
    
    if top_tasks:
        fig, axes = plt.subplots(len(top_tasks), 1, figsize=(15, 3*len(top_tasks)))
        if len(top_tasks) == 1:
            axes = [axes]
        
        for idx, (task_name, stats) in enumerate(top_tasks):
            ax = axes[idx]
            
            # í•´ë‹¹ taskì˜ ëª¨ë“  trajectory ìˆ˜ì§‘
            task_episodes = task_groups[task_name]
            all_trajs = []
            for ep in task_episodes:
                trajs = analyze_trajectory(ep['actions'], window_size=18)
                if trajs:
                    all_trajs.extend(trajs)
            
            if all_trajs:
                # ê°€ì¥ í”í•œ trajectory ì‹œê°í™”
                traj_strings = [trajectory_to_string(traj) for traj in all_trajs]
                from collections import Counter
                traj_counts = Counter(traj_strings)
                most_common_traj = traj_counts.most_common(1)[0][0]
                
                # í•´ë‹¹ trajectory ì°¾ê¸°
                for traj in all_trajs:
                    if trajectory_to_string(traj) == most_common_traj:
                        # Trajectory í”Œë¡¯
                        ax.plot(traj[:, 0], label='linear_x', marker='o', markersize=3)
                        ax.plot(traj[:, 1], label='linear_y', marker='s', markersize=3)
                        ax.set_title(f"{task_name}\nê°€ì¥ í”í•œ Trajectory: '{most_common_traj}' ({traj_counts[most_common_traj]}íšŒ)")
                        ax.set_xlabel('í”„ë ˆì„ (0-17)')
                        ax.set_ylabel('ì•¡ì…˜ ê°’')
                        ax.legend()
                        ax.grid(alpha=0.3)
                        break
        
        plt.tight_layout()
        output_path2 = Path("h5_trajectory_analysis.png")
        plt.savefig(output_path2, dpi=150, bbox_inches='tight')
        print(f"âœ… Trajectory ì‹œê°í™” ì €ì¥: {output_path2}")
    
    # JSON í†µê³„ ì €ì¥
    stats_output = {
        'analysis_date': datetime.now().isoformat(),
        'total_episodes': len(episodes),
        'total_frames': sum(all_frame_counts),
        'avg_frames_per_episode': float(np.mean(all_frame_counts)),
        'num_tasks': len(task_groups),
        'task_stats': {k: {
            'num_episodes': v['num_episodes'],
            'num_trajectories': v['num_trajectories'],
            'num_unique_trajectories': v['num_unique_trajectories'],
            'consistency': float(v['consistency']),
            'most_common_trajectories': [{'trajectory': t[0], 'count': t[1]} for t in v['most_common']]
        } for k, v in task_stats.items()}
    }
    
    stats_path = Path("h5_episode_stats.json")
    with open(stats_path, 'w') as f:
        json.dump(stats_output, f, indent=2)
    print(f"âœ… í†µê³„ ì €ì¥: {stats_path}")
    
    print("\n" + "=" * 60)
    print("ë¶„ì„ ì™„ë£Œ!")
    print("=" * 60)

if __name__ == "__main__":
    main()

