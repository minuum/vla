#!/bin/bash

# =============================================================================
# ðŸš€ Jetson Orin NX Mobile VLA Docker í™˜ê²½ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸
# JetPack 6.0 (L4T R36.4) ìµœì í™” ë²„ì „
# =============================================================================

set -e

# ìƒ‰ìƒ ì½”ë“œ ì •ì˜
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# ë¡œê·¸ í•¨ìˆ˜ë“¤
log_info() {
    echo -e "${BLUE}â„¹ï¸  $1${NC}"
}

log_success() {
    echo -e "${GREEN}âœ… $1${NC}"
}

log_warning() {
    echo -e "${YELLOW}âš ï¸  $1${NC}"
}

log_error() {
    echo -e "${RED}âŒ $1${NC}"
}

log_header() {
    echo -e "${PURPLE}$1${NC}"
}

# í—¤ë” ì¶œë ¥
clear
log_header "==============================================================================="
log_header "ðŸš€ Jetson Orin NX Mobile VLA Docker í™˜ê²½ ì„¤ì •"
log_header "   JetPack 6.0 (L4T R36.4) ìµœì í™” ë²„ì „"
log_header "==============================================================================="
echo

# 1ï¸âƒ£ ì‹œìŠ¤í…œ ì •ë³´ í™•ì¸
log_info "ì‹œìŠ¤í…œ ì •ë³´ í™•ì¸ ì¤‘..."
echo "ðŸ–¥ï¸  í˜¸ìŠ¤íŠ¸ OS: $(lsb_release -d | cut -f2)"
echo "ðŸ”§ ì»¤ë„: $(uname -r)"
echo "ðŸ—ï¸  ì•„í‚¤í…ì²˜: $(uname -m)"

# Jetson ì •ë³´ í™•ì¸
if [ -f "/etc/nv_tegra_release" ]; then
    echo "ðŸ“Ÿ Jetson: $(cat /etc/nv_tegra_release)"
else
    log_warning "Jetson ì‹œìŠ¤í…œì´ ì•„ë‹ ìˆ˜ ìžˆìŠµë‹ˆë‹¤"
fi

# CUDA ë²„ì „ í™•ì¸
if command -v nvcc &> /dev/null; then
    echo "ðŸŽ¯ CUDA: $(nvcc --version | grep release | awk '{print $6}' | cut -c2-)"
else
    log_warning "CUDAê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
fi

echo

# 2ï¸âƒ£ Docker ë° NVIDIA Container Runtime í™•ì¸
log_info "Docker í™˜ê²½ í™•ì¸ ì¤‘..."

if ! command -v docker &> /dev/null; then
    log_error "Dockerê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € Dockerë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”."
    exit 1
fi

echo "ðŸ³ Docker: $(docker --version)"

# NVIDIA Container Runtime í™•ì¸
if docker info | grep -q nvidia; then
    log_success "NVIDIA Container Runtime ê°ì§€ë¨"
else
    log_warning "NVIDIA Container Runtimeì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìžˆìŠµë‹ˆë‹¤"
fi

# Docker ê¶Œí•œ í™•ì¸
if groups | grep -q docker; then
    log_success "Docker ê·¸ë£¹ ê¶Œí•œ ìžˆìŒ"
else
    log_warning "Docker ê·¸ë£¹ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤. ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì¶”ê°€í•˜ì„¸ìš”:"
    echo "  sudo usermod -aG docker $USER"
    echo "  ê·¸ë¦¬ê³  ë¡œê·¸ì•„ì›ƒ í›„ ë‹¤ì‹œ ë¡œê·¸ì¸í•˜ì„¸ìš”."
fi

echo

# 3ï¸âƒ£ í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±
log_info "Docker ë³¼ë¥¨ ë””ë ‰í† ë¦¬ ìƒì„± ì¤‘..."

mkdir -p docker_volumes/cache
mkdir -p docker_volumes/dataset  
mkdir -p docker_volumes/logs

log_success "ë³¼ë¥¨ ë””ë ‰í† ë¦¬ ìƒì„± ì™„ë£Œ"
echo

# 4ï¸âƒ£ í™˜ê²½ ë³€ìˆ˜ ì„¤ì • íŒŒì¼ ìƒì„±
log_info ".env íŒŒì¼ ìƒì„± ì¤‘..."

cat > .env << EOF
# Mobile VLA Docker í™˜ê²½ ë³€ìˆ˜
COMPOSE_PROJECT_NAME=mobile-vla
COMPOSE_FILE=docker-compose.jetson.yml

# ROS2 ì„¤ì •
ROS_DOMAIN_ID=42

# NVIDIA ì„¤ì •
CUDA_VISIBLE_DEVICES=0
NVIDIA_VISIBLE_DEVICES=all

# ë””ìŠ¤í”Œë ˆì´ ì„¤ì • (GUI ì§€ì›)
DISPLAY=${DISPLAY:-:0}

# ë°ì´í„° ê²½ë¡œ
MOBILE_VLA_DATA_DIR=./mobile_vla_dataset
MOBILE_VLA_CACHE_DIR=./docker_volumes/cache
MOBILE_VLA_LOG_DIR=./docker_volumes/logs
EOF

log_success ".env íŒŒì¼ ìƒì„± ì™„ë£Œ"
echo

# 5ï¸âƒ£ ë¹ ë¥¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ë“¤ ìƒì„±
log_info "íŽ¸ì˜ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì¤‘..."

# Docker ë¹Œë“œ ìŠ¤í¬ë¦½íŠ¸
cat > docker-build.sh << 'EOF'
#!/bin/bash
echo "ðŸ”¨ Mobile VLA Jetson Docker ì´ë¯¸ì§€ ë¹Œë“œ ì¤‘..."
docker-compose -f docker-compose.jetson.yml build --no-cache mobile-vla
echo "âœ… ë¹Œë“œ ì™„ë£Œ!"
EOF

# Docker ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
cat > docker-run.sh << 'EOF'
#!/bin/bash
echo "ðŸš€ Mobile VLA Jetson Docker ì»¨í…Œì´ë„ˆ ì‹œìž‘ ì¤‘..."

# X11 ê¶Œí•œ ì„¤ì • (GUI ì§€ì›)
xhost +local:docker

# ì»¨í…Œì´ë„ˆ ì‹œìž‘
docker-compose -f docker-compose.jetson.yml up -d mobile-vla

echo "âœ… ì»¨í…Œì´ë„ˆ ì‹œìž‘ ì™„ë£Œ!"
echo "ðŸ“‹ ìœ ìš©í•œ ëª…ë ¹ì–´:"
echo "   docker exec -it mobile_vla_jetson bash           # ì»¨í…Œì´ë„ˆ ì ‘ì†"
echo "   docker exec -it mobile_vla_jetson vla-camera     # CSI ì¹´ë©”ë¼ ì‹œìž‘"
echo "   docker exec -it mobile_vla_jetson vla-collect    # ë°ì´í„° ìˆ˜ì§‘ ì‹œìž‘"
echo "   docker-compose -f docker-compose.jetson.yml logs # ë¡œê·¸ í™•ì¸"
echo "   docker-compose -f docker-compose.jetson.yml down # ì»¨í…Œì´ë„ˆ ì¤‘ì§€"
EOF

# Docker ì¤‘ì§€ ìŠ¤í¬ë¦½íŠ¸
cat > docker-stop.sh << 'EOF'
#!/bin/bash
echo "ðŸ›‘ Mobile VLA Jetson Docker ì»¨í…Œì´ë„ˆ ì¤‘ì§€ ì¤‘..."
docker-compose -f docker-compose.jetson.yml down
echo "âœ… ì»¨í…Œì´ë„ˆ ì¤‘ì§€ ì™„ë£Œ!"
EOF

# ëª¨ë‹ˆí„°ë§ ì‹œìž‘ ìŠ¤í¬ë¦½íŠ¸
cat > docker-monitor.sh << 'EOF'
#!/bin/bash
echo "ðŸ“Š Mobile VLA ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤ ì‹œìž‘ ì¤‘..."
docker-compose -f docker-compose.jetson.yml --profile monitoring up -d
echo "âœ… ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤ ì‹œìž‘ ì™„ë£Œ!"
echo "ðŸ“Š ëª¨ë‹ˆí„°ë§ ë¡œê·¸ í™•ì¸: docker logs -f mobile_vla_monitoring"
EOF

# ì‹¤í–‰ ê¶Œí•œ ë¶€ì—¬
chmod +x docker-build.sh docker-run.sh docker-stop.sh docker-monitor.sh

log_success "íŽ¸ì˜ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì™„ë£Œ"
echo

# 6ï¸âƒ£ CSI ì¹´ë©”ë¼ ê¶Œí•œ í™•ì¸
log_info "CSI ì¹´ë©”ë¼ ê¶Œí•œ í™•ì¸ ì¤‘..."

if [ -c "/dev/video0" ]; then
    log_success "/dev/video0 ë””ë°”ì´ìŠ¤ ì¡´ìž¬í•¨"
    ls -la /dev/video* | head -3
else
    log_warning "/dev/video0 ë””ë°”ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤"
fi

# nvargus-daemon ìƒíƒœ í™•ì¸
if systemctl is-active --quiet nvargus-daemon; then
    log_success "nvargus-daemon ì‹¤í–‰ ì¤‘"
else
    log_warning "nvargus-daemonì´ ì‹¤í–‰ë˜ì§€ ì•Šê³  ìžˆìŠµë‹ˆë‹¤"
fi

echo

# 7ï¸âƒ£ í…ŒìŠ¤íŠ¸ ëª…ë ¹ì–´ ì œê³µ
log_info "í…ŒìŠ¤íŠ¸ ëª…ë ¹ì–´ ìƒì„± ì¤‘..."

cat > test-docker-gpu.sh << 'EOF'
#!/bin/bash
echo "ðŸ§ª Docker GPU ì§€ì› í…ŒìŠ¤íŠ¸..."
docker run --rm --runtime=nvidia --gpus all \
  nvcr.io/nvidia/l4t-base:r36.4.0 \
  python3 -c "
import platform
print(f'ðŸ–¥ï¸  Platform: {platform.platform()}')
print(f'ðŸ—ï¸  Architecture: {platform.machine()}')

try:
    import torch
    print(f'ðŸ”¥ PyTorch: {torch.__version__}')
    print(f'ðŸŽ¯ CUDA Available: {torch.cuda.is_available()}')
    if torch.cuda.is_available():
        print(f'ðŸ“Ÿ CUDA Device: {torch.cuda.get_device_name(0)}')
        print(f'ðŸ’¾ CUDA Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')
except ImportError:
    print('âš ï¸  PyTorch not available in base image')

print('âœ… Docker GPU í…ŒìŠ¤íŠ¸ ì™„ë£Œ!')
"
EOF

chmod +x test-docker-gpu.sh

log_success "í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì™„ë£Œ"
echo

# 8ï¸âƒ£ ì„¤ì • ì™„ë£Œ ë©”ì‹œì§€
log_header "==============================================================================="
log_success "ðŸŽ‰ Mobile VLA Jetson Docker í™˜ê²½ ì„¤ì • ì™„ë£Œ!"
log_header "==============================================================================="
echo

echo "ðŸ“‹ ë‹¤ìŒ ë‹¨ê³„:"
echo "   1ï¸âƒ£  Docker ì´ë¯¸ì§€ ë¹Œë“œ:     ./docker-build.sh"
echo "   2ï¸âƒ£  GPU í…ŒìŠ¤íŠ¸:             ./test-docker-gpu.sh"
echo "   3ï¸âƒ£  ì»¨í…Œì´ë„ˆ ì‹œìž‘:          ./docker-run.sh"
echo "   4ï¸âƒ£  ì»¨í…Œì´ë„ˆ ì ‘ì†:          docker exec -it mobile_vla_jetson bash"
echo "   5ï¸âƒ£  CSI ì¹´ë©”ë¼ í…ŒìŠ¤íŠ¸:       docker exec -it mobile_vla_jetson vla-camera"
echo "   6ï¸âƒ£  Mobile VLA ë°ì´í„° ìˆ˜ì§‘:  docker exec -it mobile_vla_jetson vla-collect"
echo

log_info "ë¬¸ì œê°€ ë°œìƒí•˜ë©´ ë‹¤ìŒì„ í™•ì¸í•˜ì„¸ìš”:"
echo "   - Docker ê·¸ë£¹ ê¶Œí•œ: groups | grep docker"
echo "   - NVIDIA Runtime: docker info | grep nvidia"
echo "   - CSI ì¹´ë©”ë¼: ls -la /dev/video*"
echo "   - nvargus-daemon: systemctl status nvargus-daemon"
echo

log_header "Happy Mobile VLA Development! ðŸš€"