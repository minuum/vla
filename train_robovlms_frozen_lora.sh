#!/bin/bash
# Mobile VLA - RoboVLMs Frozen+LoRA í•™ìŠµ (Poetry í™˜ê²½)
# 2025-12-04

echo "========================================="
echo "ðŸš€ RoboVLMs Frozen+LoRA í•™ìŠµ ì‹œìž‘"
echo "GPU í•™ìŠµ: Poetry í™˜ê²½ ì‚¬ìš©"
echo "========================================="
echo ""

CONFIG="../Mobile_VLA/configs/mobile_vla_robovlms_frozen_lora_20251204.json"

# CUDA í™•ì¸
echo "ðŸ” CUDA í™•ì¸..."
if poetry run python -c "import torch; print(torch.cuda.is_available())" | grep -q "True"; then
    GPU_NAME=$(poetry run python -c "import torch; print(torch.cuda.get_device_name() if torch.cuda.is_available() else 'N/A')")
    echo "  âœ… GPU: $GPU_NAME"
else
    echo "  âŒ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    exit 1
fi

# Poetry í™˜ê²½ í™•ì¸
echo ""
echo "ðŸ” Poetry í™˜ê²½ í™•ì¸..."
poetry env info || {
    echo "  âŒ Poetry í™˜ê²½ ì—†ìŒ"
    exit 1
}

# íƒ€ìž„ìŠ¤íƒ¬í”„
TIMESTAMP=$(date '+%Y%m%d_%H%M%S')
LOG_FILE="../lora_training_robovlms_${TIMESTAMP}.txt"

echo ""
echo "ðŸ“ Config: mobile_vla_robovlms_frozen_lora_20251204.json"
echo "ðŸ“„ Log: $LOG_FILE"
echo ""
echo "ðŸŽ¯ ëª©ì : Robot pretrain VLM vs ì¼ë°˜ VLM ë¹„êµ"
echo ""
echo "========================================="
echo "í•™ìŠµ ì‹œìž‘..."
echo "========================================="
echo ""

# Poetry í™˜ê²½ì—ì„œ í•™ìŠµ ì‹¤í–‰
cd /home/billy/25-1kp/vla/RoboVLMs_upstream
poetry run python main.py $CONFIG 2>&1 | tee $LOG_FILE

echo ""
echo "========================================="
echo "âœ… í•™ìŠµ ì™„ë£Œ"
echo "ðŸ“„ ë¡œê·¸: $LOG_FILE"
echo "========================================="
