#!/usr/bin/env python3
"""
VLA ëª¨ë¸ê³¼ RoboVLM ì•¡ì…˜ íŒŒì„œ í†µí•© ì‹œìŠ¤í…œ
"""

import torch
import numpy as np
from PIL import Image
import json
from typing import Dict, Any, Optional, List
import sys
import os

# RoboVLM íŒŒì„œ ì„í¬íŠ¸
from robovlm_action_parser import (
    RoboVLMActionParser, 
    ActionValidator, 
    RoboAction, 
    ActionSpace, 
    RobotControl
)

class VLAModelWrapper:
    """VLA ëª¨ë¸ ë˜í¼ í´ë˜ìŠ¤"""
    
    def __init__(self, 
                 model_name: str = "openvla/openvla-7b",
                 device: str = "auto"):
        
        self.model_name = model_name
        self.device = self._setup_device(device)
        
        # ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œ ë¡œë“œ
        self.model = None
        self.processor = None
        self.is_loaded = False
        
        # ì•¡ì…˜ íŒŒì„œ ì´ˆê¸°í™”
        self.action_parser = RoboVLMActionParser(
            action_space=ActionSpace.CONTINUOUS,
            action_dim=7,  # 6DOF + ê·¸ë¦¬í¼
            prediction_horizon=1
        )
        self.action_validator = ActionValidator(
            max_translation_speed=0.5,
            max_rotation_speed=1.0
        )
        
        print(f"ğŸ¤– VLA ëª¨ë¸ ë˜í¼ ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   ëª¨ë¸: {model_name}")
        print(f"   ë””ë°”ì´ìŠ¤: {self.device}")

    def _setup_device(self, device: str) -> str:
        """ë””ë°”ì´ìŠ¤ ì„¤ì •"""
        if device == "auto":
            if torch.cuda.is_available():
                return "cuda"
            elif torch.backends.mps.is_available():
                return "mps"
            else:
                return "cpu"
        return device

    def load_model(self) -> bool:
        """VLA ëª¨ë¸ ë¡œë“œ"""
        try:
            print("ğŸ”„ VLA ëª¨ë¸ ë¡œë”© ì¤‘...")
            
            # OpenVLA ëª¨ë¸ ë¡œë“œ ì‹œë„
            try:
                from transformers import AutoModelForVision2Seq, AutoProcessor
                
                self.processor = AutoProcessor.from_pretrained(
                    self.model_name, 
                    trust_remote_code=True
                )
                self.model = AutoModelForVision2Seq.from_pretrained(
                    self.model_name,
                    torch_dtype=torch.float16,
                    device_map=self.device if self.device != "mps" else None,
                    trust_remote_code=True
                )
                
                if self.device == "mps":
                    self.model = self.model.to(self.device)
                
                self.is_loaded = True
                print("âœ… OpenVLA ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                return True
                
            except Exception as e:
                print(f"âš ï¸ OpenVLA ë¡œë“œ ì‹¤íŒ¨: {e}")
                
                # PaliGemma ëŒ€ì•ˆ ì‹œë„
                print("ğŸ”„ PaliGemma ëŒ€ì•ˆ ëª¨ë¸ ì‹œë„...")
                try:
                    from transformers import PaliGemmaForConditionalGeneration, PaliGemmaProcessor
                    
                    self.processor = PaliGemmaProcessor.from_pretrained("google/paligemma-3b-pt-224")
                    self.model = PaliGemmaForConditionalGeneration.from_pretrained(
                        "google/paligemma-3b-pt-224",
                        torch_dtype=torch.float16,
                        device_map=self.device if self.device != "mps" else None
                    )
                    
                    if self.device == "mps":
                        self.model = self.model.to(self.device)
                    
                    self.is_loaded = True
                    print("âœ… PaliGemma ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                    return True
                    
                except Exception as e2:
                    print(f"âŒ PaliGemma ë¡œë“œë„ ì‹¤íŒ¨: {e2}")
                    return False
                
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False

    def predict_action(self, 
                      image: Image.Image,
                      text_instruction: str,
                      return_raw: bool = False) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¡œë¶€í„° ì•¡ì…˜ ì˜ˆì¸¡"""
        
        if not self.is_loaded:
            print("âš ï¸ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ. í…ìŠ¤íŠ¸ ê¸°ë°˜ fallback ì‚¬ìš©")
            return self._text_fallback_action(text_instruction)
        
        try:
            # PaliGemmaëŠ” íŠ¹ë³„í•œ í”„ë¡¬í”„íŠ¸ í˜•ì‹ í•„ìš”
            prompt = f"action: {text_instruction}"
            
            # ì…ë ¥ ì „ì²˜ë¦¬
            inputs = self.processor(
                images=image,
                text=prompt,
                return_tensors="pt"
            )
            
            # MPS ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            if self.device == "mps":
                inputs = {k: v.to(self.device) if isinstance(v, torch.Tensor) else v 
                         for k, v in inputs.items()}
            else:
                inputs = inputs.to(self.device)
            
            # ëª¨ë¸ ì¶”ë¡ 
            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_new_tokens=50,
                    do_sample=False,  # ê²°ì •ì  ì¶œë ¥
                    pad_token_id=self.processor.tokenizer.eos_token_id
                )
            
            # ì…ë ¥ ê¸¸ì´ë§Œí¼ ì œê±°í•˜ì—¬ ìƒˆë¡œ ìƒì„±ëœ í† í°ë§Œ ì¶”ì¶œ
            input_length = inputs['input_ids'].shape[1]
            generated_tokens = outputs[0][input_length:]
            
            # ì¶œë ¥ ë””ì½”ë”©
            generated_text = self.processor.tokenizer.decode(generated_tokens, skip_special_tokens=True)
            
            # ì•¡ì…˜ íŒŒì‹± ì‹œë„
            action = self._parse_model_output(generated_text, text_instruction)
            
            # ì•ˆì „ì„± ê²€ì¦
            validated_action = self.action_validator.validate_action(action)
            
            result = {
                "success": True,
                "action": validated_action,
                "raw_output": generated_text if return_raw else None,
                "confidence": validated_action.confidence,
                "is_safe": self.action_validator.is_safe_action(validated_action)
            }
            
            return result
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ì¶”ë¡  ì‹¤íŒ¨: {e}")
            return self._text_fallback_action(text_instruction)

    def _parse_model_output(self, 
                           generated_text: str,
                           instruction: str) -> RoboAction:
        """ëª¨ë¸ ì¶œë ¥ íŒŒì‹±"""
        
        # ìƒì„±ëœ í…ìŠ¤íŠ¸ì—ì„œ ì•¡ì…˜ ì¶”ì¶œ ì‹œë„
        try:
            # ìˆ«ì íŒ¨í„´ ì°¾ê¸°
            import re
            numbers = re.findall(r'-?\d+\.?\d*', generated_text)
            
            if len(numbers) >= 6:
                # ì¶©ë¶„í•œ ìˆ«ìê°€ ìˆìœ¼ë©´ 6DOF ì•¡ì…˜ìœ¼ë¡œ íŒŒì‹±
                action_array = np.array([float(x) for x in numbers[:7]])
                # ì •ê·œí™” (-1 ~ 1 ë²”ìœ„ë¡œ)
                action_array = np.clip(action_array / 100.0, -1.0, 1.0)
                
                # RoboVLM íŒŒì„œë¡œ ì²˜ë¦¬
                action_tensor = torch.tensor(action_array).unsqueeze(0)
                return self.action_parser.parse_continuous_action(
                    action_tensor, instruction
                )
            else:
                # ìˆ«ìê°€ ë¶€ì¡±í•˜ë©´ í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ fallback
                return self.action_parser._text_only_action(instruction)
                
        except Exception as e:
            print(f"âš ï¸ ì¶œë ¥ íŒŒì‹± ì‹¤íŒ¨: {e}, fallback to text-only")
            return self.action_parser._text_only_action(instruction)

    def _text_fallback_action(self, instruction: str) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸ ê¸°ë°˜ fallback ì•¡ì…˜"""
        action = self.action_parser._text_only_action(instruction)
        validated_action = self.action_validator.validate_action(action)
        
        return {
            "success": False,
            "action": validated_action,
            "raw_output": None,
            "confidence": validated_action.confidence,
            "is_safe": self.action_validator.is_safe_action(validated_action),
            "fallback": True
        }

    def batch_predict(self, 
                     image_instruction_pairs: List[tuple],
                     return_raw: bool = False) -> List[Dict[str, Any]]:
        """ë°°ì¹˜ ì˜ˆì¸¡"""
        results = []
        
        for i, (image, instruction) in enumerate(image_instruction_pairs):
            print(f"ğŸ”„ ë°°ì¹˜ ì˜ˆì¸¡ {i+1}/{len(image_instruction_pairs)}: {instruction}")
            result = self.predict_action(image, instruction, return_raw)
            results.append(result)
        
        return results

class VLATestSuite:
    """VLA ëª¨ë¸ í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸"""
    
    def __init__(self, model_wrapper: VLAModelWrapper):
        self.model = model_wrapper
        
    def create_test_image(self, scenario: str = "kitchen") -> Image.Image:
        """í…ŒìŠ¤íŠ¸ìš© ì´ë¯¸ì§€ ìƒì„±"""
        # ê°„ë‹¨í•œ ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„± (ì‹¤ì œë¡œëŠ” ì¹´ë©”ë¼ ì´ë¯¸ì§€ ì‚¬ìš©)
        image = Image.new('RGB', (224, 224), color='lightblue')
        
        # ì‹œë‚˜ë¦¬ì˜¤ë³„ ê°„ë‹¨í•œ ìš”ì†Œ ì¶”ê°€ (ì‹¤ì œë¡œëŠ” ë³µì¡í•œ ì¥ë©´)
        if scenario == "kitchen":
            # ì£¼ë°© ì‹œë‚˜ë¦¬ì˜¤ ì‹œë®¬ë ˆì´ì…˜
            pass
        elif scenario == "table":
            # í…Œì´ë¸” ì‹œë‚˜ë¦¬ì˜¤ ì‹œë®¬ë ˆì´ì…˜
            pass
        
        return image

    def run_basic_tests(self) -> Dict[str, Any]:
        """ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ğŸ§ª VLA ëª¨ë¸ ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("=" * 50)
        
        test_cases = [
            ("Move forward slowly", "navigation"),
            ("Turn left and stop", "navigation"),
            ("Pick up the red cup", "manipulation"),
            ("Put the object on the table", "manipulation"),
            ("ì „ì§„í•˜ì„¸ìš”", "navigation_kr"),
            ("ë¬¼ê±´ì„ ì¡ì•„ì£¼ì„¸ìš”", "manipulation_kr")
        ]
        
        results = []
        test_image = self.create_test_image("kitchen")
        
        for instruction, category in test_cases:
            print(f"\nğŸ“ í…ŒìŠ¤íŠ¸: '{instruction}' ({category})")
            
            result = self.model.predict_action(test_image, instruction, return_raw=True)
            
            if result["success"]:
                action = result["action"]
                linear_x, linear_y, angular_z = action.to_twist_like()
                safety_icon = "âœ…" if result["is_safe"] else "âŒ"
                
                print(f"   ì•¡ì…˜ íƒ€ì…: {action.action_type}")
                print(f"   ì œì–´ ëª¨ë“œ: {action.control_mode.value}")
                print(f"   Linear: ({linear_x:.2f}, {linear_y:.2f})")
                print(f"   Angular: {angular_z:.2f}")
                print(f"   ê·¸ë¦¬í¼: {action.gripper:.2f}")
                print(f"   ì‹ ë¢°ë„: {action.confidence:.2f}")
                print(f"   ì•ˆì „ì„±: {safety_icon}")
                
                if result.get("raw_output"):
                    print(f"   ì›ë³¸ ì¶œë ¥: {result['raw_output'][:100]}...")
            else:
                print(f"   âŒ ì‹¤íŒ¨ (fallback ì‚¬ìš©)")
                if result.get("fallback"):
                    action = result["action"]
                    linear_x, linear_y, angular_z = action.to_twist_like()
                    print(f"   Fallback ì•¡ì…˜: ({linear_x:.2f}, {linear_y:.2f}, {angular_z:.2f})")
            
            results.append({
                "instruction": instruction,
                "category": category,
                "result": result
            })
        
        return {
            "total_tests": len(test_cases),
            "successful_predictions": sum(1 for r in results if r["result"]["success"]),
            "safe_actions": sum(1 for r in results if r["result"]["is_safe"]),
            "results": results
        }

    def run_sequence_tests(self) -> Dict[str, Any]:
        """ì‹œí€€ìŠ¤ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("\nğŸ”„ VLA ëª¨ë¸ ì‹œí€€ìŠ¤ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("=" * 50)
        
        sequence_instructions = [
            "Move to the table",
            "Pick up the cup", 
            "Bring it to the counter",
            "Put it down gently"
        ]
        
        test_image = self.create_test_image("kitchen")
        sequence_results = []
        
        for i, instruction in enumerate(sequence_instructions):
            print(f"\nğŸ”— ì‹œí€€ìŠ¤ {i+1}: '{instruction}'")
            
            result = self.model.predict_action(test_image, instruction)
            action = result["action"]
            
            linear_x, linear_y, angular_z = action.to_twist_like()
            print(f"   ì•¡ì…˜: ({linear_x:.2f}, {linear_y:.2f}, {angular_z:.2f})")
            print(f"   ê·¸ë¦¬í¼: {action.gripper:.2f}")
            print(f"   ì‹ ë¢°ë„: {action.confidence:.2f}")
            
            sequence_results.append(result)
        
        return {
            "sequence_length": len(sequence_instructions),
            "results": sequence_results
        }

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ VLA ëª¨ë¸ í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    # VLA ëª¨ë¸ ë˜í¼ ì´ˆê¸°í™”
    vla_model = VLAModelWrapper(
        model_name="openvla/openvla-7b",
        device="auto"
    )
    
    # ëª¨ë¸ ë¡œë“œ ì‹œë„
    if not vla_model.load_model():
        print("âš ï¸ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨. í…ìŠ¤íŠ¸ ê¸°ë°˜ ëª¨ë“œë¡œ ê³„ì†...")
    
    # í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ì‹¤í–‰
    test_suite = VLATestSuite(vla_model)
    
    # ê¸°ë³¸ í…ŒìŠ¤íŠ¸
    basic_results = test_suite.run_basic_tests()
    
    print(f"\nğŸ“Š ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
    print(f"   ì „ì²´ í…ŒìŠ¤íŠ¸: {basic_results['total_tests']}")
    print(f"   ì„±ê³µí•œ ì˜ˆì¸¡: {basic_results['successful_predictions']}")
    print(f"   ì•ˆì „í•œ ì•¡ì…˜: {basic_results['safe_actions']}")
    
    # ì‹œí€€ìŠ¤ í…ŒìŠ¤íŠ¸
    sequence_results = test_suite.run_sequence_tests()
    
    print(f"\nğŸ“Š ì‹œí€€ìŠ¤ í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
    print(f"   ì‹œí€€ìŠ¤ ê¸¸ì´: {sequence_results['sequence_length']}")
    
    # ê²°ê³¼ ì €ì¥
    final_results = {
        "basic_tests": basic_results,
        "sequence_tests": sequence_results,
        "model_info": {
            "name": vla_model.model_name,
            "device": vla_model.device,
            "loaded": vla_model.is_loaded
        }
    }
    
    with open("vla_test_results.json", "w", encoding="utf-8") as f:
        json.dump(final_results, f, indent=2, ensure_ascii=False, default=str)
    
    print(f"\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ! ê²°ê³¼ê°€ 'vla_test_results.json'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main() 