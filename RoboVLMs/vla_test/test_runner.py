#!/usr/bin/env python3
"""
ë…ë¦½í˜• VLA ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰ê¸°
"""

import cv2
import time
import os
import sys
import argparse
from typing import Optional
import numpy as np

from standalone_vla_test import StandaloneVLAInference, CameraHandler
from action_parser import VLAActionParser, ActionValidator, RobotAction

class VLATestRunner:
    """VLA ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""
    
    def __init__(self, 
                 model_id: str = "google/paligemma-3b-mix-224",
                 device: str = "cuda",
                 use_camera: bool = False,
                 camera_id: int = 0):
        
        print("ğŸš€ VLA í…ŒìŠ¤íŠ¸ ëŸ¬ë„ˆ ì´ˆê¸°í™” ì¤‘...")
        
        # VLA ì¶”ë¡  ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self.vla_system = StandaloneVLAInference(
            model_id=model_id,
            device_preference=device
        )
        
        # ì•¡ì…˜ íŒŒì„œ ì´ˆê¸°í™”
        self.action_parser = VLAActionParser()
        self.action_validator = ActionValidator()
        
        # ì¹´ë©”ë¼ í•¸ë“¤ëŸ¬ ì´ˆê¸°í™”
        self.camera_handler = CameraHandler(camera_id)
        self.use_camera = use_camera
        
        if self.use_camera:
            if not self.camera_handler.init_camera():
                print("âš ï¸ ì¹´ë©”ë¼ ì´ˆê¸°í™” ì‹¤íŒ¨ - í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ëª¨ë“œë¡œ ì „í™˜")
                self.use_camera = False
        
        # í…ŒìŠ¤íŠ¸ ìƒíƒœ
        self.test_results = []
        self.current_image = None
        
        print("âœ… VLA í…ŒìŠ¤íŠ¸ ëŸ¬ë„ˆ ì´ˆê¸°í™” ì™„ë£Œ")

    def load_test_image(self, image_path: str) -> bool:
        """í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë¡œë“œ"""
        if not os.path.exists(image_path):
            print(f"âŒ ì´ë¯¸ì§€ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {image_path}")
            return False
        
        self.current_image = self.camera_handler.load_test_image(image_path)
        return self.current_image is not None

    def capture_current_frame(self) -> bool:
        """í˜„ì¬ ì¹´ë©”ë¼ í”„ë ˆì„ ìº¡ì²˜"""
        if not self.use_camera:
            print("âŒ ì¹´ë©”ë¼ê°€ í™œì„±í™”ë˜ì§€ ì•ŠìŒ")
            return False
        
        self.current_image = self.camera_handler.capture_frame()
        return self.current_image is not None

    def run_single_test(self, command: str, use_vla_model: bool = True) -> RobotAction:
        """ë‹¨ì¼ ëª…ë ¹ì–´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        if self.current_image is None:
            print("âŒ í…ŒìŠ¤íŠ¸ìš© ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤")
            return RobotAction(action_type="UNKNOWN")
        
        print(f"\nğŸ§  í…ŒìŠ¤íŠ¸ ì‹¤í–‰: '{command}'")
        print("-" * 40)
        
        start_time = time.time()
        
        try:
            if use_vla_model:
                # VLA ëª¨ë¸ ì‚¬ìš©í•œ ì „ì²´ íŒŒì´í”„ë¼ì¸
                linear_x, linear_y, angular_z = self.vla_system.simple_command_inference(
                    self.current_image, command
                )
                
                # ê°„ë‹¨í•œ RobotAction ìƒì„± (ì‹¤ì œë¡œëŠ” VLA ê²°ê³¼ë¥¼ íŒŒì‹±í•´ì•¼ í•¨)
                action = RobotAction(
                    action_type="MOVE",
                    linear_x=linear_x,
                    linear_y=linear_y,
                    angular_z=angular_z,
                    description=f"VLA result for: {command}",
                    confidence=0.7
                )
            else:
                # ì•¡ì…˜ íŒŒì„œë§Œ ì‚¬ìš©í•œ í…ŒìŠ¤íŠ¸
                action = self.action_parser.parse_text_output(command)
            
            # ì•¡ì…˜ ìœ íš¨ì„± ê²€ì‚¬
            action = self.action_validator.validate_action(action)
            
            processing_time = time.time() - start_time
            
            # ê²°ê³¼ ì¶œë ¥
            print(f"ğŸ¯ ì•¡ì…˜ íƒ€ì…: {action.action_type.value}")
            print(f"ğŸš€ ì œì–´ ëª…ë ¹:")
            print(f"   - linear_x: {action.linear_x:.3f}")
            print(f"   - linear_y: {action.linear_y:.3f}")
            print(f"   - angular_z: {action.angular_z:.3f}")
            print(f"ğŸ¯ ëª©í‘œ ê°ì²´: {action.target_object or 'N/A'}")
            print(f"ğŸ“Š ì‹ ë¢°ë„: {action.confidence:.2f}")
            print(f"â±ï¸ ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
            print(f"âœ… ì•ˆì „ì„±: {'í†µê³¼' if self.action_validator.is_safe_action(action) else 'ì‹¤íŒ¨'}")
            
            # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥
            test_result = {
                "command": command,
                "action": action.to_dict(),
                "processing_time": processing_time,
                "safe": self.action_validator.is_safe_action(action),
                "use_vla_model": use_vla_model
            }
            self.test_results.append(test_result)
            
            return action
            
        except Exception as e:
            print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
            return RobotAction(action_type="UNKNOWN")

    def run_batch_tests(self, commands: list, use_vla_model: bool = True):
        """ë°°ì¹˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print(f"\nğŸ“‹ ë°°ì¹˜ í…ŒìŠ¤íŠ¸ ì‹œì‘ (VLA ëª¨ë¸ ì‚¬ìš©: {use_vla_model})")
        print("=" * 60)
        
        for i, command in enumerate(commands, 1):
            print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ {i}/{len(commands)}")
            self.run_single_test(command, use_vla_model)
            
            if i < len(commands):
                print("\nâ³ ì ì‹œ ëŒ€ê¸°...")
                time.sleep(1)
        
        print(f"\nâœ… ë°°ì¹˜ í…ŒìŠ¤íŠ¸ ì™„ë£Œ ({len(commands)}ê°œ ëª…ë ¹)")

    def run_interactive_test(self):
        """ëŒ€í™”í˜• í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("\nğŸ® ëŒ€í™”í˜• í…ŒìŠ¤íŠ¸ ëª¨ë“œ")
        print("=" * 40)
        print("ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œ: 'quit' ë˜ëŠ” 'exit')")
        print("ì¹´ë©”ë¼ ìº¡ì²˜: 'capture' (ì¹´ë©”ë¼ ëª¨ë“œì—ì„œë§Œ)")
        print("ì´ë¯¸ì§€ ë¡œë“œ: 'load <íŒŒì¼ê²½ë¡œ>'")
        print("VLA ëª¨ë¸ í† ê¸€: 'toggle_vla'")
        print("-" * 40)
        
        use_vla_model = True
        
        while True:
            try:
                user_input = input("\nğŸ’¬ ëª…ë ¹ì–´: ").strip()
                
                if user_input.lower() in ['quit', 'exit']:
                    print("ğŸ‘‹ í…ŒìŠ¤íŠ¸ ì¢…ë£Œ")
                    break
                elif user_input.lower() == 'capture':
                    if self.capture_current_frame():
                        print("ğŸ“¸ í”„ë ˆì„ ìº¡ì²˜ ì™„ë£Œ")
                    else:
                        print("âŒ í”„ë ˆì„ ìº¡ì²˜ ì‹¤íŒ¨")
                elif user_input.lower().startswith('load '):
                    image_path = user_input[5:].strip()
                    if self.load_test_image(image_path):
                        print(f"âœ… ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ: {image_path}")
                    else:
                        print(f"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}")
                elif user_input.lower() == 'toggle_vla':
                    use_vla_model = not use_vla_model
                    print(f"ğŸ”„ VLA ëª¨ë¸ ì‚¬ìš©: {'ON' if use_vla_model else 'OFF'}")
                elif user_input.strip():
                    self.run_single_test(user_input, use_vla_model)
                
            except KeyboardInterrupt:
                print("\nğŸ‘‹ í…ŒìŠ¤íŠ¸ ì¢…ë£Œ")
                break
            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜: {e}")

    def show_results_summary(self):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        if not self.test_results:
            print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
            return
        
        print("\nğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        print("=" * 50)
        
        total_tests = len(self.test_results)
        safe_tests = sum(1 for result in self.test_results if result["safe"])
        avg_time = np.mean([result["processing_time"] for result in self.test_results])
        
        print(f"ì´ í…ŒìŠ¤íŠ¸: {total_tests}ê°œ")
        print(f"ì•ˆì „í•œ ì•¡ì…˜: {safe_tests}ê°œ ({safe_tests/total_tests*100:.1f}%)")
        print(f"í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_time:.2f}ì´ˆ")
        
        # ì•¡ì…˜ íƒ€ì…ë³„ ë¶„ì„
        action_types = {}
        for result in self.test_results:
            action_type = result["action"]["action_type"]
            action_types[action_type] = action_types.get(action_type, 0) + 1
        
        print(f"\nì•¡ì…˜ íƒ€ì… ë¶„í¬:")
        for action_type, count in action_types.items():
            print(f"  {action_type}: {count}ê°œ")

    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.use_camera:
            self.camera_handler.release()
        print("ğŸ§¹ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")

def main():
    parser = argparse.ArgumentParser(description="VLA ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ëŸ¬ë„ˆ")
    parser.add_argument("--model", default="google/paligemma-3b-mix-224", 
                       help="ì‚¬ìš©í•  VLA ëª¨ë¸ ID")
    parser.add_argument("--device", default="cuda", choices=["cuda", "cpu"],
                       help="ì¶”ë¡ ì— ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤")
    parser.add_argument("--camera", action="store_true",
                       help="ì¹´ë©”ë¼ ì‚¬ìš©")
    parser.add_argument("--camera-id", type=int, default=0,
                       help="ì¹´ë©”ë¼ ID")
    parser.add_argument("--image", type=str,
                       help="í…ŒìŠ¤íŠ¸ìš© ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--mode", choices=["batch", "interactive", "single"], 
                       default="interactive",
                       help="í…ŒìŠ¤íŠ¸ ëª¨ë“œ")
    parser.add_argument("--command", type=str,
                       help="ë‹¨ì¼ í…ŒìŠ¤íŠ¸ ëª…ë ¹ì–´")
    parser.add_argument("--no-vla", action="store_true",
                       help="VLA ëª¨ë¸ ì—†ì´ íŒŒì„œë§Œ í…ŒìŠ¤íŠ¸")
    
    args = parser.parse_args()
    
    # í…ŒìŠ¤íŠ¸ ëŸ¬ë„ˆ ì´ˆê¸°í™”
    test_runner = VLATestRunner(
        model_id=args.model,
        device=args.device,
        use_camera=args.camera,
        camera_id=args.camera_id
    )
    
    try:
        # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë¡œë“œ
        if args.image:
            if not test_runner.load_test_image(args.image):
                print("âŒ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨")
                return
        elif not args.camera:
            # ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì°¾ê¸°
            default_images = [
                "../RoboVLMs/cat.jpg",
                "test_image.jpg", 
                "sample.jpg"
            ]
            
            image_loaded = False
            for img_path in default_images:
                if os.path.exists(img_path):
                    if test_runner.load_test_image(img_path):
                        image_loaded = True
                        break
            
            if not image_loaded:
                print("âš ï¸ ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                print("ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜ --image ì˜µì…˜ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ì§€ì •í•˜ì„¸ìš”")
        
        use_vla_model = not args.no_vla
        
        # í…ŒìŠ¤íŠ¸ ëª¨ë“œì— ë”°ë¥¸ ì‹¤í–‰
        if args.mode == "single":
            if not args.command:
                print("âŒ ë‹¨ì¼ í…ŒìŠ¤íŠ¸ ëª¨ë“œì—ì„œëŠ” --command ì˜µì…˜ì´ í•„ìš”í•©ë‹ˆë‹¤")
                return
            test_runner.run_single_test(args.command, use_vla_model)
            
        elif args.mode == "batch":
            default_commands = [
                "move forward",
                "turn left",
                "turn right", 
                "stop",
                "navigate to door",
                "avoid obstacle",
                "grab the cup",
                "look around"
            ]
            test_runner.run_batch_tests(default_commands, use_vla_model)
            
        elif args.mode == "interactive":
            test_runner.run_interactive_test()
        
        # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        test_runner.show_results_summary()
        
    finally:
        test_runner.cleanup()

if __name__ == "__main__":
    main() 