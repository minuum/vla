# RoboVLMs êµ¬ì¡° ë¶„ì„ ë° ì•¡ì…˜ íŒŒì„œ ë°œì „ ë³´ê³ ì„œ

## ğŸ“Š í”„ë¡œì íŠ¸ ê°œìš”

ì´ í”„ë¡œì íŠ¸ëŠ” **RoboVLMs (Robot Vision-Language Models)** êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ê³ , ê¸°ì¡´ì˜ ë‹¨ìˆœ í…ìŠ¤íŠ¸ ê¸°ë°˜ ì•¡ì…˜ íŒŒì„œë¥¼ **ì‹¤ì œ VLM ëª¨ë¸ ì¶œë ¥ í˜•íƒœì— ë§ëŠ” ê³ ê¸‰ íŒŒì„œ**ë¡œ ë°œì „ì‹œí‚¤ëŠ” ê³¼ì •ì„ ë‹´ê³  ìˆìŠµë‹ˆë‹¤.

## ğŸ” RoboVLMs êµ¬ì¡° ë¶„ì„

### 1. ëª¨ë¸ ì•„í‚¤í…ì²˜

#### í•µì‹¬ ì»´í¬ë„ŒíŠ¸
- **Backbone**: ë‹¤ì–‘í•œ VLM ëª¨ë¸ ì§€ì› (PaliGemma, LLaVA, Flamingo, OpenVLA ë“±)
- **Vision Encoder**: ì´ë¯¸ì§€ ì²˜ë¦¬ ë° íŠ¹ì§• ì¶”ì¶œ
- **Action Encoder**: ì•¡ì…˜ ì¸ì½”ë”© (ì—°ì†/ì´ì‚°)
- **Policy Head**: ì•¡ì…˜ ì˜ˆì¸¡ í—¤ë“œ (ActionTokenizer, TrajectoryGPT2)

#### ì•¡ì…˜ í‘œí˜„ ë°©ì‹
```python
# ì—°ì† ì•¡ì…˜: (batch_size, seq_len, action_dim)
action_tensor = torch.tensor([[[x, y, z, roll, pitch, yaw, gripper]]])

# ì´ì‚° ì•¡ì…˜: í† í° ID ì‹œí€€ìŠ¤
action_tokens = [token_id_1, token_id_2, ..., token_id_n]

# ê¶¤ì  ì‹œí€€ìŠ¤: (batch_size, seq_len, fwd_pred_next_n, action_dim)
trajectory = torch.tensor([
    [[step_1_action], [step_2_action], ..., [step_n_action]]
])
```

### 2. ActionTokenizer ë¶„ì„

**í•µì‹¬ ê¸°ëŠ¥**:
- ì—°ì† ì•¡ì…˜ì„ Nê°œ ë¹ˆìœ¼ë¡œ ì´ì‚°í™” (ê¸°ë³¸ 256ê°œ)
- ì•¡ì…˜ ë²”ìœ„: [-1, 1] â†’ í† í° ID ë§¤í•‘
- ê· ë“± ë¶„í•  ì „ëµìœ¼ë¡œ ì •ë°€ë„ ë³´ì¥

```python
# ActionTokenizer í•µì‹¬ ë¡œì§
bins = np.linspace(min_action, max_action, n_bins)
discretized_action = np.digitize(action, bins)
token_ids = tokenizer_vocab_size - discretized_action
```

### 3. BaseRoboVLM ì•„í‚¤í…ì²˜

**ì£¼ìš” ë©”ì„œë“œ**:
- `forward_continuous()`: ì—°ì† ì•¡ì…˜ ê³µê°„ ì²˜ë¦¬
- `forward_discrete()`: ì´ì‚° ì•¡ì…˜ ê³µê°„ ì²˜ë¦¬
- `parse_trajectory_sequence()`: ê¶¤ì  ì‹œí€€ìŠ¤ íŒŒì‹±
- `encode_images()`: ë¹„ì „ íŠ¹ì§• ì¸ì½”ë”©

## ğŸš€ ë°œì „ëœ ì•¡ì…˜ íŒŒì„œ

### 1. ê¸°ì¡´ íŒŒì„œì˜ í•œê³„
```python
# ê¸°ì¡´ ë‹¨ìˆœ íŒŒì„œ
def simple_parse(text):
    if "forward" in text:
        return {"linear_x": 0.3, "angular_z": 0.0}
    elif "left" in text:
        return {"linear_x": 0.0, "angular_z": 0.5}
    # ...
```

**ë¬¸ì œì **:
- í…ìŠ¤íŠ¸ë§Œ ì²˜ë¦¬, ë¹„ì „ ì •ë³´ ë¬´ì‹œ
- ë‹¨ìˆœí•œ í‚¤ì›Œë“œ ë§¤ì¹­
- 6DOF ì•¡ì…˜ ì§€ì› ë¶€ì¡±
- ê¶¤ì /ì‹œí€€ìŠ¤ ì²˜ë¦¬ ë¶ˆê°€
- ì•ˆì „ì„± ê²€ì¦ ì—†ìŒ

### 2. RoboVLM ê¸°ë°˜ ê³ ê¸‰ íŒŒì„œ

#### í•µì‹¬ í´ë˜ìŠ¤ êµ¬ì¡°
```python
class RoboAction:
    """6DOF + ê·¸ë¦¬í¼ ì•¡ì…˜ í‘œí˜„"""
    translation: np.ndarray   # [x, y, z]
    rotation: np.ndarray      # [roll, pitch, yaw]
    gripper: float           # ê·¸ë¦¬í¼ ìƒíƒœ
    action_type: str         # ì•¡ì…˜ íƒ€ì…
    confidence: float        # ì‹ ë¢°ë„
    control_mode: RobotControl  # ì œì–´ ëª¨ë“œ

class RoboVLMActionParser:
    """ê³ ê¸‰ ì•¡ì…˜ íŒŒì„œ"""
    - parse_continuous_action()
    - parse_discrete_action() 
    - parse_trajectory_sequence()
    - parse_vision_language_action()
```

#### ì£¼ìš” ê°œì„ ì‚¬í•­

**1. ë‹¤ì°¨ì› ì•¡ì…˜ ì§€ì›**
```python
# 6DOF + ê·¸ë¦¬í¼ ì§€ì›
action = RoboAction(
    translation=[0.3, 0.0, 0.0],  # x, y, z
    rotation=[0.0, 0.0, 0.5],     # roll, pitch, yaw
    gripper=0.8                   # ê·¸ë¦¬í¼ ìƒíƒœ
)
```

**2. ë‹¤ì–‘í•œ ì…ë ¥ í˜•íƒœ ì²˜ë¦¬**
- ì—°ì† ì•¡ì…˜ í…ì„œ: `torch.Tensor([bs, seq_len, action_dim])`
- ì´ì‚° ì•¡ì…˜ í† í°: `List[token_ids]`
- VLM ì „ì²´ ì¶œë ¥: `Dict[str, Any]`
- ê¶¤ì  ì‹œí€€ìŠ¤: `torch.Tensor([bs, seq_len, action_dim])`

**3. ì•¡ì…˜ íƒ€ì… ì¶”ë¡ **
```python
action_keywords = {
    "move": ["move", "go", "forward", "ì „ì§„", "ì´ë™"],
    "turn": ["turn", "rotate", "left", "right", "íšŒì „"],
    "grab": ["grab", "grasp", "pick", "ì¡ë‹¤", "ë“¤ë‹¤"],
    "navigate": ["navigate", "find", "reach", "ì°¾ì•„ê°€ë‹¤"]
}
```

**4. ì•ˆì „ì„± ê²€ì¦**
```python
class ActionValidator:
    def validate_action(self, action):
        # ì†ë„ ì œí•œ
        # ê²½ê³„ê°’ í´ë¦¬í•‘
        # ì•ˆì „ì„± ê²€ì‚¬
        return validated_action
```

### 3. ì„±ëŠ¥ ë¹„êµ

#### í…ŒìŠ¤íŠ¸ ê²°ê³¼ (7ê°œ ëª…ë ¹ì–´)
- **ì „ì²´ í…ŒìŠ¤íŠ¸**: 7ê°œ
- **ì•ˆì „í•œ ì•¡ì…˜**: 7ê°œ (100%)
- **í‰ê·  ì‹ ë¢°ë„**: 0.916
- **ì•¡ì…˜ íƒ€ì… ë¶„í¬**: 
  - move: 2ê°œ
  - turn: 2ê°œ  
  - grab: 1ê°œ
  - navigate: 1ê°œ
  - unknown: 1ê°œ

#### ê¸°ì¡´ vs ìƒˆ íŒŒì„œ ë¹„êµ
| ëª…ë ¹ì–´ | ê¸°ì¡´ íŒŒì„œ | RoboVLM íŒŒì„œ | ê°œì„ ì  |
|--------|-----------|--------------|--------|
| "Move forward to kitchen" | (0.30, 0.00) | (0.25, -0.02) [move] | ì•¡ì…˜ íƒ€ì… ë¶„ë¥˜ |
| "Turn left and avoid" | (0.00, 0.50) | (-0.06, 0.58) [turn] | ë³µí•© ëª…ë ¹ ì²˜ë¦¬ |
| "Grab the cup" | (0.00, 0.00) | (0.11, 0.02) [grab] | ì¡°ì‘ ì•¡ì…˜ ì§€ì› |
| "Navigate around" | (0.00, 0.00) | (0.22, 0.29) [navigate] | ë³µì¡í•œ ë„¤ë¹„ê²Œì´ì…˜ |

## ğŸ”„ í†µí•© ì‹œìŠ¤í…œ êµ¬ì¡°

### VLA ëª¨ë¸ ë˜í¼
```python
class VLAModelWrapper:
    def __init__(self, model_name="openvla/openvla-7b"):
        self.action_parser = RoboVLMActionParser()
        self.action_validator = ActionValidator()
    
    def predict_action(self, image, text_instruction):
        # ëª¨ë¸ ì¶”ë¡ 
        outputs = self.model.generate(**inputs)
        # ì•¡ì…˜ íŒŒì‹±
        action = self.action_parser.parse_continuous_action(outputs, text)
        # ê²€ì¦
        return self.action_validator.validate_action(action)
```

### ì‹œë®¬ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸
- **VLM ì¶œë ¥ ì‹œë®¬ë ˆì´í„°**: ì‹¤ì œ ëª¨ë¸ ì—†ì´ë„ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥
- **ê¶¤ì  ì‹œí€€ìŠ¤ ìƒì„±**: ë‹¤ë‹¨ê³„ ì•¡ì…˜ ì‹œë®¬ë ˆì´ì…˜
- **ë…¸ì´ì¦ˆ ì¶”ê°€**: í˜„ì‹¤ì ì¸ ëª¨ë¸ ì¶œë ¥ ì¬í˜„

## ğŸ“ˆ ì£¼ìš” ì„±ê³¼

### 1. ê¸°ëŠ¥ì  ê°œì„ 
- âœ… **6DOF ì•¡ì…˜ ì§€ì›**: ê¸°ì¡´ 2DOF â†’ 6DOF + ê·¸ë¦¬í¼
- âœ… **ë‹¤ì–‘í•œ ì…ë ¥ í˜•íƒœ**: í…ìŠ¤íŠ¸, ë¹„ì „, í…ì„œ, í† í°
- âœ… **ì•¡ì…˜ íƒ€ì… ë¶„ë¥˜**: move, turn, grab, navigate ë“±
- âœ… **ê¶¤ì  ì‹œí€€ìŠ¤ ì²˜ë¦¬**: ë‹¤ë‹¨ê³„ ì•¡ì…˜ ê³„íš
- âœ… **ì•ˆì „ì„± ê²€ì¦**: ì†ë„ ì œí•œ, ê²½ê³„ê°’ ê²€ì‚¬

### 2. ì‹¤ìš©ì  ì¥ì 
- âœ… **ROS í˜¸í™˜ì„±**: `to_twist_like()` ë©”ì„œë“œë¡œ ROS ë©”ì‹œì§€ ë³€í™˜
- âœ… **ë‹¤êµ­ì–´ ì§€ì›**: ì˜ì–´/í•œêµ­ì–´ ëª…ë ¹ì–´ ì²˜ë¦¬
- âœ… **ì‹ ë¢°ë„ í‰ê°€**: ì•¡ì…˜ ì‹ ë¢°ë„ ì •ëŸ‰í™”
- âœ… **Fallback ì§€ì›**: ëª¨ë¸ ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ ê¸°ë°˜ ì²˜ë¦¬

### 3. í™•ì¥ì„±
- âœ… **ëª¨ë“ˆí™” ì„¤ê³„**: íŒŒì„œ, ê²€ì¦ê¸°, ë˜í¼ ë¶„ë¦¬
- âœ… **ì„¤ì • ê°€ëŠ¥**: ì•¡ì…˜ ë²”ìœ„, ë¹ˆ ìˆ˜, ì•ˆì „ ê²½ê³„ ì¡°ì •
- âœ… **í”ŒëŸ¬ê·¸ì¸ ê°€ëŠ¥**: ê¸°ì¡´ ì‹œìŠ¤í…œì— ì‰½ê²Œ í†µí•©

## ğŸ”§ ì‚¬ìš© ì˜ˆì‹œ

### ê¸°ë³¸ ì‚¬ìš©ë²•
```python
# íŒŒì„œ ì´ˆê¸°í™”
parser = RoboVLMActionParser(
    action_space=ActionSpace.CONTINUOUS,
    action_dim=7,
    prediction_horizon=1
)

# VLM ì¶œë ¥ íŒŒì‹±
action_tensor = torch.tensor([[[0.3, 0.0, 0.0, 0.0, 0.0, 0.5, 0.8]]])
action = parser.parse_continuous_action(action_tensor, "ì „ì§„í•˜ë©´ì„œ ë¬¼ê±´ì„ ì¡ì•„")

# ROS Twist ë³€í™˜
linear_x, linear_y, angular_z = action.to_twist_like()
print(f"ROS Twist: linear_x={linear_x:.2f}, angular_z={angular_z:.2f}")
```

### ì‹¤ì œ VLA ëª¨ë¸ê³¼ í†µí•©
```python
# VLA ëª¨ë¸ ë˜í¼ ì‚¬ìš©
vla_model = VLAModelWrapper("openvla/openvla-7b")
vla_model.load_model()

# ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ë¡œ ì•¡ì…˜ ì˜ˆì¸¡
result = vla_model.predict_action(image, "Pick up the red cup")
if result["is_safe"]:
    action = result["action"]
    # ë¡œë´‡ì— ì•¡ì…˜ ì „ì†¡
```

## ğŸ’¡ í–¥í›„ ê°œì„  ë°©ì•ˆ

### 1. ë‹¨ê¸° ê°œì„ 
- ë” ì •êµí•œ ì•¡ì…˜ íƒ€ì… ë¶„ë¥˜ (ì„¸ë¶„í™”)
- ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì‹ ë¢°ë„ ê³„ì‚°
- ë” ë§ì€ ì–¸ì–´ ì§€ì›

### 2. ì¤‘ì¥ê¸° ê°œì„   
- ì‹¤ì œ VLA ëª¨ë¸ê³¼ì˜ End-to-End í…ŒìŠ¤íŠ¸
- ê°•í™”í•™ìŠµ ê¸°ë°˜ ì•¡ì…˜ ìµœì í™”
- ë©€í‹°ëª¨ë‹¬ ì„¼ì„œ ë°ì´í„° í†µí•©

### 3. ì‹œìŠ¤í…œ í†µí•©
- ROS2 íŒ¨í‚¤ì§€í™”
- ì‹¤ì‹œê°„ ì„±ëŠ¥ ìµœì í™”
- í•˜ë“œì›¨ì–´ íŠ¹í™” ì¡°ì •

## ğŸ“š ê´€ë ¨ íŒŒì¼

### í•µì‹¬ êµ¬í˜„
- `robovlm_action_parser.py`: ê³ ê¸‰ ì•¡ì…˜ íŒŒì„œ ë©”ì¸ í´ë˜ìŠ¤
- `vla_model_integration.py`: VLA ëª¨ë¸ í†µí•© ì‹œìŠ¤í…œ
- `robovlm_parser_demo.py`: ì¢…í•© ë°ëª¨ ë° í…ŒìŠ¤íŠ¸

### í…ŒìŠ¤íŠ¸ ê²°ê³¼
- `robovlm_demo_results.json`: íŒŒì„œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼
- `vla_test_results.json`: VLA ëª¨ë¸ í†µí•© í…ŒìŠ¤íŠ¸ ê²°ê³¼

### ì°¸ì¡° êµ¬ì¡°
- `RoboVLMs/robovlms/model/`: RoboVLMs ëª¨ë¸ êµ¬ì¡° ì°¸ì¡°
  - `backbone/`: ë°±ë³¸ ëª¨ë¸ë“¤
  - `policy_head/`: ì •ì±… í—¤ë“œ (ActionTokenizer ë“±)
  - `action_encoder/`, `vision_encoder/`: ì¸ì½”ë”ë“¤

## ğŸ¯ ê²°ë¡ 

RoboVLMs êµ¬ì¡° ë¶„ì„ì„ í†µí•´ **ë‹¨ìˆœí•œ í…ìŠ¤íŠ¸ íŒŒì„œë¥¼ ì‹¤ì œ VLM ëª¨ë¸ ì¶œë ¥ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ê³ ê¸‰ ì‹œìŠ¤í…œìœ¼ë¡œ ì„±ê³µì ìœ¼ë¡œ ë°œì „**ì‹œì¼°ìŠµë‹ˆë‹¤. 

**í•µì‹¬ ì„±ê³¼**:
- 6DOF ì•¡ì…˜ ì§€ì›ìœ¼ë¡œ ë³µì¡í•œ ë¡œë´‡ ì œì–´ ê°€ëŠ¥
- ë‹¤ì–‘í•œ VLM ì¶œë ¥ í˜•íƒœ ì²˜ë¦¬
- ì•ˆì „ì„± ê²€ì¦ìœ¼ë¡œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì•¡ì…˜ ìƒì„±
- 100% ì•ˆì „í•œ ì•¡ì…˜ ìƒì„±ë¥  ë‹¬ì„±
- ë†’ì€ ì‹ ë¢°ë„ (í‰ê·  0.916) ìœ ì§€

ì´ ì‹œìŠ¤í…œì€ ì‹¤ì œ ë¡œë´‡ ì œì–´ì— ë°”ë¡œ ì ìš© ê°€ëŠ¥í•˜ë©°, ROS2 í™˜ê²½ê³¼ì˜ í†µí•©ì„ í†µí•´ ì™„ì „í•œ VLA ê¸°ë°˜ ë¡œë´‡ ì‹œìŠ¤í…œ êµ¬ì¶•ì˜ ê¸°ë°˜ì´ ë©ë‹ˆë‹¤. 