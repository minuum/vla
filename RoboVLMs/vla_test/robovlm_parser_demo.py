#!/usr/bin/env python3
"""
RoboVLM ì•¡ì…˜ íŒŒì„œ ê³ ê¸‰ ë°ëª¨
ì‹¤ì œ RoboVLMs ëª¨ë¸ì˜ ì¶œë ¥ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ì—¬ íŒŒì„œ ì„±ëŠ¥ í™•ì¸
"""

import torch
import numpy as np
from typing import Dict, List, Any
import json

from robovlm_action_parser import (
    RoboVLMActionParser, 
    ActionValidator, 
    RoboAction, 
    ActionSpace, 
    RobotControl
)

class RoboVLMSimulator:
    """RoboVLM ëª¨ë¸ ì¶œë ¥ ì‹œë®¬ë ˆì´í„°"""
    
    def __init__(self):
        self.action_parser = RoboVLMActionParser(
            action_space=ActionSpace.CONTINUOUS,
            action_dim=7,
            prediction_horizon=1
        )
        self.validator = ActionValidator()
        
        # ì‹œë®¬ë ˆì´ì…˜ìš© ì•¡ì…˜ í…œí”Œë¦¿
        self.action_templates = {
            "move_forward": [0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
            "move_backward": [-0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
            "turn_left": [0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0],
            "turn_right": [0.0, 0.0, 0.0, 0.0, 0.0, -0.5, 0.0],
            "grab_object": [0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],
            "release_object": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
            "stop": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
            "complex_navigate": [0.2, 0.1, 0.0, 0.0, 0.0, 0.3, 0.0]
        }
    
    def simulate_vlm_output(self, instruction: str) -> torch.Tensor:
        """ëª…ë ¹ì–´ì— ë”°ë¥¸ VLM ì¶œë ¥ ì‹œë®¬ë ˆì´ì…˜"""
        instruction_lower = instruction.lower()
        
        # í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ì ì ˆí•œ ì•¡ì…˜ ì„ íƒ
        if "forward" in instruction_lower or "ì „ì§„" in instruction_lower:
            base_action = self.action_templates["move_forward"]
        elif "backward" in instruction_lower or "í›„ì§„" in instruction_lower:
            base_action = self.action_templates["move_backward"]
        elif "left" in instruction_lower or "ì¢Œ" in instruction_lower:
            base_action = self.action_templates["turn_left"]
        elif "right" in instruction_lower or "ìš°" in instruction_lower:
            base_action = self.action_templates["turn_right"]
        elif "grab" in instruction_lower or "pick" in instruction_lower or "ì¡" in instruction_lower:
            base_action = self.action_templates["grab_object"]
        elif "release" in instruction_lower or "drop" in instruction_lower or "ë†“" in instruction_lower:
            base_action = self.action_templates["release_object"]
        elif "stop" in instruction_lower or "ì •ì§€" in instruction_lower:
            base_action = self.action_templates["stop"]
        else:
            base_action = self.action_templates["complex_navigate"]
        
        # ë…¸ì´ì¦ˆ ì¶”ê°€ë¡œ í˜„ì‹¤ì ì¸ ëª¨ë¸ ì¶œë ¥ ì‹œë®¬ë ˆì´ì…˜
        noise = np.random.normal(0, 0.05, 7)
        noisy_action = np.array(base_action) + noise
        
        # ë°°ì¹˜ ì°¨ì› ì¶”ê°€ (bs=1, seq_len=1, action_dim=7)
        return torch.tensor(noisy_action).unsqueeze(0).unsqueeze(0).float()
    
    def simulate_trajectory_output(self, instruction: str, steps: int = 3) -> torch.Tensor:
        """ê¶¤ì  ì‹œí€€ìŠ¤ ì¶œë ¥ ì‹œë®¬ë ˆì´ì…˜"""
        base_action = self.simulate_vlm_output(instruction).squeeze()
        
        trajectory = []
        for i in range(steps):
            # ì‹œê°„ì— ë”°ë¥¸ ì•¡ì…˜ ë³€í™” ì‹œë®¬ë ˆì´ì…˜
            decay_factor = 0.8 ** i
            step_action = base_action * decay_factor
            
            # ë§ˆì§€ë§‰ ìŠ¤í…ì—ì„œëŠ” ì •ì§€
            if i == steps - 1:
                step_action[:6] = 0  # ì›€ì§ì„ ì •ì§€, ê·¸ë¦¬í¼ ìƒíƒœ ìœ ì§€
            
            trajectory.append(step_action)
        
        return torch.stack(trajectory).unsqueeze(0)  # (1, seq_len, action_dim)

def demo_continuous_parsing():
    """ì—°ì† ì•¡ì…˜ íŒŒì‹± ë°ëª¨"""
    print("ğŸ”„ ì—°ì† ì•¡ì…˜ íŒŒì‹± ë°ëª¨")
    print("=" * 40)
    
    simulator = RoboVLMSimulator()
    
    test_instructions = [
        "Move forward to the table",
        "Turn left slowly",
        "Grab the red cup carefully", 
        "Navigate around the obstacle",
        "í…Œì´ë¸”ë¡œ ì „ì§„í•˜ì„¸ìš”",
        "ì²œì²œíˆ ìš°íšŒì „í•˜ì„¸ìš”",
        "ë¹¨ê°„ ì»µì„ ì¡°ì‹¬ìŠ¤ëŸ½ê²Œ ì¡ìœ¼ì„¸ìš”"
    ]
    
    results = []
    
    for instruction in test_instructions:
        print(f"\nğŸ“ ëª…ë ¹ì–´: '{instruction}'")
        
        # VLM ì¶œë ¥ ì‹œë®¬ë ˆì´ì…˜
        simulated_output = simulator.simulate_vlm_output(instruction)
        print(f"   ì‹œë®¬ë ˆì´ì…˜ ì¶œë ¥ í˜•íƒœ: {simulated_output.shape}")
        
        # ì•¡ì…˜ íŒŒì‹±
        action = simulator.action_parser.parse_continuous_action(
            simulated_output, instruction
        )
        
        # ê²€ì¦
        validated_action = simulator.validator.validate_action(action)
        
        # ê²°ê³¼ ì¶œë ¥
        linear_x, linear_y, angular_z = validated_action.to_twist_like()
        safety_icon = "âœ…" if simulator.validator.is_safe_action(validated_action) else "âŒ"
        
        print(f"   ì•¡ì…˜ íƒ€ì…: {validated_action.action_type}")
        print(f"   ì œì–´ ëª¨ë“œ: {validated_action.control_mode.value}")
        print(f"   Linear: ({linear_x:.3f}, {linear_y:.3f})")
        print(f"   Angular: {angular_z:.3f}")
        print(f"   ê·¸ë¦¬í¼: {validated_action.gripper:.3f}")
        print(f"   ì‹ ë¢°ë„: {validated_action.confidence:.3f}")
        print(f"   ì•ˆì „ì„±: {safety_icon}")
        
        results.append({
            "instruction": instruction,
            "action_type": validated_action.action_type,
            "linear_x": linear_x,
            "linear_y": linear_y,
            "angular_z": angular_z,
            "gripper": validated_action.gripper,
            "confidence": validated_action.confidence,
            "is_safe": simulator.validator.is_safe_action(validated_action)
        })
    
    return results

def demo_trajectory_parsing():
    """ê¶¤ì  ì‹œí€€ìŠ¤ íŒŒì‹± ë°ëª¨"""
    print("\nğŸ”„ ê¶¤ì  ì‹œí€€ìŠ¤ íŒŒì‹± ë°ëª¨") 
    print("=" * 40)
    
    simulator = RoboVLMSimulator()
    
    trajectory_tasks = [
        ("Approach and pick up the object", 4),
        ("Navigate to destination and stop", 3),
        ("Avoid obstacle and continue", 5)
    ]
    
    for task, steps in trajectory_tasks:
        print(f"\nğŸ“ ê¶¤ì  íƒœìŠ¤í¬: '{task}' ({steps}ìŠ¤í…)")
        
        # ê¶¤ì  ì‹œë®¬ë ˆì´ì…˜
        trajectory_output = simulator.simulate_trajectory_output(task, steps)
        print(f"   ê¶¤ì  ì¶œë ¥ í˜•íƒœ: {trajectory_output.shape}")
        
        # ê¶¤ì  íŒŒì‹±
        actions = simulator.action_parser.parse_trajectory_sequence(
            trajectory_output, task
        )
        
        print(f"   íŒŒì‹±ëœ ì•¡ì…˜ ì‹œí€€ìŠ¤:")
        for i, action in enumerate(actions):
            validated = simulator.validator.validate_action(action)
            linear_x, linear_y, angular_z = validated.to_twist_like()
            
            print(f"     Step {i+1}/{steps}: linear_x={linear_x:.3f}, "
                  f"angular_z={angular_z:.3f}, gripper={validated.gripper:.3f}, "
                  f"remaining={validated.prediction_horizon}")

def demo_vlm_output_parsing():
    """VLM ì „ì²´ ì¶œë ¥ íŒŒì‹± ë°ëª¨"""
    print("\nğŸ”„ VLM ì „ì²´ ì¶œë ¥ íŒŒì‹± ë°ëª¨")
    print("=" * 40)
    
    simulator = RoboVLMSimulator()
    
    # RoboVLM ìŠ¤íƒ€ì¼ ì¶œë ¥ ì‹œë®¬ë ˆì´ì…˜
    mock_vlm_outputs = [
        {
            "action_pred": torch.tensor([[[0.2, 0.0, 0.0, 0.0, 0.0, 0.3, 0.0]]]),
            "confidence": 0.85
        },
        {
            "action_pred": torch.tensor([[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]]]),
            "confidence": 0.92
        },
        {
            # ì´ì‚° ì•¡ì…˜ ëŒ€ì‹  ì—°ì† ì•¡ì…˜ìœ¼ë¡œ ë³€ê²½
            "action_pred": torch.tensor([[[0.1, 0.1, 0.0, 0.0, 0.0, 0.2, 0.5]]]),
            "confidence": 0.78
        }
    ]
    
    instructions = [
        "Move forward and turn slightly",
        "Close the gripper to grab",
        "Follow the instruction sequence"
    ]
    
    for i, (vlm_output, instruction) in enumerate(zip(mock_vlm_outputs, instructions)):
        print(f"\nğŸ“ VLM ì¶œë ¥ {i+1}: '{instruction}'")
        print(f"   ì¶œë ¥ í‚¤: {list(vlm_output.keys())}")
        
        # VLM ì¶œë ¥ íŒŒì‹±
        action = simulator.action_parser.parse_vision_language_action(
            vlm_output, instruction
        )
        
        validated = simulator.validator.validate_action(action)
        linear_x, linear_y, angular_z = validated.to_twist_like()
        
        print(f"   ê²°ê³¼: {validated.action_type} - "
              f"({linear_x:.3f}, {linear_y:.3f}, {angular_z:.3f})")

def demo_comparison_with_simple_parser():
    """ê°„ë‹¨í•œ íŒŒì„œì™€ RoboVLM íŒŒì„œ ë¹„êµ"""
    print("\nğŸ”„ íŒŒì„œ ì„±ëŠ¥ ë¹„êµ ë°ëª¨")
    print("=" * 40)
    
    # ê°„ë‹¨í•œ ê¸°ì¡´ íŒŒì„œ (ê¸°ì¡´ í”„ë¡œì íŠ¸ ìŠ¤íƒ€ì¼)
    def simple_parse(text: str) -> Dict[str, float]:
        linear_x = angular_z = 0.0
        
        if "forward" in text.lower() or "ì „ì§„" in text:
            linear_x = 0.3
        elif "backward" in text.lower() or "í›„ì§„" in text:
            linear_x = -0.3
        elif "left" in text.lower() or "ì¢Œ" in text:
            angular_z = 0.5
        elif "right" in text.lower() or "ìš°" in text:
            angular_z = -0.5
        
        return {"linear_x": linear_x, "angular_z": angular_z}
    
    simulator = RoboVLMSimulator()
    
    test_cases = [
        "Move forward to the kitchen table",
        "Turn left and avoid the obstacle", 
        "Grab the cup and bring it here",
        "Navigate carefully around furniture",
        "ë¶€ì—Œ í…Œì´ë¸”ë¡œ ì „ì§„í•˜ì„¸ìš”"
    ]
    
    print("\në¹„êµ ê²°ê³¼:")
    print("ëª…ë ¹ì–´ | ê°„ë‹¨í•œ íŒŒì„œ | RoboVLM íŒŒì„œ")
    print("-" * 60)
    
    for instruction in test_cases:
        # ê°„ë‹¨í•œ íŒŒì„œ
        simple_result = simple_parse(instruction)
        
        # RoboVLM íŒŒì„œ
        simulated_output = simulator.simulate_vlm_output(instruction)
        robovlm_action = simulator.action_parser.parse_continuous_action(
            simulated_output, instruction
        )
        robovlm_result = robovlm_action.to_twist_like()
        
        print(f"{instruction[:25]:<25} | "
              f"({simple_result['linear_x']:.2f}, {simple_result['angular_z']:.2f}) | "
              f"({robovlm_result[0]:.2f}, {robovlm_result[2]:.2f}) [{robovlm_action.action_type}]")

def main():
    """ë©”ì¸ ë°ëª¨ ì‹¤í–‰"""
    print("ğŸ¤– RoboVLM ì•¡ì…˜ íŒŒì„œ ê³ ê¸‰ ë°ëª¨")
    print("=" * 60)
    
    # 1. ì—°ì† ì•¡ì…˜ íŒŒì‹± ë°ëª¨
    continuous_results = demo_continuous_parsing()
    
    # 2. ê¶¤ì  íŒŒì‹± ë°ëª¨
    demo_trajectory_parsing()
    
    # 3. VLM ì¶œë ¥ íŒŒì‹± ë°ëª¨
    demo_vlm_output_parsing()
    
    # 4. ì„±ëŠ¥ ë¹„êµ ë°ëª¨
    demo_comparison_with_simple_parser()
    
    # ê²°ê³¼ í†µê³„
    print("\nğŸ“Š ë°ëª¨ ê²°ê³¼ í†µê³„")
    print("=" * 40)
    
    total_tests = len(continuous_results)
    safe_actions = sum(1 for r in continuous_results if r["is_safe"])
    avg_confidence = sum(r["confidence"] for r in continuous_results) / total_tests
    
    action_types = {}
    for r in continuous_results:
        action_types[r["action_type"]] = action_types.get(r["action_type"], 0) + 1
    
    print(f"ì „ì²´ í…ŒìŠ¤íŠ¸: {total_tests}")
    print(f"ì•ˆì „í•œ ì•¡ì…˜: {safe_actions} ({safe_actions/total_tests*100:.1f}%)")
    print(f"í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.3f}")
    print(f"ì•¡ì…˜ íƒ€ì… ë¶„í¬: {action_types}")
    
    # ê²°ê³¼ ì €ì¥
    demo_results = {
        "continuous_parsing": continuous_results,
        "statistics": {
            "total_tests": total_tests,
            "safe_actions": safe_actions,
            "avg_confidence": avg_confidence,
            "action_type_distribution": action_types
        }
    }
    
    with open("robovlm_demo_results.json", "w", encoding="utf-8") as f:
        json.dump(demo_results, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… ë°ëª¨ ì™„ë£Œ! ê²°ê³¼ê°€ 'robovlm_demo_results.json'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main() 