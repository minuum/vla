# ë…ë¦½í˜• VLA í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ

ROS2 ì—†ì´ VLA (Vision-Language-Action) ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆëŠ” ë…ë¦½ì ì¸ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

## ğŸ“ íŒŒì¼ êµ¬ì¡°

```
ROS_action/
â”œâ”€â”€ standalone_vla_test.py    # ë©”ì¸ VLA ì¶”ë¡  ì‹œìŠ¤í…œ
â”œâ”€â”€ action_parser.py          # ì•¡ì…˜ íŒŒì‹± ëª¨ë“ˆ
â”œâ”€â”€ test_runner.py            # í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰ê¸°
â”œâ”€â”€ requirements.txt          # Python ì˜ì¡´ì„±
â””â”€â”€ README_STANDALONE.md      # ì´ íŒŒì¼
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. ì˜ì¡´ì„± ì„¤ì¹˜

```bash
# ê°€ìƒí™˜ê²½ ìƒì„± (ê¶Œì¥)
python -m venv vla_env
source vla_env/bin/activate  # macOS/Linux
# vla_env\Scripts\activate   # Windows

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt
```

### 2. ì•¡ì…˜ íŒŒì„œë§Œ í…ŒìŠ¤íŠ¸ (ëª¨ë¸ ì—†ì´)

```bash
# ì•¡ì…˜ íŒŒì„œ ë‹¨ë… í…ŒìŠ¤íŠ¸
python action_parser.py

# ë˜ëŠ” í†µí•© ëŸ¬ë„ˆë¡œ íŒŒì„œë§Œ í…ŒìŠ¤íŠ¸
python test_runner.py --no-vla --mode batch
```

### 3. VLA ëª¨ë¸ í¬í•¨ ì „ì²´ í…ŒìŠ¤íŠ¸

```bash
# ëŒ€í™”í˜• ëª¨ë“œ (ê¸°ë³¸)
python test_runner.py

# ë°°ì¹˜ í…ŒìŠ¤íŠ¸ ëª¨ë“œ
python test_runner.py --mode batch

# ë‹¨ì¼ ëª…ë ¹ì–´ í…ŒìŠ¤íŠ¸
python test_runner.py --mode single --command "move forward"
```

## ğŸ”§ ì‚¬ìš©ë²• ìƒì„¸

### standalone_vla_test.py

í•µì‹¬ VLA ì¶”ë¡  ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

```python
from standalone_vla_test import StandaloneVLAInference, CameraHandler

# VLA ì‹œìŠ¤í…œ ì´ˆê¸°í™”
vla = StandaloneVLAInference(
    model_id="google/paligemma-3b-mix-224",
    device_preference="cuda"  # ë˜ëŠ” "cpu"
)

# ì¹´ë©”ë¼ í•¸ë“¤ëŸ¬
camera = CameraHandler()

# í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë¡œë“œ
image = camera.load_test_image("test.jpg")

# ì¶”ë¡  ì‹¤í–‰
linear_x, linear_y, angular_z = vla.simple_command_inference(image, "move forward")
print(f"ì œì–´ ëª…ë ¹: linear_x={linear_x}, angular_z={angular_z}")
```

### action_parser.py

VLA ê²°ê³¼ë¥¼ ë¡œë´‡ ì•¡ì…˜ìœ¼ë¡œ íŒŒì‹±í•©ë‹ˆë‹¤.

```python
from action_parser import VLAActionParser, ActionValidator

parser = VLAActionParser()
validator = ActionValidator()

# í…ìŠ¤íŠ¸ ì¶œë ¥ íŒŒì‹±
action = parser.parse_text_output("move forward slowly")

# ì„¸ê·¸ë©˜í…Œì´ì…˜ ì¶œë ¥ íŒŒì‹±  
action = parser.parse_segmentation_output("<loc0500><loc0300><loc0700><loc0600>cup", 640, 480)

# ì•¡ì…˜ ìœ íš¨ì„± ê²€ì‚¬
action = validator.validate_action(action)

print(f"ì•¡ì…˜: {action.action_type.value}")
print(f"ì†ë„: linear_x={action.linear_x}, angular_z={action.angular_z}")
```

### test_runner.py

í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰ê¸°ì…ë‹ˆë‹¤.

```bash
# ê¸°ë³¸ ëŒ€í™”í˜• ëª¨ë“œ
python test_runner.py

# CPU ì‚¬ìš©
python test_runner.py --device cpu

# íŠ¹ì • ì´ë¯¸ì§€ë¡œ í…ŒìŠ¤íŠ¸
python test_runner.py --image path/to/image.jpg

# ì¹´ë©”ë¼ ì‚¬ìš©
python test_runner.py --camera

# VLA ëª¨ë¸ ì—†ì´ íŒŒì„œë§Œ í…ŒìŠ¤íŠ¸
python test_runner.py --no-vla

# ë‹¨ì¼ ëª…ë ¹ì–´ í…ŒìŠ¤íŠ¸
python test_runner.py --mode single --command "turn left"

# ë°°ì¹˜ í…ŒìŠ¤íŠ¸
python test_runner.py --mode batch
```

## ğŸ® ëŒ€í™”í˜• ëª¨ë“œ ëª…ë ¹ì–´

ëŒ€í™”í˜• ëª¨ë“œì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ íŠ¹ìˆ˜ ëª…ë ¹ì–´ë“¤:

- `quit` ë˜ëŠ” `exit`: í…ŒìŠ¤íŠ¸ ì¢…ë£Œ
- `capture`: ì¹´ë©”ë¼ì—ì„œ ìƒˆ í”„ë ˆì„ ìº¡ì²˜ (ì¹´ë©”ë¼ ëª¨ë“œ)
- `load <íŒŒì¼ê²½ë¡œ>`: ìƒˆ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë¡œë“œ
- `toggle_vla`: VLA ëª¨ë¸ ì‚¬ìš© ON/OFF í† ê¸€

## ğŸ“Š ì§€ì›í•˜ëŠ” ì•¡ì…˜ íƒ€ì…

- **MOVE**: ì´ë™ (ì „ì§„, í›„ì§„)
- **TURN**: íšŒì „ (ì¢ŒíšŒì „, ìš°íšŒì „) 
- **STOP**: ì •ì§€
- **GRAB**: ê°ì²´ ì¡ê¸°
- **RELEASE**: ê°ì²´ ë†“ê¸°
- **POINT**: ê°€ë¦¬í‚¤ê¸°
- **LOOK**: ê´€ì°°í•˜ê¸°
- **NAVIGATE**: ë‚´ë¹„ê²Œì´ì…˜
- **AVOID**: íšŒí”¼
- **UNKNOWN**: ë¯¸ì§€ì˜ ì•¡ì…˜

## ğŸ§ª í…ŒìŠ¤íŠ¸ ëª…ë ¹ì–´ ì˜ˆì‹œ

### ê¸°ë³¸ ì´ë™ ëª…ë ¹ì–´

```
move forward
move backward  
turn left
turn right
stop
```

### í•œêµ­ì–´ ëª…ë ¹ì–´

```
ì „ì§„í•˜ì„¸ìš”
ìš°íšŒì „ í•˜ì„¸ìš”
ì •ì§€
```

### ë³µí•© ëª…ë ¹ì–´

```
move forward slowly
turn left quickly
navigate to door
avoid obstacle
grab the cup
```

### ì„¸ê·¸ë©˜í…Œì´ì…˜ í† í° ëª…ë ¹ì–´

```
<loc0500><loc0300><loc0700><loc0600>cup segment
```

## ğŸ”§ ì„¤ì • ì˜µì…˜

### ëª¨ë¸ ì„¤ì •

ë‹¤ë¥¸ VLA ëª¨ë¸ ì‚¬ìš©:

```bash
python test_runner.py --model "google/paligemma-3b-pt-224"
```

### ë””ë°”ì´ìŠ¤ ì„¤ì •

```bash
# CUDA ì‚¬ìš© (ê¸°ë³¸)
python test_runner.py --device cuda

# CPU ì‚¬ìš©  
python test_runner.py --device cpu
```

### ì•ˆì „ì„± ì„¤ì •

`ActionValidator`ì—ì„œ ì†ë„ ì œí•œ ì„¤ì •:

```python
validator = ActionValidator(
    max_linear_speed=0.5,    # ìµœëŒ€ ì§ì„  ì†ë„
    max_angular_speed=1.0    # ìµœëŒ€ íšŒì „ ì†ë„
)
```

## ğŸ› ë¬¸ì œ í•´ê²°

### CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±

```bash
# CPU ì‚¬ìš©ìœ¼ë¡œ ì „í™˜
python test_runner.py --device cpu
```

### ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨

```bash
# ìºì‹œ ë””ë ‰í† ë¦¬ í™•ì¸/ìƒì„±
mkdir -p .vla_models_cache
```

### ì¹´ë©”ë¼ ì ‘ê·¼ ì˜¤ë¥˜

```bash
# ì¹´ë©”ë¼ ê¶Œí•œ í™•ì¸ ë˜ëŠ” ë‹¤ë¥¸ ì¹´ë©”ë¼ ID ì‹œë„
python test_runner.py --camera --camera-id 1
```

### ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨

```bash
# ì§€ì› í˜•ì‹: jpg, png, bmp
# OpenCVë¡œ ì½ì„ ìˆ˜ ìˆëŠ” í˜•ì‹ì´ì–´ì•¼ í•¨
```

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™”

### ëª¨ë¸ ì–‘ìí™” (ì„ íƒì‚¬í•­)

```bash
# requirements.txtì—ì„œ ì£¼ì„ í•´ì œ
pip install bitsandbytes>=0.41.0
```

### Flash Attention (ì„ íƒì‚¬í•­)

```bash
# requirements.txtì—ì„œ ì£¼ì„ í•´ì œ  
pip install flash-attn>=2.0.0
```

## ğŸ” ë””ë²„ê¹…

### ë¡œê·¸ ë ˆë²¨ ì¡°ì •

ì½”ë“œì—ì„œ ë””ë²„ê·¸ ì¶œë ¥ ì¶”ê°€:

```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

### ëª¨ë¸ ìƒíƒœ í™•ì¸

```python
# standalone_vla_test.pyì—ì„œ
print(f"Model loaded: {vla.model is not None}")
print(f"Device: {vla.device}")
```

## ğŸ¤ í™•ì¥

### ìƒˆë¡œìš´ ì•¡ì…˜ íƒ€ì… ì¶”ê°€

`action_parser.py`ì˜ `ActionType` enumì— ì¶”ê°€:

```python
class ActionType(Enum):
    # ê¸°ì¡´ íƒ€ì…ë“¤...
    CUSTOM_ACTION = "custom_action"
```

### ìƒˆë¡œìš´ ëª…ë ¹ì–´ íŒ¨í„´ ì¶”ê°€

`VLAActionParser`ì˜ í‚¤ì›Œë“œ ì‚¬ì „ì— ì¶”ê°€:

```python
self.action_keywords = {
    ActionType.CUSTOM_ACTION: ["custom", "special", "ë§ì¶¤"]
}
```

## ğŸ“ ë¼ì´ì„¼ìŠ¤

ì´ ì½”ë“œëŠ” ì›ë³¸ VLA ì‹œìŠ¤í…œê³¼ ë™ì¼í•œ ë¼ì´ì„¼ìŠ¤ë¥¼ ë”°ë¦…ë‹ˆë‹¤. 