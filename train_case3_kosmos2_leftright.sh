#!/bin/bash
# Case 3: Kosmos-2 Frozen+LoRA, Left+Right ê· í˜• ë°ì´í„°
# 2025-12-04

echo "========================================="
echo "ðŸš€ Case 3 í•™ìŠµ ì‹œìž‘"
echo "========================================="
echo ""
echo "ì‹¤í—˜: Kosmos-2 Frozen+LoRA + Left+Right"
echo "ë°ì´í„°: 500 episodes (250 left + 250 right)"
echo ""

CONFIG="../Mobile_VLA/configs/mobile_vla_kosmos2_frozen_lora_leftright_20251204.json"

# CUDA í™•ì¸
echo "ðŸ” GPU í™•ì¸..."
if python3 -c "import torch; print(torch.cuda.is_available())" | grep -q "True"; then
    GPU_NAME=$(python3 -c "import torch; print(torch.cuda.get_device_name() if torch.cuda.is_available() else 'N/A')")
    echo "  âœ… GPU: $GPU_NAME"
else
    echo "  âŒ CUDA ì‚¬ìš© ë¶ˆê°€"
    exit 1
fi

# íƒ€ìž„ìŠ¤íƒ¬í”„
TIMESTAMP=$(date '+%Y%m%d_%H%M%S')
LOG_FILE="../case3_kosmos2_leftright_${TIMESTAMP}.txt"

echo ""
echo "ðŸ“ Config: mobile_vla_kosmos2_frozen_lora_leftright_20251204.json"
echo "ðŸ“„ Log: $LOG_FILE"
echo ""
echo "========================================="
echo "í•™ìŠµ ì‹œìž‘..."
echo "========================================="
echo ""

# í•™ìŠµ ì‹¤í–‰
cd /home/billy/25-1kp/vla/RoboVLMs_upstream
python3 main.py $CONFIG 2>&1 | tee $LOG_FILE

echo ""
echo "========================================="
echo "âœ… Case 3 í•™ìŠµ ì™„ë£Œ"
echo "ðŸ“„ ë¡œê·¸: $LOG_FILE"
echo "========================================="
