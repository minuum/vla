#!/usr/bin/env python3
"""
Step 3: í•™ìŠµ íŒŒì´í”„ë¼ì¸ êµ¬í˜„
ë°ì´í„° ë¡œë”, Loss í•¨ìˆ˜, Optimizer ì„¤ì •, í•™ìŠµ ë£¨í”„
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import h5py
import json
import numpy as np
from pathlib import Path
import logging
from typing import Dict, List, Tuple, Optional
from tqdm import tqdm
import matplotlib.pyplot as plt

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MobileVLADataset(Dataset):
    """Mobile VLA ë°ì´í„°ì…‹"""
    
    def __init__(
        self,
        data_dir: str,
        split: str = "train",
        max_episodes: Optional[int] = None
    ):
        self.data_dir = Path(data_dir)
        self.split = split
        self.max_episodes = max_episodes
        
        # ì—í”¼ì†Œë“œ ëª©ë¡ ë¡œë“œ
        self.episodes = self._load_episodes()
        
        logger.info(f"ğŸ“ {split} ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ: {len(self.episodes)}ê°œ ì—í”¼ì†Œë“œ")
    
    def _load_episodes(self) -> List[Dict]:
        """ì—í”¼ì†Œë“œ ëª©ë¡ ë¡œë“œ"""
        episodes = []
        
        # ì—í”¼ì†Œë“œ íŒŒì¼ë“¤ ì°¾ê¸°
        episode_files = list(self.data_dir.glob("episode_*.json"))
        
        if self.max_episodes:
            episode_files = episode_files[:self.max_episodes]
        
        for episode_file in episode_files:
            try:
                with open(episode_file, 'r') as f:
                    episode_data = json.load(f)
                    episodes.append(episode_data)
            except Exception as e:
                logger.warning(f"ì—í”¼ì†Œë“œ ë¡œë“œ ì‹¤íŒ¨: {episode_file}, {e}")
        
        return episodes
    
    def __len__(self) -> int:
        return len(self.episodes)
    
    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
        """ë°ì´í„° ì•„ì´í…œ ë°˜í™˜"""
        episode = self.episodes[idx]
        
        # ì´ë¯¸ì§€ ë¡œë“œ (ì‹œë®¬ë ˆì´ì…˜)
        # ì‹¤ì œë¡œëŠ” HDF5 íŒŒì¼ì—ì„œ ë¡œë“œ
        images = torch.randn(3, 224, 224)  # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°
        
        # ì•¡ì…˜ ë¡œë“œ (ì‹œë®¬ë ˆì´ì…˜)
        # ì‹¤ì œë¡œëŠ” HDF5 íŒŒì¼ì—ì„œ ë¡œë“œ
        actions = torch.randn(3)  # X, Y, Gripper
        
        # ì–¸ì–´ ëª…ë ¹
        language = episode.get("language", "go to the object")
        
        return {
            "images": images,
            "actions": actions,
            "language": language,
            "episode_id": episode.get("episode_id", idx)
        }

class MobileVLATrainer:
    """Mobile VLA í•™ìŠµê¸°"""
    
    def __init__(
        self,
        model: nn.Module,
        loss_fn: nn.Module,
        train_loader: DataLoader,
        val_loader: DataLoader,
        device: str = "cuda" if torch.cuda.is_available() else "cpu"
    ):
        self.model = model.to(device)
        self.loss_fn = loss_fn
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.device = device
        
        # Optimizer ì„¤ì •
        self.optimizer = optim.AdamW(
            self.model.parameters(),
            lr=1e-4,
            weight_decay=0.01
        )
        
        # Learning Rate Scheduler
        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(
            self.optimizer,
            T_max=100,
            eta_min=1e-6
        )
        
        # í•™ìŠµ ê¸°ë¡
        self.train_losses = []
        self.val_losses = []
        self.learning_rates = []
        
        logger.info(f"ğŸš€ Mobile VLA í•™ìŠµê¸° ì´ˆê¸°í™” ì™„ë£Œ (Device: {self.device})")
    
    def train_epoch(self, epoch: int) -> Dict[str, float]:
        """í•œ ì—í¬í¬ í•™ìŠµ"""
        self.model.train()
        total_loss = 0.0
        movement_loss = 0.0
        gripper_loss = 0.0
        num_batches = 0
        
        progress_bar = tqdm(
            self.train_loader,
            desc=f"Epoch {epoch+1} [Train]",
            leave=False
        )
        
        for batch_idx, batch in enumerate(progress_bar):
            # ë°ì´í„°ë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            images = batch["images"].to(self.device)
            actions = batch["actions"].to(self.device)
            language = batch["language"]
            
            # íƒ€ê²Ÿ ë°ì´í„° ì¤€ë¹„
            targets = {
                "movement_targets": actions[:, :2],  # X, Y
                "gripper_targets": actions[:, 2]     # Gripper
            }
            
            # Forward pass
            self.optimizer.zero_grad()
            
            # ë°°ì¹˜ë³„ë¡œ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
            batch_outputs = []
            for i in range(images.shape[0]):
                single_image = images[i:i+1]
                single_text = language[i]
                
                outputs = self.model(single_image, single_text)
                batch_outputs.append(outputs)
            
            # ë°°ì¹˜ ì¶œë ¥ ê²°í•©
            combined_outputs = {
                "action_logits": torch.cat([out["action_logits"] for out in batch_outputs]),
                "gripper_logits": torch.cat([out["gripper_logits"] for out in batch_outputs])
            }
            
            # Loss ê³„ì‚°
            losses = self.loss_fn(combined_outputs, targets)
            
            # Backward pass
            losses["total_loss"].backward()
            
            # Gradient clipping
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            
            # Optimizer step
            self.optimizer.step()
            
            # Loss ê¸°ë¡
            total_loss += losses["total_loss"].item()
            movement_loss += losses["movement_loss"].item()
            gripper_loss += losses["gripper_loss"].item()
            num_batches += 1
            
            # Progress bar ì—…ë°ì´íŠ¸
            progress_bar.set_postfix({
                "Loss": f"{losses['total_loss'].item():.4f}",
                "Movement": f"{losses['movement_loss'].item():.4f}",
                "Gripper": f"{losses['gripper_loss'].item():.4f}"
            })
        
        # í‰ê·  Loss ê³„ì‚°
        avg_total_loss = total_loss / num_batches
        avg_movement_loss = movement_loss / num_batches
        avg_gripper_loss = gripper_loss / num_batches
        
        return {
            "total_loss": avg_total_loss,
            "movement_loss": avg_movement_loss,
            "gripper_loss": avg_gripper_loss
        }
    
    def validate_epoch(self, epoch: int) -> Dict[str, float]:
        """í•œ ì—í¬í¬ ê²€ì¦"""
        self.model.eval()
        total_loss = 0.0
        movement_loss = 0.0
        gripper_loss = 0.0
        num_batches = 0
        
        with torch.no_grad():
            progress_bar = tqdm(
                self.val_loader,
                desc=f"Epoch {epoch+1} [Val]",
                leave=False
            )
            
            for batch_idx, batch in enumerate(progress_bar):
                # ë°ì´í„°ë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
                images = batch["images"].to(self.device)
                actions = batch["actions"].to(self.device)
                language = batch["language"]
                
                # íƒ€ê²Ÿ ë°ì´í„° ì¤€ë¹„
                targets = {
                    "movement_targets": actions[:, :2],  # X, Y
                    "gripper_targets": actions[:, 2]     # Gripper
                }
                
                # Forward pass
                batch_outputs = []
                for i in range(images.shape[0]):
                    single_image = images[i:i+1]
                    single_text = language[i]
                    
                    outputs = self.model(single_image, single_text)
                    batch_outputs.append(outputs)
                
                # ë°°ì¹˜ ì¶œë ¥ ê²°í•©
                combined_outputs = {
                    "action_logits": torch.cat([out["action_logits"] for out in batch_outputs]),
                    "gripper_logits": torch.cat([out["gripper_logits"] for out in batch_outputs])
                }
                
                # Loss ê³„ì‚°
                losses = self.loss_fn(combined_outputs, targets)
                
                # Loss ê¸°ë¡
                total_loss += losses["total_loss"].item()
                movement_loss += losses["movement_loss"].item()
                gripper_loss += losses["gripper_loss"].item()
                num_batches += 1
                
                # Progress bar ì—…ë°ì´íŠ¸
                progress_bar.set_postfix({
                    "Loss": f"{losses['total_loss'].item():.4f}"
                })
        
        # í‰ê·  Loss ê³„ì‚°
        avg_total_loss = total_loss / num_batches
        avg_movement_loss = movement_loss / num_batches
        avg_gripper_loss = gripper_loss / num_batches
        
        return {
            "total_loss": avg_total_loss,
            "movement_loss": avg_movement_loss,
            "gripper_loss": avg_gripper_loss
        }
    
    def train(self, num_epochs: int = 10, save_dir: str = "checkpoints"):
        """ì „ì²´ í•™ìŠµ ì‹¤í–‰"""
        save_dir = Path(save_dir)
        save_dir.mkdir(exist_ok=True)
        
        logger.info(f"ğŸš€ Mobile VLA í•™ìŠµ ì‹œì‘ ({num_epochs} ì—í¬í¬)")
        
        best_val_loss = float('inf')
        
        for epoch in range(num_epochs):
            # í•™ìŠµ
            train_metrics = self.train_epoch(epoch)
            
            # ê²€ì¦
            val_metrics = self.validate_epoch(epoch)
            
            # Learning rate ì—…ë°ì´íŠ¸
            self.scheduler.step()
            current_lr = self.optimizer.param_groups[0]['lr']
            
            # ê¸°ë¡ ì €ì¥
            self.train_losses.append(train_metrics["total_loss"])
            self.val_losses.append(val_metrics["total_loss"])
            self.learning_rates.append(current_lr)
            
            # ë¡œê·¸ ì¶œë ¥
            logger.info(f"Epoch {epoch+1}/{num_epochs}")
            logger.info(f"  Train Loss: {train_metrics['total_loss']:.4f}")
            logger.info(f"  Val Loss: {val_metrics['total_loss']:.4f}")
            logger.info(f"  Learning Rate: {current_lr:.6f}")
            
            # ìµœê³  ëª¨ë¸ ì €ì¥
            if val_metrics["total_loss"] < best_val_loss:
                best_val_loss = val_metrics["total_loss"]
                self.save_checkpoint(epoch, val_metrics, save_dir / "best_model.pth")
                logger.info(f"  âœ… ìµœê³  ëª¨ë¸ ì €ì¥ (Val Loss: {best_val_loss:.4f})")
            
            # ì£¼ê¸°ì  ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            if (epoch + 1) % 5 == 0:
                self.save_checkpoint(epoch, val_metrics, save_dir / f"checkpoint_epoch_{epoch+1}.pth")
        
        logger.info("ğŸ‰ í•™ìŠµ ì™„ë£Œ!")
        self.plot_training_curves(save_dir)
    
    def save_checkpoint(self, epoch: int, metrics: Dict, filepath: Path):
        """ì²´í¬í¬ì¸íŠ¸ ì €ì¥"""
        checkpoint = {
            "epoch": epoch,
            "model_state_dict": self.model.state_dict(),
            "optimizer_state_dict": self.optimizer.state_dict(),
            "scheduler_state_dict": self.scheduler.state_dict(),
            "metrics": metrics,
            "train_losses": self.train_losses,
            "val_losses": self.val_losses,
            "learning_rates": self.learning_rates
        }
        
        torch.save(checkpoint, filepath)
        logger.info(f"ì²´í¬í¬ì¸íŠ¸ ì €ì¥: {filepath}")
    
    def plot_training_curves(self, save_dir: Path):
        """í•™ìŠµ ê³¡ì„  í”Œë¡¯"""
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        
        # Loss ê³¡ì„ 
        axes[0].plot(self.train_losses, label='Train Loss', color='blue')
        axes[0].plot(self.val_losses, label='Val Loss', color='red')
        axes[0].set_title('Training and Validation Loss')
        axes[0].set_xlabel('Epoch')
        axes[0].set_ylabel('Loss')
        axes[0].legend()
        axes[0].grid(True)
        
        # Learning Rate ê³¡ì„ 
        axes[1].plot(self.learning_rates, color='green')
        axes[1].set_title('Learning Rate Schedule')
        axes[1].set_xlabel('Epoch')
        axes[1].set_ylabel('Learning Rate')
        axes[1].grid(True)
        
        # Loss ë¹„êµ (ë¡œê·¸ ìŠ¤ì¼€ì¼)
        axes[2].semilogy(self.train_losses, label='Train Loss', color='blue')
        axes[2].semilogy(self.val_losses, label='Val Loss', color='red')
        axes[2].set_title('Training and Validation Loss (Log Scale)')
        axes[2].set_xlabel('Epoch')
        axes[2].set_ylabel('Loss (Log Scale)')
        axes[2].legend()
        axes[2].grid(True)
        
        plt.tight_layout()
        plt.savefig(save_dir / "training_curves.png", dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"í•™ìŠµ ê³¡ì„  ì €ì¥: {save_dir / 'training_curves.png'}")

def create_data_loaders(
    data_dir: str,
    batch_size: int = 4,
    num_workers: int = 2,
    train_ratio: float = 0.8
) -> Tuple[DataLoader, DataLoader]:
    """ë°ì´í„° ë¡œë” ìƒì„±"""
    
    # ì „ì²´ ë°ì´í„°ì…‹ ë¡œë“œ
    full_dataset = MobileVLADataset(data_dir, split="all")
    
    # Train/Val ë¶„í• 
    train_size = int(len(full_dataset) * train_ratio)
    val_size = len(full_dataset) - train_size
    
    train_dataset, val_dataset = torch.utils.data.random_split(
        full_dataset, [train_size, val_size]
    )
    
    # DataLoader ìƒì„±
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=True
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True
    )
    
    logger.info(f"ğŸ“Š ë°ì´í„° ë¡œë” ìƒì„± ì™„ë£Œ")
    logger.info(f"  - Train: {len(train_dataset)} ìƒ˜í”Œ")
    logger.info(f"  - Val: {len(val_dataset)} ìƒ˜í”Œ")
    logger.info(f"  - Batch Size: {batch_size}")
    
    return train_loader, val_loader

def test_training_pipeline():
    """í•™ìŠµ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ§ª Mobile VLA í•™ìŠµ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    try:
        # ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)
        data_dir = Path("test_data")
        data_dir.mkdir(exist_ok=True)
        
        # í…ŒìŠ¤íŠ¸ ì—í”¼ì†Œë“œ ìƒì„±
        for i in range(10):
            episode_data = {
                "episode_id": i + 1,
                "language": f"test_task_{i+1}",
                "timestamp": i
            }
            
            with open(data_dir / f"episode_{i+1}.json", 'w') as f:
                json.dump(episode_data, f)
        
        # ë°ì´í„° ë¡œë” ìƒì„±
        train_loader, val_loader = create_data_loaders(str(data_dir), batch_size=2)
        
        # ëª¨ë¸ ìƒì„± (ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ìš©)
        from step2_mobile_vla_model import create_mobile_vla_model
        model, loss_fn = create_mobile_vla_model()
        
        # í•™ìŠµê¸° ìƒì„±
        trainer = MobileVLATrainer(model, loss_fn, train_loader, val_loader)
        
        # ì§§ì€ í•™ìŠµ ì‹¤í–‰
        trainer.train(num_epochs=2, save_dir="test_checkpoints")
        
        logger.info("âœ… í•™ìŠµ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        return True
        
    except Exception as e:
        logger.error(f"âŒ í•™ìŠµ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    logger.info("ğŸš€ Mobile VLA í•™ìŠµ íŒŒì´í”„ë¼ì¸ êµ¬í˜„ ì‹œì‘")
    
    # í•™ìŠµ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    success = test_training_pipeline()
    
    if success:
        logger.info("âœ… Mobile VLA í•™ìŠµ íŒŒì´í”„ë¼ì¸ êµ¬í˜„ ì™„ë£Œ")
        logger.info("ğŸ¯ ë‹¤ìŒ ë‹¨ê³„: ì¶”ë¡  ì‹œìŠ¤í…œ êµ¬í˜„")
    else:
        logger.error("âŒ Mobile VLA í•™ìŠµ íŒŒì´í”„ë¼ì¸ êµ¬í˜„ ì‹¤íŒ¨")
        logger.error("ğŸ”§ ë¬¸ì œë¥¼ í•´ê²°í•œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”")

if __name__ == "__main__":
    main()
