#!/usr/bin/env python3
"""
κ°„λ‹¨ν• Mobile VLA λ¨λΈ λ΅λ” ν…μ¤νΈ
"""

import torch
import torch.nn as nn
import os

class SimpleMobileVLAModel(nn.Module):
    """κ°„λ‹¨ν• Mobile VLA λ¨λΈ κµ¬μ΅°"""
    
    def __init__(self):
        super().__init__()
        
        # Vision Encoder
        self.vision_encoder = nn.Linear(2048, 4096)
        
        # Text Encoder  
        self.text_encoder = nn.Linear(2048, 4096)
        
        # LSTM
        self.lstm = nn.LSTM(8192, 4096, batch_first=True)
        
        # Action Head
        self.action_head = nn.Linear(4096, 2)
    
    def forward(self, vision_features, text_features):
        vision_encoded = self.vision_encoder(vision_features)
        text_encoded = self.text_encoder(text_features)
        combined = torch.cat([vision_encoded, text_encoded], dim=-1)
        lstm_out, _ = self.lstm(combined.unsqueeze(1))
        actions = self.action_head(lstm_out.squeeze(1))
        return actions

def test_cuda():
    """CUDA ν…μ¤νΈ"""
    print("π”§ CUDA ν…μ¤νΈ μ¤‘...")
    print(f"PyTorch λ²„μ „: {torch.__version__}")
    print(f"CUDA μ‚¬μ© κ°€λ¥: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"CUDA λ””λ°”μ΄μ¤: {torch.cuda.get_device_name(0)}")
        print(f"CUDA λ²„μ „: {torch.version.cuda}")
        
        # κ°„λ‹¨ν• CUDA μ—°μ‚° ν…μ¤νΈ
        x = torch.randn(100, 100).cuda()
        y = torch.randn(100, 100).cuda()
        z = torch.mm(x, y)
        print(f"CUDA μ—°μ‚° μ„±κ³µ: {z.shape}")
    else:
        print("β CUDAλ¥Ό μ‚¬μ©ν•  μ μ—†μµλ‹λ‹¤.")

def test_model():
    """λ¨λΈ ν…μ¤νΈ"""
    print("\nπ¤– λ¨λΈ ν…μ¤νΈ μ¤‘...")
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"μ‚¬μ© λ””λ°”μ΄μ¤: {device}")
    
    # λ¨λΈ μƒμ„±
    model = SimpleMobileVLAModel().to(device)
    model.eval()
    
    # ν…μ¤νΈ μ…λ ¥
    batch_size = 2
    vision_features = torch.randn(batch_size, 2048).to(device)
    text_features = torch.randn(batch_size, 2048).to(device)
    
    # μ¶”λ΅ 
    with torch.no_grad():
        actions = model(vision_features, text_features)
        print(f"μ¶”λ΅  μ„±κ³µ: {actions.shape}")
        print(f"μ¶λ ¥ κ°’: {actions}")

def test_checkpoint():
    """μ²΄ν¬ν¬μΈνΈ ν…μ¤νΈ"""
    print("\nπ“¦ μ²΄ν¬ν¬μΈνΈ ν…μ¤νΈ μ¤‘...")
    
    # μ²΄ν¬ν¬μΈνΈ νμΌ μ°ΎκΈ°
    checkpoint_paths = [
        "./Robo+/Mobile_VLA/results/simple_clip_lstm_results_extended/best_simple_clip_lstm_model.pth",
        "./mobile-vla-omniwheel/best_simple_lstm_model.pth"
    ]
    
    for path in checkpoint_paths:
        if os.path.exists(path):
            print(f"β… μ²΄ν¬ν¬μΈνΈ λ°κ²¬: {path}")
            size_mb = os.path.getsize(path) / (1024 * 1024)
            print(f"   ν¬κΈ°: {size_mb:.1f} MB")
            
            try:
                # μ²΄ν¬ν¬μΈνΈ λ΅λ“ μ‹λ„
                checkpoint = torch.load(path, map_location='cpu')
                print(f"   λ΅λ“ μ„±κ³µ: {type(checkpoint)}")
                
                if isinstance(checkpoint, dict):
                    print(f"   ν‚¤λ“¤: {list(checkpoint.keys())}")
                
            except Exception as e:
                print(f"   λ΅λ“ μ‹¤ν¨: {e}")
        else:
            print(f"β μ²΄ν¬ν¬μΈνΈ μ—†μ: {path}")

def main():
    """λ©”μΈ ν•¨μ"""
    print("π§ Mobile VLA λ¨λΈ λ΅λ” ν…μ¤νΈ")
    print("=" * 50)
    
    test_cuda()
    test_model()
    test_checkpoint()
    
    print("\nβ… ν…μ¤νΈ μ™„λ£!")

if __name__ == "__main__":
    main()
