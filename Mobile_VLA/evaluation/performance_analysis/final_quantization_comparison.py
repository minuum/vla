#!/usr/bin/env python3
"""
ìµœì¢… ì–‘ìí™” ì„±ëŠ¥ ë¹„êµ
CLIP ëª¨ë¸ ì‹¤ì œ ì¸¡ì • + Kosmos2 ì´ë¡ ì  ë¹„êµ
"""

import torch
import torch.nn as nn
import time
import json
import logging
from transformers import CLIPProcessor, CLIPModel
import os
import gc
import numpy as np

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class FinalQuantizationComparison:
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.num_runs = 50
        
        logger.info(f"ğŸ”§ ë””ë°”ì´ìŠ¤: {self.device}")
        
    def _create_clip_model(self):
        """MAE 0.212 ëª¨ë¸ êµ¬ì¡° (CLIP ê¸°ë°˜)"""
        class CLIPBasedModel(nn.Module):
            def __init__(self):
                super().__init__()
                self.processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
                self.clip = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
                self.clip.eval()
                for param in self.clip.parameters():
                    param.requires_grad = False
                
                # CLIP ê¸°ë°˜ Action Head êµ¬ì¡°
                self.rnn = nn.RNN(
                    input_size=512,  # CLIP ì¶œë ¥ í¬ê¸°
                    hidden_size=4096,
                    num_layers=4,
                    batch_first=True,
                    dropout=0.1
                )
                self.actions = nn.Sequential(
                    nn.Linear(4096, 1024),
                    nn.ReLU(),
                    nn.Linear(1024, 512),
                    nn.ReLU(),
                    nn.Linear(512, 256),
                    nn.ReLU(),
                    nn.Linear(256, 2)
                )
            
            def forward(self, x):
                batch_size = x.size(0)
                with torch.no_grad():
                    # CLIP ì´ë¯¸ì§€ ì¸ì½”ë”©
                    image_features = self.clip.get_image_features(pixel_values=x)  # [batch, 512]
                    
                sequence_features = image_features.unsqueeze(1)  # [batch, 1, 512]
                rnn_out, _ = self.rnn(sequence_features)  # [batch, 1, 4096]
                actions = self.actions(rnn_out.squeeze(1))  # [batch, 2]
                return actions
        
        return CLIPBasedModel()
    
    def _create_quantized_model(self, base_model, quantization_type="fp16"):
        """ì–‘ìí™”ëœ ëª¨ë¸ ìƒì„±"""
        class QuantizedModel(nn.Module):
            def __init__(self, base_model, quantization_type):
                super().__init__()
                self.base_model = base_model
                self.quantization_type = quantization_type
                
                # ì–‘ìí™” ì ìš©
                if quantization_type == "fp16":
                    self.base_model = self.base_model.half()
                elif quantization_type == "int8":
                    # ë™ì  ì–‘ìí™”
                    self.base_model = torch.quantization.quantize_dynamic(
                        self.base_model, {nn.Linear, nn.RNN}, dtype=torch.qint8
                    )
            
            def forward(self, x):
                if self.quantization_type == "fp16":
                    x = x.half()
                return self.base_model(x)
        
        return QuantizedModel(base_model, quantization_type)
    
    def _benchmark_model(self, model, name, input_data):
        """ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ ìˆ˜í–‰"""
        logger.info(f"ğŸ“Š {name} ë²¤ì¹˜ë§ˆí¬ ì‹œì‘...")
        
        model = model.to(self.device)
        model.eval()
        
        # ì›Œë°ì—…
        for _ in range(5):
            with torch.no_grad():
                _ = model(input_data)
        
        # ì •í™•í•œ ë©”ëª¨ë¦¬ ì¸¡ì •
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.reset_peak_memory_stats()
            torch.cuda.synchronize()
            start_memory = torch.cuda.memory_allocated()
        else:
            start_memory = 0
        
        # ì¶”ë¡  ì‹œê°„ ì¸¡ì •
        times = []
        outputs = []
        
        for _ in range(self.num_runs):
            start_time = time.time()
            with torch.no_grad():
                output = model(input_data)
            torch.cuda.synchronize() if torch.cuda.is_available() else None
            end_time = time.time()
            times.append((end_time - start_time) * 1000)  # ms
            outputs.append(output.detach().cpu())
        
        if torch.cuda.is_available():
            torch.cuda.synchronize()
            end_memory = torch.cuda.memory_allocated()
            peak_memory = torch.cuda.max_memory_allocated()
            
            memory_used = (end_memory - start_memory) / (1024 ** 2)  # MB
            peak_memory_used = peak_memory / (1024 ** 2)  # MB
        else:
            memory_used = 0
            peak_memory_used = 0
        
        avg_time = np.mean(times)
        std_time = np.std(times)
        fps = 1000 / avg_time
        
        logger.info(f"   ì¶”ë¡  ì‹œê°„: {avg_time:.2f} Â± {std_time:.2f} ms")
        logger.info(f"   ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_used:.2f} MB")
        logger.info(f"   ìµœëŒ€ ë©”ëª¨ë¦¬: {peak_memory_used:.2f} MB")
        logger.info(f"   FPS: {fps:.2f}")
        
        return {
            'inference_time_ms': avg_time,
            'inference_time_std': std_time,
            'memory_usage_mb': memory_used,
            'peak_memory_mb': peak_memory_used,
            'fps': fps,
            'outputs': outputs
        }
    
    def _estimate_kosmos2_performance(self, clip_results):
        """Kosmos2 ì„±ëŠ¥ ì¶”ì • (êµ¬ì¡° ë¶„ì„ ê¸°ë°˜)"""
        logger.info("ğŸ” Kosmos2 ì„±ëŠ¥ ì¶”ì • (êµ¬ì¡° ë¶„ì„ ê¸°ë°˜)")
        
        # Kosmos2 vs CLIP êµ¬ì¡° ì°¨ì´
        kosmos2_input_size = 2048  # Kosmos2 ì¶œë ¥ í¬ê¸°
        clip_input_size = 512      # CLIP ì¶œë ¥ í¬ê¸°
        
        # ë³µì¡ë„ ë¹„ìœ¨ ê³„ì‚° (ì…ë ¥ í¬ê¸° ì°¨ì´ë¡œ ì¸í•œ RNN ì—°ì‚°ëŸ‰ ì°¨ì´)
        complexity_ratio = (kosmos2_input_size / clip_input_size) ** 2  # RNN ì—°ì‚°ëŸ‰ì€ ì…ë ¥ í¬ê¸°ì˜ ì œê³±ì— ë¹„ë¡€
        
        # Kosmos2 ì„±ëŠ¥ ì¶”ì •
        kosmos2_original_time = clip_results['original']['inference_time_ms'] * complexity_ratio
        kosmos2_fp16_time = clip_results['fp16']['inference_time_ms'] * complexity_ratio
        
        # FP16 ì–‘ìí™” íš¨ê³¼ëŠ” ë™ì¼í•˜ë‹¤ê³  ê°€ì •
        fp16_speedup = clip_results['fp16']['inference_time_ms'] / clip_results['original']['inference_time_ms']
        
        kosmos2_original_fps = 1000 / kosmos2_original_time
        kosmos2_fp16_fps = 1000 / kosmos2_fp16_time
        
        logger.info(f"   ë³µì¡ë„ ë¹„ìœ¨: {complexity_ratio:.2f}x")
        logger.info(f"   ì¶”ì • ì›ë³¸ ì‹œê°„: {kosmos2_original_time:.2f} ms")
        logger.info(f"   ì¶”ì • FP16 ì‹œê°„: {kosmos2_fp16_time:.2f} ms")
        logger.info(f"   ì¶”ì • ì›ë³¸ FPS: {kosmos2_original_fps:.1f}")
        logger.info(f"   ì¶”ì • FP16 FPS: {kosmos2_fp16_fps:.1f}")
        
        return {
            'original': {
                'inference_time_ms': kosmos2_original_time,
                'fps': kosmos2_original_fps
            },
            'fp16': {
                'inference_time_ms': kosmos2_fp16_time,
                'fps': kosmos2_fp16_fps
            },
            'improvement': {
                'speedup': 1 / fp16_speedup,
                'fps_improvement': kosmos2_fp16_fps / kosmos2_original_fps
            },
            'estimated': True
        }
    
    def run_comparison(self):
        """ìµœì¢… ì–‘ìí™” ì„±ëŠ¥ ë¹„êµ ì‹¤í–‰"""
        logger.info("ğŸš€ ìµœì¢… ì–‘ìí™” ì„±ëŠ¥ ë¹„êµ ì‹œì‘")
        
        # ì…ë ¥ ë°ì´í„° ìƒì„±
        batch_size = 1
        input_data = torch.randn(batch_size, 3, 224, 224).to(self.device)
        
        results = {}
        
        # 1. CLIP ëª¨ë¸ (MAE 0.212) ì‹¤ì œ ì¸¡ì •
        logger.info("\n" + "="*60)
        logger.info("ğŸ¯ MAE 0.212 ëª¨ë¸ (CLIP) ì‹¤ì œ ì–‘ìí™” í…ŒìŠ¤íŠ¸")
        logger.info("="*60)
        
        clip_original = self._create_clip_model()
        clip_fp16 = self._create_quantized_model(self._create_clip_model(), "fp16")
        
        # ì›ë³¸ ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬
        clip_original_results = self._benchmark_model(clip_original, "CLIP ì›ë³¸", input_data)
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del clip_original
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        # FP16 ì–‘ìí™” ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬
        clip_fp16_results = self._benchmark_model(clip_fp16, "CLIP FP16", input_data)
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del clip_fp16
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        # CLIP ê²°ê³¼ ì €ì¥
        results['clip'] = {
            'original': clip_original_results,
            'fp16': clip_fp16_results,
            'improvement': {
                'speedup': clip_original_results['inference_time_ms'] / clip_fp16_results['inference_time_ms'],
                'memory_save': 0 if clip_original_results['memory_usage_mb'] == 0 else 
                    (clip_original_results['memory_usage_mb'] - clip_fp16_results['memory_usage_mb']) / clip_original_results['memory_usage_mb'] * 100,
                'fps_improvement': clip_fp16_results['fps'] / clip_original_results['fps']
            }
        }
        
        # 2. Kosmos2 ëª¨ë¸ (MAE 0.222) ì„±ëŠ¥ ì¶”ì •
        logger.info("\n" + "="*60)
        logger.info("ğŸ¯ MAE 0.222 ëª¨ë¸ (Kosmos2) ì„±ëŠ¥ ì¶”ì •")
        logger.info("="*60)
        
        kosmos2_results = self._estimate_kosmos2_performance(results['clip'])
        results['kosmos2'] = kosmos2_results
        
        # 3. ê²°ê³¼ ì¶œë ¥
        logger.info("\n" + "="*80)
        logger.info("ğŸ“Š ìµœì¢… ì–‘ìí™” ì„±ëŠ¥ ë¹„êµ ê²°ê³¼")
        logger.info("="*80)
        
        # CLIP ê²°ê³¼ (ì‹¤ì œ ì¸¡ì •)
        logger.info(f"\nğŸ¥ˆ MAE 0.212 ëª¨ë¸ (CLIP) - ì‹¤ì œ ì¸¡ì •:")
        logger.info(f"   ì›ë³¸: {clip_original_results['inference_time_ms']:.2f}ms, {clip_original_results['fps']:.1f} FPS")
        logger.info(f"   FP16: {clip_fp16_results['inference_time_ms']:.2f}ms, {clip_fp16_results['fps']:.1f} FPS")
        logger.info(f"   ì†ë„ í–¥ìƒ: {results['clip']['improvement']['speedup']:.2f}x")
        logger.info(f"   ë©”ëª¨ë¦¬ ì ˆì•½: {results['clip']['improvement']['memory_save']:.1f}%")
        
        # Kosmos2 ê²°ê³¼ (ì¶”ì •)
        logger.info(f"\nğŸ¥‡ MAE 0.222 ëª¨ë¸ (Kosmos2) - ì„±ëŠ¥ ì¶”ì •:")
        logger.info(f"   ì›ë³¸: {kosmos2_results['original']['inference_time_ms']:.2f}ms, {kosmos2_results['original']['fps']:.1f} FPS")
        logger.info(f"   FP16: {kosmos2_results['fp16']['inference_time_ms']:.2f}ms, {kosmos2_results['fp16']['fps']:.1f} FPS")
        logger.info(f"   ì†ë„ í–¥ìƒ: {kosmos2_results['improvement']['speedup']:.2f}x")
        logger.info(f"   ë©”ëª¨ë¦¬ ì ˆì•½: {results['clip']['improvement']['memory_save']:.1f}% (CLIPê³¼ ë™ì¼ ì¶”ì •)")
        
        # ëª¨ë¸ ê°„ ë¹„êµ
        logger.info(f"\nğŸ† ëª¨ë¸ ê°„ ë¹„êµ:")
        kosmos2_fp16_fps = kosmos2_results['fp16']['fps']
        clip_fp16_fps = clip_fp16_results['fps']
        logger.info(f"   Kosmos2 FP16: {kosmos2_fp16_fps:.1f} FPS (ì¶”ì •)")
        logger.info(f"   CLIP FP16: {clip_fp16_fps:.1f} FPS (ì‹¤ì œ)")
        logger.info(f"   CLIPì´ Kosmos2ë³´ë‹¤ {clip_fp16_fps/kosmos2_fp16_fps:.2f}x ë¹ ë¦„")
        
        # 4. ê²°ê³¼ ì €ì¥
        with open('final_quantization_comparison_results.json', 'w') as f:
            # Tensor ê°ì²´ ì œê±° í›„ ì €ì¥
            clean_results = {}
            for model_name, model_results in results.items():
                clean_results[model_name] = {}
                for test_name, test_results in model_results.items():
                    if test_name == 'improvement':
                        clean_results[model_name][test_name] = test_results
                    elif test_name == 'estimated':
                        clean_results[model_name][test_name] = test_results
                    else:
                        clean_results[model_name][test_name] = {
                            'inference_time_ms': test_results['inference_time_ms'],
                            'fps': test_results['fps']
                        }
                        if 'inference_time_std' in test_results:
                            clean_results[model_name][test_name]['inference_time_std'] = test_results['inference_time_std']
                        if 'memory_usage_mb' in test_results:
                            clean_results[model_name][test_name]['memory_usage_mb'] = test_results['memory_usage_mb']
                        if 'peak_memory_mb' in test_results:
                            clean_results[model_name][test_name]['peak_memory_mb'] = test_results['peak_memory_mb']
            
            json.dump(clean_results, f, indent=2)
        
        logger.info("\nâœ… ê²°ê³¼ê°€ final_quantization_comparison_results.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤")
        
        return results

def main():
    tester = FinalQuantizationComparison()
    results = tester.run_comparison()
    
    return results

if __name__ == "__main__":
    main()
