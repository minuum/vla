#!/usr/bin/env python3
"""
RoboVLM ê¸°ë°˜ ê³ ê¸‰ ì•¡ì…˜ íŒŒì„œ
ì‹¤ì œ RoboVLMs ëª¨ë¸ì˜ ì¶œë ¥ í˜•íƒœë¥¼ ì²˜ë¦¬í•˜ëŠ” ì „ë¬¸ íŒŒì„œ
"""

import torch
import numpy as np
from typing import Dict, List, Tuple, Optional, Any, Union
from dataclasses import dataclass
from enum import Enum
import json
import copy

class ActionSpace(Enum):
    """ì•¡ì…˜ ê³µê°„ íƒ€ìž…"""
    CONTINUOUS = "continuous"
    DISCRETE = "discrete"

class RobotControl(Enum):
    """ë¡œë´‡ ì œì–´ íƒ€ìž…"""
    POSITION = "position"      # ìœ„ì¹˜ ì œì–´
    VELOCITY = "velocity"      # ì†ë„ ì œì–´  
    FORCE = "force"           # íž˜ ì œì–´
    TRAJECTORY = "trajectory"  # ê¶¤ì  ì œì–´

@dataclass
class RoboAction:
    """RoboVLMs ìŠ¤íƒ€ì¼ ë¡œë´‡ ì•¡ì…˜"""
    # 6DOF ì•¡ì…˜ (x, y, z, roll, pitch, yaw)
    translation: np.ndarray = None  # (3,) [x, y, z]
    rotation: np.ndarray = None     # (3,) [roll, pitch, yaw] 
    gripper: float = 0.0           # ê·¸ë¦¬í¼ ìƒíƒœ (0: ì—´ë¦¼, 1: ë‹«íž˜)
    
    # ë©”íƒ€ë°ì´í„°
    action_type: str = "unknown"
    confidence: float = 0.0
    control_mode: RobotControl = RobotControl.VELOCITY
    
    # ì‹œí€€ìŠ¤ ì •ë³´
    sequence_length: int = 1
    prediction_horizon: int = 1
    
    def to_6dof_array(self) -> np.ndarray:
        """6DOF ë°°ì—´ë¡œ ë³€í™˜"""
        if self.translation is None:
            self.translation = np.zeros(3)
        if self.rotation is None:
            self.rotation = np.zeros(3)
        
        return np.concatenate([self.translation, self.rotation])
    
    def to_twist_like(self) -> Tuple[float, float, float]:
        """ROS Twist ë©”ì‹œì§€ ìŠ¤íƒ€ì¼ë¡œ ë³€í™˜"""
        if self.translation is None:
            linear_x, linear_y = 0.0, 0.0
        else:
            linear_x, linear_y = float(self.translation[0]), float(self.translation[1])
            
        if self.rotation is None:
            angular_z = 0.0
        else:
            angular_z = float(self.rotation[2])  # yawë§Œ ì‚¬ìš©
            
        return linear_x, linear_y, angular_z
    
    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            "translation": self.translation.tolist() if self.translation is not None else None,
            "rotation": self.rotation.tolist() if self.rotation is not None else None,
            "gripper": self.gripper,
            "action_type": self.action_type,
            "confidence": self.confidence,
            "control_mode": self.control_mode.value,
            "sequence_length": self.sequence_length,
            "prediction_horizon": self.prediction_horizon
        }

class RoboVLMActionParser:
    """RoboVLMs ëª¨ë¸ ì¶œë ¥ì„ íŒŒì‹±í•˜ëŠ” ê³ ê¸‰ íŒŒì„œ"""
    
    def __init__(self, 
                 action_space: ActionSpace = ActionSpace.CONTINUOUS,
                 action_dim: int = 6,
                 bins: int = 256,
                 min_action: float = -1.0,
                 max_action: float = 1.0,
                 prediction_horizon: int = 1):
        
        self.action_space = action_space
        self.action_dim = action_dim
        self.bins = bins
        self.min_action = min_action
        self.max_action = max_action
        self.prediction_horizon = prediction_horizon
        
        # ì•¡ì…˜ ì •ê·œí™”ë¥¼ ìœ„í•œ ë¹ˆ ìƒì„± (ActionTokenizer ìŠ¤íƒ€ì¼)
        if action_space == ActionSpace.DISCRETE:
            self.action_bins = np.linspace(min_action, max_action, bins)
            self.bin_centers = (self.action_bins[:-1] + self.action_bins[1:]) / 2.0
        
        # ì•¡ì…˜ íƒ€ìž…ë³„ ê¸°ë³¸ ì„¤ì •
        self.action_configs = {
            "move": {
                "control_mode": RobotControl.VELOCITY,
                "default_speed": 0.3,
                "gripper_action": False
            },
            "turn": {
                "control_mode": RobotControl.VELOCITY, 
                "default_angular_speed": 0.5,
                "gripper_action": False
            },
            "stop": {
                "control_mode": RobotControl.VELOCITY,
                "gripper_action": False
            },
            "grab": {
                "control_mode": RobotControl.POSITION,
                "approach_speed": 0.1,
                "gripper_action": True,
                "gripper_state": 1.0
            },
            "release": {
                "control_mode": RobotControl.POSITION,
                "gripper_action": True,
                "gripper_state": 0.0
            },
            "navigate": {
                "control_mode": RobotControl.TRAJECTORY,
                "approach_speed": 0.2,
                "gripper_action": False
            }
        }

    def parse_continuous_action(self, 
                              action_tensor: torch.Tensor,
                              text_instruction: str = "",
                              vision_features: Optional[torch.Tensor] = None) -> RoboAction:
        """ì—°ì† ì•¡ì…˜ í…ì„œ íŒŒì‹± (BaseRoboVLM.forward_continuous ì¶œë ¥)"""
        
        if isinstance(action_tensor, torch.Tensor):
            action_array = action_tensor.detach().cpu().numpy()
        else:
            action_array = np.array(action_tensor)
            
        # í˜•íƒœ í™•ì¸ ë° ì •ê·œí™”
        if action_array.ndim == 3:  # (batch, seq_len, action_dim)
            action_array = action_array[0, -1]  # ë§ˆì§€ë§‰ ì‹œí€€ìŠ¤ ì‚¬ìš©
        elif action_array.ndim == 2:  # (seq_len, action_dim)
            action_array = action_array[-1]     # ë§ˆì§€ë§‰ ì‹œí€€ìŠ¤ ì‚¬ìš©
        
        # ì•¡ì…˜ ì •ê·œí™” ([-1, 1] -> ì‹¤ì œ ì œì–´ ê°’)
        action_array = np.clip(action_array, self.min_action, self.max_action)
        
        # 6DOF ì•¡ì…˜ ë¶„í•´
        if len(action_array) >= 6:
            translation = action_array[:3]
            rotation = action_array[3:6]
            gripper = action_array[6] if len(action_array) > 6 else 0.0
        else:
            # ë¶€ì¡±í•œ ì°¨ì›ì€ 0ìœ¼ë¡œ íŒ¨ë”©
            padded_action = np.zeros(6)
            padded_action[:len(action_array)] = action_array
            translation = padded_action[:3]
            rotation = padded_action[3:6]
            gripper = 0.0
        
        # í…ìŠ¤íŠ¸ ê¸°ë°˜ ì•¡ì…˜ íƒ€ìž… ì¶”ë¡ 
        action_type = self._infer_action_type(text_instruction)
        
        # ì‹ ë¢°ë„ ê³„ì‚°
        confidence = self._calculate_confidence(action_array, text_instruction)
        
        return RoboAction(
            translation=translation,
            rotation=rotation,
            gripper=gripper,
            action_type=action_type,
            confidence=confidence,
            control_mode=self.action_configs.get(action_type, {}).get(
                "control_mode", RobotControl.VELOCITY
            ),
            prediction_horizon=self.prediction_horizon
        )

    def parse_discrete_action(self, 
                            action_token_ids: Union[torch.Tensor, List[int]],
                            text_instruction: str = "") -> RoboAction:
        """ì´ì‚° ì•¡ì…˜ í† í° íŒŒì‹± (ActionTokenizer.decode_token_ids_to_actions ìŠ¤íƒ€ì¼)"""
        
        if isinstance(action_token_ids, torch.Tensor):
            token_ids = action_token_ids.detach().cpu().numpy()
        else:
            token_ids = np.array(action_token_ids)
        
        # í† í° IDë¥¼ ì—°ì† ì•¡ì…˜ìœ¼ë¡œ ë³€í™˜
        if self.action_space == ActionSpace.DISCRETE:
            # ActionTokenizer ìŠ¤íƒ€ì¼ ë””ì½”ë”©
            discretized_actions = self.bins - token_ids
            discretized_actions = np.clip(
                discretized_actions - 1, 
                a_min=0, 
                a_max=self.bin_centers.shape[0] - 1
            )
            action_array = self.bin_centers[discretized_actions]
        else:
            raise ValueError("Discrete parsing requires ActionSpace.DISCRETE")
        
        # ì—°ì† ì•¡ì…˜ íŒŒì‹±ê³¼ ë™ì¼í•˜ê²Œ ì²˜ë¦¬
        return self.parse_continuous_action(action_array, text_instruction)

    def parse_trajectory_sequence(self,
                                action_sequence: torch.Tensor,
                                text_instruction: str = "") -> List[RoboAction]:
        """ê¶¤ì  ì‹œí€€ìŠ¤ íŒŒì‹± (trajectory_gpt2 ì¶œë ¥)"""
        
        if isinstance(action_sequence, torch.Tensor):
            seq_array = action_sequence.detach().cpu().numpy()
        else:
            seq_array = np.array(action_sequence)
        
        # (batch, seq_len, action_dim) or (seq_len, action_dim)
        if seq_array.ndim == 3:
            seq_array = seq_array[0]  # ì²« ë²ˆì§¸ ë°°ì¹˜ ì‚¬ìš©
        
        actions = []
        for i, action_step in enumerate(seq_array):
            action = self.parse_continuous_action(action_step, text_instruction)
            action.sequence_length = len(seq_array)
            action.prediction_horizon = len(seq_array) - i  # ë‚¨ì€ ìŠ¤í…
            actions.append(action)
        
        return actions

    def parse_vision_language_action(self,
                                   vlm_output: Dict[str, Any],
                                   text_instruction: str = "",
                                   image_features: Optional[torch.Tensor] = None) -> RoboAction:
        """VLM ì „ì²´ ì¶œë ¥ íŒŒì‹± (BaseRoboVLM.forward ì¶œë ¥)"""
        
        # VLM ì¶œë ¥ì—ì„œ ì•¡ì…˜ ê´€ë ¨ ë¶€ë¶„ ì¶”ì¶œ
        if "action_pred" in vlm_output:
            action_pred = vlm_output["action_pred"]
            
            if self.action_space == ActionSpace.CONTINUOUS:
                return self.parse_continuous_action(action_pred, text_instruction, image_features)
            else:
                return self.parse_discrete_action(action_pred, text_instruction)
        
        elif "instr_and_action_pred" in vlm_output:
            # ëª…ë ¹ì–´ì™€ ì•¡ì…˜ì´ í•¨ê»˜ ì˜ˆì¸¡ëœ ê²½ìš°
            pred_tokens = vlm_output["instr_and_action_pred"]
            return self.parse_discrete_action(pred_tokens, text_instruction)
        
        else:
            # fallback: í…ìŠ¤íŠ¸ë§Œìœ¼ë¡œ ì•¡ì…˜ ìƒì„±
            return self._text_only_action(text_instruction)

    def _infer_action_type(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ì—ì„œ ì•¡ì…˜ íƒ€ìž… ì¶”ë¡ """
        text_lower = text.lower()
        
        action_keywords = {
            "move": ["move", "go", "forward", "backward", "ì „ì§„", "í›„ì§„", "ì´ë™"],
            "turn": ["turn", "rotate", "left", "right", "íšŒì „", "ëŒë‹¤"],
            "stop": ["stop", "halt", "brake", "ì •ì§€", "ë©ˆì¶¤"],
            "grab": ["grab", "grasp", "pick", "take", "ìž¡ë‹¤", "ë“¤ë‹¤"],
            "release": ["release", "drop", "put", "place", "ë†“ë‹¤", "ë‚´ë ¤ë†“ë‹¤"],
            "navigate": ["navigate", "find", "reach", "go to", "ì°¾ì•„ê°€ë‹¤"]
        }
        
        for action_type, keywords in action_keywords.items():
            if any(keyword in text_lower for keyword in keywords):
                return action_type
        
        return "unknown"

    def _calculate_confidence(self, action_array: np.ndarray, text: str) -> float:
        """ì•¡ì…˜ ì‹ ë¢°ë„ ê³„ì‚°"""
        base_confidence = 0.7
        
        # ì•¡ì…˜ í¬ê¸° ê¸°ë°˜ ì‹ ë¢°ë„
        action_magnitude = np.linalg.norm(action_array)
        magnitude_confidence = min(action_magnitude * 0.2, 0.2)
        
        # í…ìŠ¤íŠ¸ ë§¤ì¹­ ê¸°ë°˜ ì‹ ë¢°ë„  
        text_confidence = 0.1 if text and len(text) > 3 else 0.0
        
        return min(base_confidence + magnitude_confidence + text_confidence, 1.0)

    def _text_only_action(self, text: str) -> RoboAction:
        """í…ìŠ¤íŠ¸ë§Œìœ¼ë¡œ ê¸°ë³¸ ì•¡ì…˜ ìƒì„± (fallback)"""
        action_type = self._infer_action_type(text)
        config = self.action_configs.get(action_type, {})
        
        # ê¸°ë³¸ ì•¡ì…˜ ìƒì„±
        translation = np.zeros(3)
        rotation = np.zeros(3)
        gripper = 0.0
        
        if action_type == "move":
            if "forward" in text.lower() or "ì „ì§„" in text:
                translation[0] = config.get("default_speed", 0.3)
            elif "backward" in text.lower() or "í›„ì§„" in text:
                translation[0] = -config.get("default_speed", 0.3)
        
        elif action_type == "turn":
            if "left" in text.lower() or "ì¢Œ" in text:
                rotation[2] = config.get("default_angular_speed", 0.5)
            elif "right" in text.lower() or "ìš°" in text:
                rotation[2] = -config.get("default_angular_speed", 0.5)
        
        elif action_type == "grab":
            gripper = config.get("gripper_state", 1.0)
            translation[0] = config.get("approach_speed", 0.1)
        
        return RoboAction(
            translation=translation,
            rotation=rotation,
            gripper=gripper,
            action_type=action_type,
            confidence=0.6,  # í…ìŠ¤íŠ¸ë§Œìœ¼ë¡œëŠ” ë‚®ì€ ì‹ ë¢°ë„
            control_mode=config.get("control_mode", RobotControl.VELOCITY)
        )

class ActionValidator:
    """RoboVLM ì•¡ì…˜ ê²€ì¦ê¸°"""
    
    def __init__(self,
                 max_translation_speed: float = 0.5,
                 max_rotation_speed: float = 1.0,
                 safety_bounds: Dict[str, Tuple[float, float]] = None):
        
        self.max_translation_speed = max_translation_speed
        self.max_rotation_speed = max_rotation_speed
        
        # ì•ˆì „ ê²½ê³„ê°’
        self.safety_bounds = safety_bounds or {
            "x": (-1.0, 1.0),
            "y": (-1.0, 1.0), 
            "z": (-0.5, 0.5),
            "roll": (-np.pi, np.pi),
            "pitch": (-np.pi/2, np.pi/2),
            "yaw": (-np.pi, np.pi)
        }

    def validate_action(self, action: RoboAction) -> RoboAction:
        """ì•¡ì…˜ ìœ íš¨ì„± ê²€ì‚¬ ë° í´ë¦¬í•‘"""
        if action.translation is not None:
            # ì†ë„ ì œí•œ
            speed = np.linalg.norm(action.translation)
            if speed > self.max_translation_speed:
                action.translation = action.translation * (self.max_translation_speed / speed)
            
            # ê²½ê³„ê°’ í´ë¦¬í•‘
            action.translation[0] = np.clip(action.translation[0], 
                                          self.safety_bounds["x"][0], 
                                          self.safety_bounds["x"][1])
            action.translation[1] = np.clip(action.translation[1],
                                          self.safety_bounds["y"][0],
                                          self.safety_bounds["y"][1])
            action.translation[2] = np.clip(action.translation[2],
                                          self.safety_bounds["z"][0], 
                                          self.safety_bounds["z"][1])
        
        if action.rotation is not None:
            # íšŒì „ ì†ë„ ì œí•œ
            angular_speed = np.linalg.norm(action.rotation)
            if angular_speed > self.max_rotation_speed:
                action.rotation = action.rotation * (self.max_rotation_speed / angular_speed)
            
            # ê°ë„ ì œí•œ
            action.rotation[0] = np.clip(action.rotation[0],
                                       self.safety_bounds["roll"][0],
                                       self.safety_bounds["roll"][1])
            action.rotation[1] = np.clip(action.rotation[1],
                                       self.safety_bounds["pitch"][0], 
                                       self.safety_bounds["pitch"][1])
            action.rotation[2] = np.clip(action.rotation[2],
                                       self.safety_bounds["yaw"][0],
                                       self.safety_bounds["yaw"][1])
        
        # ê·¸ë¦¬í¼ ìƒíƒœ í´ë¦¬í•‘
        action.gripper = np.clip(action.gripper, 0.0, 1.0)
        
        return action

    def is_safe_action(self, action: RoboAction) -> bool:
        """ì•¡ì…˜ ì•ˆì „ì„± ê²€ì‚¬"""
        if action.translation is not None:
            if np.any(np.abs(action.translation) > self.max_translation_speed):
                return False
        
        if action.rotation is not None:
            if np.any(np.abs(action.rotation) > self.max_rotation_speed):
                return False
        
        if action.confidence < 0.3:
            return False
        
        return True

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    print("ðŸ¤– RoboVLM ì•¡ì…˜ íŒŒì„œ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # íŒŒì„œ ì´ˆê¸°í™”
    parser = RoboVLMActionParser(
        action_space=ActionSpace.CONTINUOUS,
        action_dim=7,  # 6DOF + ê·¸ë¦¬í¼
        prediction_horizon=1
    )
    validator = ActionValidator()
    
    # í…ŒìŠ¤íŠ¸ 1: ì—°ì† ì•¡ì…˜ íŒŒì‹±
    print("\n1. ì—°ì† ì•¡ì…˜ íŒŒì‹± í…ŒìŠ¤íŠ¸")
    action_tensor = torch.tensor([[0.3, 0.0, 0.0, 0.0, 0.0, 0.5, 0.8]])  # ì „ì§„ + ì¢ŒíšŒì „ + ê·¸ë¦¬í¼ ë‹«ê¸°
    action = parser.parse_continuous_action(action_tensor, "ì „ì§„í•˜ë©´ì„œ ë¬¼ê±´ì„ ìž¡ì•„")
    print(f"   ì•¡ì…˜ íƒ€ìž…: {action.action_type}")
    print(f"   ìœ„ì¹˜: {action.translation}")
    print(f"   íšŒì „: {action.rotation}")
    print(f"   ê·¸ë¦¬í¼: {action.gripper}")
    print(f"   ì‹ ë¢°ë„: {action.confidence:.2f}")
    
    # Twist ë³€í™˜ í…ŒìŠ¤íŠ¸
    linear_x, linear_y, angular_z = action.to_twist_like()
    print(f"   ROS Twist: linear_x={linear_x:.2f}, angular_z={angular_z:.2f}")
    
    # í…ŒìŠ¤íŠ¸ 2: í…ìŠ¤íŠ¸ë§Œìœ¼ë¡œ ì•¡ì…˜ ìƒì„±
    print("\n2. í…ìŠ¤íŠ¸ ì „ìš© ì•¡ì…˜ ìƒì„±")
    text_commands = [
        "move forward slowly",
        "turn right quickly", 
        "stop immediately",
        "grab the red cup",
        "ìš°íšŒì „í•˜ì„¸ìš”"
    ]
    
    for cmd in text_commands:
        action = parser._text_only_action(cmd)
        action = validator.validate_action(action)
        linear_x, linear_y, angular_z = action.to_twist_like()
        safety = "âœ…" if validator.is_safe_action(action) else "âŒ"
        print(f"   '{cmd}' â†’ {action.action_type}: ({linear_x:.2f}, {linear_y:.2f}, {angular_z:.2f}) {safety}")
    
    # í…ŒìŠ¤íŠ¸ 3: ê¶¤ì  ì‹œí€€ìŠ¤ íŒŒì‹±
    print("\n3. ê¶¤ì  ì‹œí€€ìŠ¤ íŒŒì‹±")
    trajectory = torch.tensor([
        [0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],  # ì²œì²œížˆ ì „ì§„
        [0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],  # ë” ë¹ ë¥´ê²Œ
        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],  # ì •ì§€í•˜ê³  ê·¸ë¦¬í¼ ë‹«ê¸°
    ])
    
    actions = parser.parse_trajectory_sequence(trajectory, "ì»µì— ì ‘ê·¼í•´ì„œ ìž¡ê¸°")
    for i, action in enumerate(actions):
        linear_x, _, angular_z = action.to_twist_like()
        print(f"   Step {i+1}: linear_x={linear_x:.2f}, gripper={action.gripper:.1f}, remaining={action.prediction_horizon}")
    
    print("\nâœ… RoboVLM ì•¡ì…˜ íŒŒì„œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ") 