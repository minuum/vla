#!/usr/bin/env python3
"""
Mobile VLA HDF5 Dataset Implementation for 20251106 Episodes
ì°¸ì¡°: https://github.com/Robot-VLAs/RoboVLMs/blob/main/robovlms/data/calvin_dataset.py
"""

import h5py
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import logging
from PIL import Image
import cv2
import glob

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MobileVLAH5Dataset(Dataset):
    """
    Mobile VLA HDF5 ë°ì´í„°ì…‹ í´ë˜ìŠ¤ (20251106 ì—í”¼ì†Œë“œìš©)
    ì°¸ì¡°: https://github.com/Robot-VLAs/RoboVLMs/blob/main/robovlms/data/calvin_dataset.py:63-71
    CALVIN ë°ì´í„°ì…‹ì˜ obs_config êµ¬ì¡°ë¥¼ ì°¸ê³ í•˜ì—¬ Mobile VLAì— ë§ê²Œ ìˆ˜ì •
    
    HDF5 êµ¬ì¡°:
    - images: (T, 720, 1280, 3) uint8 - RGB ì´ë¯¸ì§€
    - actions: (T, 3) float32 - [linear_x, linear_y, angular_z]
    - action_event_types: (T,) - ì•¡ì…˜ ì´ë²¤íŠ¸ íƒ€ì…
    """
    
    def __init__(
        self,
        data_dir: str,
        episode_pattern: str = "episode_20251106_*.h5",
        window_size: int = 8,
        action_chunk_size: int = 10,
        image_size: int = 224,
        image_mean: List[float] = [0.48145466, 0.4578275, 0.40821073],
        image_std: List[float] = [0.26862954, 0.26130258, 0.27577711],
        train_split: float = 0.8,
        is_validation: bool = False,
        norm_action: bool = True,
        norm_min: float = -1.0,
        norm_max: float = 1.0
    ):
        """
        Mobile VLA HDF5 ë°ì´í„°ì…‹ ì´ˆê¸°í™”
        
        Args:
            data_dir: ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ
            episode_pattern: ì—í”¼ì†Œë“œ íŒŒì¼ íŒ¨í„´
            window_size: ìœˆë„ìš° í¬ê¸° (ì°¸ì¡°: RoboVLMs window_size=8)
            action_chunk_size: ì•¡ì…˜ ì²­í¬ í¬ê¸° (ì°¸ì¡°: RoboVLMs fwd_pred_next_n=10)
            image_size: ì´ë¯¸ì§€ í¬ê¸° (224x224)
            image_mean: ì´ë¯¸ì§€ ì •ê·œí™” í‰ê· 
            image_std: ì´ë¯¸ì§€ ì •ê·œí™” í‘œì¤€í¸ì°¨
            train_split: í›ˆë ¨ ë°ì´í„° ë¹„ìœ¨
            is_validation: ê²€ì¦ ë°ì´í„°ì…‹ ì—¬ë¶€
            norm_action: ì•¡ì…˜ ì •ê·œí™” ì—¬ë¶€
            norm_min: ì•¡ì…˜ ì •ê·œí™” ìµœì†Œê°’
            norm_max: ì•¡ì…˜ ì •ê·œí™” ìµœëŒ€ê°’
        """
        self.data_dir = Path(data_dir)
        self.window_size = window_size
        self.action_chunk_size = action_chunk_size
        self.image_size = image_size
        self.image_mean = np.array(image_mean).reshape(1, 1, 3)
        self.image_std = np.array(image_std).reshape(1, 1, 3)
        self.norm_action = norm_action
        self.norm_min = norm_min
        self.norm_max = norm_max
        
        # ì—í”¼ì†Œë“œ íŒŒì¼ ë¡œë“œ
        episode_files = sorted(glob.glob(str(self.data_dir / episode_pattern)))
        
        if not episode_files:
            raise ValueError(f"No episodes found matching pattern: {episode_pattern}")
        
        # Train/Val ë¶„í• 
        split_idx = int(len(episode_files) * train_split)
        if is_validation:
            self.episode_files = episode_files[split_idx:]
            logger.info(f"ğŸ“Š Validation ë°ì´í„°ì…‹: {len(self.episode_files)}ê°œ ì—í”¼ì†Œë“œ")
        else:
            self.episode_files = episode_files[:split_idx]
            logger.info(f"ğŸ“Š Training ë°ì´í„°ì…‹: {len(self.episode_files)}ê°œ ì—í”¼ì†Œë“œ")
        
        # ìƒ˜í”Œ ì¸ë±ìŠ¤ ìƒì„±
        self.samples = self._build_sample_index()
        
        logger.info(f"âœ… ì´ {len(self.samples)}ê°œ ìƒ˜í”Œ ìƒì„±")
    
    def _build_sample_index(self) -> List[Tuple[str, int]]:
        """
        ìƒ˜í”Œ ì¸ë±ìŠ¤ ìƒì„± (ì—í”¼ì†Œë“œ íŒŒì¼, ì‹œì‘ í”„ë ˆì„)
        ì°¸ì¡°: https://github.com/Robot-VLAs/RoboVLMs/blob/main/robovlms/data/calvin_dataset.py:870-887
        Window size ì²˜ë¦¬ ë°©ì‹ ì°¸ê³ 
        """
        samples = []
        
        for episode_file in self.episode_files:
            with h5py.File(episode_file, 'r') as f:
                num_frames = f['images'].shape[0]
                
                # Window size + action chunkë¥¼ ê³ ë ¤í•œ ìƒ˜í”Œ ìƒì„±
                max_start_idx = num_frames - self.window_size - self.action_chunk_size + 1
                
                if max_start_idx > 0:
                    for start_idx in range(max_start_idx):
                        samples.append((episode_file, start_idx))
        
        return samples
    
    def __len__(self) -> int:
        return len(self.samples)
    
    def _preprocess_image(self, image: np.ndarray) -> np.ndarray:
        """
        ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        ì°¸ì¡°: https://github.com/Robot-VLAs/RoboVLMs/blob/main/robovlms/data/calvin_dataset.py:73-81
        ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë°©ì‹ ì°¸ê³ 
        
        Args:
            image: (H, W, 3) uint8 RGB ì´ë¯¸ì§€
        
        Returns:
            (3, 224, 224) float32 ì •ê·œí™”ëœ ì´ë¯¸ì§€
        """
        # Resize to 224x224
        image = cv2.resize(image, (self.image_size, self.image_size))
        
        # Normalize to [0, 1]
        image = image.astype(np.float32) / 255.0
        
        # Apply ImageNet normalization
        image = (image - self.image_mean) / self.image_std
        
        # HWC -> CHW
        image = np.transpose(image, (2, 0, 1))
        
        return image
    
    def _normalize_action(self, action: np.ndarray) -> np.ndarray:
        """
        ì•¡ì…˜ ì •ê·œí™”
        ì°¸ì¡°: https://github.com/Robot-VLAs/RoboVLMs/blob/main/robovlms/data/calvin_dataset.py
        norm_action ì²˜ë¦¬ ë°©ì‹ ì°¸ê³ 
        
        Args:
            action: (2,) [linear_x, linear_y] ë˜ëŠ” (T, 2)
        
        Returns:
            ì •ê·œí™”ëœ ì•¡ì…˜ [-1, 1] ë²”ìœ„
        """
        if not self.norm_action:
            return action
        
        # Clip to [norm_min, norm_max]
        action = np.clip(action, self.norm_min, self.norm_max)
        
        # Normalize to [-1, 1]
        action = 2.0 * (action - self.norm_min) / (self.norm_max - self.norm_min) - 1.0
        
        return action
    
    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
        """
        ë°ì´í„° ì•„ì´í…œ ë°˜í™˜
        ì°¸ì¡°: https://github.com/Robot-VLAs/RoboVLMs/blob/main/robovlms/data/calvin_dataset.py:857-858
        CALVIN ë°ì´í„°ì…‹ì˜ collater í•¨ìˆ˜ êµ¬ì¡°ë¥¼ ì°¸ê³ 
        """
        episode_file, start_idx = self.samples[idx]
        
        with h5py.File(episode_file, 'r') as f:
            # ì´ë¯¸ì§€ ë¡œë“œ (window_size í”„ë ˆì„)
            # ì°¸ì¡°: RoboVLMs window_size=8 ì‚¬ìš©
            images = f['images'][start_idx:start_idx + self.window_size]  # (T, H, W, 3)
            
            # ì•¡ì…˜ ë¡œë“œ (action_chunk_size í”„ë ˆì„)
            # ì°¸ì¡°: RoboVLMs fwd_pred_next_n=10 ì‚¬ìš©
            actions = f['actions'][start_idx + self.window_size:start_idx + self.window_size + self.action_chunk_size]  # (T, 3)
            
            # Mobile VLAëŠ” 2D ì•¡ì…˜ë§Œ ì‚¬ìš© (linear_x, linear_y)
            actions = actions[:, :2]  # (T, 2)
        
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        # ì°¸ì¡°: https://github.com/Robot-VLAs/RoboVLMs/blob/main/robovlms/data/calvin_dataset.py:73-81
        processed_images = []
        for img in images:
            processed_img = self._preprocess_image(img)
            processed_images.append(processed_img)
        
        processed_images = np.stack(processed_images, axis=0)  # (T, 3, 224, 224)
        
        # ì•¡ì…˜ ì •ê·œí™”
        actions = self._normalize_action(actions)
        
        # ì–¸ì–´ ëª…ë ¹ (ê³ ì •)
        # ì‹¤ì œë¡œëŠ” ì—í”¼ì†Œë“œë³„ ëª…ë ¹ì„ ë¡œë“œí•´ì•¼ í•¨
        language = "go to the red box"
        
        # ì•¡ì…˜ ë§ˆìŠ¤í¬ ìƒì„±
        # ì°¸ì¡°: https://github.com/Robot-VLAs/RoboVLMs/blob/main/robovlms/data/calvin_dataset.py:884-887
        action_mask = np.ones((self.action_chunk_size,), dtype=bool)
        
        return {
            "images": torch.from_numpy(processed_images).float(),  # (T, 3, 224, 224)
            "actions": torch.from_numpy(actions).float(),  # (T, 2)
            "action_mask": torch.from_numpy(action_mask),  # (T,)
            "language": language,
            "episode_file": episode_file
        }

def create_mobile_vla_h5_dataloader(
    data_dir: str,
    episode_pattern: str = "episode_20251106_*.h5",
    batch_size: int = 2,
    num_workers: int = 4,
    window_size: int = 8,
    action_chunk_size: int = 10,
    train_split: float = 0.8
) -> Tuple[DataLoader, DataLoader]:
    """
    Mobile VLA HDF5 ë°ì´í„° ë¡œë” ìƒì„± í•¨ìˆ˜
    ì°¸ì¡°: https://github.com/Robot-VLAs/RoboVLMs/blob/main/robovlms/data/calvin_dataset.py:22-25
    """
    # í›ˆë ¨ ë°ì´í„°ì…‹
    train_dataset = MobileVLAH5Dataset(
        data_dir=data_dir,
        episode_pattern=episode_pattern,
        window_size=window_size,
        action_chunk_size=action_chunk_size,
        train_split=train_split,
        is_validation=False
    )
    
    # ê²€ì¦ ë°ì´í„°ì…‹
    val_dataset = MobileVLAH5Dataset(
        data_dir=data_dir,
        episode_pattern=episode_pattern,
        window_size=window_size,
        action_chunk_size=action_chunk_size,
        train_split=train_split,
        is_validation=True
    )
    
    # DataLoader ìƒì„±
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=True
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True
    )
    
    logger.info(f"ğŸ“Š Mobile VLA HDF5 ë°ì´í„° ë¡œë” ìƒì„± ì™„ë£Œ")
    logger.info(f"  - Train: {len(train_dataset)} ìƒ˜í”Œ")
    logger.info(f"  - Val: {len(val_dataset)} ìƒ˜í”Œ")
    logger.info(f"  - Batch Size: {batch_size}")
    
    return train_loader, val_loader

def test_mobile_vla_h5_dataset():
    """Mobile VLA HDF5 ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ§ª Mobile VLA HDF5 ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    try:
        # ë°ì´í„° ë¡œë” ìƒì„±
        train_loader, val_loader = create_mobile_vla_h5_dataloader(
            data_dir="/home/billy/25-1kp/vla/ROS_action/mobile_vla_dataset",
            episode_pattern="episode_20251106_*.h5",
            batch_size=2,
            num_workers=0
        )
        
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        for batch in train_loader:
            logger.info(f"âœ… ë°°ì¹˜ ë¡œë“œ ì„±ê³µ:")
            logger.info(f"  - images shape: {batch['images'].shape}")
            logger.info(f"  - actions shape: {batch['actions'].shape}")
            logger.info(f"  - language: {batch['language']}")
            break
        
        logger.info("âœ… Mobile VLA HDF5 ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Mobile VLA HDF5 ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    test_mobile_vla_h5_dataset()

