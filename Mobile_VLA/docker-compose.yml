version: '3.8'

services:
  # K-í”„ë¡œì íŠ¸ Event-Triggered VLA ë©”ì¸ ì„œë¹„ìŠ¤
  k_project_event_vla:
    image: nvcr.io/nvidia/pytorch:23.10-py3
    container_name: k_project_event_vla
    restart: unless-stopped
    
    # GPU ë° íŠ¹ê¶Œ ì„¤ì •
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    
    privileged: true
    
    # ë„¤íŠ¸ì›Œí¬ ì„¤ì • (ROS2 í†µì‹ ì„ ìœ„í•´ host ë„¤íŠ¸ì›Œí¬ ì‚¬ìš©)
    network_mode: host
    
    # í™˜ê²½ ë³€ìˆ˜
    environment:
      - DISPLAY=${DISPLAY:-:0}
      - ROS_DOMAIN_ID=42
      - CUDA_VISIBLE_DEVICES=0
      - TORCH_DTYPE=bfloat16
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
      - TRANSFORMERS_CACHE=/workspace/.vlms
      - HF_HOME=/workspace/.vlms
      - PYTHONPATH=/workspace:/workspace/robovlms
      - VLA_MODEL=paligemma-3b-mix-224
      - ACTION_MODE=automotive
      - ACTION_DIM=4
      - WINDOW_SIZE=8
      - INFERENCE_LATENCY_TARGET=100
      - PROJECT_NAME=k_project_event_vla
    
    # ë³¼ë¥¨ ë§ˆìš´íŠ¸
    volumes:
      # ì‘ì—… ë””ë ‰í† ë¦¬
      - .:/workspace
      - ../Model_ws:/model_ws
      - ../ROS_action:/ros_action
      
      # ì‹œìŠ¤í…œ ì ‘ê·¼ (ì„¼ì„œ, GPU ë“±)
      - /dev:/dev
      - /tmp/.X11-unix:/tmp/.X11-unix:rw
      
      # ëª¨ë¸ ìºì‹œ (í˜¸ìŠ¤íŠ¸ì— ì €ì¥)
      - ./models_cache:/workspace/.vlms
      
      # ROS2 DDS ì„¤ì •
      - /etc/localtime:/etc/localtime:ro
    
    # ì‘ì—… ë””ë ‰í† ë¦¬
    working_dir: /workspace
    
    # ì»¨í…Œì´ë„ˆ ì‹œì‘ ëª…ë ¹ì–´
    command: >
      bash -c "
        echo 'ğŸš€ K-í”„ë¡œì íŠ¸ Event-Triggered VLA ì»¨í…Œì´ë„ˆ ì‹œì‘' &&
        
        # ROS2 í™˜ê²½ ì„¤ì •
        source /opt/ros/humble/setup.bash &&
        export ROS_DOMAIN_ID=42 &&
        
        # Python ì˜ì¡´ì„± ì„¤ì¹˜ (ìºì‹œëœ ê²½ìš° ë¹ ë¦„)
        pip install --no-cache-dir transformers torch torchvision accelerate &&
        pip install --no-cache-dir datasets pillow numpy opencv-python &&
        
        # VLA ì‹œìŠ¤í…œ ëŒ€ê¸° ëª¨ë“œë¡œ ì‹œì‘
        echo 'âœ… VLA ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ. ëª…ë ¹ ëŒ€ê¸° ì¤‘...' &&
        
        # ë¬´í•œ ëŒ€ê¸° (ë‹¤ë¥¸ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì»¨í…Œì´ë„ˆ ë‚´ë¶€ ì‹¤í–‰)
        tail -f /dev/null
      "
    
    # í—¬ìŠ¤ì²´í¬
    healthcheck:
      test: ["CMD", "python3", "-c", "import torch; print('GPU:', torch.cuda.is_available())"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # ROS2 ë¸Œë¦¿ì§€ ì„œë¹„ìŠ¤ (ì„ íƒì )
  ros2_bridge:
    image: ros:humble
    container_name: k_project_ros2_bridge
    restart: unless-stopped
    
    network_mode: host
    
    environment:
      - ROS_DOMAIN_ID=42
      - ROS_LOCALHOST_ONLY=0
    
    volumes:
      - ../Model_ws:/model_ws
      - ../ROS_action:/ros_action
      - /dev:/dev
    
    working_dir: /model_ws
    
    command: >
      bash -c "
        source /opt/ros/humble/setup.bash &&
        export ROS_DOMAIN_ID=42 &&
        
        # ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ë¹Œë“œ
        if [ -d 'src' ]; then
          colcon build --packages-select vla_node &&
          source install/setup.bash &&
          echo 'âœ… ROS2 ë¸Œë¦¿ì§€ ì¤€ë¹„ ì™„ë£Œ'
        fi &&
        
        # ROS2 ë…¸ë“œ ì‹¤í–‰ ëŒ€ê¸°
        sleep infinity
      "
    
    depends_on:
      - k_project_event_vla
    
    profiles:
      - ros2  # ì„ íƒì  ì‹¤í–‰: docker-compose --profile ros2 up

  # ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤ (ì„ íƒì )
  monitoring:
    image: nvcr.io/nvidia/pytorch:23.10-py3
    container_name: k_project_monitoring
    restart: unless-stopped
    
    network_mode: host
    
    environment:
      - ROS_DOMAIN_ID=42
    
    volumes:
      - .:/workspace
      - /var/run/docker.sock:/var/run/docker.sock:ro
    
    working_dir: /workspace
    
    command: >
      bash -c "
        echo 'ğŸ“Š K-í”„ë¡œì íŠ¸ ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤ ì‹œì‘' &&
        
        # ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
        while true; do
          echo '=== System Status ===' &&
          date &&
          nvidia-smi --query-gpu=memory.used,memory.total,utilization.gpu --format=csv,noheader &&
          docker stats --no-stream k_project_event_vla | tail -1 &&
          echo '' &&
          sleep 30
        done
      "
    
    profiles:
      - monitoring  # ì„ íƒì  ì‹¤í–‰: docker-compose --profile monitoring up

# ë„¤íŠ¸ì›Œí¬ ì„¤ì • (host ë„¤íŠ¸ì›Œí¬ ì‚¬ìš©ìœ¼ë¡œ ë¶ˆí•„ìš”í•˜ì§€ë§Œ ëª…ì‹œ)
networks:
  default:
    external: true
    name: host

# ë³¼ë¥¨ ì„¤ì •
volumes:
  models_cache:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${PWD}/models_cache