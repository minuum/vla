# 📚 RoboVLMs 논문 Appendix E: DETAILED PERFORMANCE ON CALVIN 섹션 분석

> **인용**: 논문 "APPENDIX E: DETAILED PERFORMANCE ON CALVIN" 섹션

## 🎯 **1. CALVIN 상세 성능 개요**

### **Table VII 개요**
> **인용**: "TABLE VII: Generalization and data efficiency of VLAs with or without vision-language pre-train on different settings of the CALVIN benchmark." (논문 Appendix E 섹션)

#### **Table VII의 목적**
- **일반화**: VLAs의 일반화 능력 평가
- **데이터 효율성**: 데이터 효율성 평가
- **비전-언어 사전 훈련**: VL 사전 훈련의 영향 분석
- **다양한 설정**: CALVIN 벤치마크의 다양한 설정

### **표기법 설명**
> **인용**: "'Inter.' denotes interleaved modeling. 'P.H.' denotes policy head. 'No VL' suggests models without VL pre-training. '5x' represents training with 5x re-generated training data." (논문 Appendix E 섹션)

#### **아키텍처 표기법**
- **Inter.**: Interleaved modeling (인터리브 모델링)
- **P.H.**: Policy head (정책 헤드)
- **No VL**: Vision-language 사전 훈련 없는 모델
- **5x**: 5배 재생성 훈련 데이터로 훈련

#### **결과 보고 방법**
> **인용**: "The results for 5x data are the model performance at 1 epoch, and the best-behaved model checkpoints within 5 epochs for the others." (논문 Appendix E 섹션)

- **5x 데이터**: 1 에포크에서의 모델 성능
- **기타**: 5 에포크 내 최고 성능 체크포인트

## 📊 **2. Table VII: 상세 성능 결과**

### **ABCD 훈련 결과**

#### **KosMos Inter. No VL**
- **1개 연속 작업**: 0.692 (69.2%)
- **2개 연속 작업**: 0.382 (38.2%)
- **3개 연속 작업**: 0.189 (18.9%)
- **4개 연속 작업**: 0.085 (8.5%)
- **5개 연속 작업**: 0.036 (3.6%)
- **평균 길이**: 1.38

#### **KosMos Inter.**
- **1개 연속 작업**: 0.987 (98.7%)
- **2개 연속 작업**: 0.915 (91.5%)
- **3개 연속 작업**: 0.824 (82.4%)
- **4개 연속 작업**: 0.737 (73.7%)
- **5개 연속 작업**: 0.660 (66.0%)
- **평균 길이**: 4.12

#### **KosMos P.H. No VL**
- **1개 연속 작업**: 0.815 (81.5%)
- **2개 연속 작업**: 0.626 (62.6%)
- **3개 연속 작업**: 0.473 (47.3%)
- **4개 연속 작업**: 0.349 (34.9%)
- **5개 연속 작업**: 0.245 (24.5%)
- **평균 길이**: 2.51

#### **KosMos P.H.**
- **1개 연속 작업**: 0.967 (96.7%)
- **2개 연속 작업**: 0.930 (93.0%)
- **3개 연속 작업**: 0.899 (89.9%)
- **4개 연속 작업**: 0.865 (86.5%)
- **5개 연속 작업**: 0.826 (82.6%)
- **평균 길이**: 4.49

#### **Flamingo P.H. 9B No VL**
- **1개 연속 작업**: 0.733 (73.3%)
- **2개 연속 작업**: 0.444 (44.4%)
- **3개 연속 작업**: 0.270 (27.0%)
- **4개 연속 작업**: 0.161 (16.1%)
- **5개 연속 작업**: 0.077 (7.7%)
- **평균 길이**: 1.69

#### **Flamingo P.H. 9B**
- **1개 연속 작업**: 0.955 (95.5%)
- **2개 연속 작업**: 0.879 (87.9%)
- **3개 연속 작업**: 0.784 (78.4%)
- **4개 연속 작업**: 0.714 (71.4%)
- **5개 연속 작업**: 0.634 (63.4%)
- **평균 길이**: 3.97

### **5x ABCD 훈련 결과**

#### **KosMos Inter. No VL**
- **1개 연속 작업**: 0.833 (83.3%)
- **2개 연속 작업**: 0.588 (58.8%)
- **3개 연속 작업**: 0.421 (42.1%)
- **4개 연속 작업**: 0.297 (29.7%)
- **5개 연속 작업**: 0.209 (20.9%)
- **평균 길이**: 2.35

#### **KosMos Inter.**
- **1개 연속 작업**: 0.989 (98.9%)
- **2개 연속 작업**: 0.940 (94.0%)
- **3개 연속 작업**: 0.892 (89.2%)
- **4개 연속 작업**: 0.842 (84.2%)
- **5개 연속 작업**: 0.795 (79.5%)
- **평균 길이**: 4.46

#### **KosMos P.H. No VL**
- **1개 연속 작업**: 0.893 (89.3%)
- **2개 연속 작업**: 0.755 (75.5%)
- **3개 연속 작업**: 0.644 (64.4%)
- **4개 연속 작업**: 0.564 (56.4%)
- **5개 연속 작업**: 0.462 (46.2%)
- **평균 길이**: 3.32

#### **KosMos P.H.**
- **1개 연속 작업**: 0.968 (96.8%)
- **2개 연속 작업**: 0.937 (93.7%)
- **3개 연속 작업**: 0.903 (90.3%)
- **4개 연속 작업**: 0.872 (87.2%)
- **5개 연속 작업**: 0.830 (83.0%)
- **평균 길이**: 4.51

### **ABC 훈련 결과**

#### **KosMos Inter. No VL**
- **1개 연속 작업**: 0.432 (43.2%)
- **2개 연속 작업**: 0.162 (16.2%)
- **3개 연속 작업**: 0.044 (4.4%)
- **4개 연속 작업**: 0.007 (0.7%)
- **5개 연속 작업**: 0.002 (0.2%)
- **평균 길이**: 0.65

#### **KosMos Inter.**
- **1개 연속 작업**: 0.824 (82.4%)
- **2개 연속 작업**: 0.684 (68.4%)
- **3개 연속 작업**: 0.524 (52.4%)
- **4개 연속 작업**: 0.376 (37.6%)
- **5개 연속 작업**: 0.296 (29.6%)
- **평균 길이**: 2.70

#### **KosMos P.H. No VL**
- **1개 연속 작업**: 0.389 (38.9%)
- **2개 연속 작업**: 0.121 (12.1%)
- **3개 연속 작업**: 0.038 (3.8%)
- **4개 연속 작업**: 0.008 (0.8%)
- **5개 연속 작업**: 0.001 (0.1%)
- **평균 길이**: 0.56

#### **KosMos P.H.**
- **1개 연속 작업**: 0.980 (98.0%)
- **2개 연속 작업**: 0.936 (93.6%)
- **3개 연속 작업**: 0.854 (85.4%)
- **4개 연속 작업**: 0.778 (77.8%)
- **5개 연속 작업**: 0.704 (70.4%)
- **평균 길이**: 4.25

## 📈 **3. 성능 분석**

### **비전-언어 사전 훈련의 영향**

#### **ABCD 훈련에서의 VL 사전 훈련 효과**

| 모델 | VL 사전 훈련 | 1개 작업 | 5개 작업 | 평균 길이 |
|------|-------------|----------|----------|-----------|
| **KosMos Inter.** | ❌ | 0.692 | 0.036 | 1.38 |
| **KosMos Inter.** | ✅ | 0.987 | 0.660 | 4.12 |
| **개선도** | - | +42.6% | +1733% | +198% |

| 모델 | VL 사전 훈련 | 1개 작업 | 5개 작업 | 평균 길이 |
|------|-------------|----------|----------|-----------|
| **KosMos P.H.** | ❌ | 0.815 | 0.245 | 2.51 |
| **KosMos P.H.** | ✅ | 0.967 | 0.826 | 4.49 |
| **개선도** | - | +18.7% | +237% | +79% |

#### **ABC 훈련에서의 VL 사전 훈련 효과**

| 모델 | VL 사전 훈련 | 1개 작업 | 5개 작업 | 평균 길이 |
|------|-------------|----------|----------|-----------|
| **KosMos Inter.** | ❌ | 0.432 | 0.002 | 0.65 |
| **KosMos Inter.** | ✅ | 0.824 | 0.296 | 2.70 |
| **개선도** | - | +91% | +14700% | +315% |

| 모델 | VL 사전 훈련 | 1개 작업 | 5개 작업 | 평균 길이 |
|------|-------------|----------|----------|-----------|
| **KosMos P.H.** | ❌ | 0.389 | 0.001 | 0.56 |
| **KosMos P.H.** | ✅ | 0.980 | 0.704 | 4.25 |
| **개선도** | - | +152% | +70300% | +659% |

### **아키텍처 비교**

#### **Interleaved vs Policy Head (ABCD 훈련)**

| 아키텍처 | VL 사전 훈련 | 1개 작업 | 5개 작업 | 평균 길이 |
|----------|-------------|----------|----------|-----------|
| **KosMos Inter.** | ✅ | 0.987 | 0.660 | 4.12 |
| **KosMos P.H.** | ✅ | 0.967 | 0.826 | 4.49 |
| **차이** | - | -2.0% | +25.2% | +9.0% |

#### **Interleaved vs Policy Head (ABC 훈련)**

| 아키텍처 | VL 사전 훈련 | 1개 작업 | 5개 작업 | 평균 길이 |
|----------|-------------|----------|----------|-----------|
| **KosMos Inter.** | ✅ | 0.824 | 0.296 | 2.70 |
| **KosMos P.H.** | ✅ | 0.980 | 0.704 | 4.25 |
| **차이** | - | +19.0% | +138% | +57% |

### **데이터 효율성 분석**

#### **5x 데이터의 효과 (KosMos Inter.)**

| 데이터 | 1개 작업 | 5개 작업 | 평균 길이 |
|--------|----------|----------|-----------|
| **ABCD** | 0.987 | 0.660 | 4.12 |
| **5x ABCD** | 0.989 | 0.795 | 4.46 |
| **개선도** | +0.2% | +20.5% | +8.3% |

#### **5x 데이터의 효과 (KosMos P.H.)**

| 데이터 | 1개 작업 | 5개 작업 | 평균 길이 |
|--------|----------|----------|-----------|
| **ABCD** | 0.967 | 0.826 | 4.49 |
| **5x ABCD** | 0.968 | 0.830 | 4.51 |
| **개선도** | +0.1% | +0.5% | +0.4% |

### **일반화 능력 분석**

#### **ABCD vs ABC 훈련 (KosMos P.H.)**

| 훈련 데이터 | 1개 작업 | 5개 작업 | 평균 길이 |
|-------------|----------|----------|-----------|
| **ABCD** | 0.967 | 0.826 | 4.49 |
| **ABC** | 0.980 | 0.704 | 4.25 |
| **차이** | +1.3% | -14.8% | -5.3% |

## 🎯 **4. 핵심 발견사항**

### **비전-언어 사전 훈련의 중요성**
1. **일반화**: VL 사전 훈련이 일반화 능력에 결정적 영향
2. **데이터 효율성**: 적은 데이터로도 높은 성능 달성
3. **장기 작업**: 연속 작업에서 특히 큰 성능 향상

### **아키텍처의 영향**
1. **Policy Head**: Interleaved보다 우수한 성능
2. **일반화**: Policy Head가 더 나은 일반화 능력
3. **데이터 효율성**: Policy Head가 더 효율적

### **데이터 스케일의 효과**
1. **5x 데이터**: 성능 향상에 기여
2. **수렴 속도**: 더 빠른 수렴
3. **최종 성능**: 더 높은 최종 성능

## 📊 **5. 성능 지표 해석**

### **연속 작업 성공률**
- **1개 작업**: 단일 작업 완료 능력
- **5개 작업**: 장기 연속 작업 능력
- **의의**: 복잡한 작업 시퀀스 처리 능력

### **평균 길이**
- **의의**: 평균적으로 완료할 수 있는 연속 작업 수
- **해석**: 높을수록 더 복잡한 작업 시퀀스 처리 가능
- **비교**: 모델 간 장기 작업 능력 비교

### **성능 저하 패턴**
- **일반적 패턴**: 연속 작업 수가 증가할수록 성능 저하
- **VL 사전 훈련**: 저하 속도가 느림
- **아키텍처**: Policy Head가 더 안정적

## 🚀 **6. 결론**

### **Table VII의 핵심 의의**
1. **비전-언어 사전 훈련**: VLA 성능에 결정적 영향
2. **아키텍처 선택**: Policy Head가 Interleaved보다 우수
3. **데이터 효율성**: VL 사전 훈련이 데이터 효율성 향상
4. **일반화 능력**: VL 사전 훈련이 일반화 능력 향상

### **연구의 의의**
1. **체계적 분석**: 다양한 설정에서의 체계적 성능 분석
2. **비교 연구**: 아키텍처와 훈련 방법의 공정한 비교
3. **실용적 가치**: 실제 적용에 유용한 성능 지표

### **미래 연구 방향**
1. **더 큰 데이터**: 더 큰 데이터셋에서의 성능 분석
2. **새로운 아키텍처**: 새로운 VLA 아키텍처 개발
3. **효율성**: 더 효율적인 훈련 방법론

---

*분석 작성일: 2024년 12월*  
*원본 논문: "Towards Generalist Robot Policies: What Matters in Building Vision-Language-Action Models"*
