#!/usr/bin/env python3
"""
ğŸ¯ ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
LSTM + MLP Action Head ì¡°í•© ëª¨ë¸ í•™ìŠµ
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import logging
import json
import os
from pathlib import Path
import time
from datetime import datetime
import sys

# ê²½ë¡œ ì„¤ì •
sys.path.append('/home/billy/25-1kp/vla/Robo+/Mobile_VLA')
from core.data_core.mobile_vla_dataset import MobileVLADataset
from ensemble_action_head_model import create_ensemble_model

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def train_ensemble_model(
    epochs: int = 5,
    batch_size: int = 4,
    learning_rate: float = 1e-4,
    device: str = "cuda" if torch.cuda.is_available() else "cpu",
    save_dir: str = "ensemble_action_head_results"
):
    """ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ"""
    
    logger.info("ğŸš€ ì•™ìƒë¸” Action Head ëª¨ë¸ í•™ìŠµ ì‹œì‘")
    logger.info(f"Device: {device}")
    logger.info(f"Epochs: {epochs}")
    logger.info(f"Batch size: {batch_size}")
    logger.info(f"Learning rate: {learning_rate}")
    
    # ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    save_path = Path(save_dir)
    save_path.mkdir(exist_ok=True)
    
    # ì•™ìƒë¸” ëª¨ë¸ ìƒì„±
    logger.info("ì•™ìƒë¸” ëª¨ë¸ ìƒì„± ì¤‘...")
    ensemble_model = create_ensemble_model(
        lstm_model_path="enhanced_kosmos2_clip_hybrid_with_normalization_results/best_enhanced_kosmos2_clip_hybrid_with_mobile_normalization.pth",
        mlp_model_path="Robo+/Mobile_VLA/results/mobile_vla_epoch_3.pt",
        action_dim=2,
        fusion_method="weighted"
    )
    
    ensemble_model = ensemble_model.to(device)
    
    # ë°ì´í„°ì…‹ ë¡œë“œ
    logger.info("ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘...")
    dataset = MobileVLADataset(
        data_dir="ROS_action/mobile_vla_dataset",
        max_episodes=72,
        image_size=224,
        action_dim=2
    )
    
    # Train/Val split
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])
    
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)
    
    logger.info(f"Train samples: {len(train_dataset)}")
    logger.info(f"Val samples: {len(val_dataset)}")
    
    # ì˜µí‹°ë§ˆì´ì € ë° ì†ì‹¤ í•¨ìˆ˜
    optimizer = optim.AdamW(ensemble_model.parameters(), lr=learning_rate, weight_decay=0.01)
    criterion = nn.MSELoss()
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)
    
    # í•™ìŠµ íˆìŠ¤í† ë¦¬
    history = {
        "train_loss": [],
        "train_mae": [],
        "val_loss": [],
        "val_mae": [],
        "learning_rate": [],
        "ensemble_weights": []
    }
    
    best_val_loss = float('inf')
    best_model_path = None
    
    # í•™ìŠµ ë£¨í”„
    for epoch in range(epochs):
        logger.info(f"\nğŸ“Š Epoch {epoch+1}/{epochs}")
        
        # Training
        ensemble_model.train()
        train_loss = 0.0
        train_mae = 0.0
        train_samples = 0
        
        for batch_idx, (images, actions) in enumerate(train_loader):
            images = images.to(device)
            actions = actions.to(device)
            
            optimizer.zero_grad()
            
            # Forward pass
            predicted_actions = ensemble_model(images)
            loss = criterion(predicted_actions, actions)
            
            # Backward pass
            loss.backward()
            optimizer.step()
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            train_loss += loss.item() * images.size(0)
            mae = torch.mean(torch.abs(predicted_actions - actions)).item()
            train_mae += mae * images.size(0)
            train_samples += images.size(0)
            
            if batch_idx % 10 == 0:
                logger.info(f"  Batch {batch_idx}/{len(train_loader)}: Loss={loss.item():.4f}, MAE={mae:.4f}")
        
        # Validation
        ensemble_model.eval()
        val_loss = 0.0
        val_mae = 0.0
        val_samples = 0
        
        with torch.no_grad():
            for images, actions in val_loader:
                images = images.to(device)
                actions = actions.to(device)
                
                predicted_actions = ensemble_model(images)
                loss = criterion(predicted_actions, actions)
                
                val_loss += loss.item() * images.size(0)
                mae = torch.mean(torch.abs(predicted_actions - actions)).item()
                val_mae += mae * images.size(0)
                val_samples += images.size(0)
        
        # í‰ê·  ê³„ì‚°
        avg_train_loss = train_loss / train_samples
        avg_train_mae = train_mae / train_samples
        avg_val_loss = val_loss / val_samples
        avg_val_mae = val_mae / val_samples
        current_lr = optimizer.param_groups[0]['lr']
        
        # ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ì¶”ì¶œ
        if hasattr(ensemble_model, 'ensemble_weights'):
            ensemble_weights = ensemble_model.ensemble_weights.detach().cpu().numpy().tolist()
        else:
            ensemble_weights = [0.5, 0.5]  # ê¸°ë³¸ê°’
        
        # íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
        history["train_loss"].append(avg_train_loss)
        history["train_mae"].append(avg_train_mae)
        history["val_loss"].append(avg_val_loss)
        history["val_mae"].append(avg_val_mae)
        history["learning_rate"].append(current_lr)
        history["ensemble_weights"].append(ensemble_weights)
        
        logger.info(f"Train Loss: {avg_train_loss:.4f}, Train MAE: {avg_train_mae:.4f}")
        logger.info(f"Val Loss: {avg_val_loss:.4f}, Val MAE: {avg_val_mae:.4f}")
        logger.info(f"Learning Rate: {current_lr:.6f}")
        logger.info(f"Ensemble Weights: LSTM={ensemble_weights[0]:.3f}, MLP={ensemble_weights[1]:.3f}")
        
        # ìµœê³  ëª¨ë¸ ì €ì¥
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            best_model_path = save_path / f"best_ensemble_model_epoch_{epoch+1}.pth"
            
            torch.save({
                'epoch': epoch + 1,
                'model_state_dict': ensemble_model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'train_loss': avg_train_loss,
                'train_mae': avg_train_mae,
                'val_loss': avg_val_loss,
                'val_mae': avg_val_mae,
                'ensemble_weights': ensemble_weights,
                'model_info': ensemble_model.get_model_info()
            }, best_model_path)
            
            logger.info(f"âœ… ìƒˆë¡œìš´ ìµœê³  ëª¨ë¸ ì €ì¥: {best_model_path}")
        
        # ì—í¬í¬ë³„ ëª¨ë¸ ì €ì¥
        epoch_model_path = save_path / f"ensemble_model_epoch_{epoch+1}.pth"
        torch.save({
            'epoch': epoch + 1,
            'model_state_dict': ensemble_model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'train_loss': avg_train_loss,
            'train_mae': avg_train_mae,
            'val_loss': avg_val_loss,
            'val_mae': avg_val_mae,
            'ensemble_weights': ensemble_weights,
            'model_info': ensemble_model.get_model_info()
        }, epoch_model_path)
        
        scheduler.step()
    
    # ìµœì¢… ëª¨ë¸ ì €ì¥
    final_model_path = save_path / "final_ensemble_model.pth"
    torch.save({
        'epoch': epochs,
        'model_state_dict': ensemble_model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'train_loss': avg_train_loss,
        'train_mae': avg_train_mae,
        'val_loss': avg_val_loss,
        'val_mae': avg_val_mae,
        'ensemble_weights': ensemble_weights,
        'model_info': ensemble_model.get_model_info()
    }, final_model_path)
    
    # í•™ìŠµ íˆìŠ¤í† ë¦¬ ì €ì¥
    history_path = save_path / "training_history_ensemble.json"
    with open(history_path, 'w') as f:
        json.dump(history, f, indent=2)
    
    # ëª¨ë¸ ì •ë³´ ì €ì¥
    model_info_path = save_path / "model_info.json"
    with open(model_info_path, 'w') as f:
        json.dump(ensemble_model.get_model_info(), f, indent=2)
    
    logger.info(f"\nğŸ‰ ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
    logger.info(f"ìµœê³  Val Loss: {best_val_loss:.4f}")
    logger.info(f"ìµœê³  ëª¨ë¸: {best_model_path}")
    logger.info(f"ìµœì¢… ì•™ìƒë¸” ê°€ì¤‘ì¹˜: LSTM={ensemble_weights[0]:.3f}, MLP={ensemble_weights[1]:.3f}")
    logger.info(f"ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {save_path}")
    
    return {
        "best_val_loss": best_val_loss,
        "best_model_path": str(best_model_path),
        "final_model_path": str(final_model_path),
        "final_ensemble_weights": ensemble_weights,
        "history": history
    }

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="ì•™ìƒë¸” Action Head ëª¨ë¸ í•™ìŠµ")
    parser.add_argument("--epochs", type=int, default=5, help="í•™ìŠµ ì—í¬í¬ ìˆ˜")
    parser.add_argument("--batch_size", type=int, default=4, help="ë°°ì¹˜ í¬ê¸°")
    parser.add_argument("--learning_rate", type=float, default=1e-4, help="í•™ìŠµë¥ ")
    parser.add_argument("--device", type=str, default="cuda", help="ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤")
    parser.add_argument("--save_dir", type=str, default="ensemble_action_head_results", help="ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬")
    
    args = parser.parse_args()
    
    # í•™ìŠµ ì‹¤í–‰
    results = train_ensemble_model(
        epochs=args.epochs,
        batch_size=args.batch_size,
        learning_rate=args.learning_rate,
        device=args.device,
        save_dir=args.save_dir
    )
    
    print(f"\nğŸ“Š ì•™ìƒë¸” ëª¨ë¸ ìµœì¢… ê²°ê³¼:")
    print(f"Best Val Loss: {results['best_val_loss']:.4f}")
    print(f"Best Model: {results['best_model_path']}")
    print(f"Final Ensemble Weights: LSTM={results['final_ensemble_weights'][0]:.3f}, MLP={results['final_ensemble_weights'][1]:.3f}")
