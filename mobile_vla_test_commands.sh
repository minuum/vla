#!/bin/bash

# ğŸš€ Mobile VLA ì‹¤ì œ í…ŒìŠ¤íŠ¸ ëª…ë ¹ì–´ ëª¨ìŒ
# ê³¼ê±° í„°ë¯¸ë„ íˆìŠ¤í† ë¦¬ì—ì„œ í™•ì¸ëœ ì‹¤ì œ ì‘ë™í–ˆë˜ ëª…ë ¹ì–´ë“¤

echo "ğŸš€ Mobile VLA ì‹¤ì œ í…ŒìŠ¤íŠ¸ ëª…ë ¹ì–´ ëª¨ìŒ"
echo "ğŸ“‹ ê³¼ê±° í„°ë¯¸ë„ íˆìŠ¤í† ë¦¬ì—ì„œ í™•ì¸ëœ ì‹¤ì œ ì‘ë™í–ˆë˜ ëª…ë ¹ì–´ë“¤"
echo ""

# 1. ê¸°ë³¸ CUDA í…ŒìŠ¤íŠ¸
echo "1ï¸âƒ£ ê¸°ë³¸ CUDA í…ŒìŠ¤íŠ¸:"
echo "   cuda-test"
echo "   torch_cuda_test"
echo "   nvidia-smi"
echo ""

# 2. Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ í…ŒìŠ¤íŠ¸
echo "2ï¸âƒ£ Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ í…ŒìŠ¤íŠ¸:"
echo "   python3 -c \"import transformers; print(f'Transformers: {transformers.__version__}')\""
echo "   python3 -c \"from transformers import AutoModel, AutoProcessor; print('âœ… Transformers import ì„±ê³µ')\""
echo ""

# 3. Mobile VLA ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸
echo "3ï¸âƒ£ Mobile VLA ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸:"
echo "   python3 -c \"from transformers import AutoModel, AutoProcessor; model_name='minium/mobile-vla-omniwheel'; print(f'ëª¨ë¸ ë¡œë”© ì¤‘: {model_name}'); processor = AutoProcessor.from_pretrained(model_name); model = AutoModel.from_pretrained(model_name); print('âœ… Mobile VLA ëª¨ë¸ ë¡œë“œ ì„±ê³µ (MAE 0.222)')\""
echo ""

# 4. ì‹¤ì œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° í…ŒìŠ¤íŠ¸
echo "4ï¸âƒ£ ì‹¤ì œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° í…ŒìŠ¤íŠ¸:"
echo "   git clone https://huggingface.co/minium/mobile-vla-omniwheel"
echo "   ls -la mobile-vla-omniwheel/"
echo "   cat mobile-vla-omniwheel/config.json"
echo "   cat mobile-vla-omniwheel/README.md"
echo ""

# 5. ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸
echo "5ï¸âƒ£ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸:"
echo "   python3 -c \"import torch; print('PyTorch ë¡œë”©'); model = torch.load('mobile-vla-omniwheel/best_simple_lstm_model.pth', map_location='cpu'); print('âœ… ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì„±ê³µ!'); print(f'ëª¨ë¸ íƒ€ì…: {type(model)}')\""
echo ""

# 6. ìƒì„¸ ëª¨ë¸ ì •ë³´ í™•ì¸
echo "6ï¸âƒ£ ìƒì„¸ ëª¨ë¸ ì •ë³´ í™•ì¸:"
echo "   python3 -c \"import torch; checkpoint = torch.load('mobile-vla-omniwheel/best_simple_lstm_model.pth', map_location='cpu'); print('í‚¤:', list(checkpoint.keys())); print('MAE:', checkpoint.get('val_mae', 'N/A')); print('Epoch:', checkpoint.get('epoch', 'N/A'))\""
echo ""

# 7. ì‹¤ì œ ì¶”ë¡  í…ŒìŠ¤íŠ¸
echo "7ï¸âƒ£ ì‹¤ì œ ì¶”ë¡  í…ŒìŠ¤íŠ¸:"
echo "   python3 -c \"from transformers import AutoModel, AutoProcessor; import torch; model_name='minium/mobile-vla-omniwheel'; processor = AutoProcessor.from_pretrained(model_name); model = AutoModel.from_pretrained(model_name); device = torch.device('cuda' if torch.cuda.is_available() else 'cpu'); model = model.to(device); print(f'âœ… ëª¨ë¸ì´ {device}ì— ë¡œë“œë¨')\""
echo ""

echo "ğŸ¯ ì‚¬ìš© ë°©ë²•:"
echo "   ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì—ì„œ ìœ„ ëª…ë ¹ì–´ë“¤ì„ í•˜ë‚˜ì”© ì‹¤í–‰í•´ë³´ì„¸ìš”!"
echo "   ì˜ˆ: docker exec -it mobile_vla_robovlms_final bash"
echo "   ê·¸ ë‹¤ìŒ ìœ„ ëª…ë ¹ì–´ë“¤ì„ ë³µì‚¬í•´ì„œ ì‹¤í–‰"
echo ""
echo "ğŸ“Š ì˜ˆìƒ ê²°ê³¼:"
echo "   âœ… CUDA Available: True"
echo "   âœ… Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ì •ìƒ ì‘ë™"
echo "   âœ… minium/mobile-vla-omniwheel ëª¨ë¸ ë¡œë“œ ì„±ê³µ"
echo "   âœ… ì‹¤ì œ ì¶”ë¡  ê°€ëŠ¥"
