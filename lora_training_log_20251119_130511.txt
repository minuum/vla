=========================================
Mobile VLA LoRA Fine-tuning
Date: 2025-11-14
=========================================

üìÑ Config: /home/billy/25-1kp/vla/Mobile_VLA/configs/mobile_vla_20251114_lora.json
üîß Device: CUDA
üì¶ Model: Kosmos-2 with LoRA

üîç CUDA ÌôïÏù∏...
CUDA available: True
CUDA device: NVIDIA RTX A5000

üìä Îç∞Ïù¥ÌÑ∞ÏÖã ÌôïÏù∏...
  - Found 219 episodes matching pattern 'episode_2025111*.h5'
  ‚úÖ Episodes found

üöÄ LoRA Fine-tuning ÏãúÏûë...
   - Using RoboVLMs main.py
   - Dataset: MobileVLAH5Dataset
   - LoRA: r=32, alpha=16, dropout=0.1
   - Epochs: 20

[rank: 0] Seed set to 123
Using 16bit Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
/home/billy/.cache/pypoetry/virtualenvs/vla-tensorrt-sSUdR_m1-py3.10/lib/python3.10/site-packages/transformers/models/auto/modeling_auto.py:2199: FutureWarning: The class `AutoModelForVision2Seq` is deprecated and will be removed in v5.0. Please use `AutoModelForImageTextToText` instead.
  warnings.warn(
Kosmos2TextForCausalLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From üëâv4.50üëà onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
config not in config. The value is /home/billy/25-1kp/vla/Mobile_VLA/configs/mobile_vla_20251114_lora.json.
log_dir not in config. The value is None.
output_dir not in config. The value is None.
data_dir not in config. The value is None.
annotation_file not in config. The value is None.
data_subfolder not in config. The value is None.
task_num not in config. The value is None.
use_multi_modal_emb not in config. The value is False.
no_video_pretrained_model not in config. The value is False.
finetune not in config. The value is False.
llm not in config. The value is {'type': None, 'n_embd': None, 'n_layer': None, 'n_head': None}.
--------------- model configs ---------------
{'robovlm_name': 'RoboKosMos', 'exp_name': 'mobile_vla_lora_20251114', 'parent': None, 'task_name': 'mobile_vla_finetune', 'model': 'kosmos', 'model_url': 'https://huggingface.co/microsoft/kosmos-2-patch14-224', 'seq_len': 1, 'image_size': 224, 'image_mean': [0.48145466, 0.4578275, 0.40821073], 'image_std': [0.26862954, 0.26130258, 0.27577711], 'window_size': 8, 'fwd_pred_next_n': 10, 'arm_gripper_loss_ratio': 0.0, 'cap_loss_ratio': 0.0, 'fwd_loss_ratio': 0, 'seed': 123, 'batch_size': 1, 'num_workers': 2, 'data_scale': 1, 'optimizer': 'adamw', 'learning_rate': 0.0001, 'min_lr_scale': 0.001, 'weight_decay': 0.01, 'warmup_epochs': 0.1, 'warmup_steps': 0, 'warmup_ratio': None, 'use_hand_rgb': False, 'use_time_causal_attn': False, 'use_mim_obs_loss': False, 'use_pixel_loss': False, 'use_obs_queries': True, 'use_vision_resampler': False, 'vision_masked_ratio': 0.9, 'use_tube_mask': False, 'cache_root': 'runs/cache/kosmos', 'model_load_path': None, 'model_load_source': 'torch', 'resume': None, 'model_path': '.vlms/kosmos-2-patch14-224', 'model_config': '.vlms/kosmos-2-patch14-224/config.json', 'gpus': 1, 'num_nodes': 1, 'train_setup': {'precision': '16-mixed', 'predict_action': True, 'predict_forward': False, 'predict_forward_hand': False, 'predict_caption': False, 'train_vision': False, 'bits': -1, 'freeze_mm_mlp_adapter': False, 'freeze_backbone': True, 'freeze_resampler': False, 'tune_mm_mlp_adapter': False, 'mm_use_im_start_end': False, 'mm_use_im_patch_token': False, 'gradient_checkpointing': False, 'lora_enable': True, 'mm_projector_lr': 0.0001, 'lora_r': 32, 'lora_alpha': 16, 'lora_dropout': 0.1, 'lora_bias': 'none', 'train_text_embedding': False}, 'vision_resampler': {'vis_dim': 1024, 'depth': 8, 'dim_head': 64, 'heads': 8, 'num_latents': 64}, 'act_encoder': None, 'trainer_type': 'MobileVLATrainer', 'act_head': {'type': 'MobileVLALSTMDecoder', 'hidden_size': 512, 'action_dim': 2, 'down_sample': 'none', 'latent': 1, 'fwd_pred_next_n': 10, 'window_size': 8, 'action_space': 'continuous', 'with_history': True, 'history_type': 'post'}, 'fwd_head': None, 'tokenizer': {'type': 'AutoProcessor', 'pretrained_model_name_or_path': '.vlms/kosmos-2-patch14-224', 'tokenizer_type': 'kosmos', 'max_text_len': 256, 'additional_special_tokens': None}, 'vlm': {'type': 'AutoModelForVision2Seq', 'name': 'kosmos', 'pretrained_model_name_or_path': '.vlms/kosmos-2-patch14-224'}, 'trainer': {'accelerator': 'gpu', 'strategy': 'auto', 'precision': '16-mixed', 'logger': ['tensorboard', 'csv'], 'gradient_clip_val': 1.0, 'use_distributed_sampler': False, 'log_every_n_steps': 5, 'max_epochs': 20, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'max_steps': -1, 'accumulate_grad_batches': 8}, 'train_dataset': {'type': 'MobileVLAH5Dataset', 'data_dir': '/home/billy/25-1kp/vla/ROS_action/mobile_vla_dataset', 'episode_pattern': 'episode_2025111*.h5', 'shift_first': False, 'model_name': 'kosmos', 'rgb_pad': 10, 'train_split': 0.8}, 'val_dataset': {'type': 'MobileVLAH5Dataset', 'data_dir': '/home/billy/25-1kp/vla/ROS_action/mobile_vla_dataset', 'episode_pattern': 'episode_2025111*.h5', 'model_name': 'kosmos', 'train_split': 0.8, 'is_validation': True}, 'norm_action': True, 'norm_min': -1.0, 'norm_max': 1.0, 'raw_config_path': '/home/billy/25-1kp/vla/Mobile_VLA/configs/mobile_vla_20251114_lora.json', 'config': '/home/billy/25-1kp/vla/Mobile_VLA/configs/mobile_vla_20251114_lora.json', 'log_dir': 'runs/mobile_vla_lora_20251114/kosmos/mobile_vla_finetune/2025-11-19/mobile_vla_lora_20251114', 'output_dir': 'runs/mobile_vla_lora_20251114/kosmos/mobile_vla_finetune/2025-11-19/mobile_vla_lora_20251114', 'data_dir': None, 'annotation_file': None, 'data_subfolder': None, 'task_num': None, 'use_multi_modal_emb': False, 'no_video_pretrained_model': False, 'finetune': False, 'llm': {'type': None, 'n_embd': None, 'n_layer': None, 'n_head': None}}
fwd next n: 10
Adding LoRA adapters...
Traceback (most recent call last):
  File "/home/billy/.cache/pypoetry/virtualenvs/vla-tensorrt-sSUdR_m1-py3.10/lib/python3.10/site-packages/peft/tuners/tuners_utils.py", line 1236, in __getattr__
    return super().__getattr__(name)  # defer to nn.Module's logic
  File "/home/billy/.cache/pypoetry/virtualenvs/vla-tensorrt-sSUdR_m1-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1688, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'LoraModel' object has no attribute 'prepare_inputs_for_generation'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/billy/25-1kp/vla/RoboVLMs_upstream/main.py", line 356, in <module>
    experiment(variant=configs)
  File "/home/billy/25-1kp/vla/RoboVLMs_upstream/main.py", line 155, in experiment
    model = TrainerClass.from_checkpoint(
  File "/home/billy/25-1kp/vla/RoboVLMs_upstream/robovlms/train/base_trainer.py", line 125, in from_checkpoint
    return cls(configs)
  File "/home/billy/25-1kp/vla/RoboVLMs_upstream/robovlms/train/base_trainer.py", line 26, in __init__
    self._initialize()
  File "/home/billy/25-1kp/vla/RoboVLMs_upstream/robovlms/train/base_trainer.py", line 85, in _initialize
    self.model = self._init_policy()
  File "/home/billy/25-1kp/vla/RoboVLMs_upstream/robovlms/train/base_trainer.py", line 41, in _init_policy
    model = self.model_fn(
  File "/home/billy/25-1kp/vla/RoboVLMs_upstream/robovlms/model/backbone/base_backbone.py", line 157, in __init__
    self._trainable_params_setup()
  File "/home/billy/25-1kp/vla/RoboVLMs_upstream/robovlms/model/backbone/base_backbone.py", line 508, in _trainable_params_setup
    self.model = get_peft_model(model, lora_config)
  File "/home/billy/.cache/pypoetry/virtualenvs/vla-tensorrt-sSUdR_m1-py3.10/lib/python3.10/site-packages/peft/mapping_func.py", line 122, in get_peft_model
    return MODEL_TYPE_TO_PEFT_MODEL_MAPPING[peft_config.task_type](
  File "/home/billy/.cache/pypoetry/virtualenvs/vla-tensorrt-sSUdR_m1-py3.10/lib/python3.10/site-packages/peft/peft_model.py", line 1886, in __init__
    self.base_model_prepare_inputs_for_generation = self.base_model.prepare_inputs_for_generation
  File "/home/billy/.cache/pypoetry/virtualenvs/vla-tensorrt-sSUdR_m1-py3.10/lib/python3.10/site-packages/peft/tuners/tuners_utils.py", line 1240, in __getattr__
    return getattr(self.model, name)
  File "/home/billy/.cache/pypoetry/virtualenvs/vla-tensorrt-sSUdR_m1-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1688, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'Kosmos2ForConditionalGeneration' object has no attribute 'prepare_inputs_for_generation'
