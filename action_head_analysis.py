#!/usr/bin/env python3
"""
ğŸ¯ VLM + Action Head êµ¬ì¡° ëª¨ë¸ ë¶„ì„
ê° ëª¨ë¸ì˜ Action Head íƒ€ì…ë³„ ì„±ëŠ¥ ë¹„êµ
"""

import torch
import torch.nn as nn
import json
import os
from pathlib import Path
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def analyze_model_action_head(model_path: str) -> dict:
    """ëª¨ë¸ì˜ Action Head êµ¬ì¡° ë¶„ì„"""
    try:
        checkpoint = torch.load(model_path, map_location='cpu')
        
        # ëª¨ë¸ êµ¬ì¡° ë¶„ì„
        model_info = {
            'path': model_path,
            'action_head_type': 'Unknown',
            'action_dim': 'Unknown',
            'has_lstm': False,
            'has_mlp': False,
            'has_gpt2': False,
            'has_discrete': False,
            'model_size_mb': os.path.getsize(model_path) / (1024 * 1024),
            'mae': 'N/A',
            'val_loss': 'N/A',
            'train_loss': 'N/A',
            'epoch': 'N/A'
        }
        
        # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ëª¨ë¸ êµ¬ì¡° ì¶”ì¶œ
        if 'model_state_dict' in checkpoint:
            state_dict = checkpoint['model_state_dict']
        elif 'state_dict' in checkpoint:
            state_dict = checkpoint['state_dict']
        else:
            state_dict = checkpoint
        
        # Action Head íƒ€ì… ë¶„ì„
        action_head_keys = [k for k in state_dict.keys() if 'action_head' in k.lower()]
        lstm_keys = [k for k in state_dict.keys() if 'lstm' in k.lower()]
        mlp_keys = [k for k in state_dict.keys() if any(x in k.lower() for x in ['linear', 'fc', 'dense'])]
        gpt2_keys = [k for k in state_dict.keys() if 'gpt' in k.lower() or 'transformer' in k.lower()]
        discrete_keys = [k for k in state_dict.keys() if 'discrete' in k.lower() or 'token' in k.lower()]
        
        # Action Head íƒ€ì… ê²°ì •
        if lstm_keys and any('action_head' in k for k in action_head_keys):
            model_info['action_head_type'] = 'LSTM'
            model_info['has_lstm'] = True
        elif mlp_keys and any('action_head' in k for k in action_head_keys):
            model_info['action_head_type'] = 'MLP'
            model_info['has_mlp'] = True
        elif gpt2_keys:
            model_info['action_head_type'] = 'GPT2'
            model_info['has_gpt2'] = True
        elif discrete_keys:
            model_info['action_head_type'] = 'Discrete'
            model_info['has_discrete'] = True
        else:
            # ê¸°ë³¸ì ìœ¼ë¡œ LSTMìœ¼ë¡œ ë¶„ë¥˜ (ëŒ€ë¶€ë¶„ì˜ ëª¨ë¸ì´ LSTM ì‚¬ìš©)
            if lstm_keys:
                model_info['action_head_type'] = 'LSTM'
                model_info['has_lstm'] = True
            elif mlp_keys:
                model_info['action_head_type'] = 'MLP'
                model_info['has_mlp'] = True
        
        # Action ì°¨ì› ì¶”ì¶œ
        for key in action_head_keys:
            if 'weight' in key and len(state_dict[key].shape) == 2:
                # ë§ˆì§€ë§‰ ë ˆì´ì–´ì˜ ì¶œë ¥ ì°¨ì›
                if state_dict[key].shape[0] in [2, 3, 4]:  # ì¼ë°˜ì ì¸ ì•¡ì…˜ ì°¨ì›
                    model_info['action_dim'] = state_dict[key].shape[0]
                    break
        
        # ì„±ëŠ¥ ì§€í‘œ ì¶”ì¶œ
        if 'mae' in checkpoint:
            model_info['mae'] = checkpoint['mae']
        if 'val_loss' in checkpoint:
            model_info['val_loss'] = checkpoint['val_loss']
        if 'train_loss' in checkpoint:
            model_info['train_loss'] = checkpoint['train_loss']
        if 'epoch' in checkpoint:
            model_info['epoch'] = checkpoint['epoch']
        
        return model_info
        
    except Exception as e:
        logger.error(f"Error analyzing {model_path}: {e}")
        return {
            'path': model_path,
            'action_head_type': 'Error',
            'error': str(e)
        }

def find_training_history(model_path: str) -> dict:
    """í•™ìŠµ íˆìŠ¤í† ë¦¬ íŒŒì¼ ì°¾ê¸°"""
    model_dir = Path(model_path).parent
    history_files = list(model_dir.glob("*history*.json")) + list(model_dir.glob("*training*.json"))
    
    for history_file in history_files:
        try:
            with open(history_file, 'r') as f:
                history = json.load(f)
                return history
        except:
            continue
    
    return {}

def main():
    """ë©”ì¸ ë¶„ì„ í•¨ìˆ˜"""
    logger.info("ğŸ” VLM + Action Head êµ¬ì¡° ëª¨ë¸ ë¶„ì„ ì‹œì‘")
    
    # ëª¨ë¸ ê²½ë¡œë“¤
    model_paths = [
        # Enhanced Kosmos2+CLIP ëª¨ë¸ë“¤
        "enhanced_kosmos2_clip_hybrid_results/best_enhanced_kosmos2_clip_hybrid.pth",
        "enhanced_kosmos2_clip_hybrid_with_normalization_results/best_enhanced_kosmos2_clip_hybrid_with_mobile_normalization.pth",
        
        # ê¸°ì¡´ ëª¨ë¸ë“¤
        "best_simple_clip_lstm_model.pth",
        "final_simple_lstm_model.pth",
        "best_model_epoch_3.pt",
        "best_model_epoch_2.pt",
        "best_model_epoch_1.pt",
        
        # Mobile VLA ëª¨ë¸ë“¤
        "Robo+/Mobile_VLA/results/mobile_vla_epoch_3.pt",
        "Robo+/Mobile_VLA/results/mobile_vla_epoch_2.pt",
        "Robo+/Mobile_VLA/results/mobile_vla_epoch_1.pt",
        
        # Simple ëª¨ë¸ë“¤
        "Robo+/Mobile_VLA/simple_models_original_results/simple_clip/best_simple_clip_epoch_2.pth",
        "Robo+/Mobile_VLA/simple_models_original_results/clip_with_lstm/best_clip_with_lstm_epoch_1.pth",
        
        # Original ëª¨ë¸ë“¤
        "Robo+/Mobile_VLA/original_clip_augmented_results/best_original_clip_augmented_epoch_2.pth",
        "best_original_72_episodes_model_epoch_3.pth"
    ]
    
    # ëª¨ë¸ ë¶„ì„ ê²°ê³¼
    model_analyses = []
    
    for model_path in model_paths:
        if os.path.exists(model_path):
            logger.info(f"ë¶„ì„ ì¤‘: {model_path}")
            analysis = analyze_model_action_head(model_path)
            
            # í•™ìŠµ íˆìŠ¤í† ë¦¬ ì¶”ê°€
            history = find_training_history(model_path)
            if history:
                analysis['training_history'] = history
            
            model_analyses.append(analysis)
        else:
            logger.warning(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {model_path}")
    
    # Action Head íƒ€ì…ë³„ ê·¸ë£¹í™”
    action_head_groups = {}
    for analysis in model_analyses:
        head_type = analysis['action_head_type']
        if head_type not in action_head_groups:
            action_head_groups[head_type] = []
        action_head_groups[head_type].append(analysis)
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*80)
    print("ğŸ¯ VLM + Action Head êµ¬ì¡° ëª¨ë¸ ë¶„ì„ ê²°ê³¼")
    print("="*80)
    
    for head_type, models in action_head_groups.items():
        print(f"\nğŸ“Š {head_type} Action Head ëª¨ë¸ë“¤:")
        print("-" * 50)
        
        # MAE ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        valid_models = [m for m in models if m['mae'] != 'N/A' and isinstance(m['mae'], (int, float))]
        valid_models.sort(key=lambda x: x['mae'])
        
        for i, model in enumerate(valid_models, 1):
            print(f"{i:2d}. {Path(model['path']).name}")
            print(f"    MAE: {model['mae']:.4f}")
            print(f"    Val Loss: {model['val_loss']}")
            print(f"    Action Dim: {model['action_dim']}")
            print(f"    Model Size: {model['model_size_mb']:.1f} MB")
            print(f"    Epoch: {model['epoch']}")
            print()
    
    # Action Head íƒ€ì…ë³„ ì„±ëŠ¥ ë¹„êµ
    print("\nğŸ† Action Head íƒ€ì…ë³„ ìµœê³  ì„±ëŠ¥:")
    print("-" * 50)
    
    for head_type, models in action_head_groups.items():
        if head_type == 'Error':
            continue
            
        valid_models = [m for m in models if m['mae'] != 'N/A' and isinstance(m['mae'], (int, float))]
        if valid_models:
            best_model = min(valid_models, key=lambda x: x['mae'])
            print(f"{head_type:10s}: MAE {best_model['mae']:.4f} ({Path(best_model['path']).name})")
    
    # ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥
    output_file = "action_head_analysis_results.json"
    with open(output_file, 'w') as f:
        json.dump({
            'model_analyses': model_analyses,
            'action_head_groups': action_head_groups
        }, f, indent=2)
    
    logger.info(f"ë¶„ì„ ê²°ê³¼ê°€ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
