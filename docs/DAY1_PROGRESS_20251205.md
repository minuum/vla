# Day 1 ì§„í–‰ ìƒí™© (2025-12-05)

## âœ… ì™„ë£Œëœ ì‘ì—…

### 1. ê³„íš ìˆ˜ë¦½ âœ…
- **êµìˆ˜ë‹˜ ë¯¸íŒ… ì •ë¦¬**: `docs/PROFESSOR_MEETING_20251205.md`
- **ì‹¤í—˜ ê³„íš ìˆ˜ë¦½**: Frozen vs LoRA ë¹„êµ í”„ë ˆì„ì›Œí¬
- **TODO ì—…ë°ì´íŠ¸**: `docs/PROFESSOR_QUESTIONS_TODO.md` Priority 0 ì¶”ê°€

### 2. Frozen Baseline ì¶”ì¶œ âœ…
- **ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±**: `scripts/compare_frozen_vs_lora.py`
- **ì‹¤í–‰ ì™„ë£Œ**: 2025-12-05 20:08
- **ìƒì„± íŒŒì¼**:
  - `context_frozen_baseline.npy` (201 MB)
  - `latent_frozen_baseline.npy` (101 KB)
  - `context_comparison_results.json`

---

## ğŸ“Š Frozen Baseline ê²°ê³¼

### Context Vector
```json
{
  "context_mean": -0.0103,
  "context_std": 0.1534,
  "context_shape": [50, 8, 64, 2048]
}
```

**í•´ì„**:
- Shape: (50 episodes, 8 frames, 64 tokens, 2048 features)
- Mean â‰ˆ 0: ì˜ ì •ê·œí™”ë¨
- Std â‰ˆ 0.15: ì ì ˆí•œ ë¶„ì‚°

### Latent Space
```json
{
  "latent_shape": [50, 512],  # (batch, hidden_size)
}
```

**í•´ì„**:
- LSTM hidden size: 512
- 50ê°œ episodesì˜ latent state ì¶”ì¶œ ì™„ë£Œ

### Predictions
```json
{
  "prediction_mean": 0.4157,
  "prediction_std": 0.7614,
  "prediction_shape": [50, 512, 10, 2]  # (batch, seq, chunks, actions)
}
```

**í•´ì„**:
- Action chunks: 10ê°œ (0.4s ê°„ê²©)
- Actions: 2D (linear_x, angular_z)

---

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„ (Day 2: 2025-12-06)

### ë…¼ë¬¸ ì‚¬ë¡€ ì¡°ì‚¬

#### 1. RT-2 (Frozen VLM)
**Citation**: Brohan et al., "RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control" (2023)

**í•µì‹¬ ë‚´ìš©**:
- **ì ‘ê·¼**: VLM (PaLI-X) Frozen
- **ë°©ë²•**: Actionì„ language tokenìœ¼ë¡œ ì¶œë ¥
- **ë°ì´í„°**: Bridge V2 (60K trajectories)
- **ê²°ê³¼**: Frozen VLMë„ robot taskì— íš¨ê³¼ì 
- **ì¥ì **: 
  * Zero-shot generalization
  * ì ì€ robot ë°ì´í„°ë¡œ í•™ìŠµ ê°€ëŠ¥
  * Language reasoning ìœ ì§€

**ê´€ë ¨ì„±**:
- ìš°ë¦¬ì˜ ë°©ë²• 2 (Frozen)ì™€ ë™ì¼í•œ ì ‘ê·¼
- VLM freezeê°€ íš¨ê³¼ì ì„ì„ ì…ì¦

---

#### 2. OpenVLA (Fine-tuning)
**Citation**: Kim et al., "OpenVLA: An Open-Source Vision-Language-Action Model" (2024)

**í•µì‹¬ ë‚´ìš©**:
- **ì ‘ê·¼**: VLM Fine-tuning
- **ë°©ë²•**: DinoV2 + Llama ì „ì²´ fine-tuning
- **ë°ì´í„°**: Open-X (970K trajectories)
- **ê²°ê³¼**: Large-scale dataë¡œ ì„±ëŠ¥ í–¥ìƒ
- **ì¥ì **:
  * High performance
  * Task-specific adaptation
  * Multi-robot generalization

**ê´€ë ¨ì„±**:
- ìš°ë¦¬ì˜ ë°©ë²• 1 (LoRA)ì™€ ìœ ì‚¬í•œ ì ‘ê·¼
- í•˜ì§€ë§Œ ë§ì€ ë°ì´í„° í•„ìš” (970K vs ìš°ë¦¬ 500)

---

#### 3. RoboFlamingo (Frozen + Few-shot)
**Citation**: Li et al., "RoboFlamingo: Vision-Language Foundation Models as Effective Robot Policies" (2023)

**í•µì‹¬ ë‚´ìš©**:
- **ì ‘ê·¼**: VLM (Flamingo) Frozen
- **ë°©ë²•**: Action headë§Œ í•™ìŠµ, Few-shot learning
- **ë°ì´í„°**: ì ì€ ë°ì´í„° (ìˆ˜ë°± trajectories)
- **ê²°ê³¼**: Few-shotìœ¼ë¡œë„ ì¢‹ì€ ì„±ëŠ¥
- **ì¥ì **:
  * Data efficient
  * Fast adaptation
  * In-context learning

**ê´€ë ¨ì„±**:
- ìš°ë¦¬ì™€ ê°€ì¥ ìœ ì‚¬ (Frozen VLM + ì ì€ ë°ì´í„°)
- 500 episodesë¡œ ì¶©ë¶„í•  ê°€ëŠ¥ì„± ì§€ì§€

---

#### 4. PaLM-E (Fine-tuning)
**Citation**: Driess et al., "PaLM-E: An Embodied Multimodal Language Model" (2023)

**í•µì‹¬ ë‚´ìš©**:
- **ì ‘ê·¼**: VLM Fine-tuning
- **ë°©ë²•**: PaLM (540B) + ViT ì „ì²´ fine-tuning
- **ë°ì´í„°**: ëŒ€ê·œëª¨ (ìˆ˜ë°±ë§Œ)
- **ê²°ê³¼**: ë§¤ìš° ë†’ì€ ì„±ëŠ¥, multi-task
- **ë‹¨ì **:
  * ì—„ì²­ë‚œ ë°ì´í„° í•„ìš”
  * ê³„ì‚° ë¹„ìš© ë†’ìŒ
  * Overfitting ìœ„í—˜

**ê´€ë ¨ì„±**:
- ì´ìƒì ì´ì§€ë§Œ í˜„ì‹¤ì ìœ¼ë¡œ ì–´ë ¤ì›€
- ìš°ë¦¬ í™˜ê²½ì—ëŠ” ë¶€ì í•© (ë°ì´í„° ë¶€ì¡±)

---

## ğŸ“ˆ ë¹„êµ ë¶„ì„

### Data Requirements

| ë°©ë²• | ë°ì´í„° í•„ìš”ëŸ‰ | ìš°ë¦¬ ë³´ìœ  | ì í•©ì„± |
|:---|---:|---:|:---:|
| **RT-2 (Frozen)** | 60K | 500 | âš ï¸ 1% |
| **OpenVLA (Fine-tune)** | 970K | 500 | âŒ 0.05% |
| **RoboFlamingo (Frozen)** | ìˆ˜ë°± | 500 | âœ… ì¶©ë¶„ |
| **PaLM-E (Fine-tune)** | ìˆ˜ë°±ë§Œ | 500 | âŒ 0.01% |

**ê²°ë¡ **: 
- **RoboFlamingo ì ‘ê·¼ì´ ê°€ì¥ ì í•©**
- Frozen VLM + ì ì€ ë°ì´í„°ë¡œë„ íš¨ê³¼ì 
- ìš°ë¦¬ 500 episodesëŠ” ì¶©ë¶„í•  ìˆ˜ ìˆìŒ

---

### Performance vs Data

```
Performance
    â†‘
    â”‚                     PaLM-E â—
    â”‚                   /
    â”‚         OpenVLA â—
    â”‚               /
    â”‚     RT-2  â—
    â”‚         /
    â”‚   RoboFlamingo â—
    â”‚        /
    â”‚  ìš°ë¦¬ (ì˜ˆìƒ) â—
    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Data
      100  1K  10K  100K  1M
```

**Trade-off**:
- Frozen: ì ì€ ë°ì´í„°, ì¤‘ê°„ ì„±ëŠ¥, ë¹ ë¥¸ í•™ìŠµ
- Fine-tuning: ë§ì€ ë°ì´í„°, ë†’ì€ ì„±ëŠ¥, ëŠë¦° í•™ìŠµ

---

## ğŸ’¡ êµìˆ˜ë‹˜ê»˜ ë³´ê³ í•  ë‚´ìš©

### Frozenì˜ ì¥ì  (êµìˆ˜ë‹˜ ì˜ê²¬ ì§€ì§€)

1. **ë°ì´í„° íš¨ìœ¨ì„±** âœ…
   - RoboFlamingo: ìˆ˜ë°± trajectoriesë¡œ ì„±ê³µ
   - ìš°ë¦¬ 500 episodes: ì¶©ë¶„í•  ê°€ëŠ¥ì„±

2. **ì•ˆì •ì„±** âœ…
   - VLM frozen â†’ catastrophic forgetting ë°©ì§€
   - Pretrain knowledge ë³´ì¡´

3. **ë¹ ë¥¸ í•™ìŠµ** âœ…
   - Action headë§Œ í•™ìŠµ
   - ì ì€ GPU ì‹œê°„

4. **ì¼ë°˜í™”** âœ…
   - Pretrain knowledge í™œìš©
   - Multi-task ê°€ëŠ¥ì„±

### LoRAì˜ ì¥ì  (ëŒ€ì•ˆ)

1. **ì„±ëŠ¥ í–¥ìƒ ê°€ëŠ¥ì„±**
   - OpenVLA: 970Kë¡œ high performance
   - Task-specific adaptation

2. **ì¤‘ê°„ ì§€ì **
   - Full fine-tuning vs Frozen
   - ì ë‹¹í•œ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸

3. **ë‹¨ì **
   - ìš°ë¦¬ ë°ì´í„°(500)ë¡œëŠ” ë¶€ì¡±í•  ìˆ˜ ìˆìŒ
   - OpenVLAëŠ” 970K ì‚¬ìš©

---

## ğŸ¯ ì‹¤í—˜ ì œì•ˆ

### Option 1: Frozenë§Œ (ì¶”ì²œ)
```
í˜„ì¬ ìƒíƒœ í™œìš©:
  - Case 3 (Frozen, 500 episodes)
  - ì„±ëŠ¥ ê²€ì¦
  - ë…¼ë¬¸ ì‘ì„±

ì¥ì :
  - ì¦‰ì‹œ ê°€ëŠ¥
  - RoboFlamingo ì‚¬ë¡€ ì§€ì§€
  - êµìˆ˜ë‹˜ ì˜ê²¬ê³¼ ì¼ì¹˜

ë‹¨ì :
  - LoRAì™€ ì§ì ‘ ë¹„êµ ë¶ˆê°€
```

### Option 2: Frozen + LoRA ë¹„êµ
```
ì¶”ê°€ ì‘ì—…:
  - ë°ì´í„° ìˆ˜ì§‘ (500 â†’ 1,000)
  - Case 4 (LoRA) í•™ìŠµ
  - ë¹„êµ ë¶„ì„

ì¥ì :
  - ì§ì ‘ ë¹„êµ ê°€ëŠ¥
  - ë…¼ë¬¸ ê¸°ì—¬ë„ í–¥ìƒ

ë‹¨ì :
  - 1ì£¼ì¼ ì¶”ê°€ ì†Œìš”
  - ë°ì´í„° ìˆ˜ì§‘ í•„ìš”
```

### Option 3: Simulation ì¦ê°• í›„ ë¹„êµ
```
ì¥ê¸° ê³„íš:
  - Simulation í™˜ê²½ êµ¬ì¶•
  - 3,000+ episodes ìƒì„±
  - Robust comparison

ì¥ì :
  - Publication-quality
  - Real-world deployment ëŒ€ë¹„

ë‹¨ì :
  - 2~3ì£¼ ì†Œìš”
  - Simulation í™˜ê²½ í•„ìš”
```

---

## ğŸ“‹ ë‹¤ìŒ ë¯¸íŒ… (12/11) ë°œí‘œ ìë£Œ

### ì¤€ë¹„ ì‚¬í•­

1. **Frozen Baseline ë¶„ì„** âœ…
   - Context vector statistics
   - Latent space distribution
   - ì„±ëŠ¥ ë©”íŠ¸ë¦­

2. **ë…¼ë¬¸ ì‚¬ë¡€ ì¡°ì‚¬** âœ… (ì§„í–‰ ì¤‘)
   - RT-2 (Frozen)
   - OpenVLA (Fine-tuning)
   - RoboFlamingo (Frozen)
   - PaLM-E (Fine-tuning)

3. **ì‹¤í—˜ ì œì•ˆ**
   - Frozenë§Œ vs Frozen+LoRA ë¹„êµ
   - ë°ì´í„° ìš”êµ¬ì‚¬í•­
   - íƒ€ì„ë¼ì¸

4. **ì‹œê°í™”**
   - Context distribution
   - Frozen baseline heatmap
   - ë…¼ë¬¸ ë¹„êµ ì°¨íŠ¸

---

## âœ… Day 1 ì²´í¬ë¦¬ìŠ¤íŠ¸

- [x] ë¯¸íŒ… ë‚´ìš© ì •ë¦¬
- [x] ê³„íš ìˆ˜ë¦½
- [x] Context vector ì¶”ì¶œ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
- [x] Frozen baseline ì¶”ì¶œ ì™„ë£Œ
- [x] ê²°ê³¼ ì €ì¥ (201 MB npy íŒŒì¼)
- [ ] ë…¼ë¬¸ ì‚¬ë¡€ ì¡°ì‚¬ (ì§„í–‰ ì¤‘)
- [ ] ì‹œê°í™” ìƒì„±

---

**ë‹¤ìŒ ì‘ì—…**: ë…¼ë¬¸ ì‚¬ë¡€ ìµœì¢… ì •ë¦¬ ë° ì‹œê°í™” ìƒì„±
**ì˜ˆìƒ ì†Œìš”**: 2ì‹œê°„
**ëª©í‘œ**: Day 2 (ê¸ˆìš”ì¼) ì™„ë£Œ
