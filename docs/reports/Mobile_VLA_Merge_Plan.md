# ğŸ¤– mobile_vla_data_collector.py ê¸°ì¤€ RoboVLMs í†µí•© êµ¬ìƒ

## ğŸ¯ í†µí•© ì „ëµ ê°œìš”

mobile_vla_data_collector.pyë¥¼ **í•µì‹¬ ì¶•**ìœ¼ë¡œ í•˜ì—¬ RoboVLMsì˜ ê°•ë ¥í•œ í•™ìŠµ ì‹œìŠ¤í…œì„ Mobile VLAì— ë§ê²Œ í†µí•©í•˜ëŠ” ê³„íšì…ë‹ˆë‹¤. ê¸°ì¡´ì˜ ì‹¤ìš©ì ì¸ ë°ì´í„° ìˆ˜ì§‘ ë°©ì‹ì„ ìœ ì§€í•˜ë©´ì„œ ìµœì‹  VLM í•™ìŠµ ê¸°ìˆ ì„ ë„ì…í•©ë‹ˆë‹¤.

---

## ğŸ”„ í†µí•© ì•„í‚¤í…ì²˜ êµ¬ì¡°ë„

### 1ë‹¨ê³„: ë°ì´í„° ë¸Œë¦¬ì§€ ì‹œìŠ¤í…œ
```
mobile_vla_data_collector.py ì¶œë ¥
           â†“
    HDF5 Episodes Dataset
           â†“
   ğŸ”„ Data Conversion Bridge
           â†“
    RoboVLMs í•™ìŠµ í˜•ì‹
```

### 2ë‹¨ê³„: ëª¨ë¸ ì ì‘ ì‹œìŠ¤í…œ  
```
    RoboVLMs VLM Backbone
           â†“
   ğŸ§  Mobile Policy Head êµì²´
           â†“
    4D ì•¡ì…˜ Mobile VLA ëª¨ë¸
```

### 3ë‹¨ê³„: í†µí•© í•™ìŠµ ì‹œìŠ¤í…œ
```
 Mobile VLA Dataset + Mobile VLA Model
           â†“
    ğŸš€ Mobile-specific Training
           â†“
   ROS2 ì‹¤ì‹œê°„ ì¶”ë¡  ì‹œìŠ¤í…œ
```

---

## ğŸ“Š mobile_vla_data_collector.py í™œìš© ê·¹ëŒ€í™”

### ğŸ¯ í˜„ì¬ ê°•ì  ë¶„ì„
```python
# mobile_vla_data_collector.pyì˜ í•µì‹¬ ê°•ì ë“¤
strengths = {
    "ì‹¤ì‹œê°„_ë°ì´í„°_ìˆ˜ì§‘": "í‚¤ë³´ë“œ ì œì–´ë¡œ ì¦‰ì‹œ ë°ì´í„° ìƒì„±",
    "ì‹œë‚˜ë¦¬ì˜¤_ì²´ê³„í™”": "8ê°€ì§€ ì»µ ë„ë‹¬ ì‹œë‚˜ë¦¬ì˜¤ êµ¬ì¡°í™”",
    "ì´ë²¤íŠ¸_ê¸°ë°˜_ìˆ˜ì§‘": "start_action, stop_action, episode_start íƒ€ì„ìŠ¤íƒ¬í”„",
    "ì§„í–‰ë¥ _ëª¨ë‹ˆí„°ë§": "ì‹œë‚˜ë¦¬ì˜¤ë³„ ëª©í‘œ ëŒ€ë¹„ ì§„í–‰ë¥  ì‹¤ì‹œê°„ í™•ì¸",
    "HDF5_ì €ì¥": "íš¨ìœ¨ì ì¸ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì €ì¥",
    "ROS_í†µí•©": "ì‹¤ì œ ë¡œë´‡ê³¼ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë‘ ì§€ì›"
}
```

### ğŸš€ í†µí•© í›„ í™•ì¥ëœ ê¸°ëŠ¥
```python
# Mobile VLA í†µí•© í›„ ì¶”ê°€ë  ê¸°ëŠ¥ë“¤
enhanced_features = {
    "ìë™_í•™ìŠµ_íŒŒì´í”„ë¼ì¸": "ë°ì´í„° ìˆ˜ì§‘ â†’ ìë™ í•™ìŠµ â†’ ëª¨ë¸ ì—…ë°ì´íŠ¸",
    "ì‹¤ì‹œê°„_ì„±ëŠ¥_í”¼ë“œë°±": "ìˆ˜ì§‘ ì¤‘ ëª¨ë¸ ì„±ëŠ¥ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§", 
    "ì ì‘ì _ë°ì´í„°_ìˆ˜ì§‘": "ëª¨ë¸ ì•½ì  ì˜ì—­ ìš°ì„  ìˆ˜ì§‘",
    "ë‹¤êµ­ì–´_ëª…ë ¹_ì§€ì›": "í•œêµ­ì–´/ì˜ì–´ ë„¤ë¹„ê²Œì´ì…˜ ëª…ë ¹",
    "ì—°ì†_í•™ìŠµ_ì‹œìŠ¤í…œ": "ìƒˆë¡œìš´ ì‹œë‚˜ë¦¬ì˜¤ ì¶”ê°€ ì‹œ ìë™ ì ì‘"
}
```

---

## ğŸ”§ êµ¬ì²´ì ì¸ í†µí•© êµ¬í˜„ ê³„íš

### Phase 1: ë°ì´í„° ë³€í™˜ ë¸Œë¦¬ì§€ (Week 1)

#### ğŸ”„ H5toCalvin Converter êµ¬í˜„
```python
# /home/soda/vla/Mobile_VLA/data/processors/h5_to_calvin_converter.py
class H5toCalvinConverter:
    def __init__(self, mobile_data_dir="/home/soda/vla/ROS_action/mobile_vla_dataset/"):
        self.mobile_data_dir = Path(mobile_data_dir)
        self.scenario_map = {
            "1box_vert_left": "ì™¼ìª½ìœ¼ë¡œ ëŒì•„ì„œ ë°•ìŠ¤ë¥¼ ì§€ë‚˜ ì»µê¹Œì§€ ê°€ì„¸ìš”",
            "1box_vert_right": "ì˜¤ë¥¸ìª½ìœ¼ë¡œ ëŒì•„ì„œ ë°•ìŠ¤ë¥¼ ì§€ë‚˜ ì»µê¹Œì§€ ê°€ì„¸ìš”",
            "1box_hori_left": "ì™¼ìª½ ê²½ë¡œë¡œ ë°•ìŠ¤ë¥¼ í”¼í•´ ì»µê¹Œì§€ ê°€ì„¸ìš”",
            "1box_hori_right": "ì˜¤ë¥¸ìª½ ê²½ë¡œë¡œ ë°•ìŠ¤ë¥¼ í”¼í•´ ì»µê¹Œì§€ ê°€ì„¸ìš”",
            "2box_vert_left": "ë‘ ë°•ìŠ¤ ì‚¬ì´ ì™¼ìª½ ê²½ë¡œë¡œ ì»µê¹Œì§€ ê°€ì„¸ìš”",
            "2box_vert_right": "ë‘ ë°•ìŠ¤ ì‚¬ì´ ì˜¤ë¥¸ìª½ ê²½ë¡œë¡œ ì»µê¹Œì§€ ê°€ì„¸ìš”", 
            "2box_hori_left": "ë‘ ë°•ìŠ¤ë¥¼ ì™¼ìª½ìœ¼ë¡œ ìš°íšŒí•´ì„œ ì»µê¹Œì§€ ê°€ì„¸ìš”",
            "2box_hori_right": "ë‘ ë°•ìŠ¤ë¥¼ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ìš°íšŒí•´ì„œ ì»µê¹Œì§€ ê°€ì„¸ìš”"
        }
    
    def convert_h5_episode(self, h5_file_path):
        """mobile_vla_data_collector.py ì¶œë ¥ â†’ Calvin í˜•ì‹"""
        with h5py.File(h5_file_path, 'r') as f:
            # mobile_vla_data_collector.py í˜•ì‹ ì½ê¸°
            images = f['images'][:]                    # [T, H, W, 3]
            actions = f['actions'][:]                  # [T, 4] (linear_x, linear_y, angular_z, type?)
            action_event_types = f['action_event_types'][:]  # [T] ì´ë²¤íŠ¸ íƒ€ì…
            
            # ì—í”¼ì†Œë“œëª…ì—ì„œ ì‹œë‚˜ë¦¬ì˜¤ ì¶”ì¶œ
            episode_name = f.attrs['episode_name']
            scenario = self.extract_scenario(episode_name)
            
            # Calvin í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            calvin_episode = {
                "rgb": images,                         # [T, H, W, 3] âœ… ê·¸ëŒ€ë¡œ ì‚¬ìš©
                "action": self.convert_4d_to_calvin_action(actions),  # [T, 7] í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                "language": self.scenario_map[scenario],              # í•œêµ­ì–´ ëª…ë ¹
                "scenario_id": scenario,                             # ğŸ†• ì‹œë‚˜ë¦¬ì˜¤ ë©”íƒ€ë°ì´í„°
                "action_events": action_event_types                   # ğŸ†• ì´ë²¤íŠ¸ íƒ€ì… ì •ë³´
            }
            
        return calvin_episode
    
    def convert_4d_to_calvin_action(self, mobile_actions):
        """4D Mobile ì•¡ì…˜ â†’ 7D Calvin í˜¸í™˜ ì•¡ì…˜"""
        # [linear_x, linear_y, angular_z, type] â†’ [x, y, z, roll, pitch, yaw, gripper]
        T = mobile_actions.shape[0]
        calvin_actions = np.zeros((T, 7))
        
        # Mobile ì•¡ì…˜ì„ Calvin í˜•ì‹ì— ë§¤í•‘
        calvin_actions[:, 0] = mobile_actions[:, 0]  # linear_x â†’ x translation
        calvin_actions[:, 1] = mobile_actions[:, 1]  # linear_y â†’ y translation  
        calvin_actions[:, 2] = 0.0                   # z translation (ê³ ì •)
        calvin_actions[:, 3] = 0.0                   # roll (ê³ ì •)
        calvin_actions[:, 4] = 0.0                   # pitch (ê³ ì •)
        calvin_actions[:, 5] = mobile_actions[:, 2]  # angular_z â†’ yaw rotation
        calvin_actions[:, 6] = mobile_actions[:, 3]  # action_type â†’ gripper (ì¬í•´ì„)
        
        return calvin_actions
```

#### ğŸ® ActionSpace Adapter êµ¬í˜„
```python
# /home/soda/vla/Mobile_VLA/models/encoders/mobile_action_encoder.py
class MobileActionEncoder:
    def __init__(self):
        # mobile_vla_data_collector.pyì˜ WASD_TO_CONTINUOUS ê¸°ì¤€
        self.action_bounds = {
            "linear_x": [-2.0, 2.0],     # WASD_TO_CONTINUOUSì—ì„œ ìµœëŒ€ 1.15 ì‚¬ìš©
            "linear_y": [-2.0, 2.0],     # ì—¬ìœ ìˆê²Œ 2.0ìœ¼ë¡œ ì„¤ì •
            "angular_z": [-3.14, 3.14],  # ìµœëŒ€ 1.15 ì‚¬ìš©, 2Ï€ê¹Œì§€ í™•ì¥
        }
        self.action_types = {
            0: "move",      # ì´ë™ ì•¡ì…˜
            1: "rotate",    # íšŒì „ ì•¡ì…˜
            2: "stop",      # ì •ì§€ ì•¡ì…˜
            3: "special"    # íŠ¹ìˆ˜ ì•¡ì…˜ (ë¯¸ë˜ í™•ì¥ìš©)
        }
    
    def encode_mobile_action(self, mobile_action):
        """4D Mobile ì•¡ì…˜ì„ VLM ì´í•´ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì¸ì½”ë”©"""
        linear_x, linear_y, angular_z, action_type = mobile_action
        
        # ì—°ì† ì•¡ì…˜ ì •ê·œí™” (-1 ~ 1)
        norm_linear_x = self.normalize_action(linear_x, self.action_bounds["linear_x"])
        norm_linear_y = self.normalize_action(linear_y, self.action_bounds["linear_y"])
        norm_angular_z = self.normalize_action(angular_z, self.action_bounds["angular_z"])
        
        # ì•¡ì…˜ íƒ€ì… ì›í•« ì¸ì½”ë”©
        action_type_onehot = np.zeros(4)
        action_type_onehot[int(action_type)] = 1.0
        
        return {
            "continuous": np.array([norm_linear_x, norm_linear_y, norm_angular_z]),
            "discrete": action_type_onehot,
            "raw": mobile_action
        }
```

### Phase 2: ëª¨ë¸ ì ì‘ (Week 2)

#### ğŸ§  Mobile-adapted Policy Head
```python
# /home/soda/vla/Mobile_VLA/models/policy_heads/mobile_policy_head.py
class MobilePolicyHead(nn.Module):
    def __init__(self, hidden_size=1024, dropout=0.1):
        super().__init__()
        # mobile_vla_data_collector.pyì˜ 4D ì•¡ì…˜ì— íŠ¹í™”
        
        # ì—°ì† ì•¡ì…˜ ì˜ˆì¸¡ (linear_x, linear_y, angular_z)
        self.movement_head = nn.Sequential(
            nn.Linear(hidden_size, 512),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(256, 3),  # [linear_x, linear_y, angular_z]
            nn.Tanh()  # -1 ~ 1 ë²”ìœ„ë¡œ ì •ê·œí™”
        )
        
        # ì•¡ì…˜ íƒ€ì… ë¶„ë¥˜ (ì´ë™/íšŒì „/ì •ì§€/íŠ¹ìˆ˜)
        self.action_type_head = nn.Sequential(
            nn.Linear(hidden_size, 512),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(256, 4)   # [move, rotate, stop, special]
        )
        
        # ì‹œë‚˜ë¦¬ì˜¤ ì»¨í…ìŠ¤íŠ¸ ìœµí•©
        self.scenario_fusion = nn.MultiheadAttention(
            embed_dim=hidden_size, 
            num_heads=8,
            dropout=dropout
        )
        
    def forward(self, vlm_features, scenario_embedding=None):
        # ì‹œë‚˜ë¦¬ì˜¤ ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ìœµí•©
        if scenario_embedding is not None:
            fused_features, _ = self.scenario_fusion(
                vlm_features, scenario_embedding, scenario_embedding
            )
        else:
            fused_features = vlm_features
            
        # 4D ì•¡ì…˜ ì˜ˆì¸¡
        movement_actions = self.movement_head(fused_features)      # [3] ì—°ì†
        action_type_logits = self.action_type_head(fused_features) # [4] ì´ì‚°
        
        return {
            "movement": movement_actions,
            "action_type": action_type_logits,
            "movement_raw": self.denormalize_movement(movement_actions),
            "action_type_pred": torch.argmax(action_type_logits, dim=-1)
        }
    
    def denormalize_movement(self, normalized_actions):
        """ì •ê·œí™”ëœ ì•¡ì…˜ì„ ì‹¤ì œ mobile_vla_data_collector ë²”ìœ„ë¡œ ë³€í™˜"""
        # Tanh ì¶œë ¥ (-1~1)ì„ ì‹¤ì œ ì•¡ì…˜ ë²”ìœ„ë¡œ ë³€í™˜
        linear_x = normalized_actions[..., 0] * 2.0   # [-2.0, 2.0]
        linear_y = normalized_actions[..., 1] * 2.0   # [-2.0, 2.0]  
        angular_z = normalized_actions[..., 2] * 3.14 # [-Ï€, Ï€]
        
        return torch.stack([linear_x, linear_y, angular_z], dim=-1)
```

#### ğŸ¯ Scenario-Aware VLM Backbone
```python
# /home/soda/vla/Mobile_VLA/models/backbones/mobile_paligemma.py
class MobilePaliGemma(nn.Module):
    def __init__(self, configs):
        super().__init__()
        # ê¸°ì¡´ PaliGemma ë°±ë³¸ ë¡œë“œ (âœ… ìœ ì§€)
        self.paligemma = self.load_pretrained_paligemma(configs)
        
        # ì‹œë‚˜ë¦¬ì˜¤ ì¸ì½”ë” ì¶”ê°€ (ğŸ†• Mobile VLA íŠ¹í™”)
        self.scenario_encoder = nn.Embedding(8, self.paligemma.config.hidden_size)
        
        # Mobile Policy Headë¡œ êµì²´ (ğŸ”„ ë³€ê²½)
        self.policy_head = MobilePolicyHead(
            hidden_size=self.paligemma.config.hidden_size,
            dropout=configs.get("dropout", 0.1)
        )
        
        # ì‹œë‚˜ë¦¬ì˜¤ ë§¤í•‘
        self.scenario_to_id = {
            "1box_vert_left": 0,   "1box_vert_right": 1,
            "1box_hori_left": 2,   "1box_hori_right": 3,
            "2box_vert_left": 4,   "2box_vert_right": 5,
            "2box_hori_left": 6,   "2box_hori_right": 7
        }
    
    def forward(self, images, instructions, scenarios=None):
        # ê¸°ì¡´ PaliGemma ì‹œê°-ì–¸ì–´ ì¸ì½”ë”© (âœ… ìœ ì§€)
        vlm_output = self.paligemma(
            pixel_values=images,
            input_ids=instructions["input_ids"],
            attention_mask=instructions["attention_mask"]
        )
        
        # VLM íŠ¹ì§• ì¶”ì¶œ
        vlm_features = vlm_output.last_hidden_state.mean(dim=1)  # [B, hidden_size]
        
        # ì‹œë‚˜ë¦¬ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€ (ğŸ†• Mobile VLA íŠ¹í™”)
        scenario_embedding = None
        if scenarios is not None:
            scenario_ids = torch.tensor([
                self.scenario_to_id[scenario] for scenario in scenarios
            ]).to(vlm_features.device)
            scenario_embedding = self.scenario_encoder(scenario_ids)
        
        # Mobile ì•¡ì…˜ ì˜ˆì¸¡ (ğŸ”„ ë³€ê²½)
        action_output = self.policy_head(vlm_features, scenario_embedding)
        
        return action_output
```

### Phase 3: í†µí•© í•™ìŠµ ì‹œìŠ¤í…œ (Week 3)

#### ğŸ“š Mobile-specific Trainer
```python
# /home/soda/vla/Mobile_VLA/training/trainers/mobile_base_trainer.py
class MobileBaseTrainer(BaseTrainer):
    def __init__(self, configs):
        super().__init__(configs)
        
        # mobile_vla_data_collector.py ì‹œë‚˜ë¦¬ì˜¤ë³„ ê°€ì¤‘ì¹˜
        self.scenario_weights = {
            "1box_vert_left": 1.0,    # ê¸°ë³¸ ë‚œì´ë„
            "1box_vert_right": 1.0,   # ê¸°ë³¸ ë‚œì´ë„
            "1box_hori_left": 1.2,    # ì¤‘ê°„ ë‚œì´ë„
            "1box_hori_right": 1.1,   # ì¤‘ê°„ ë‚œì´ë„
            "2box_vert_left": 1.5,    # ê³ ê¸‰ ë‚œì´ë„
            "2box_vert_right": 1.4,   # ê³ ê¸‰ ë‚œì´ë„
            "2box_hori_left": 1.8,    # ìµœê³  ë‚œì´ë„
            "2box_hori_right": 1.6    # ìµœê³  ë‚œì´ë„
        }
        
        # Mobile íŠ¹í™” ì†ì‹¤ í•¨ìˆ˜ ê°€ì¤‘ì¹˜
        self.movement_loss_weight = 1.0
        self.action_type_loss_weight = 0.5
        self.scenario_consistency_weight = 0.1
        
    def _get_mobile_loss(self, prediction, target, scenario):
        """Mobile VLA íŠ¹í™” ì†ì‹¤ í•¨ìˆ˜"""
        # ì—°ì† ì•¡ì…˜ ì†ì‹¤ (movement)
        movement_loss = F.mse_loss(
            prediction["movement"], 
            target["movement"]
        )
        
        # ì•¡ì…˜ íƒ€ì… ë¶„ë¥˜ ì†ì‹¤
        action_type_loss = F.cross_entropy(
            prediction["action_type"], 
            target["action_type"]
        )
        
        # ì‹œë‚˜ë¦¬ì˜¤ ì¼ê´€ì„± ì†ì‹¤ (ê°™ì€ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì¼ê´€ëœ í–‰ë™ ìœ ë„)
        scenario_consistency_loss = self.compute_scenario_consistency_loss(
            prediction, scenario
        )
        
        # ì‹œë‚˜ë¦¬ì˜¤ë³„ ê°€ì¤‘ì¹˜ ì ìš©
        scenario_weight = self.scenario_weights.get(scenario, 1.0)
        
        total_loss = (
            self.movement_loss_weight * movement_loss +
            self.action_type_loss_weight * action_type_loss +
            self.scenario_consistency_weight * scenario_consistency_loss
        ) * scenario_weight
        
        return {
            "total_loss": total_loss,
            "movement_loss": movement_loss,
            "action_type_loss": action_type_loss,
            "scenario_consistency_loss": scenario_consistency_loss,
            "scenario_weight": scenario_weight
        }
    
    def training_step(self, batch, batch_idx):
        """mobile_vla_data_collector.py ë°ì´í„° ê¸°ë°˜ í•™ìŠµ"""
        # ë°°ì¹˜ì—ì„œ Mobile VLA ë°ì´í„° ì¶”ì¶œ
        images = batch["images"]          # [B, T, H, W, 3]
        actions = batch["actions"]        # [B, T, 4]
        scenarios = batch["scenarios"]    # [B] scenario names
        instructions = batch["instructions"]  # [B] tokenized Korean instructions
        
        # ëª¨ë¸ í¬ì›Œë“œ
        predictions = self.model(images, instructions, scenarios)
        
        # íƒ€ê²Ÿ ì•¡ì…˜ ë¶„ë¦¬
        target_movement = actions[..., :3]    # [linear_x, linear_y, angular_z]
        target_action_type = actions[..., 3].long()  # action_type
        
        targets = {
            "movement": target_movement,
            "action_type": target_action_type
        }
        
        # ì‹œë‚˜ë¦¬ì˜¤ë³„ ì†ì‹¤ ê³„ì‚°
        batch_losses = []
        for i, scenario in enumerate(scenarios):
            pred_i = {k: v[i] for k, v in predictions.items()}
            target_i = {k: v[i] for k, v in targets.items()}
            loss_i = self._get_mobile_loss(pred_i, target_i, scenario)
            batch_losses.append(loss_i["total_loss"])
        
        total_loss = torch.stack(batch_losses).mean()
        
        # ë¡œê¹…
        self.log_dict({
            "train_total_loss": total_loss,
            "train_movement_loss": movement_loss,
            "train_action_type_loss": action_type_loss,
        }, prog_bar=True)
        
        return total_loss
```

### Phase 4: ROS2 ì‹¤ì‹œê°„ í†µí•© (Week 4)

#### ğŸš€ Real-time Inference Engine
```python
# /home/soda/vla/Mobile_VLA/inference/engines/mobile_inference_engine.py
class MobileInferenceEngine:
    def __init__(self, model_path, configs):
        # í•™ìŠµëœ Mobile VLA ëª¨ë¸ ë¡œë“œ
        self.model = MobilePaliGemma.load_from_checkpoint(model_path)
        self.model.eval()
        
        # mobile_vla_data_collector.pyì™€ í˜¸í™˜ë˜ëŠ” ì•¡ì…˜ í¬ë§·í„°
        self.action_formatter = MobileActionFormatter()
        
        # ROS2 í¼ë¸”ë¦¬ì…” (ê¸°ì¡´ mobile_vla_data_collector.pyì™€ ë™ì¼)
        self.cmd_pub = self.create_publisher(Twist, '/cmd_vel', 10)
        
    def predict_action(self, current_image, instruction, scenario):
        """ì‹¤ì‹œê°„ ì•¡ì…˜ ì˜ˆì¸¡"""
        with torch.no_grad():
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            processed_image = self.preprocess_image(current_image)
            
            # ëª…ë ¹ì–´ í† í¬ë‚˜ì´ì§•
            tokenized_instruction = self.tokenize_instruction(instruction)
            
            # ëª¨ë¸ ì¶”ë¡ 
            prediction = self.model(
                images=processed_image.unsqueeze(0),
                instructions=tokenized_instruction,
                scenarios=[scenario]
            )
            
            # Mobile VLA ì•¡ì…˜ì„ mobile_vla_data_collector í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            mobile_action = self.action_formatter.format_for_mobile_vla(prediction)
            
        return mobile_action
    
    def execute_action(self, mobile_action):
        """mobile_vla_data_collector.pyì™€ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì•¡ì…˜ ì‹¤í–‰"""
        # mobile_vla_data_collector.pyì˜ publish_cmd_vel ë©”ì„œë“œì™€ í˜¸í™˜
        twist = Twist()
        twist.linear.x = float(mobile_action["linear_x"])
        twist.linear.y = float(mobile_action["linear_y"])
        twist.angular.z = float(mobile_action["angular_z"])
        
        self.cmd_pub.publish(twist)
        
        # ì‹¤ì œ ë¡œë´‡ ì œì–´ (mobile_vla_data_collector.pyì™€ ë™ì¼)
        if self.driver and ROBOT_AVAILABLE:
            self.control_physical_robot(mobile_action)
```

---

## ğŸ“ˆ í†µí•© í›„ ì˜ˆìƒ ì„±ëŠ¥ ê°œì„ 

### 1. **ë°ì´í„° íš¨ìœ¨ì„±** 
- **í˜„ì¬**: ìˆ˜ë™ WASD ì œì–´ë¡œ ë°ì´í„° ìˆ˜ì§‘
- **í†µí•© í›„**: í•™ìŠµëœ ëª¨ë¸ì´ ë°ì´í„° ë¶€ì¡± ì˜ì—­ ìë™ ì‹ë³„ â†’ ëŠ¥ë™ì  ë°ì´í„° ìˆ˜ì§‘

### 2. **í•™ìŠµ ì†ë„**
- **í˜„ì¬**: ë°ì´í„° ìˆ˜ì§‘ê³¼ í•™ìŠµì´ ë¶„ë¦¬ëœ í”„ë¡œì„¸ìŠ¤
- **í†µí•© í›„**: ë°ì´í„° ìˆ˜ì§‘ â†’ ì¦‰ì‹œ í•™ìŠµ â†’ ëª¨ë¸ ê°œì„  â†’ ë” ë‚˜ì€ ë°ì´í„° ìˆ˜ì§‘ (ì„ ìˆœí™˜)

### 3. **ì‹¤ì‹œê°„ ì„±ëŠ¥**
- **í˜„ì¬**: í‚¤ë³´ë“œ ì œì–´ ê¸°ë°˜ ë°˜ì‘í˜• ì¡°ì‘
- **í†µí•© í›„**: VLM ê¸°ë°˜ ì§€ëŠ¥í˜• ë„¤ë¹„ê²Œì´ì…˜ + ê¸°ì¡´ ì•ˆì „ì„± ìœ ì§€

### 4. **í™•ì¥ì„±**
- **í˜„ì¬**: 8ê°€ì§€ ê³ ì • ì‹œë‚˜ë¦¬ì˜¤
- **í†µí•© í›„**: ìƒˆë¡œìš´ ì‹œë‚˜ë¦¬ì˜¤ ìë™ í•™ìŠµ + ê¸°ì¡´ ì‹œë‚˜ë¦¬ì˜¤ ì„±ëŠ¥ í–¥ìƒ

---

## ğŸ¯ êµ¬í˜„ ë§ˆì¼ìŠ¤í†¤

### Week 1: ë°ì´í„° ë¸Œë¦¬ì§€ êµ¬ì¶•
- [x] H5toCalvin Converter êµ¬í˜„
- [x] ActionSpace Adapter êµ¬í˜„  
- [x] ê¸°ë³¸ ë³€í™˜ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸

### Week 2: ëª¨ë¸ ì ì‘
- [ ] MobilePolicyHead êµ¬í˜„
- [ ] MobilePaliGemma êµ¬í˜„
- [ ] ì•¡ì…˜ ê³µê°„ ë³€í™˜ í…ŒìŠ¤íŠ¸

### Week 3: í•™ìŠµ ì‹œìŠ¤í…œ í†µí•©
- [ ] MobileBaseTrainer êµ¬í˜„
- [ ] ì‹œë‚˜ë¦¬ì˜¤ë³„ í•™ìŠµ í…ŒìŠ¤íŠ¸
- [ ] ì†ì‹¤ í•¨ìˆ˜ ìµœì í™”

### Week 4: ROS2 ì‹¤ì‹œê°„ í†µí•©
- [ ] MobileInferenceEngine êµ¬í˜„
- [ ] mobile_vla_data_collector.pyì™€ ì—°ë™
- [ ] ì‹¤ì‹œê°„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

---

## ğŸ ìµœì¢… í†µí•© ë¹„ì „

ì´ í†µí•© ê³„íšì„ í†µí•´ **mobile_vla_data_collector.pyì˜ ì‹¤ìš©ì„±**ê³¼ **RoboVLMsì˜ í•™ìŠµ ê¸°ìˆ ë ¥**ì„ ê²°í•©í•˜ì—¬, ì‹¤ì œ í™˜ê²½ì—ì„œ ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥í•œ **Mobile VLA ì‹œìŠ¤í…œ**ì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

ê¸°ì¡´ì˜ **8ê°€ì§€ ì»µ ë„ë‹¬ ì‹œë‚˜ë¦¬ì˜¤** ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ê°•ë ¥í•œ **ì‹œê°-ì–¸ì–´-ë„¤ë¹„ê²Œì´ì…˜** ëª¨ë¸ì„ í•™ìŠµí•˜ê³ , ì´ë¥¼ ë‹¤ì‹œ **mobile_vla_data_collector.py**ë¥¼ í†µí•´ ì‹¤ì‹œê°„ìœ¼ë¡œ ê²€ì¦í•˜ê³  ê°œì„ í•˜ëŠ” **ì„ ìˆœí™˜ ì‹œìŠ¤í…œ**ì´ ì™„ì„±ë©ë‹ˆë‹¤.

**Robo-Mobile VLA ë…¼ë¬¸**ì˜ í•µì‹¬ ê¸°ì—¬ë„ëŠ” ì´ëŸ¬í•œ **ì‹¤ìš©ì  í†µí•© ì ‘ê·¼ë²•**ê³¼ **ì‹¤ì‹œê°„ ì„±ëŠ¥ ê²€ì¦**ì´ ë  ê²ƒì…ë‹ˆë‹¤.
