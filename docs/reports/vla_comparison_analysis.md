# VLA 모델 비교 분석: 데이터셋 규모 및 과적합 평가

**날짜**: 2025-12-07 03:25  
**목적**: 다른 VLA 논문들과 비교하여 데이터셋 충분성 및 과적합 여부 평가

---

## 📊 데이터셋 규모 비교 (출처: 논문 검색 결과)

### 주요 VLA 모델 데이터셋

| 모델 | 에피소드 수 | 태스크 수 | 오브젝트 수 | 환경 수 |
|:---|:---:|:---:|:---:|:---:|
| **OpenVLA** (pre-train) | **970,000** | 20+ datasets | 다수 | 다수 |
| **OpenVLA** (fine-tune) | ~100 | 1-few | 소수 | 1 |
| **RT-2** (RT-1 data) | **73,499** | 200+ | 17 | 1 |
| **RoboFlamingo** | "소량" | CALVIN 기준 | 다수 | 4 |
| **CALVIN** | ~24시간 (2.4M steps) | 32 | 다수 | 4 |
| **우리 모델** | **500** | **2** | **2** | **1** |

---

## 🚨 솔직한 평가

### 1. 에피소드 수

| 비교 대상 | 비율 | 평가 |
|:---|:---:|:---|
| vs OpenVLA (pre-train) | 0.05% | 🔴 매우 부족 |
| vs RT-2 | 0.68% | 🔴 매우 부족 |
| vs OpenVLA (fine-tune) | 500% | 🟢 충분 |

**해석**: 
- **Pre-training 수준과 비교하면 매우 부족**
- **Fine-tuning 수준과 비교하면 충분**
- OpenVLA 논문에서 fine-tuning에 ~100 에피소드 권장 → 우리는 5배

### 2. 태스크 다양성

| 항목 | 우리 | 다른 연구 | 평가 |
|:---|:---:|:---:|:---:|
| 태스크 수 | 2 | 32~200+ | 🔴 매우 부족 |
| 태스크 유형 | Left/Right | pick/place/push/pull 등 | 🔴 단순 |

**해석**:
- 우리는 **2개의 태스크** (Left, Right obstacle avoidance)
- CALVIN은 32개, RT-2는 200개 이상
- **일반화 능력 검증에는 부족**

### 3. 오브젝트 다양성

| 항목 | 우리 | 다른 연구 | 평가 |
|:---|:---:|:---:|:---:|
| 오브젝트 수 | 2 | 17~수십개 | 🔴 매우 부족 |
| 오브젝트 종류 | bottle, box | 다양 | 🔴 단순 |

**해석**:
- RT-1/RT-2: 17개 오브젝트
- 우리: **고정된 2개 오브젝트**
- **새로운 오브젝트에 대한 일반화 불가능**

### 4. 환경 다양성

| 항목 | 우리 | 다른 연구 | 평가 |
|:---|:---:|:---:|:---:|
| 환경 수 | 1 | 4+ | 🔴 부족 |
| 환경 변화 | 없음 | 조명/배치/텍스처 | 🔴 없음 |

---

## 📈 과적합 분석

### Train vs Validation Loss

| Epoch | Train Loss | Val Loss | Gap |
|:---|:---:|:---:|:---:|
| 0 | 0.418 | - | - |
| 9 (최종) | **0.012** | **0.036** | 0.024 |

### 과적합 지표

```
Train Loss: 0.012
Val Loss:   0.036
Gap:        0.024 (3배 차이)
```

### 과적합 진단

| 지표 | 값 | 평가 |
|:---|:---:|:---|
| **Train/Val Gap** | 3x | 🟡 경미한 과적합 |
| **Val Loss 수렴** | 0.036 | 🟢 안정적 |
| **Train Loss** | 0.012 | 🟢 학습 성공 |

**결론**: 
- **경미한 과적합 존재** (train 0.012 vs val 0.036)
- 하지만 **심각한 수준은 아님** (val loss도 수렴)
- **데이터 증강 또는 regularization으로 개선 가능**

---

## 🔍 심층 분석

### 우리 실험의 성격

| 항목 | 설명 |
|:---|:---|
| **목적** | RoboVLMs Transfer 검증 |
| **범위** | Proof of Concept |
| **주장** | 7DOF → 2DOF 가능한가? |

### 정당화 가능한 부분

1. **Fine-tuning 수준으로는 충분**
   - OpenVLA fine-tune: ~100 episodes
   - 우리: 500 episodes (5배)

2. **Task-specific 학습**
   - 단일 태스크에 집중
   - 깊이 있는 학습

3. **Proof of Concept**
   - 완전한 generalist 목표 아님
   - Transfer 가능성 검증이 목적

### 한계점 (인정해야 할 부분)

1. **일반화 능력 미검증**
   - 새 오브젝트 ❌
   - 새 환경 ❌
   - 새 태스크 ❌

2. **데이터 다양성 부족**
   - 고정된 환경
   - 고정된 오브젝트
   - 2개 태스크만

3. **경미한 과적합**
   - Train/Val gap 존재
   - 추가 데이터 필요

---

## 📝 교수님께 솔직하게 말씀드릴 내용

### 우리 데이터의 위치

```
                        데이터 스케일
                        
OpenVLA Pre-train ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 970,000
RT-2 (RT-1)       ━━━━━━━━━━━━━━━━━━━ 73,499
CALVIN            ━━━━━━━━━━ (24h, 2.4M steps)
RoboFlamingo      ━━━━ "소량"
OpenVLA Fine-tune ━ ~100
우리 모델          ━━━ 500  ← 여기
```

### 결론

> **"우리 데이터는 Pre-training 수준에 비해 100배 이상 부족하지만,  
> Fine-tuning 수준에서는 충분합니다.  
> 목표가 'Transfer 가능성 검증'이었다면, 500개로도 성공적으로 증명했습니다.  
> 다만, 일반화 능력이나 robustness를 주장하기는 어렵습니다."**

---

## 🎯 Honest Assessment

### 우리가 증명한 것

✅ RoboVLMs 7DOF → 2DOF Transfer 가능  
✅ 언어 조건화 (Left/Right) 작동  
✅ 500개 에피소드로 92% 방향 정확도  

### 우리가 증명하지 못한 것

❌ 새로운 오브젝트에 대한 일반화  
❌ 새로운 환경에 대한 일반화  
❌ 다양한 태스크 처리 능력  
❌ 과적합 완전 해소  

---

## 🚀 향후 개선 방향

| 우선순위 | 개선 사항 | 효과 |
|:---:|:---|:---|
| 1 | 환경 다양화 (조명, 배경) | 일반화 향상 |
| 2 | 오브젝트 추가 (3-5개) | 물체 인식 검증 |
| 3 | 태스크 추가 (forward, backward) | 태스크 일반화 |
| 4 | 데이터 증강 | 과적합 감소 |
| 5 | Regularization 추가 | 안정성 향상 |

---

## 📊 비유적 요약

> **"마라톤 선수 훈련으로 비유하면..."**
>
> - **OpenVLA**: 올림픽 선수 (수년간 전 세계 마라톤 참가)
> - **RT-2**: 국가대표 (수천 번 연습)
> - **우리 모델**: 동네 마라톤 완주자 (500번 연습)
>
> 우리는 "달릴 수 있다"는 것을 증명했지만,  
> "모든 코스에서 달릴 수 있다"고 주장하기는 어렵습니다.
