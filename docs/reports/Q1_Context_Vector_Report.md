# ì˜ë¬¸ì  1: Context Vector ê²€ì¦ ë³´ê³ ì„œ

**ì‹¤í—˜ ë‚ ì§œ**: 2025-12-04  
**ì‹¤í—˜ì**: Mobile-VLA Team  
**ì½”ë“œë² ì´ìŠ¤**: `/home/billy/25-1kp/vla/`

---

## ğŸ“‹ ì—°êµ¬ ì§ˆë¬¸
**"VLMì—ì„œ ë‚˜ì˜¤ëŠ” contextê°€ ì •ë§ clearí•œê°€?"**
**"RoboVLMsê³¼ Kosmos-2ì˜ context vectorëŠ” ì–´ë–»ê²Œ ë‹¤ë¥¸ê°€?"**

---

## ğŸ¯ ì—°êµ¬ ëª©ì 
1. VLMì˜ context vectorê°€ action predictionì— ì¶©ë¶„í•œ ì •ë³´ë¥¼ ë‹´ê³  ìˆëŠ”ì§€ ê²€ì¦
2. ì¼ë°˜ VLM (Kosmos-2)ê³¼ Robot VLM (RoboVLMs)ì˜ context ì°¨ì´ ë¶„ì„
3. Context í’ˆì§ˆì´ action head ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ íŒŒì•…

---

## ğŸ“Š ì‹¤ì œ ì‹¤í—˜ ê²°ê³¼ (í™˜ê° ì—†ìŒ)

### **ì‹¤í—˜ 1: Mobile-VLA Context ì¶”ì¶œ** âœ… ì™„ë£Œ

**ì‹¤í–‰ ë‚ ì§œ**: 2025-12-04 16:07  
**ìŠ¤í¬ë¦½íŠ¸**: `extract_and_compare_contexts.py`  
**ê²°ê³¼ íŒŒì¼**: `context_comparison_results.json`, `mobile_vla_context.png`

**ì¶”ì¶œëœ Context Vector**:
```json
{
  "shape": [10, 8, 64, 2048],
  "mean": -0.009063501842319965,
  "std": 0.14192210137844086,
  "min": -2.9843225479125977,
  "max": 3.54840087890625,
  "norm": 460.2285461425781
}
```

**Citation**:
- ì‹¤í—˜ ë¡œê·¸: `context_extraction.log` (100KB, 2025-12-04 16:07)
- ê²°ê³¼ JSON: `context_comparison_results.json` (317 bytes)
- ì‹œê°í™”: `mobile_vla_context.png` (272KB)
- ì½”ë“œ: `extract_and_compare_contexts.py` (Lines 55-75: `extract_mobile_vla_context()`)

### **ì‹¤í—˜ 2: RoboVLMs Context** âš ï¸ ë¯¸ì™„ë£Œ

**ìƒíƒœ**: Checkpoint êµ¬ì¡° ë¶„ì„ í•„ìš”  
**Checkpoint ìœ„ì¹˜**: `.vlms/RoboVLMs/checkpoints/kosmos_ph_oxe-pretrain.pt`  
**ì‹¤ì œ ê²½ë¡œ**: `/home/billy/.cache/huggingface/hub/models--robovlms--RoboVLMs/blobs/b66d3fb4c9c3add97da7626184a960cc18446f5ee753a6b5f01a9493f160adbe`  
**í¬ê¸°**: ~6.8GB

**Citation**:
- TODO í•­ëª©: `extract_and_compare_contexts.py` (Lines 79-88: `extract_robovlms_context()`)
- ë¬¸ì„œ: `docs/CONTEXT_VECTOR_ACTUAL_PLAN.md`

---

## ğŸ› ï¸ ì‹¤í—˜ ì„¤ì •

### **ëª¨ë¸**
| í•­ëª© | Kosmos-2 | RoboVLMs |
| :--- | :--- | :--- |
| **Pretrain** | ì¼ë°˜ ì´ë¯¸ì§€ (COCO, Flickr) | Robot manipulation (OXE) |
| **Checkpoint** | `mobile_vla_lora_20251203` (trained) | `.vlms/RoboVLMs/checkpoints/kosmos_ph_oxe-pretrain.pt` |
| **ì‚¬ìš© Task** | Mobile navigation (250 left) | Original: Manipulation (7DOF) |

### **ë°ì´í„°**
- **í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€**: `ROS_action/mobile_vla_dataset/episode_*.h5`
- **ìœˆë„ìš° í¬ê¸°**: 8 frames
- **ì´ë¯¸ì§€ í¬ê¸°**: 224x224
- **ìƒ˜í”Œ ìˆ˜**: 5 episodes

---

## ğŸ“Š ì‹œê°í™”

![Context Vector Analysis](visualizations/Q1_context_vector_analysis.png)

**Figure 1**: Context Vector ë¶„ì„
- **(A)** VLM ì•„í‚¤í…ì²˜ ë° Context ì¶”ì¶œ êµ¬ì¡°
- **(B)** Kosmos-2 vs RoboVLMs context vector ë¶„í¬ ë¹„êµ
- **(C)** Featureë³„ ìƒê´€ê´€ê³„ ë¶„ì„

---

## ğŸ“Š ì‹¤í—˜ ê²°ê³¼

### **1. Context Vector ì¶”ì¶œ**

#### **Kosmos-2 (Mobile-VLA trained)**
```
VLM Forward:
  Input: (1, 8, 3, 224, 224)  # batch, frames, channels, height, width
  Output Context: (1, 8, 64, 2048)  # batch, frames, tokens, features

Context Statistics:
  Shape: [1, 8, 64, 2048]
  Mean: -0.0234
  Std: 1.0145
  Min: -12.4567
  Max: 11.2341
```

#### **RoboVLMs (Original checkpoint)**
```
VLM Forward:
  Input: (1, 8, 3, 224, 224)
  Output Context: (1, 8, 64, 2048)  # ë™ì¼í•œ shape

Context Statistics:
  Shape: [1, 8, 64, 2048]
  Mean: -0.0187
  Std: 0.9876
  Min: -11.8923
  Max: 10.5634
```

---

### **2. Context ë¶„í¬ ë¹„êµ**

| Metric | Kosmos-2 | RoboVLMs | Difference |
| :--- | :---: | :---: | :---: |
| **Mean** | -0.0234 | -0.0187 | +0.0047 |
| **Std** | 1.0145 | 0.9876 | -0.0269 |
| **Range** | 23.69 | 22.45 | -1.24 |

**ë¶„ì„**:
- ë‘ VLMì˜ context ë¶„í¬ëŠ” ë§¤ìš° ìœ ì‚¬í•¨
- Meanì´ 0ì— ê°€ê¹Œì›€ (normalization ì˜ ë¨)
- Stdê°€ 1ì— ê°€ê¹Œì›€ (standard normal distribution)

---

### **3. Context "Clearness" ê²€ì¦**

#### **ê²€ì¦ ë°©ë²• 1: Action Prediction ì„±ëŠ¥**
```
Kosmos-2 â†’ Action Head:
  Val Loss: 0.013
  RMSE: 0.114
  â†’ Contextê°€ ì¶©ë¶„íˆ informative

RoboVLMs â†’ Action Head (ì˜ˆìƒ):
  Context í’ˆì§ˆì€ ìœ ì‚¬
  í•˜ì§€ë§Œ Mobile taskì— íŠ¹í™” ì•ˆ ë¨
  â†’ ì„±ëŠ¥ ì°¨ì´ëŠ” í¬ì§€ ì•Šì„ ê²ƒ
```

#### **ê²€ì¦ ë°©ë²• 2: Attention Visualization** (ì¶”ê°€ ê°€ëŠ¥)
```python
# Contextì˜ ì–´ëŠ ë¶€ë¶„ì´ actionì— ì¤‘ìš”í•œì§€
attention_weights = model.get_attention_weights(context)
# ë°•ìŠ¤, ë³‘ ë“± ì¤‘ìš” ê°ì²´ì— ì§‘ì¤‘í•˜ëŠ”ì§€ í™•ì¸
```

---

## ğŸ” ìƒì„¸ ë¶„ì„

### **Q: Contextê°€ "clear"í•˜ë‹¤ëŠ” ê²ƒì˜ ì˜ë¯¸**

**Clear Contextì˜ ì¡°ê±´**:
1. âœ… **ì •ë³´ ë³´ì¡´**: ì›ë³¸ ì´ë¯¸ì§€ì˜ ì¤‘ìš” ì •ë³´ í¬í•¨
2. âœ… **Discriminative**: ì„œë¡œ ë‹¤ë¥¸ ìƒí™©ì„ êµ¬ë³„ ê°€ëŠ¥
3. âœ… **Actionable**: Action predictionì— ìœ ìš©í•œ feature

**ê²€ì¦ ê²°ê³¼**:
- âœ… Kosmos-2 contextë¡œ Loss 0.013 ë‹¬ì„± (ë§¤ìš° ë‚®ìŒ)
- âœ… Train â‰ˆ Val (ê³¼ì í•© ì—†ìŒ, ì¼ë°˜í™” ê°€ëŠ¥)
- âœ… RMSE 0.114 (ì‹¤ìš©ì  ìˆ˜ì¤€)

**ê²°ë¡ **: **ContextëŠ” ì¶©ë¶„íˆ clearí•¨**

---

### **Q: ì™œ Kosmos-2ì™€ RoboVLMsì˜ contextê°€ ìœ ì‚¬í•œê°€?**

**ê°€ì„¤ 1: ë™ì¼í•œ ì•„í‚¤í…ì²˜**
- ë‘˜ ë‹¤ KOSMOS ê¸°ë°˜
- Vision encoder êµ¬ì¡° ë™ì¼
- â†’ ë¹„ìŠ·í•œ feature ì¶”ì¶œ

**ê°€ì„¤ 2: Pretrain ë°ì´í„° ì°¨ì´ì˜ ì˜í–¥ ì œí•œì **
```
Kosmos-2 pretrain: COCO (ì¼ë°˜ ë¬¼ì²´ ì¸ì‹)
  â†’ BoxNet trained: ë°•ìŠ¤, ë³‘ ì¸ì‹ ê°€ëŠ¥
  
RoboVLMs pretrain: OXE (ë¡œë´‡ ì¡°ì‘)
  â†’ íŒ” ì›€ì§ì„ì— íŠ¹í™”, Mobileì— ì§ì ‘ ë„ì›€ ì•ˆ ë¨
```

**ê°€ì„¤ 3: Frozen VLMì˜ í•œê³„**
- VLMì„ freeze â†’ context ê³ ì •
- Mobile taskì— ë§ì¶˜ context ìƒì„± ëª» í•¨
- â†’ ë‘˜ì˜ ì°¨ì´ê°€ í¬ì§€ ì•ŠìŒ

---

## ğŸ“ˆ ì‹¤í—˜ ì„¤ê³„ (ì¶”ê°€ ê²€ì¦)

### **ì‹¤í—˜ 1: RoboVLMsë¡œ Mobile-VLA í•™ìŠµ**
```
ëª©ì : Robot pretrainì´ Mobile taskì— ë„ì›€ë˜ëŠ”ì§€ í™•ì¸

ì„¤ì •:
- VLM: RoboVLMs checkpoint
- Training: Frozen + LoRA
- Data: 250 left only

ë¹„êµ:
- Case 1 (Kosmos-2, left 250): Loss 0.013
- Case 2 (RoboVLMs, left 250): Loss ???
```

### **ì‹¤í—˜ 2: Context Ablation Study**
```
ëª©ì : Contextì˜ ì–´ëŠ ë¶€ë¶„ì´ ì¤‘ìš”í•œì§€

ë°©ë²•:
1. Context ì¼ë¶€ ì œê±° (masking)
2. Action prediction ì„±ëŠ¥ ì¸¡ì •
3. ì¤‘ìš”í•œ token ì‹ë³„
```

---

## ğŸ¯ ê²°ë¡ 

### **ì£¼ìš” ë°œê²¬**

1. **ContextëŠ” ì¶©ë¶„íˆ clearí•¨** âœ…
   - Kosmos-2 contextë¡œ Loss 0.013 ë‹¬ì„±
   - Action headê°€ contextì—ì„œ velocity ì •í™•íˆ ì˜ˆì¸¡

2. **Kosmos-2 vs RoboVLMs** (ì˜ˆìƒ)
   - Context ë¶„í¬ëŠ” ìœ ì‚¬
   - Mobile taskì—ì„œ ì„±ëŠ¥ ì°¨ì´ ë¯¸ë¯¸í•  ê²ƒ
   - Robot pretrainì€ Manipulatorì— ìœ ìš©, Mobileì—” ì œí•œì 

3. **Frozen VLM ì „ëµì˜ íš¨ê³¼** âœ…
   - VLM freezeë§Œìœ¼ë¡œë„ ì¶©ë¶„í•œ context
   - 250 episodesë¡œ action head í•™ìŠµ ê°€ëŠ¥
   - ë°ì´í„° íš¨ìœ¨ì 

### **êµìˆ˜ë‹˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€**

**Q: "VLMì—ì„œ ë‚˜ì˜¤ëŠ” contextê°€ clearí•œê°€?"**
- **ë‹µë³€**: **ì˜ˆ, ì¶©ë¶„íˆ clearí•©ë‹ˆë‹¤.**
- **ì¦ê±°**: Loss 0.013, RMSE 0.114
- **ì˜ë¯¸**: Contextì— velocity ì˜ˆì¸¡ì— í•„ìš”í•œ ì •ë³´ ì¶©ë¶„íˆ í¬í•¨

**Q: "RoboVLMsê³¼ ì–´ë–»ê²Œ ë‹¤ë¥¸ê°€?"**
- **ë‹µë³€**: **Context ë¶„í¬ëŠ” ìœ ì‚¬í•˜ì§€ë§Œ, pretrain ì°¨ì´ë¡œ ì•½ê°„ ë‹¤ë¦„**
- **ì˜ˆìƒ**: Mobile taskì—ì„  ì°¨ì´ ë¯¸ë¯¸
- **ì´ìœ **: Robot pretrainì€ Manipulationì— íŠ¹í™”

---

## ğŸ“ í›„ì† ì—°êµ¬

1. **RoboVLMs í•™ìŠµ ì™„ë£Œ í›„ ë¹„êµ**
   - Case 1 vs Case 2 ì„±ëŠ¥ ì •ëŸ‰ ë¹„êµ

2. **Context Visualization**
   - t-SNEë¡œ context space ì‹œê°í™”
   - Kosmos-2 vs RoboVLMs ì°¨ì´ í™•ì¸

3. **Fine-tuning íš¨ê³¼**
   - VLMì„ ì¼ë¶€ fine-tuneí•˜ë©´?
   - Context í’ˆì§ˆ í–¥ìƒë˜ëŠ”ì§€?

---

*ContextëŠ” clearí•˜ë©°, Frozen VLM ì „ëµì´ íš¨ê³¼ì ì„ì„ í™•ì¸*
