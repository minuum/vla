# Frozen vs LoRA: ë…¼ë¬¸ ì‚¬ë¡€ ì¡°ì‚¬

**ì‘ì„±ì¼**: 2025-12-06  
**ëª©ì **: êµìˆ˜ë‹˜ ë¯¸íŒ… ì¤€ë¹„ - VLM Frozen vs Fine-tuning ë¹„êµ

---

## ğŸ“š ì£¼ìš” ë…¼ë¬¸ ìš”ì•½

### 1. RT-2 (Robotics Transformer 2) - Google DeepMind

**ì ‘ê·¼ ë°©ì‹**: **Co-Fine-tuning (Frozen ê¸°ë°˜)**

**í•µì‹¬ íŠ¹ì§•**:
- Pre-trained VLM (PaLM-E, PaLI-X) ê¸°ë°˜
- VLMì€ web-scale ë°ì´í„°ë¡œ ì‚¬ì „ í•™ìŠµ í›„ **"frozen" ìƒíƒœ ìœ ì§€**
- Robotics ë°ì´í„°ë¡œ **co-fine-tuning** (action-oriented adaptation)
- Actionì„ **text tokens**ë¡œ í‘œí˜„í•˜ì—¬ VLMì˜ ì–¸ì–´ ì´í•´ í™œìš©

**ì¥ì **:
- âœ… **Emergent capabilities**: ìƒˆë¡œìš´ ëª…ë ¹ì–´ ì´í•´
- âœ… **Zero-shot generalization**: í•™ìŠµí•˜ì§€ ì•Šì€ ê°ì²´/í™˜ê²½ì—ì„œ ì‘ë™
- âœ… **Reasoning**: ë„êµ¬ ì„ íƒ, ì“°ë ˆê¸° íŒë³„ ë“±
- âœ… Web knowledge í™œìš©

**ë°ì´í„° ìš”êµ¬ëŸ‰**:
- Pre-training: Web-scale (ìˆ˜ë°±ë§Œ~ìˆ˜ì‹­ì–µ ì´ë¯¸ì§€)
- Fine-tuning: Robotics demonstrations (ìƒëŒ€ì ìœ¼ë¡œ ì ìŒ)

**ê²°ë¡ **: **Frozen VLM + Minimal Fine-tuning**ì´ íš¨ê³¼ì 

---

### 2. OpenVLA - Stanford

**ì ‘ê·¼ ë°©ì‹**: **Full Fine-tuning + LoRA ì˜µì…˜**

**í•µì‹¬ íŠ¹ì§•**:
- 7B parameter VLA model (Llama 2 + DINOv2 + SigLIP)
- Open X-Embodiment dataset (970K demonstrations)
- **3ê°€ì§€ Fine-tuning ë°©ë²• ì œê³µ**:
  1. **LoRA**: Parameter-efficient (A100 1ê°œ, 27GB)
  2. **Full Fine-tuning**: ëª¨ë“  7.5B params (A100 8ê°œ)
  3. **OFT (Optimized Fine-Tuning)**: ìµœì‹  ê¶Œì¥ (25-50x faster)

**ì„±ëŠ¥ ë¹„êµ**:
- LoRA: íš¨ìœ¨ì , ì„±ëŠ¥ ìœ ì‚¬
- Full Fine-tuning: ìµœê³  ì„±ëŠ¥ (ë¶„í¬ ì°¨ì´ í´ ë•Œ)
- OFT: 76.5% â†’ 97.1% success rate

**ë°ì´í„° ìš”êµ¬ëŸ‰**:
- Pre-training: 970K demonstrations
- Fine-tuning: Minimal (ìˆ˜ë°±~ìˆ˜ì²œ)

**ê²°ë¡ **: **LoRAê°€ íš¨ìœ¨ì **, Fullì€ ì„±ëŠ¥ ê·¹ëŒ€í™”

---

### 3. RoboFlamingo - TU Darmstadt

**ì ‘ê·¼ ë°©ì‹**: **Frozen VLM + Lightweight Policy Head**

**í•µì‹¬ íŠ¹ì§•**:
- OpenFlamingo VLMì„ **ì™„ì „íˆ frozen**
- **Policy headë§Œ í•™ìŠµ** (imitation learning)
- VLM: Vision-language comprehension
- Policy head: Sequential history + low-level control

**ì¥ì **:
- âœ… **Data efficiency**: ë§¤ìš° ì ì€ demonstration í•„ìš”
- âœ… **Zero-shot generalization**: ìƒˆë¡œìš´ ê°ì²´/ëª…ë ¹ì–´
- âœ… **Cost-effective**: Single GPU í•™ìŠµ ê°€ëŠ¥
- âœ… **Open-loop control**: ì €ì„±ëŠ¥ í”Œë«í¼ ë°°í¬ ê°€ëŠ¥

**ì„±ëŠ¥**:
- CALVIN benchmark: State-of-the-art
- ê¸°ì¡´ ë°©ë²• ëŒ€ë¹„ í° ì„±ëŠ¥ í–¥ìƒ

**ë°ì´í„° ìš”êµ¬ëŸ‰**:
- Pre-training: VLM ì‚¬ì „ í•™ìŠµ (frozen)
- Fine-tuning: **ë§¤ìš° ì ìŒ** (ìˆ˜ì‹­~ìˆ˜ë°±)

**ê²°ë¡ **: **Frozen VLMì´ ê°€ì¥ íš¨ìœ¨ì **, ìš°ë¦¬ ìƒí™©ê³¼ ê°€ì¥ ìœ ì‚¬

---

### 4. PaLM-E - Google Research

**ì ‘ê·¼ ë°©ì‹**: **Frozen vs Fine-tuning ëª¨ë‘ ì‹¤í—˜**

**í•µì‹¬ íŠ¹ì§•**:
- Embodied multimodal language model
- **2ê°€ì§€ variant ë¹„êµ**:
  1. **Frozen LLM + Trained Encoders**: Input encodersë§Œ í•™ìŠµ
  2. **Full Fine-tuning**: ëª¨ë“  params í•™ìŠµ

**ê²°ê³¼**:
- **Fine-tuningì´ ì¼ë°˜ì ìœ¼ë¡œ ë” ì¢‹ì€ ì„±ëŠ¥**
- Frozen: íš¨ìœ¨ì , general representation ìœ ì§€
- Fine-tuning: Task-specific adaptation ìš°ìˆ˜

**íŠ¹ì´ì‚¬í•­**:
- OK-VQA benchmark: Fine-tuning ì—†ì´ë„ SOTA
- General language proficiency ìœ ì§€

**ë°ì´í„° ìš”êµ¬ëŸ‰**:
- Pre-training: Large-scale language + vision + embodied data
- Fine-tuning: Task-specific (ë‹¤ì–‘)

**ê²°ë¡ **: **Fine-tuningì´ ì„±ëŠ¥ ìš°ìˆ˜**, Frozenì€ íš¨ìœ¨ì„± ìš°ìˆ˜

---

## ğŸ“Š ë¹„êµ ìš”ì•½í‘œ

| ëª¨ë¸ | ì ‘ê·¼ ë°©ì‹ | VLM ìƒíƒœ | ë°ì´í„° íš¨ìœ¨ì„± | ì„±ëŠ¥ | ê³„ì‚° ë¹„ìš© |
|:---|:---|:---|:---:|:---:|:---:|
| **RT-2** | Co-Fine-tuning | Frozen â†’ Fine-tuned | â­â­â­ | â­â­â­â­ | â­â­â­ |
| **OpenVLA (LoRA)** | LoRA | Partially Frozen | â­â­â­â­ | â­â­â­â­ | â­â­â­â­ |
| **OpenVLA (Full)** | Full Fine-tuning | Trainable | â­â­ | â­â­â­â­â­ | â­â­ |
| **RoboFlamingo** | Frozen + Policy | **Fully Frozen** | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­â­ |
| **PaLM-E (Frozen)** | Frozen + Encoders | Frozen LLM | â­â­â­â­ | â­â­â­ | â­â­â­â­ |
| **PaLM-E (Full)** | Full Fine-tuning | Trainable | â­â­ | â­â­â­â­â­ | â­â­ |

---

## ğŸ¯ ìš°ë¦¬ í”„ë¡œì íŠ¸ì— ì ìš©

### ìš°ë¦¬ ìƒí™©:
- **ë°ì´í„°**: 500 episodes (ë§¤ìš° ì œí•œì )
- **íƒœìŠ¤í¬**: Mobile navigation (7DOF â†’ 2DOF)
- **ëª©í‘œ**: ë¹ ë¥¸ í”„ë¡œí† íƒ€ì…, íš¨ìœ¨ì  í•™ìŠµ

### ì¶”ì²œ ì ‘ê·¼ ë°©ì‹: **Frozen VLM + Action Head (RoboFlamingo ë°©ì‹)**

**ì´ìœ **:
1. âœ… **ë°ì´í„° íš¨ìœ¨ì„±**: 500 episodesë¡œ ì¶©ë¶„
2. âœ… **ê³„ì‚° íš¨ìœ¨ì„±**: Single GPU í•™ìŠµ ê°€ëŠ¥
3. âœ… **ì¼ë°˜í™”**: VLMì˜ ì‚¬ì „ ì§€ì‹ í™œìš©
4. âœ… **ë¹ ë¥¸ ì‹¤í—˜**: Policy headë§Œ í•™ìŠµ

### ëŒ€ì•ˆ: **LoRA (OpenVLA ë°©ì‹)**

**ì–¸ì œ ì‚¬ìš©**:
- Frozenë§Œìœ¼ë¡œ ì„±ëŠ¥ ë¶€ì¡±í•  ë•Œ
- ë°ì´í„° 1,000+ episodes í™•ë³´ ì‹œ
- VLM adaptation í•„ìš”í•  ë•Œ

---

## ğŸ“ êµìˆ˜ë‹˜ ë¯¸íŒ… í¬ì¸íŠ¸

### 1. **Frozenì´ ìš°ë¦¬ì—ê²Œ ì í•©í•œ ì´ìœ **
- ë°ì´í„° ì œí•œì  (500 episodes)
- Mobile taskëŠ” manipulationë³´ë‹¤ ë‹¨ìˆœ
- VLMì˜ spatial reasoning í™œìš© ê°€ëŠ¥

### 2. **Context Vector ë¹„êµì˜ ì˜ë¯¸**
- Frozen: VLMì˜ ì›ë³¸ representation ìœ ì§€
- LoRA: Task-specific adaptation
- ìœ ì‚¬ë„ ë†’ìœ¼ë©´ â†’ Frozenìœ¼ë¡œ ì¶©ë¶„
- ìœ ì‚¬ë„ ë‚®ìœ¼ë©´ â†’ LoRA í•„ìš”

### 3. **ì˜ˆìƒ ê²°ê³¼**
- Context similarity: **ë†’ì„ ê²ƒ** (0.8+)
  - ì´ìœ : Mobile taskê°€ VLM ì‚¬ì „ ì§€ì‹ê³¼ align
- Performance: **ë¹„ìŠ·í•  ê²ƒ**
  - ì´ìœ : Action headê°€ í•µì‹¬ ì—­í• 

### 4. **ë‹¤ìŒ ë‹¨ê³„**
1. Frozen baseline ë¶„ì„ ì™„ë£Œ âœ…
2. LoRA í•™ìŠµ (ë°ì´í„° ì¶”ê°€ ìˆ˜ì§‘ ê³ ë ¤)
3. Context vector ë¹„êµ
4. ì„±ëŠ¥ ë¹„êµ (RMSE, Success rate)

---

## ğŸ“š ì°¸ê³  ë¬¸í—Œ

1. **RT-2**: Brohan et al., "RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control", 2023
2. **OpenVLA**: Kim et al., "OpenVLA: An Open-Source Vision-Language-Action Model", 2024
3. **RoboFlamingo**: Li et al., "Vision-Language Foundation Models as Effective Robot Imitators", 2023
4. **PaLM-E**: Driess et al., "PaLM-E: An Embodied Multimodal Language Model", 2023

---

**ê²°ë¡ **: **Frozen VLM + Action Head ì ‘ê·¼ì´ ìš°ë¦¬ ìƒí™©ì— ìµœì **. RoboFlamingo ì‚¬ë¡€ê°€ ê°€ì¥ ìœ ì‚¬í•˜ë©°, ë°ì´í„° íš¨ìœ¨ì„±ê³¼ ì„±ëŠ¥ì˜ ê· í˜•ì´ ìš°ìˆ˜í•¨.
