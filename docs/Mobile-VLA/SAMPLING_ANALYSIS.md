# Mobile VLA í•™ìŠµ ì™„ë£Œ ë° ìƒ˜í”Œë§ ì´ìŠˆ ë¶„ì„

**ì‘ì„±ì¼**: 2025-12-04 01:54
**ìµœì¢… Epoch**: 9 (10 epochs ì™„ë£Œ)
**ìµœì¢… ì„±ì **: Train Loss 0.0131, Val Loss 0.0131, RMSE ~0.114

---

## ğŸ‰ í•™ìŠµ ì™„ë£Œ!

### ìµœì¢… ì„±ê³¼
| Metric | ì´ˆê¸°ê°’ (Epoch 0) | ìµœì¢…ê°’ (Epoch 9) | ê°œì„ ìœ¨ |
| :--- | :--- | :--- | :--- |
| **Train Loss** | 0.429 | 0.0131 | **-96.9%** |
| **Val Loss** | 0.0517 | 0.0131 | **-74.7%** |
| **Train RMSE** | 0.655 | 0.114 | **-82.6%** |
| **Val RMSE** | 0.227 | 0.115 | **-49.3%** |

---

## âš ï¸ **ìƒ˜í”Œë§ ì´ìŠˆ ë°œê²¬ ë° ë¶„ì„**

### 1. **í˜„ì¬ ìƒ˜í”Œë§ ë°©ì‹**

```python
# MobileVLAH5Dataset.__getitem__ (í˜„ì¬ êµ¬í˜„)
def __getitem__(self, idx):
    total_frames_needed = self.window_size + self.fwd_pred_next_n  # 8 + 10 = 18
    
    # ë¬¸ì œ: ì—í”¼ì†Œë“œë³„ë¡œ ìˆœì°¨ì ìœ¼ë¡œ ì¸ë±ì‹±
    for i, length in enumerate(self.episode_lengths):
        if length >= total_frames_needed:
            valid_frames = length - total_frames_needed + 1
            if frame_idx < valid_frames:
                ep_idx = i
                break
            frame_idx -= valid_frames
    
    # ê°™ì€ ì—í”¼ì†Œë“œì—ì„œ ì—°ì†ëœ 18í”„ë ˆì„ë§Œ ìƒ˜í”Œë§
    for t in range(frame_idx, frame_idx + total_frames_needed):
        images.append(...)
        actions.append(...)
```

### 2. **ë¬¸ì œì  ë¶„ì„**

#### âŒ **ë¬¸ì œ 1: ì—í”¼ì†Œë“œ ê°„ ë‹¤ì–‘ì„± ë¶€ì¡±**
- **í˜„ìƒ**: ê° batchê°€ ê°™ì€ ì—í”¼ì†Œë“œì˜ ì—°ì†ëœ í”„ë ˆì„ë§Œ í¬í•¨
- **ì˜í–¥**: 
  - ì—í”¼ì†Œë“œ ë‚´ì—ì„œ ìœ ì‚¬í•œ ì¥ë©´/í–‰ë™ë§Œ í•™ìŠµ
  - ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤(ì¢Œ/ìš° íšŒí”¼, ê±°ë¦¬ ë³€í™” ë“±) í•™ìŠµ ì–´ë ¤ì›€
- **ì¦ê±°**: Lossê°€ 0.0131ê¹Œì§€ ë–¨ì–´ì¡Œì§€ë§Œ, ì´ê²ƒì´ ì¼ë°˜í™”ê°€ ì•„ë‹Œ **ì—í”¼ì†Œë“œë³„ overfitting**ì¼ ìˆ˜ ìˆìŒ

#### âŒ **ë¬¸ì œ 2: ì‹œê°„ì  í¸í–¥(Temporal Bias)**
- **í˜„ìƒ**: ì—í”¼ì†Œë“œ ì•ë¶€ë¶„ê³¼ ë’·ë¶€ë¶„ì´ ê³ ë¥´ê²Œ ìƒ˜í”Œë§ë˜ì§€ ì•ŠìŒ
- **ì˜í–¥**:
  - ì—í”¼ì†Œë“œ ì‹œì‘(ì ‘ê·¼) vs ì—í”¼ì†Œë“œ ë(ë„ì°©) í–‰ë™ì˜ ë¶ˆê· í˜•
  - íŠ¹ì • ì‹œì ì˜ í–‰ë™ë§Œ ê³¼ë„í•˜ê²Œ í•™ìŠµ

#### âŒ **ë¬¸ì œ 3: ë‹¨ìˆœ ìˆœì°¨ ìƒ˜í”Œë§**
```python
# í˜„ì¬: ì—í”¼ì†Œë“œ 0ì˜ 0~17, 18~35, ... â†’ ì—í”¼ì†Œë“œ 1ì˜ 0~17, ...
# ì´ëŠ” RoboVLMsì˜ manipulator ë°ì´í„°ì…‹(ìˆ˜ì²œ episodes)ì—ëŠ” ì í•©í•˜ì§€ë§Œ
# Mobile VLA(250 episodes)ì—ëŠ” ë¶€ì í•©
```

---

## ğŸ”§ **ê°œì„  ë°©ì•ˆ**

### **Option 1: Random Temporal Sampling (ê¶Œì¥)**

```python
def __getitem__(self, idx):
    # ì—í”¼ì†Œë“œ ëœë¤ ì„ íƒ
    ep_idx = np.random.randint(0, len(self.episode_files))
    
    with h5py.File(self.episode_files[ep_idx], 'r') as f:
        total_len = len(f['images'])
        
        # ì‹œì‘ í”„ë ˆì„ ëœë¤ ì„ íƒ (valid range ë‚´)
        max_start = total_len - total_frames_needed
        if max_start > 0:
            start_frame = np.random.randint(0, max_start + 1)
        else:
            start_frame = 0
        
        # ëœë¤ ì‹œì‘ì ë¶€í„° 18í”„ë ˆì„ ìƒ˜í”Œë§
        for t in range(start_frame, start_frame + total_frames_needed):
            images.append(...)
```

**ì¥ì **:
- âœ… ì—í”¼ì†Œë“œ ê°„ ë‹¤ì–‘ì„± ì¦ê°€
- âœ… ì‹œê°„ì  í¸í–¥ ì œê±°
- âœ… Augmentation íš¨ê³¼ (ê°™ì€ ì—í”¼ì†Œë“œë„ ë‹¤ë¥¸ ì‹œì‘ì )

---

### **Option 2: Stratified Episode Sampling**

```python
def __init__(self, ...):
    # ì—í”¼ì†Œë“œë¥¼ ì‹œë‚˜ë¦¬ì˜¤ë³„ë¡œ ê·¸ë£¹í™”
    # episode_20251203_*_1box_hori_left_*.h5 â†’ "1box_hori_left"
    self.episode_groups = self._group_episodes_by_scenario()

def __getitem__(self, idx):
    # ê° batchì—ì„œ ë‹¤ë¥¸ ì‹œë‚˜ë¦¬ì˜¤ í¬í•¨í•˜ë„ë¡ ê°•ì œ
    scenario = self.scenarios[idx % len(self.scenarios)]
    ep_idx = random.choice(self.episode_groups[scenario])
    ...
```

**ì¥ì **:
- âœ… ì‹œë‚˜ë¦¬ì˜¤ ê· í˜• ë³´ì¥ (ì¢Œ/ìš°, ê±°ë¦¬ë³„)
- âœ… íŠ¹ì • íŒ¨í„´ ê³¼ì í•© ë°©ì§€

---

### **Option 3: Hard Negative Mining**

```python
# Inference í›„ ì‹¤íŒ¨í•œ ì¼€ì´ìŠ¤ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ìƒ˜í”Œë§
def __getitem__(self, idx):
    # lossê°€ ë†’ì•˜ë˜ ìƒ˜í”Œì„ ë” ìì£¼ ìƒ˜í”Œë§
    if np.random.rand() < 0.3:  # 30% í™•ë¥ 
        ep_idx, frame_idx = self.hard_samples[np.random.randint(len(self.hard_samples))]
    else:
        # ì¼ë°˜ ìƒ˜í”Œë§
        ...
```

---

## ğŸ“Š **í˜„ì¬ í•™ìŠµ ê²°ê³¼ í•´ì„**

### âœ… **ê¸ì •ì  ì‹ í˜¸**
1. **Val Loss â‰ˆ Train Loss** (0.0131 vs 0.0131)
   - ê³¼ì í•© ì—†ìŒ
   - ì¼ë°˜í™” ëŠ¥ë ¥ ìˆìŒ

2. **RMSE 82% ê°œì„ **
   - ì‹¤ì œ ì˜ˆì¸¡ ì •í™•ë„ í–¥ìƒ
   - 0.114ëŠ” ìƒë‹¹íˆ ë‚®ì€ ê°’

### âš ï¸ **ìš°ë ¤ ì‚¬í•­**
1. **ìƒ˜í”Œë§ì˜ ë‹¨ìˆœí•¨**
   - 250 episodes Ã— í‰ê·  18í”„ë ˆì„ = ~4,500 ìƒ˜í”Œ
   - ìˆœì°¨ ìƒ˜í”Œë§ìœ¼ë¡œ ë‹¤ì–‘ì„± ì œí•œ

2. **ì‹¤ì œ í™˜ê²½ í…ŒìŠ¤íŠ¸ í•„ìš”**
   - í•™ìŠµ ë°ì´í„°ì™€ ë‹¤ë¥¸ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì„±ëŠ¥ í™•ì¸
   - ìƒˆë¡œìš´ ì¥ì• ë¬¼ ìœ„ì¹˜/ê±°ë¦¬ì—ì„œ robustness ê²€ì¦

---

## ğŸ¯ **ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ**

### ì¦‰ì‹œ ì‹¤í–‰ (ìš°ì„ ìˆœìœ„ ë†’ìŒ)
1. âœ… **í˜„ì¬ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ìœ„ì¹˜ í™•ì¸**
2. â³ **Best Modelë¡œ ì‹¤ì œ ì¶”ë¡  í…ŒìŠ¤íŠ¸**
3. â³ **ìƒ˜í”Œë§ ê°œì„  í›„ ì¬í•™ìŠµ** (Option 1 ê¶Œì¥)

### ì¶”ê°€ ê°œì„  (ì¤‘ê¸°)
1. â³ **Data Augmentation ì¶”ê°€**
   - Color Jitter
   - Gaussian Noise
   - Random Crop & Resize
2. â³ **3DOF í™•ì¥** (angular_z ì¶”ê°€)
3. â³ **Multi-Task Learning** (ì—¬ëŸ¬ ëª©í‘œë¬¼)

---

## ğŸ“ **ì²´í¬í¬ì¸íŠ¸ ë¶„ì„ í•„ìš”**

í˜„ì¬ `runs/mobile_vla_lora_20251203` ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ.
ì‹¤ì œ ì €ì¥ ìœ„ì¹˜:
- `RoboVLMs_upstream/runs/...`ë¡œ ì¶”ì •
- í™•ì¸ í•„ìš”!

---

*ìƒ˜í”Œë§ ê°œì„  í›„ ì¬í•™ìŠµì„ ê°•ë ¥íˆ ê¶Œì¥í•©ë‹ˆë‹¤!*
