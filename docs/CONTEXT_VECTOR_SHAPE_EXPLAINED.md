# Shape [10, 8, 64, 2048] ì •í™•í•œ ì„¤ëª…

## ğŸ“ ì „ì²´ êµ¬ì¡°

```python
shape: [10, 8, 64, 2048]
       â”‚   â”‚  â”‚   â””â”€â”€â”€ Feature Dimension (íŠ¹ì§• ì°¨ì›)
       â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€ Token Dimension (í† í° ê°œìˆ˜)
       â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Frame/Temporal Dimension (í”„ë ˆì„ ê°œìˆ˜)
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Batch Dimension (ë°°ì¹˜/ì—í”¼ì†Œë“œ ê°œìˆ˜)
```

---

## ğŸ” ê° ì°¨ì› ìƒì„¸ ì„¤ëª…

### **Dimension 0: `10` = Batch Size (ì—í”¼ì†Œë“œ ê°œìˆ˜)**
- **ì˜ë¯¸**: í•œ ë²ˆì— ì²˜ë¦¬í•œ episode ê°œìˆ˜
- **ì½”ë“œ ê·¼ê±°**:
  ```python
  # extract_and_compare_contexts.py Line 211
  images = load_sample_images(num_episodes=10)
  ```
- **ì‹¤ì œ**: 10ê°œ ì—í”¼ì†Œë“œ (left 5ê°œ + right 5ê°œ)

---

### **Dimension 1: `8` = Window Size (ì‹œê°„ í”„ë ˆì„)**
- **ì˜ë¯¸**: ê° ì—í”¼ì†Œë“œì—ì„œ ì‚¬ìš©í•˜ëŠ” ì—°ì†ëœ ì´ë¯¸ì§€ í”„ë ˆì„ ìˆ˜
- **ì´ìœ **: Temporal contextë¥¼ íŒŒì•…í•˜ê¸° ìœ„í•¨
- **ì½”ë“œ ê·¼ê±°**:
  ```python
  # extract_and_compare_contexts.py Lines 52-56
  for i in range(min(8, len(f['images']))):
      img = Image.fromarray(f['images'][i].astype(np.uint8))
      frames.append(transform(img))
  ```
- **ì„¤ì • íŒŒì¼**:
  ```json
  // mobile_vla_lora_20251203.json
  "window_size": 8
  ```

**ì™œ 8í”„ë ˆì„ì¸ê°€?**
- ë¡œë´‡ì´ "ì›€ì§ì„ì˜ ë§¥ë½"ì„ ì´í•´í•˜ê¸° ìœ„í•¨
- ì •ì§€ ì´ë¯¸ì§€ vs ì›€ì§ì´ëŠ” ë¬¼ì²´ êµ¬ë¶„ ê°€ëŠ¥
- ì†ë„ì™€ ë°©í–¥ ì¶”ì • ê°€ëŠ¥

---

### **Dimension 2: `64` = Number of Tokens (í† í° ê°œìˆ˜)**
- **ì˜ë¯¸**: Kosmos-2 VLMì´ í•œ ì´ë¯¸ì§€ë¥¼ 64ê°œì˜ "ì˜ë¯¸ ì¡°ê°"ìœ¼ë¡œ ë‚˜ëˆ”
- **Vision Transformer êµ¬ì¡°**:
  ```
  Image (224Ã—224) 
    â†’ Patch Embedding (14Ã—14 patches)
    â†’ Position Encoding
    â†’ Transformer Processing
    â†’ 64 tokens (ì••ì¶•ëœ í‘œí˜„)
  ```

**ì™œ 64ê°œì¸ê°€?**
- Vision Transformerì˜ êµ¬ì¡°ì  ì„ íƒ
- 224Ã—224 ì´ë¯¸ì§€ë¥¼ 14Ã—14 = 196ê°œ íŒ¨ì¹˜ë¡œ ë‚˜ëˆ”
- Transformerë¡œ ì••ì¶•í•˜ì—¬ 64ê°œ í† í°ìœ¼ë¡œ í‘œí˜„
- ê° í† í° = ì´ë¯¸ì§€ì˜ íŠ¹ì • "ì˜ì—­/ì˜ë¯¸"

**ì˜ˆì‹œ**:
```
Token 0-10:  ë°•ìŠ¤ ì˜ì—­
Token 11-20: ë°°ê²½
Token 21-30: ë³‘ ì˜ì—­
Token 31-40: ë°”ë‹¥
...
```

---

### **Dimension 3: `2048` = Feature Dimension (íŠ¹ì§• ì°¨ì›)**
- **ì˜ë¯¸**: ê° í† í°ì„ í‘œí˜„í•˜ëŠ” feature vectorì˜ í¬ê¸°
- **Kosmos-2 êµ¬ì¡°**:
  ```
  Vision Features:  1024D
  Language Features: 1024D
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Total Context:    2048D (Concatenation)
  ```

**ì™œ 2048ì°¨ì›ì¸ê°€?**
- Kosmos-2ê°€ Vision + Languageë¥¼ ê²°í•©í•˜ì—¬ í‘œí˜„
- 1024 (vision) + 1024 (language) = 2048
- ì¶©ë¶„íˆ í’ë¶€í•œ ì •ë³´ í‘œí˜„ ê°€ëŠ¥

---

## ğŸ“Š ì‹¤ì œ ë°ì´í„° íë¦„

```python
# 1. ì…ë ¥ ì´ë¯¸ì§€
Input: (10, 8, 3, 224, 224)
       â”‚   â”‚  â”‚  â”‚    â””â”€â”€ Height
       â”‚   â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€ Width  
       â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Channels (RGB)
       â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Frames
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Episodes

# 2. VLM Forward Pass
VLM.encode_images(Input)

# 3. Context Vector ì¶œë ¥
Output: (10, 8, 64, 2048)
        â”‚   â”‚  â”‚   â””â”€â”€ Features per token
        â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€ Tokens per frame
        â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€ Frames per episode
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Episodes
```

---

## ğŸ¯ ì‹¤ì œ ì˜ˆì‹œ (ì—í”¼ì†Œë“œ 1ê°œ)

```python
episode_1_context = context[0]  # Shape: (8, 64, 2048)

# Frame 0 (t=0ì´ˆ)
frame_0 = episode_1_context[0]  # Shape: (64, 2048)

# Token 5 (ì˜ˆ: ë°•ìŠ¤ ì˜ì—­)
token_5_features = frame_0[5]   # Shape: (2048,)
# â†’ ì´ 2048ê°œ ìˆ«ìê°€ "ë°•ìŠ¤ì˜ ìœ„ì¹˜, í¬ê¸°, ìƒ‰ìƒ, ê±°ë¦¬ ë“±"ì„ í‘œí˜„
```

---

## ğŸ”„ Action Headë¡œ ì „ë‹¬

```python
# Context: (10, 8, 64, 2048)
# â†“
# LSTM Decoderì— ì…ë ¥
# â†“
# Velocity ì˜ˆì¸¡: (10, 2)
#   - linear_x: ì „ì§„ ì†ë„
#   - angular_z: íšŒì „ ì†ë„
```

**í•µì‹¬**: 
- 2048ì°¨ì› featureê°€ ì¶©ë¶„íˆ "clear"í•´ì•¼ ì†ë„ ì˜ˆì¸¡ ê°€ëŠ¥
- Case 1: Val Loss 0.013 ë‹¬ì„± â†’ Contextê°€ ì¶©ë¶„íˆ informative!

---

## ğŸ“ ìš”ì•½

| Dimension | ê°’ | ì˜ë¯¸ | ì´ìœ  |
|:---|---:|:---|:---|
| **0** | `10` | Episodes | í•œ ë²ˆì— 10ê°œ ì—í”¼ì†Œë“œ ì²˜ë¦¬ |
| **1** | `8` | Frames | Window size (temporal context) |
| **2** | `64` | Tokens | ì´ë¯¸ì§€ë¥¼ 64ê°œ ì˜ë¯¸ ì¡°ê°ìœ¼ë¡œ ë¶„í•´ |
| **3** | `2048` | Features | Vision(1024) + Language(1024) |

**ì „ì²´ í¬ê¸°**:
- 10 Ã— 8 Ã— 64 Ã— 2048 = **10,485,760** ê°œ ìˆ«ì
- Float32: 10,485,760 Ã— 4 bytes = **40 MB**

---

## âœ… ê²°ë¡ 

**Shape [10, 8, 64, 2048]**ì€:
1. **10ê°œ ì—í”¼ì†Œë“œ**ë¥¼ 
2. ê°ê° **8í”„ë ˆì„ì”©** ë³´ê³ 
3. ê° í”„ë ˆì„ì„ **64ê°œ í† í°**ìœ¼ë¡œ ë‚˜ëˆ„ê³ 
4. ê° í† í°ì„ **2048ì°¨ì› ë²¡í„°**ë¡œ í‘œí˜„í•œ ê²ƒ!

ì´ê²ƒì´ **Kosmos-2 VLMì´ ì´ë¯¸ì§€ë¥¼ "ì´í•´"í•œ ê²°ê³¼**ì´ë©°,  
ì´ contextê°€ ì¶©ë¶„íˆ "clear"í•˜ê¸° ë•Œë¬¸ì— LSTMì´ **ì •í™•í•œ ì†ë„ë¥¼ ì˜ˆì¸¡**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

**ì°¸ì¡°**: 
- ì½”ë“œ: `extract_and_compare_contexts.py`
- ëª¨ë¸: Kosmos-2 Vision-Language Model
- ë…¼ë¬¸: [Kosmos-2 Paper](https://arxiv.org/abs/2306.14824)
